<testset name="IWSLT2025" type="output">
  <task track="long" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind große webbasierte Datensätze, darunter politische Nachrichtenmedien.</sample>
    <sample id="1">Die Autoren sind an der University of Magelhaen und Microsoft Research verbunden.</sample>
    <sample id="2">Das Paper beschäftigt sich mit dem Problem der visuellen Dokumentenverstehbarkeit und gibt einen Überblick über die Arbeitspraxis von Ad Group, bei der das Team aus Algorithmikern Lösungen entwickelt. Das Paper konzentriert sich auf die Verwendung visueller Methoden zur Verbesserung der Verständlichkeit von Dokumenten.</sample>
    <sample id="3">Hallo und willkommen zu unserer Präsentation von DeepL, einem neuen Modul für die German Textentwicklung auf Dokumentebene und Satzebene. Mein Name ist Regina Stodden und ich werde Ihnen den ersten Teil der Präsentation vorstellen. Lassen Sie uns zunächst definieren, was Textsimplifizierung ist. Textsimplifizierung ist ein Prozess, bei dem ein Text angepasst wird, um seine Verständlichkeit für einen bestimmten Zielgruppe zu verbessern. Wie Menschen lesen.</sample>
    <sample id="4">Der Referent*in heißt Kayo Yan.</sample>
    <sample id="5">Das Multi-Head Attentive Model (MHA) wurde verwendet.</sample>
    <sample id="6">In der vorliegenden Präsentation wird ein gemeinsames Projekt präsentiert, das die Multilingualisierung und Cross-Lingualisierung vereinigt. Die Autoren haben dazu beigetragen, diese beiden Konzepte in eine allgemeine Form zu überführen und sie unter dem Namen Many-to-Many-Summarization zusammengefasst.</sample>
    <sample id="7">Die Präsentation besagt, dass der CoNLL-2003-Tagger immer noch gut funktioniert.</sample>
    <sample id="8">Die vorgeschlagene menschliche Bewertungsmethode ist eine neue Dimensionale Herangehensweise zur Evaluierung von konversationaler AI.</sample>
    <sample id="9">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von der Qualität der Daten, der gewählten Methode zur Analyse und dementsprechend der interpretierten Ergebnisse ab.</sample>
    <sample id="10">Die Qualität der Übersetzung kann durch eine präzise Wortwahl, eine sorgfältige Grammatik und eine genaue Recherche über die Bedeutung der Wörter verbessert werden.</sample>
    <sample id="11">Jack Hessel, ein Forscher am AI2, präsentiert humorvolle Erkennungs Benchmarks für New Yorker-Caption-Wettbewerbe.联合工作与来自犹他大学、康奈尔大学、华盛顿大学、美国邮政服务和OpenAI的众多出色合作者。大型语言模型现在可以生成并解释笑话，例如在ChatGPT上询问它讲一个笑话时。</sample>
    <sample id="12">Zwei.</sample>
    <sample id="13">In der Präsentation wird über die Arbeit 'Finding the Sweet Spot: Analysis and Improvement of Adaptive Inference in Low Resource Settings' gesprochen, die im Labor von Professor Roy Schwartz am Hebrew University in Jerusalem durchgeführt wurde. Adaptive Inference ist ein Verfahren zur Verringerung der Vorhersagezeit für große Sprachmodelle. Es basiert auf der Tatsache, dass real world-Daten in Komplexität variiert. Daher können low-capacity-Modelle verwendet werden.</sample>
    <sample id="14">Hallo, mein Name ist Adam Skurawski und dieser Vortrag geht über die Abhängigkeitsstruktur der Koordination. Wie Sie vielleicht wissen, werden verschiedene Abhängigkeitsstrukturen durch verschiedene Theorien und Ansätze festgelegt. Zum Beispiel in der universellen Abhängigkeit sind die Strukturen der Koordinatkoordination Lisa Bart und Maggie so, dass der erste Konjunkt der gesamten Koordinatensysteme ist. Im Falle von Lisa ist es also so. Ein ähnlicher Ansatz wird in Godwin's gezeigt, was bedeutet text.</sample>
    <sample id="15">Die Arbeitsgruppe besteht aus drei Personen: dem Sprecher, Alexander Coler und Ivan Titev.</sample>
    <sample id="16">Die deutschen Textquellenniveau- und Satzebene-Domains werden stärker vereinfacht.</sample>
    <sample id="17">The speech discusses multi-model relation extraction, a widely researched task aimed at determining the semantic relationship between entities in text. However, in real-world scenarios like social media, data is often presented in various forms and modalities, making it challenging to apply traditional methods. The speaker introduces their work addressing this issue.</sample>
    <sample id="18">In der Coordinierung von LISA-Bart und Maggie ist die erste Konjunktion die Head der ganzen Koordinatensstruktur.</sample>
    <sample id="19">Der Masterstudent Zhang Chen aus der Universität Shenzhen präsentiert sein Werk zur effektiven Beantwortung von offenen Domänenfragen mit einem Two-Stage-Modell als主打.</sample>
    <sample id="20">Ja, das Modell kann in Ihrer Forschung verwendet werden, vorausgesetzt es entspricht den Anforderungen Ihrer Untersuchung.</sample>
    <sample id="21">DEplain-web beinhaltet deutsche Texte für German text simplification auf Dokumentebene und auf Satzebene.</sample>
    <sample id="22">Die gute Generalisierung wird durch eine ausreichende Menge an trainierten Daten, das Verständnis der zugrunde liegenden Struktur des Datensatzes und die Verwendung geeigneter Algorithmen erreicht.</sample>
    <sample id="23">In diesem Interview spricht Dan Garvey über seine Arbeit an der Verbesserung der Fähigkeit von Text-Image-Modellen, visuelle Text darzustellen. Er betont, dass die Forschung in diesem Bereich in den letzten Jahren enorme Fortschritte gemacht hat und es ist möglich, sehr hochwertige und interessante Bilder zu generieren. Allerdings haben viele Menschen bemerkt, dass diese Modelle oft sehr schlecht beim Darstellen von Text sind. In diesem Interview konzentriert sich Garvey auf das Modell Imagine, das versucht, Eingabetext mit einem T-X-S symbol zu codieren.</sample>
    <sample id="24">Die Tendenz zu kürzeren linken Konjunktionen wurde durch eine Analyse der Verwendung von Konjunktionen in Texten ermittelt, insbesondere im Vergleich zwischen englischsprachigen und chinesischsprachigen Texten.</sample>
    <sample id="25">Die Experimente wurden so gestaltet, dass verschiedene Teilchen in einem Gasströmungsdurchgang verwendet wurden, dessen Richtung durch einen Begrenzer kontrolliert wurde.</sample>
    <sample id="26">Ein Basisklassifikator performs poorly with unbalanced data.</sample>
    <sample id="27">Ein Autor.</sample>
    <sample id="28">Jabot Hossaini, Philip Radoszky, Silvia Parity und Anna Lewis.</sample>
    <sample id="29">Kontextsensitive MÜ-Modelle schneiden besser ab bei der Verarbeitung von Übersetzungsproblemen, bei denen der Kontext eine wichtige Rolle spielt, wie zum Beispiel bei der Verwendung von Fremdwörtern oder in komplexen Sätzen.</sample>
    <sample id="30">Das Paper 'Bender' ist ein einfaches und effektives Ensemble-Lernwerkzeug für große Sprachmodelle, das auf der Parzen-Ranking-Technik basiert. Das Team, bestehend aus AI2 und USC, hat es entwickelt und besteht aus Yanming Chen. Es gibt viele große Sprachmodelle, die每周 veröffentlicht werden, und viele behaupten, großartige Leistungen erzielt zu haben. Die Bender-Plattform soll es ermöglichen, diese Modelle miteinander zu vergleichen und die besten zu identifizieren.</sample>
    <sample id="31">Die Autoren sind alle Studenten an der University of Cambridge.</sample>
    <sample id="33">Das vorgestellte Framework quantifiziert die Positionalität durch die Anzahl der Verbindungen zwischen Atomen in einem Molekül.</sample>
    <sample id="34">Das von Marcus Treviso präsentierte Werk 'Crest' ist ein gemeinsames Framework zur Rationalisierung und Generierung von konträren Texten. Das Projekt entstand durch eine erfolgreiche Zusammenarbeit mit Alexis Ross, Fernando Guerrero und Daniel Martinez. Es dient dazu, Entscheidungen aus einem Input zu interpretieren, für den der Klassifizierer eine bestimmte Entscheidung vorausgesagt hat. Es gibt verschiedene Methoden zur Interpretation dieser Entscheidung, wobei eine Gruppe davon die selektive Rationalisierung nutzt, bei der durch das Hervorheben von relevanten Informationen im Input die Entscheidung erläutert wird.</sample>
    <sample id="36">In diesem Video wird Thilo Peich von ACL begrüßt und es gibt einen Einblick in die Arbeit an spezifischen Schichten für mehrsprachige Maschinenübersetzung.联合工作与罗宾·施密特、伊什利娅和斯蒂芬·比奇斯。多语言机器翻译有几个优点，例如可扩展性，因为可以训练和维护一个单独的模型，而不是每种语言方向一个模型；速度，可以直接在任何两种语言之间进行翻译，而不需要先将一种语言转换成另一种语言。</sample>
    <sample id="37">Es wurde festgestellt, dass die Teilnehmer Personen mit ähnlichen Eigenschaften auswählten.</sample>
    <sample id="38">Die genauen Datenquellen wurden nicht in der angegebenen Zusammenfassung erwähnt.</sample>
    <sample id="39">Zwei, Adam Skurkowski und Maggi.</sample>
    <sample id="40">Cognitive dissonance refers to the mental discomfort that arises from holding two conflicting beliefs or values, and it is often studied in relation to how people change their attitudes or behaviors.</sample>
    <sample id="41">The speech is about a research project called 'Peacock', which is a personal common sense knowledge system designed for generating consistent and engaging narratives. The project was done in collaboration with Sony Group Corporation. The main goal of the project is to develop natural language processing systems that can understand the context and relationships among speakers, listeners, or characters in order to create coherent and engaging dialogues or stories.</sample>
    <sample id="42">Ein Autor.</sample>
    <sample id="43">Eine.</sample>
    <sample id="44">Das vorgestellte Framework ist durch eine ' annual positionality' gekennzeichnet, was bedeutet, dass es sich um eine jährliche Betrachtungsweise handelt, die sich von vorherigen Arbeiten unterscheidet.</sample>
    <sample id="45">Das Setup mit den meisten Überschneidungen ist das, in dem Natural Language Prompts verwendet werden.</sample>
    <sample id="46">Die kommerziellen Systeme wurden nicht spezifiziert, nur dass eine Vergleichstabelle erstellt wurde.</sample>
    <sample id="47">Hallo, ich bin Changbing, ein Promovierter Student an der University of Washington. Heute präsentiere ich unsere Arbeit von Vorbereitungsdaten bis hin zu Sprachmodellen und nachgelagerten Aufgaben. Die Verfolgung der Spuren politischer Vorurteile, die zu unfairen NLB-Modellen führen, ist unser Schwerpunkt. Sprachmodelle werden auf großen Online-Datenbanken trainiert, darunter auch politische Nachrichtenmedien. Laut einer Umfrage des C4-Publikums sind New York Times, Los Angeles Times, The Guardian, Huffington Post usw. gut abgedeckt in ihren Vorbereitungsdaten.</sample>
    <sample id="48">Die Zusammenarbeit mit meinen Kollegen von Google Translate.</sample>
    <sample id="49">Die genaue Anzahl der Token-Kontextlängen wurde nicht angegeben, es wird nur erwähnt, dass die Auswertungen für bis zu 50 Token durchgeführt wurden.</sample>
    <sample id="50">In der Präsentation wird über 'de plane', ein neues Modell für die Germanische Textkennzeichnung auf Dokument- und Satzebene, gesprochen. Der Name des Speakers ist Regina Stodden, und sie wird von einem anderen, nicht genannten Speaker begleitet. Die Präsentation beginnt mit der Definition von Textsimplifizierung als dem Prozess, bei dem Texte angepasst werden, um ihre Verständlichkeit für einen bestimmten Zielgruppe zu verbessern.</sample>
    <sample id="51">Die Domains, die in ihren Datensatz aufgenommen wurden, sind 'entity' und 'user'.</sample>
    <sample id="52">Positionalität bezieht sich auf die Art und Weise, wie Objekte oder Personen in einem Raum oder einer Gesellschaft的位置 eingenommen werden.</sample>
    <sample id="53">Der Referent*in heißt Dawei.</sample>
    <sample id="54">In this abstract, the speaker presents their research paper titled 'Transfer Learning for Dissonance Detection Addressing the Rare Class Challenge in ASL'. They define cognitive dissonance and its significance in language studies. The paper presents a solution using transfer learning for detecting dissonance in American Sign Language, addressing a rare class challenge.</sample>
    <sample id="55">Nein, EDAtt passt nicht zu einem bestehenden Offline-ST-Modell.</sample>
    <sample id="56">Ein Autor ist an der Arbeit beteiligt.</sample>
    <sample id="57">Ja, das Modell funktioniert in der Testsuite.</sample>
    <sample id="58">Die drei Varianten von KITMUS sind基线模型、增强学习模型和迁移学习模型。</sample>
    <sample id="59">In this presentation, the speaker will discuss language modeling in healthcare and present their work on 'Dr. Bert', a robust pre-trained model in French for biomedical and clinical domains. The main contribution of their article is introducing the first biomedical model in French named Dr. Bert, which is based on Roberta and trained on a dataset called Natsos, containing medical crowdsourced data.</sample>
    <sample id="60">Die Autoren besitzen keine festgelegte Universität, sondern arbeiten an der Stanford University.</sample>
    <sample id="61">Die abschließende Forschungsfrage betrifft die Wirksamkeit von wöchentlichen Überwachungen bei der Verbesserung der Leistung in der Schule.</sample>
    <sample id="62">Der Autor spricht über sein纸上的系统研究，这是关于自然语言生成的能源系统的。该研究专注于大规模语言模型，并随着模型变大变得更复杂和更慢，成本也会增加。</sample>
    <sample id="63">Die Sensitivitätmetrik misst die Anzahl der Änderungen an einer Vorhersage, die notwendig sind, um eine bestimmte Veränderung in der Vorhersagemaximierung zu erreichen.</sample>
    <sample id="64">Der Referent ist Jin Weiyi von der Universität für Wissenschaft und Technologie Chinas.</sample>
    <sample id="65">Eine höhere Sensitivität bedeutet in diesem Kontext eine bessere Leistung des Modells.</sample>
    <sample id="66">The English content describes the significance of mathematical reasoning in human intelligence, its role in understanding and making decisions based on data and language, and how the development of machines capable of solving mathematical problems has been a long-standing focus of AI and LP research.</sample>
    <sample id="67">In diesem Artikel wird über Interferenz bei multilingualen Übersetzungsmodellen gesprochen. Solche Modelle können von der Synergi zwischen verschiedenen Sprachbärern profitieren oder leiden unter Interferenz. Zum Beispiel kann das Training auf die Übersetzung von Englisch nach Finnisch die Qualität von Englisch-Hessischen verbessern, während die Übersetzung von Englisch nach Chinesisch negative Auswirkungen haben könnte. Es gibt viele vorgeschlagenen Methoden, um Interferenz zu reduzieren, aber sie werden oft mit kleinen Modellen demonstriert und nicht auf größeren Daten sets getestet.</sample>
    <sample id="68">Die Modelle werden vor der Trainingsphase mit minimaler Paarungstheorie evaluiert, um ihre Verarbeitungsfähigkeit von Sprachmustern zu überprüfen.</sample>
    <sample id="69">Es wurden mindestens 3 saubere Validierungsbeispiele für eine gute Leistung an der WSL benötigt.</sample>
    <sample id="70">Die Autoren sind an der University of Pennsylvania tätig.</sample>
    <sample id="71">Die Autoren beschreiben ihre Arbeit an der Lösung von indirekten Abfragen für Entitätselektion, bei der sie das Konzept der Identitätskanten einführen. Sie arbeiten zusammen mit Philip Radoszky, Silvia Parity und Anna Lewis und haben das Ziel, den Benutzern bei der Entscheidungsfindung zu helfen, indem sie ihr Sprachverhalten beim Auswählen berücksichtigen. In einem Beispiel wird eine alternative Fragestellung vorgestellt, um herauszufinden, ob eine Entscheidung leicht fällt oder ob der Nutzer eine bestimmte Gefühlslage hat.</sample>
    <sample id="72">Es ist notwendig, neue Methoden zur Messung von Medienverzerrungen zu entwickeln, da politische Nachrichtenmedien in ihren Vor-Trainingsdaten überwiegend eine bestimmte politische Sichtweise vermitteln, was zu unfairen NLB-Modellen führen kann.</sample>
    <sample id="73">Der Referent ist Axel.</sample>
    <sample id="74">Der Vortrag beschreibt die纸笔舞动（Dance Dance Revolution）-Technologie, eine dance-connected Automatik mit hoher覆盖率 und vielen Multifunktionsplätzen. Die Technologie basiert auf der Common Technology for Humans and Machines (CTM). Die CTM ist eine umfassende Basis für die menschenorientierte Kommunikationstechnologie, die für Maschinen bei Interaktionen mit Menschen unerlässlich ist. Sie deckt sogar zentrale soziale Aspekte der kognitiven Kompetenz ab.</sample>
    <sample id="75">The speaker, Jing Yan Dan, presents their collaborative work 'John Prop' with friends and supervisor. The project is motivated by the need for efficient information extraction, highlighting named entity recognition and relation extraction as key tasks. They mention that the Linux game has made significant progress.</sample>
    <sample id="76">Die Pipeline beginnt mit der Sammlung von Daten, einschließlich pre-trainingsdaten, Sprachmodellen und Downstream-Tasks wie dem Nachverfolgen von politischen Vorurteilen, die zu unfairen NLB-Modellen führen können. Die Daten basieren auf einer großen Menge an webbasiertem Datenmaterial, wobei politische Nachrichtenmedien gut abgedeckt sind. Ein Beispiel dafür sind die New York Times, Los Angeles Times, The Guardian und Huffington Post.</sample>
    <sample id="77">The speaker is discussing their research focused on improving summerization and factual consistency using natural language feedback, which is a collaborative effort between Yale University and Microsoft Research. The majority of the work was completed during an intern's time at Microsoft Research. Additionally, they have introduced a new dataset in this research.</sample>
    <sample id="78">Nein, der Vereinfachungsprozess ist bei DEplane-apa und Web gleich.</sample>
    <sample id="79">Nein, der Inhalt gibt keine Informationen darüber, ob Coscript öffentlich verfügbar ist.</sample>
    <sample id="80">Das Wasserzeichen 'viu bagto watermark' wird als Schriftzug eingebracht, der unter dem Namen des Unternehmens 'Jin Weiyi' von der Universität für Wissenschaft und Technologie Chinas zu sehen ist.</sample>
    <sample id="81">Die Autoren gehören zur Pinnstate University.</sample>
    <sample id="82">Das Video beschäftigt sich mit der Arbeit, die unter dem Titel 'Aggregating Multi-Modal Signatures for Supervised Unsupervised Automated Essay Scoring' durchgeführt wurde. Das Ziel besteht darin, die Schreibqualität von Aufsätzen automatisch ohne menschliche Überprüfung zu bewerten. Dies ist ein wichtiger Anwendungsfall für die Verarbeitung natürlicher Sprache in der Bildung. State-of-the-Art-Modelle werden üblicherweise trainiert.</sample>
    <sample id="83">Ja, Encoder-Decoder-Modelle wie mt5 können durch Training mit einer Mischung von Sprachen verbessert werden.</sample>
    <sample id="84">The speaker discusses their paper on developing an efficient framework for dynamic networks, emphasizing the background knowledge of such networks and how they differ from traditional static networks.</sample>
    <sample id="85">Ein Beispiel für eingeschränkte Sprachplanung wäre das Führen von Schritten nach vorgegebener Anweisung, wie z.B. beim Kochen eines Rezepts.</sample>
    <sample id="86">Die Opazität wird durch das Verwenden von Wasserstoffperoxid und einem pH-Wert von 4 erreicht.</sample>
    <sample id="87">Die Arbeit nutzt bestehende PLMs, um ein neues PLM aufzubauen, indem sie die Datenbanken und Strukturen der bestehenden PLMs integriert und diese mit dem neuen Modell verknüpft.</sample>
    <sample id="88">GPT-4 ist am wenigsten ausgerichtet auf Spanien.</sample>
    <sample id="89">The model uses the attention mechanism to learn from patterns in the data.</sample>
    <sample id="90">Autoren von 'ReThinking Annotation' betonen, dass native-Sprecher für die Datensatzannotation wichtig sind, insbesondere bei少言种语言. Obwohl es schwierig ist, native-Sprecher für viele Sprachen zu rekrutieren, gibt es viele Sprachlernende. Es gibt keine monolingualen Native-Sprecher und lediglich 73.000.</sample>
    <sample id="91">Die Anzahl der Aufgaben hat keinen Einfluss auf die Leistung des Modells.</sample>
    <sample id="92">The authors do not specify any treeless baselines in their paper.</sample>
    <sample id="93">Die beiden Co-Autoren sind Alexander Colah und Ivan Titev.</sample>
    <sample id="94">The video is a brief advertisement for paper, a large language model created by the University of Science and Technology of China. It emphasizes the importance of protecting the copyright of such models when used for embedding services. The background information explains that embedding services currently utilize large language models like GPT-3 and LaMa.</sample>
    <sample id="95">Ivan is the first author of PaLM.</sample>
    <sample id="96">Hallo everyone, ich bin Jennie, ein erster Jahr PHS-Student an der Carnegie Mellon University und heute werde ich unsere Arbeit 'annal positionality' präsentieren, die durch Design-basierte Methoden gekennzeichnet ist. Diese Arbeit wurde in Zusammenarbeit mit Leuten an der University of Washington gemacht und die Leitung hatte AI, insbesondere Sebastian Santi, Ronan LaBosse, Katarina Rainera und Martin SAP. Also lasst uns damit beginnen, indem wir vorstellen, dass Sie für eine Zeitung arbeiten und Sie Ihre Kommentare unter Ihrem Nachrichtenartikel sichten, versuchen Sie, Unterhaltungen zu entfernen.</sample>
    <sample id="97">Die Referentin geht auf vier Probleme von SimulST ein.</sample>
    <sample id="98">Die Verwendung von prä-trainierten Daten, um die Auswirkungen politischer Meinungen auf NLP-Modelle zu minimieren, kann dazu beitragen, soziale und politische Verzerrungen zu reduzieren.</sample>
    <sample id="99">Hallo, ich bin Si Yu Yuan von der Fernuniversität. Ich bin hier, um unsere Arbeit zu präsentieren, die Unterscheidung zwischen Skriptwissen und groß angelegten Sprachmodellen für konkrete Sprachplanung. Im Alltag planen Menschen ihre Handlungen oft durch die Verfolgung vorgegebener Anweisungen in Form von festgelegten Skripts. Vorherige Arbeiten haben Sprachmodelle verwendet, um abstrakte Ziele stereotypischer Aktivitäten wie das Erstellen von zu planen.</sample>
    <sample id="100">The speech is about a method of answering questions that require multiple reasoning steps, called multi-hop QA. Each step corresponds to a document in the corpus. To answer a question about a 1988 Christmas comedy film featuring Brian Doyle-Murphy, one would find all the movies he starred in, then find the movie released in 1988.</sample>
    <sample id="101">PaLM erreicht einen State-of-the-Art-Status in hunderten von NLP-Tasks.</sample>
    <sample id="102">A valid watermarking method should be able to withstand various attacks including noise, distortion, and tampering. It should also provide high visibility and be computationally efficient. Additionally, it should ensure that the watermark is not easily removed or obfuscated, while still being readable by humans.</sample>
    <sample id="103">Die Übersetzungen der englischen TED Talks in 14 Sprachen sind: Chinesisch (Mandarin), Arabisch, Bengalisch, Hindi, Japanisch, Koreanisch, Malaiisch, Rumänisch, Russisch, Schwedisch,泰米尔语, Urdu und Vietnamisch.</sample>
    <sample id="104">Eine Instanz wird aus einem Datensatz für die erneute Annotierung extrahiert.</sample>
    <sample id="105">The speech mentions that distance metrics such as Euclidean distance and cosine similarity are used to measure the difference between harmless and backdoor data sets.</sample>
    <sample id="106">DieSpeakerin spricht über ihre Arbeit 'Quest', die in Zusammenarbeit mit Pete, Miguel, Kenton und Crisina von Google DeepMind entstanden ist. Sie verwendet zwei Beispiele, um die Bedeutung ihrer Arbeit zu verdeutlichen. Im ersten Beispiel beobachtet Jane, eine Zoologin auf einer Feldtruppe in Costa Rica, eine unbekannte Reptilienart. Im zweiten Beispiel geht sie auf einen anderen Aspekt ihrer Arbeit ein, ohne weitere Details zu geben.</sample>
    <sample id="107">In dieser Aufgabe wurden Modelle, die auf einem mehrsprachigen Encoder basieren, verwendet, um semantische Representations von Benutzeranfragen in verschiedenen Natur Sprachen zu erstellen.</sample>
    <sample id="108">In dem Paper 'Language Model Acceptability Judgments are not Always Robust to Context' wird die Minimalpair-Paradigma Methode zur Bewertung von Sprachmodellen überprüft. Die Autoren untersuchen, ob diese Methodik in verschiedenen Kontexten robust ist und finden heraus, dass sie nicht immer zuverlässig ist. Sie arbeiten dabei zusammen mit John Gathman, Aaron Muller, Kanishka Mishra, Karen Fuentes, Roger Levy und Atina Williams. In diesem Projekt werden sie das Minimalpair-Paradigma erneut durchleuchten. Das Minimalpair-Paradigma ist eine Methode, die Sprachmodelle auf ihre Verträglichkeit gegenüber akzeptabilitätsurteilen evaluiert.</sample>
    <sample id="109">Die vorliegende Präsentation beschäftigt sich mit der Entwicklung von Sprachmodellen für die Natural Language Processing (NLP). Insbesondere geht es um das Konzept der 'Instruction Tuning', bei dem es darum geht, diese Modelle in der Lage zu machen, auf neue und unvorhergesehene Aufgabenstellungen zuzugreifen. Eine Möglichkeit, Beispiele für Instruction Tuning zu erhalten, besteht darin, bestehende NLP-Datenbanken zu reformulieren. Allerdings sind die resultierenden Daten nur auf existing academic benchmarks beschränkt, während Instruction Tuning tatsächlich dazu beitragen kann, jedes textuelle Material zu beschreiben.</sample>
    <sample id="111">Die Autoren definieren Wörter mit mittlerer Häufigkeit als jene, die in einer bestimmten Textmenge vorkommen, aber nicht so häufig wie häufige Wörter und auch nicht so selten wie seltene Wörter.</sample>
    <sample id="112">Hallo everyone, mein Name ist Shu Han. Heute werde ich unser Paper vorstellen, das die Frage untersucht, ob der von uns genannte Entitätstagger 'Connel' in 2023 noch funktioniert. Los geht's.
Unser Paper hat die Problematik der Generalisierung unter dem Aspekt der benannten Entitätserkennung oder der NER-Tasks untersucht. Wir haben beobachtet, dass Modelle bisher Connel verwendet haben, um NER für alle Arten von Daten zu entwickeln.</sample>
    <sample id="114">Die Forscher der National University of Singapore arbeiten an der Entwicklung von Modellen zur Verarbeitung von Natural Language, die alle Aufgaben in einem Modell lernen können. Sie beziehen sich dabei auf das Konzept der Multihead Attension und untersuchen die Verwendung von Strukturierungsmodellen für die Verbesserung der Leistung dieser Modelle.</sample>
    <sample id="115">Die Größe der Sprachsegmente variiert, aber es werden normalerweise kleine Segmente verwendet, die schnell übersetzt werden können.</sample>
    <sample id="116">National Language Understanding Models</sample>
    <sample id="117">Die Übereinstimmung mit dem Ausgangssatz ist der wichtigste Faktor für die Qualität des Beispiels.</sample>
    <sample id="118">Die Präsentation befasst sich mit der Verbesserung von Vorbereitungsverfahren für Code-Swichtung auf NLP. Es wird definiert, was Code-Swichtung ist und es wird ein Beispiel gegeben. Code-Mix-Sätze wie 'Lap top mirror bag mirror' werden diskutiert, die aus englischen und indischen Wörtern bestehen. Building computational models for code switching ist wichtig.</sample>
    <sample id="119">Die Arbeiten konzentrieren sich auf large-scale web crawling Daten und politische News-Medien.</sample>
    <sample id="120">Das Modell verwendet Werte aus mehreren Ebenen.</sample>
    <sample id="121">Beispiele für direkte Inferenz sind die Verwendung von 'if', 'then', 'else' oder der Schleife ('while') in Programmiersprachen.</sample>
    <sample id="122">Die Autoren gehören der Fernuniversität an.</sample>
    <sample id="123">In der vorliegenden Präsentation werden die Forscher Yin und Zhiyang ihre Forschungen zu Multi-Instruction, einem Verfahren zur Verbesserung von Multi-Modell-SQL-Lernung mittels Instruction Tuning, vorstellen. Sie weisen darauf hin, dass mit den Fortschritten in großen Sprachmodellen immer mehr Arbeiten begannen, neue Lernparadigmen zu erforschen, bei denen präzise Sprachmodelle für verschiedene untergeordnete Aufgaben in Parameter und Daten effizient genutzt werden. Letztlich haben viele Studien gezeigt, dass Instruction Tuning große Sprachmodelle ermöglicht.</sample>
    <sample id="124">In der vorliegenden Aussage wird beschrieben, dass Tan Ching von der National University of Singapore und Alibaba über die Verbesserung der Zeitrechnungsfähigkeit von künstlichen Intelligenzen spricht. Sie unterteilt die Zeitrechnung in drei verschiedene Ebenen: Zeit zu Zeit-Reasoning, beispielsweise 'Was ist das Jahr nach 2020?', bei dem nur das Verständnis der Zeitachse erforderlich ist.</sample>
    <sample id="125">Es ist ein einziger Autor, der die Arbeit präsentiert.</sample>
    <sample id="126">Nein, die Übersetzung der natürlichsprachlichen Anfrage wurde nicht mit einem maschinellen Übersetzungsmodell vor dem semantischen Parsing betrachtet. Stattdessen wird in diesem Vortrag ein Cross-Lingual Semantic Parsing-Algorithmus vorgestellt, der es ermöglicht, semantische Representations von Benutzeranfragen in mehreren Natur Sprachen zu erstellen.</sample>
    <sample id="127">In der vorliegenden Studie wird die Arbeit von NAM Gyu-Ho, Laura Schmidt und Seong-Yun Lee untersucht, bei der es darum geht, große Sprachmodell zu entwickeln, die komplexe Aufgaben lösen können. Die CBT-Technik (Chain-of-Thought Reasoning) wurde hierbei als Mittel eingesetzt, um diese großen Modell zu unterstützen. Allerdings funktioniert diese Technik nur mit großen Modellen wie GPT-3 oder POM.</sample>
    <sample id="128">Die Arbeit 'Kit Master' untersucht die Integration von Wissen aus verschiedenen Quellen bei der National Language Understanding Modellierung. Sie ist eine Zusammenarbeit zwischen McGill University, Microsoft Research und der Mila. Die Modelle beruhen auf einer Vielzahl von Wissensquellen wie den Parametern des Modells, die normalerweise durch Vorkursen gewonnen werden, sowie anderen Knowledge Sources.</sample>
    <sample id="129">Die Autoren haben 'Papiere mit Markierungen' als Beispiel für eine markierte Gruppe genannt.</sample>
    <sample id="130">Konvexmodellarchitekturen generieren nicht gut.</sample>
    <sample id="131">Die Testdatensätze sind Widerstandsfähigkeit und Leistung.</sample>
    <sample id="132">Zwei Autoren, Martin und das Co-Autorkommando.</sample>
    <sample id="133">Die Autoren arbeiten mit mehreren Modulen.</sample>
    <sample id="135">In this audio, James Finch and Sarah Finch introduce ABC-Eval, a new approach to evaluating conversational AI developed by the Emory NLP lab in collaboration with Amazon Alexa AI. The common practice is human evaluation, but ABC-Eval offers a more efficient way using three metrics: accuracy, fluency, and naturalness. The speakers also discuss the importance of testing AI models against current standards and the benefits of using machine learning for objective evaluations.</sample>
    <sample id="136">Das Paper von Chad und Nefisa untersucht die Verwendung alternativer Methoden zur numerischen Berechnung, insbesondere der Formel 'Fermatsche'. Die Motivation für ihre Arbeit stammt aus Anwendungen in der Realität, bei denen eine genaue Berechnung notwendig ist, sowie Downstream-Task, die eine faktische Korrektheit erfordern.</sample>
    <sample id="137">Der Sprecher aus Singapur, SiSone von der Technologie- und Designuniversität, präsentiert ihre Arbeit 'Tela Design', eine Datenbank für Sprachgestützte Flurplanerstellung, die in ACoS veröffentlicht wurde. Sie beschreibt, wie konditionale generative AI-Modelle in der Erzeugung hochgenauer Bilder verwendet werden, die auf high-level visuellen Konzepten basieren und für ihre realistische Aussehen und Bewertung geschätzt werden.</sample>
    <sample id="138">Das Lernmodell muss in der Lage sein, Wissen aus verschiedenen Quellen zu integrieren.</sample>
    <sample id="139">Die Referenten sind Yin und ihre Kollegin Zhong Yang.</sample>
    <sample id="140">Nein, der Inhalt gibt keine Informationen über eine Qualitätskontrolle von Coscript an.</sample>
    <sample id="141">Bestehende Ressourcen für kontextbasierte Übersetzung sind begrenzt durch die limitierten Fähigkeiten menschlicher Verstandes, die Anforderungen an präzise Übersetzungen und die notwendigen Zeit- und Budgetressourcen für eine vollständige Datenanalyse und -整合.</sample>
    <sample id="142">Der englische Text übersetzt ins Deutsche lautet: 'Hallo, und ich werde über unsere Arbeit an der Lösung von indirekten Verknüpfungen für Entitätselektion sprechen, bei der wir das Attributskorpus einführen. Mein Name ist Javot Hosaini, und dies ist eine gemeinsame Arbeit mit Philip Bradbury, Sylvia Parity und Anna Lewis. Unser Ziel ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Entscheidung treffen möchten. Und berücksichtigen Sie diese alternative Frage: Did you mean easy on me or I got a feeling? Hier hat ein Benutzer gesagt.'</sample>
    <sample id="143">The approach is compared with the existing SimulST guidelines.</sample>
    <sample id="144">Die Autoren sind angestellt an der Universität von Paris-Saclay.</sample>
    <sample id="145">Der Referent*in heißt Jennie.</sample>
    <sample id="146">The speaker is giving a talk about their paper on the analysis of omissions in dialogue summarization. They will introduce the background of dialogue summarization, which is a subtask of text summarization, and explain the process of creating a concise summary that represents the most important information within a dialogue. There are various scenarios in dialogue summarization.</sample>
    <sample id="147">Zwei, Myra und Esen Derush.</sample>
    <sample id="148">Hallo, ich bin Sara Papaioannou von der Universität Toronto und Förderndemmitglied von Bruno Kassler, und ich werde die Aufmerksamkeit als Leitfaden für eine gleichzeitige Übersetzungsdokumentation vorstellen. Es ist ein gemeinsames Projekt mit Matteo Negrini und Marco Turco. Was ist gleichzeitige Sprachübersetzung? Gleichzeitige Sprachübersetzung oder SimulST ist der Prozess, bei dem gesprochene Sprache in Echtzeit in einem anderen Text übersetzt wird. Dies ermöglicht es, mehrsprachige Kommunikation zu ermöglichen.</sample>
    <sample id="149">Nein, es ist nicht bekannt, ob der Datensatz öffentlich zugänglich ist.</sample>
    <sample id="150">Das Audio beschreibt die Präsentation einer Paper-Session zu Meeting-Transkripten und betont ihre Bedeutung für die Research in der Natural Language Processing (NLP). DieSpeaker dankt ihren Co-Autoren von Adobe Research und UNC Chapel Hill. Sie betonen, dass es weltweit täglich viele Meetings gibt, was zu großen Mengen an Meeting-Transkripten führt, die als neues Domänenfeld für NLP-Forschung erscheinen. Die Besonderheit dieses domains liegt darin, dass es sich um Meeting-Transkripte handelt, was es einzigartig macht.</sample>
    <sample id="151">Hallo everyone, mein Name ist Yin und meine Kollegin Zhixiang, und wir werden unsere Forschung über Multi-Instanz vorstellen, die Verbesserung von Multi-Modell-Sicherheitslernung durch Instruction Tuning. So mit den Fortschritten in großen Sprachmodellen haben viele Arbeiten begonnen, neue Lernparadigmen zu erforschen, bei denen per Trainingslanguage-Modelle für verschiedene unterer Schichten verwendet werden, um Parameter und Daten effizienter zu verwenden. Kürzlich haben viele Studien gezeigt, dass Instruction Tuning große Sprachmodelle ermöglicht.</sample>
    <sample id="152">In der vorliegenden Präsentation wird über die Arbeit an der Schnittstelle zwischen NLP und klassischer Philologie gesprochen. Der Redner, Fredric Grimes Schneider, wird wichtige Ressourcen für das Studium alter griechischer und lateinischer Sprachen vorstellen und die Implikationen und Herausforderungen der Multilingualität in diesen Modellen untersuchen. Zuvor wird jedoch ein Überblick über den aktuellen Stand der Sprachmodellierung in der Klassik gegeben.</sample>
    <sample id="153">The speaker's name is Nina and she works as a postdoctoral scientist at Amazon Alexa AI, focusing on resolving ambiguities in text-to-image generative models. She presented their work on studying existing ambiguities in prompts provided to these models, such as the prompt 'a girl interested,' which can be interpreted in various ways.</sample>
    <sample id="154">Die Autoren gehören zur University of Toronto.</sample>
    <sample id="155">Der Referent*in heißt Javot Hosaini.</sample>
    <sample id="157">The speech is about a research collaboration with Xingceng, Mingzhe Li, Xiuying Chen, Jinpeng Li, Dongyan Zhao and Ruiyan on dialogue summarization with a static dynamic structure fusion graph. The aim of the research is to extract hidden information from dialogues into concise summaries.</sample>
    <sample id="158">The speaker introduces a paper on 'dual cash for long document neural coreference resolution'. It explains the task of coreference resolution, where entities in a text can have multiple mentions, and the goal is to identify and cluster these mentions that refer to the same entity.</sample>
    <sample id="159">Hallo everyone, ich bin Kostas Sina und es freut mich, Sie zu unserem Talk über unsere ACER Paper Language Model Acceptability Judgments sind nicht immer robust zu Kontexten willkommen zu sein. Es ist ein gemeinsames Werk mit John Goughere, Aaron Muller, Kanishka Mishra, Karen Fuentes, Roger Levy und Atina Williams. In diesem Werk besuchen wir das Minimal-Paar-Paradigma erneut. Das Minimal-Paar-Paradigma beurteilt Sprachmodelle auf der Grundlage von Akzeptabilitätsurteilen.</sample>
    <sample id="160">Die Input-Tokens werden in erster Linie auf ihre Wortart (Wörter, Adjektive, Pronomen usw.) und ihre grammatische Funktion (Nominativ, Genitiv, Dativ usw.) geprüft.</sample>
    <sample id="161">Coscript enthält ein Skript.</sample>
    <sample id="163">Die beste Methode zur Ausrichtung von DEplane hängt von der spezifischen Zielgruppe ab, da es sich um eine neue Quelle für German text simplification handelt.</sample>
    <sample id="164">Der Vorteil von schwach überwachtem Lernen ist eine höhere Flexibilität und Autonomie für den Lernenden.</sample>
    <sample id="165">Der Vortragende, Wenyuan Zhao, ein PhD-Student an der Cornell University, spricht über 'Adaptive Common Sense Reasoning' und verwendet 'mutual exclusive explanations'. Er gibt ein konkretes Beispiel und folgt dies mit einer formelleren Definition.</sample>
    <sample id="166">Ein neues Arbeitspapier zur Verarbeitung von komplexen Bildern, basierend auf einer neuralen Netzwerkarchitektur und einem Konzepts der Konsistenz. Es befasst sich mit der Verarbeitung von Bildern, die sehr ähnlich aussehen, aber ihre Beschreibung unterschiedlich ist.</sample>
    <sample id="167">Alle Dokumente wurden mit manuellen Methoden ausgerichtet.</sample>
    <sample id="168">Der CoNLL++-Datensatz wurde mit dem Ziel erstellt, die Performanz von Modellen bei der Generalisierung zu testen, indem er als Aufgabenstellung für die named entity recognition (NER) verwendet wurde.</sample>
    <sample id="169">Das Paper 'Gruntling: Parameterized Machine Translation with Large-Scale Text' beschreibt das Gruntling-Modell, ein 540 Milliarden-Parameter-Langmodell, das im letzten Jahr vorgestellt wurde und auf einer großen Sammlung von Texten trainiert wurde. Das Modell erreichte in Tests state-of-the-art-Leistungen bei mehreren hundert Aufgaben.</sample>
    <sample id="170">Hallo everyone, mein Name ist Jiaxuan Zheng vom Peking-Universität. Heute werde ich meine Arbeit vorstellen: Exemplarische Cross-Lingual-Semantik-Parsing in mehreren natürlichen Sprachen und Minimalrepräsentationen. Also, Semantik-Parsing ist die Aufgabe, semantische Representierungen von Benutzeranfragen zu erstellen, wie z.B. SQL und Lambda-Calculus. Und Cross-Lingual-Semantik-Parse ist es, die Aufgabe, Anfragen in mehreren NaturSprachen in multiple Minimalrepräsentationen zu übersetzen.</sample>
    <sample id="171">Die Arbeit von Jiaolong et al. wurde bereits durchgeführt.</sample>
    <sample id="172">Es wird nicht direkt erwähnt, ob mehrsprachige LLMs wie Codex oder Bloom für CLSP ausreichend sind.</sample>
    <sample id="174">In diesem Video wird die Autoren besprechen, warum dieser Datensatz einzigartig ist und was ihn von anderen Datenbanken auf dem gleichen Thema unterscheidet. Es gibt eine kurze Übersicht über spezielle Funktionen des Datensatzes, einschließlich der Daten收集- und Anmerkungsprozesse.</sample>
    <sample id="175">Die Methode nutzt Multisets und Latente Permutations für die Kompositionale Generalisierung ohne Bäume.</sample>
    <sample id="176">Die Fairness eines nachgeschalteten NLP-Modells wird durch das Verfolgen der Spuren politischer Biase in den vorbereiteten Daten definiert, die zu unfairen Modellen führen können.</sample>
    <sample id="177">Der Referent ist Yannick Lavaud.</sample>
    <sample id="178">Coast of Sina</sample>
    <sample id="179">In English, the speech discusses the concept of 'mind-mapping' as applied to language models, referencing the 'Theory of Mind,' a multi-character belief tracker traditionally measured in humans and models alike. It suggests using false belief questions to probe understanding in these models.</sample>
    <sample id="180">Der Referent*in heißt Myra.</sample>
    <sample id="181">The talk is about using large language models for constrained language planning, focusing on how humans plan their actions by following step-by-step instructions in the form of scripts. Previous work has used language models to plan abstract goals of stereotypical activities, but this talk will discuss how to distinguish script knowledge from general language knowledge and apply it to constrained language planning.</sample>
    <sample id="182">Tropikalismus bezieht sich auf eine Vorliebe für bestimmte Dinge oder Praktiken, die in tropischen Gebieten üblich sind und möglicherweise auch in anderen Regionen verbreitet sind.</sample>
    <sample id="183">Die Autoren haben natural language prompts verwendet, um stereotype in großen Sprachmodellen oder LMs zu messen.</sample>
    <sample id="184">Es wurde eine datadriven multilinguale Exploration eingesetzt.</sample>
    <sample id="185">DrBERT ist ein französisches Modell, während ChuBERT ein chinesisches Modell ist.</sample>
    <sample id="187">Zwei.</sample>
    <sample id="188">Iteratives Transferlernen ist ein Lernverfahren, bei dem Wissen und Fähigkeiten aus einer Domäne auf eine andere übertragen werden.</sample>
    <sample id="189">Das Ziel des Datensatzes ist es, die Verwendung von indirekten Abfragen für Entitätselektion zu lösen und dabei die Entitätskorrekturen einzuführen.</sample>
    <sample id="190">Es ist nicht möglich, den genauen Inhalt der Anzeigevideo zu beschreiben, ohne dass man die gesamte Anzeige oder sogar das Video selbst sieht. Die Informationen sind daher begrenzt und es gibt keine Möglichkeit, eine vollständige Antwort auf diese Frage zu geben.</sample>
    <sample id="191">Zwei Autoren sind an der Arbeit beteiligt: Sarah Papa und Bruno Kassler.</sample>
    <sample id="192">Der Vortragender, Yang Lu, präsentiert seine Arbeit zu einer kognitiv orientierten, adaptiven und effizienten Optimierungsmethode für große Sprachmodell-Trainings. Diese basiert auf adaptiven Gradienten. Er hebt hervor, dass diese Methode von einigen verbreiteten Optimierern wie Adam verwendet wird.</sample>
    <sample id="193">Zwei.</sample>
    <sample id="194">Die Autoren sind Studenten an der Carnegie Mellon University.</sample>
    <sample id="195">In diesem Artikel wird über die 'hierarchische Frage-Dekompositionstree für explizite Frage-Antworten' in der XQAS (Explainable Question Answering System) berichtet. Die XQAS ist ein System, das es ermöglicht, Fragen zu beantworten und zu erklären, warum eine bestimmte Antwort ausgewählt wurde. In jüngster Zeit wurden verschiedene Methoden entwickelt, um diese Aufgabe in XQAS zu bewältigen, wie zum Beispiel neurosymbolische Methoden, die natürliche Sprachfragen in formale Darstellungen wie 'Sparkle' übersetzen.</sample>
    <sample id="196">Lisabart und Maggie</sample>
    <sample id="197">Die Common Practice ist die Verwendung menschlicher Bewertung.</sample>
    <sample id="198">Die Akzeptanz der Modelle muss über das gesamte Kontextfenster bewertet werden, da dies notwendig ist, um sicherzustellen, dass sie in verschiedenen Situationen korrekt funktionieren.</sample>
    <sample id="199">Nein, das mehrsprachige Training hat keinen Leistungsabfall im Vergleich zum einsprachigen englischen Modell verursacht.</sample>
    <sample id="200">Nein, die Annotatoren kennen die Entität nicht im Voraus.</sample>
    <sample id="201">Die Metriken, die für die Bewertung verwendet wurden, sind WPM (Wörter pro Minute) und BLEU (Bilingual Evaluation Understudy).</sample>
    <sample id="202">Nein, das Paper untersuchte nicht spezifisch, ob die Regression bei der Generalisierung auf bestimmte NER-Typen auswirkt.</sample>
    <sample id="203">Positionalität ist wichtig, weil sie es ermöglicht, die Bedeutung von Wörtern in einem Satz oder Text zu verstehen, ohne dass man die Kontexte anderer Wörter kennt.</sample>
    <sample id="204">Nein, es wurde lediglich erwähnt, dass BLOOM-Adaptoren verwendet wurden, um die Anpassung an verschiedene Sprachen zu erleichtern, aber keine vollständige Feinabstimmung wurde beschrieben.</sample>
    <sample id="205">In diesem Vortrag wird vorgestellt, wie politische Meinungen in Sprachmodellen beeinflusst werden können. Die Präsentation beginnt mit der Vorstellung des Autors, Shangbin, einem PhD-Studenten an der University of Washington. Er beschreibt seinen Schwerpunkt auf der Verfolgung von Trends in politischer Meinung und ihrer Auswirkungen auf unfairere NLB-Modelle. Im Folgenden wird dargestellt, wie Sprachmodelle auf großen Web-Crawl-Daten trainiert werden und dass politische Nachrichtenmedien wie New York Times, Los Angeles Times und The Guardian in ihren Trainingsdaten gut vertreten sind.</sample>
    <sample id="206">Das Modell, das für das Transferlernen verwendet wird, ist ein Deep Neural Network.</sample>
    <sample id="207">Es wurden hunderte von NLP-Testsets verwendet.</sample>
    <sample id="208">Die Autoren haben vorgeschlagen, dass man Personen in einem Dokument markiert, um Stereotypen in Sprachmodellen zu messen.</sample>
    <sample id="209">The speech does not provide information on the specific gain of the proposed method over the strongest baseline, only that it outperforms baselines in a certain task.</sample>
    <sample id="210">Der Referent*in heißt Stu Heng.</sample>
    <sample id="211">Ja, die Ergebnisse und der Datensatz der Studie können als Benchmark verwendet werden.</sample>
    <sample id="212">Mit verschiedenen kleineren Modellen wird experimentiert.</sample>
    <sample id="213">Das研究中使用的基线模型是多模态神经网络。</sample>
    <sample id="215">Der Vortrag handelt über die Abhängigkeitsstruktur der Koordination und gibt einen Überblick über verschiedene Theorien und Ansätze zur Strukturierung von Koordinaten. Im Fokus steht die Coordinatensysteme von Lisa Bart und Maggie, bei denen das erste Konstante die Leitungsperson für das gesamte Koordinatensystem ist. Eine ähnliche Ansatz wird in der Theorie der 'Einfachen Koordinaten' von Godfrey Chomsky vorgestellt.</sample>
    <sample id="217">The speaker will present their work on 'Scene to Unseen: Exploring Compositional Generation of Multi-Modal Dialogue' with partners Lu Lu Zhao and Ke Jinhua from Beijing University of Posts and Telecommunications, explaining their motivations in the following seven aspects.</sample>
    <sample id="218">Die Autoren sind von Google Translate.</sample>
    <sample id="219">Jia Huichu, ein Forschungsassistent an der Academy for Economic and Management Research, präsentiert ihre Arbeit über die Entwicklung eines multi-stufigen Verfahrens zur Erkennung von Finanzsignalen in Finanzberichten. Die Studie wurde gemeinsam mit Yu Xianghao und Chen Weiliang durchgeführt und von der Business Authority of China unterstützt. Sie werden sich auf den Hintergrund der Finanzberichtsanalyse konzentrieren, die Grundlage dieser Arbeit darstellt.</sample>
    <sample id="220">Die Autoren sind an der University of Stony Brook University.</sample>
    <sample id="221">Die Arbeit untersuchte die Übersetzung von chinesischen Texten ins Englische.</sample>
    <sample id="222">The speech discusses the process of answering open-domain questions using Wikipedia articles and a question-answering model. First, relevant passages from the Wikipedia corpus are retrieved using a retriever model. Then, the reader model processes the question and the retrieved passages to generate the answer. This approach involves adapting or annotating challenges and interventions in the QA process. The motivation for this work is to improve the effectiveness of open-domain question answering systems.</sample>
    <sample id="223">Der Referent ist Changbing, ein PhD-Student an der University of Washington.</sample>
    <sample id="224">Die experimentellen Modelle wurden nicht spezifiziert.</sample>
    <sample id="225">Alle 62 Aufgaben werden für Training und Tests verwendet.</sample>
    <sample id="226">Es ist ein einziger Autor, Regina Stodden.</sample>
    <sample id="227">The speech discusses the success of language models in solving various NLP tasks and asks what is currently missing in their research. The speaker believes that grounding language understanding, which involves turning natural language expressions into actionable plans or programs for specific environments, is the key missing element.</sample>
    <sample id="228">Die genauen Datenätze, an denen die Autoren gearbeitet haben, wurden nicht in der angegebenen Zusammenfassung erwähnt.</sample>
    <sample id="229">The speaker discusses the importance of text revision, a crucial part of professional writing that involves repeatedly refining language until it meets the author's standards.</sample>
    <sample id="231">NACHOS ist ein Datensatz medizinischer Karteile Big Data aus Frankreich.</sample>
    <sample id="232">Der Referent ist Aydin Bilir.</sample>
    <sample id="233">The abstract describes 'simultaneous speech translation' (SST), a real-time process that translates spoken language into text in another language, facilitating cross-language communication.</sample>
    <sample id="234">Die Prompt-Strategie beeinflusst die Ergebnisse positiv.</sample>
    <sample id="235">Die Autoren sind Patrick Farnsworth, MEYU, Andrae F. Martinez und Graham Newbigging.</sample>
    <sample id="236">The 5 instructions are: 'First, make sure the data is labeled correctly.', 'Second, preprocess the text data.', 'Third, train the model using the preprocessed data.', 'Fourth, tune the model using the hyperparameters.', 'Finally, evaluate the performance of the tuned model.'</sample>
    <sample id="237">Die Autoren schlagen vor, National Language Understanding-Modelle zu entwickeln, die auf einer Vielzahl von Wissensquellen basieren, einschließlich dem in ihren Parametern enthaltenen Wissen, das normalerweise durch Vorkursen erworben wird, sowie anderen Knowledge Integrationstechnologien.</sample>
    <sample id="238">In diesem Video wird ein neues Benchmark-Datenbankmodell vorgestellt, das für die Entwicklung von Zusammenfassungstechnologien für verschiedene Meetingdomänen entwickelt wurde. Das Modell basiert auf den Erfahrungen der University of Central Florida.</sample>
    <sample id="239">Hallo everyone, mein Name ist Avi Bilad und ich werde Euch einen kurzen Überblick über das Paper 'Grundlegende Aspekte der Übersetzungsstrategie und -leistung bei PAMM-Translation' geben. Dies ist gemeinsam mit meinen Kollegen von Google Translate. PAMM ist ein 540 Milliarden-Parameter-Langmodell, das letztes Jahr auf der ICLR präsentiert wurde. Es basiert auf einer großen Sammlung von Texten, die 180 Milliarden Token umfassen. Beim letzten Test hat es eine State-of-the-Art-Leistung in mehreren hundert NLP Aufgaben erreicht.</sample>
    <sample id="240">Hallo, ich bin Daewi, ein PhD-Student an der Universität Hamburg in Deutschland. In diesem Video möchte ich Ihnen unser aktuelles Werk präsentieren: "Weiter als Sie denken - Eine kritische Betrachtung der wöchentlichen Überwachung". Dies ist gemeinsame Arbeit mit Xiao Yunshen, Majos Musba, Gia Stephen und Dieter Klackow. Ich würde gerne mit einer kurzen Einführung zu wöchentlicher Überwachung beginnen und wöchentlicher Überwachung. In der wöchentlichen Überwachung werden wir nicht managen.</sample>
    <sample id="241">In dem Paper 'Human in the Loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments' diskutieren Ethan, Yang Chen, Wei Xu und Alvin Ritter die Ergebnisse einer联合研究, bei der sie die Wirksamkeit von automatischen Methoden zur Erkennung von Falschnachrichten auf sozialen Medienplattformen untersuchten. Die Studie befasst sich speziell mit den Behandlungsmethoden für COVID-19. Die Autoren betonen, dass bisherige Ansätze zur automatischen Erkennung von Falschnachrichten aufgrund mangelnder Realitätsbewertung und fehlender präziser Kriterien nicht sehr erfolgreich waren.</sample>
    <sample id="242">Gängige Bewertungsmethoden sind die Verwendung menschlicher Bewertung.</sample>
    <sample id="243">Zwei.</sample>
    <sample id="244">National Language Understanding Models</sample>
    <sample id="245">Das Paper 'A Needle in a Haystack: An Analysis of High Agreement Workers on AMT for Summarization' untersucht die Arbeitsweise von hochagreignen Mitarbeitern auf der Plattform AMT für Zusammenfassungen. Die Autoren haben eine Zwei-Schritt-Pipeline entwickelt, um high agreement workers zu identifizieren. Diese Pipeline basiert auf automatischen Matrixen und zielt darauf ab, Probleme bei der Verwendung dieser Methoden zu lösen. Das Paper enthält auch eine Grafik, die die pipeline visuell darstellt.</sample>
    <sample id="246">Der Code ist nicht direkt verfügbar, aber es wurde eine Zusammenarbeit zwischen Macquarie University, Microsoft Research und National Language Understanding Models angekündigt.</sample>
    <sample id="247">Die vorliegende Präsentation beschreibt ein neues Datenbankmodell namens 'KG-Fact-Verifizierung via Reasoning' für die Verifizierung von Fakten in Wikipedia-Artikeln. Es gibt bestehende Datensätze wie 'Fever' und 'Vitamin C', die auf Wikipedia-Texten basieren, aber es fehlt bisher ein Datenbankmodell, das mit reasonnden Methoden arbeitet.</sample>
    <sample id="248">Nein, es gibt keine Informationen darüber, ob die Annotatoren für NLPositionality in Bezug auf jede demografische Gruppe ausgewogen sind.</sample>
    <sample id="249">Die Sätze wurden durch das Hinzufügen von 'um' zwischen 'kann man' und 'sich' durcheinandergebracht.</sample>
    <sample id="250">Eine dimensionale Bewertung bedeutet, dass man某件事情 in mehreren Bereichen oder Aspekten gleichzeitig bewertet.</sample>
    <sample id="251">Die Autoren gehören zur University of Science and Technology of China.</sample>
    <sample id="252">Die vorliegende Präsentation beinhaltet die Vorstellung eines von Saikiran Tan尼亚 Kalila, einem Masterstudenten an der IIT Kharagpur, entwickelten und mit anderen zusammengeführten unsupervised Caseretrieval-Systems namens 'You Create'. Das System nutzt Event-Extraktionstechnologie zur Identifizierung relevanter Informationen in gerichtlichen Dokumenten. Traditionell haben juristische Fachleute wie Anwälte und Richter auf ihre Erfahrung zurückgegriffen, um relevante frühere Entscheidungen zu zitieren, was jedoch durch das neue System verbessert werden soll.</sample>
    <sample id="253">Das Paper präsentiert ein双域适应模型 'DisorderBird' zur Erkennung von Anzeichen von psychischen Störungen in sozialen Medien. Die Autoren sind Forscher aus Mexiko und Spanien. Sie definieren eine psychologische Störung als ein Syndrom, das mit Angstzuständen, Veränderungen im Denken, Fühlen, Stimmung und Verhalten verbunden ist. Es gibt verschiedene Arten von psychischen Störungen.</sample>
    <sample id="254">Die vorliegende Präsentation beschäftigt sich mit der Forschungsarbeit zum 'uncertainty-guided level denoising for document-level distant relation extraction'. Die Autoren arbeiten an der Fudan-Universität und ihre Arbeit beinhaltet die Entwicklung eines Verfahrens zur Extraktion von Beziehungen zwischen Entitäten in Dokumenten. Die bisherigen Methoden basieren auf großen, von menschen annotierten Corpora.</sample>
    <sample id="255">In der Übersetzung von Texten kann die Form des Prompts wichtig sein, um sicherzustellen, dass der zu übersetzende Text in der gleichen Struktur wie der Originaltext bleibt.</sample>
    <sample id="257">Die Autoren haben verschiedene Dialogmodelle evaluiert.</sample>
    <sample id="258">In this video, Jiang Xunhai discusses his new work on using large language models to evaluate text quality in natural language processing tasks. He explains that they provide instructions to the models, which then use these instructions to evaluate samples. The goal is to determine if large language models can replace human evaluations in assessing text quality.</sample>
    <sample id="259">Der Vortragende spricht über seine Arbeit an der cross-lingualen Syntaxparsing in mehreren Natur Sprachen und Minimalrepräsentationen. Syntaxparsing ist die Aufgabe, semantische Darstellungen von Benutzeranfragen wie SQL oder Lambda-Kalkül zu erstellen. Cross-lingual bedeutet dabei, dass Anfragen in verschiedenen Sprachen übersetzt werden.</sample>
    <sample id="260">Es ist nicht klar, wie viele Autoren an der Arbeit beteiligt sind.</sample>
    <sample id="261">Gute Planer sollten in der Lage sein, komplexe Aufgaben zu definieren, Prioritäten zu setzen, Ressourcen effektiv zu nutzen und flexibel bei der Anpassung an unvorhergesehene Veränderungen zu sein. Sie sollten auch in der Lage sein, Risiken zu identifizieren und abzufangen, sowie in der Lage sein, ihre Pläne erfolgreich zu kommunizieren und durchzusetzen.</sample>
    <sample id="262">Ein Autor ist an der Arbeit beteiligt.</sample>
    <sample id="263">Das Paper präsentiert die Arbeit zur Minderung von Labelbiases bei In-context-Lernen. Es beschreibt, wie In-context-Lernen aufgrund diverser Design-Entscheidungen instabil ist und wie es durch verschiedene Methoden stabilisiert werden kann. Die Studie zeigt auch, dass die Instabilität von In-context-Lernen aus verschiedenen Gründen entsteht.</sample>
    <sample id="264">Der Vortragende gibt eine Präsentation über sein Papier, das sich mit der Transformierbaren Audio-Visual-Textgenerierungstask beschäftigt. Er spricht über die aktuellen Entwicklungen in der maschinellem Übersetzung und Bildkaptivation aufgrund der größeren Datengröße und Modellkapazität.</sample>
    <sample id="265">Der Referent*in heißt Vasudha.</sample>
    <sample id="266">Die Autoren gehören zur University of Cambridge.</sample>
    <sample id="268">Die häufigsten Fehler von PaLM sind mangelhafte Übersetzungen und fehlende Kontextualisierung.</sample>
    <sample id="269">Hallo, ich bin James Finch und ich bin Sarah Finch. Und heute werden wir Ihnen alles über ABC-Eval berichten, eine neue dimensionale Ansatz zur Evaluierung von konversationaler AI. Dieses Werk wurde vom Emery NLP-Lab unter der Leitung von Professor Gino Choi an der Emory University durchgeführt und in Zusammenarbeit mit Amazon Alexa AI. Lassen Sie uns sagen, dass Sie gerade ein Dialogmodell entwickelt haben und Sie sehen möchten, wie gut es gegen den aktuellen Stand der Technik abschneidet. Die übliche Praxis besteht darin, menschenständige Bewertung zu verwenden.</sample>
    <sample id="270">Die Autoren, James Finch und Sarah Finch, gehören der Emory-Universität an.</sample>
    <sample id="271">CFT steht für 'Critical Failure Threshold', ein Begriff aus der mathematischen Statistik, der verwendet wird, um den Punkt zu definieren, an dem ein System oder Prozess einen kritischen Fehler hat.</sample>
    <sample id="272">Zusammen mit John Gathman arbeiten auch Aaron Muller, Kanishka Mishra, Karen Fuentes, Roger Levy und Ada Williams an der Arbeit.</sample>
    <sample id="273">Der englische Inhalt lautet: 'Hallo, mein Name ist Kaiyang und ich werde unsere Arbeit präsentieren, die titled When Does Translation Require Context? A Data-Driven Multilingual Exploration. Dieses Werk wurde in Zusammenarbeit mit Patrick Farnance, MEYU, Andrae FT Martinez und Graham Newbigging durchgeführt. So viele Übersetzungen hängen von Kontext ab. Zum Beispiel, wie würde man mole in diesem Satz übersetzen? Wohl, wenn der vorherige Satz war, dass Dinge beginnen könnten, gefährlich zu werden, wenn die Ministeriumsmitglieder herausfinden würden, dann bezieht sich mole auf einen Skandal. Aber.'</sample>
    <sample id="274">Der Referent*in heißt Lucas John.</sample>
    <sample id="276">Die vorliegende Präsentation beschäftigt sich mit der Entwicklung eines Daten sets für die Metarevalierung von Maschinensprachübersetzungsmetriken für indische Sprachen. Es werden verschiedene Bewertungsmetriken vorgeschlagen, die zur Beurteilung von zwei Englisch-Übersetzungen verwendet werden, und es werden auch viele Studien vorgestellt, die diese Metriken mithilfe der Analyse ihrer Korrelation mit menschlichen Bewertungen metarevaluieren.</sample>
    <sample id="277">Wenn die neue Methode einen Namen hat, lautet dieser 'compositional generalisation'.</sample>
    <sample id="278">Die Autoren beschreiben die Methode der 'markierten Wörter' als eine Möglichkeit, Stereotypen in großen Sprachmodellen oder LMs zu messen, indem sie natürliche Sprachprompts verwenden.</sample>
    <sample id="279">Die Autoren sind Studenten der University of Washington.</sample>
    <sample id="280">Der Sprecher Shou Tao präsentiert seine Arbeit zu einer multiplen E-Mail- und Aufmerksamkeitsbasierten Koordination für Emotionserkennung in Konversationen. Die Hauptaufgabe besteht darin, die emotionalen Ausdrücke in einer Unterhaltung vorherzusagen. Dabei werden jedes Äußerungsmedium (Text, Audio) und dessen Merkmale berücksichtigt.</sample>
    <sample id="281">The speech discusses a collaborative research project titled 'When Does Translation Require Context? A Data-Driven Multilingual Exploration.' The team, consisting of Kayo Yan, Patrick Farnsworth, MEYU, Andrae F. Martinez, and Graham Newman, explores the significance of context in translation. They give an example of how the word 'moel' can have different meanings based on the context in which it is used.</sample>
    <sample id="282">The talk is about a new work in SL '23 titled 'Story Trans, Non-Parallel Story Author Style Transfer with Discourse Representations and Content Enhancing'. It addresses the challenge of non平行文本风格迁移 at the discourse level. Most previous studies have focused on the token or sentence level.</sample>
    <sample id="283">Lisa</sample>
    <sample id="284">In his presentation at the ACL Main Conference, Peng Tian Shuo from Wuhan University introduced his paper titled "FSUIE: A Novel Fused Distant Supervision Mechanism for Enhancing Universal Information Extraction." The current span-based information extraction model identifies and labels the boundaries of the target in the text by relying on boundary positions. However, this method has limitations. Shuo's proposed novel mechanism, called FSUIE, integrates distant supervision to improve the accuracy and robustness of information extraction. This fusion of two different approaches aims to enhance the overall performance of the model.</sample>
    <sample id="285">Die Video-Präsentation beschäftigt sich mit der Fehlerkorrektur von Referenzmaterien für die Datenintegration unter Verwendung des FAN-Grant-Evaluierungskonzepts. Es untersucht zwei Haupttypen von Lösungen: die Einführung von Reviews und die Verwendung von maschinellem Lernen zur automatischen Überprüfung von Referenzmaterialien auf fehlerhafte Informationen.</sample>
    <sample id="286">Sarah Finch</sample>
    <sample id="287">Vier Autoren sind an der Arbeit beteiligt: Javot, Hussein, Radinski, und Silvia Parity.</sample>
    <sample id="288">Es wurden verschiedene Datensätze verwendet, einschließlich der Penn Treebank, OntoNotes und Twitter.</sample>
    <sample id="290">The five methods for the first research question are: QM, MC, SC, PC, and AC.</sample>
    <sample id="291">Das Modell wird auf seine Fähigkeit evaluiert, medizinische Daten in französisch zu modellieren.</sample>
    <sample id="294">CamemBERT wurde mit einem Datensatz namens 'Natschos', der aus medizinischer Crowdsourcedaten besteht, trainiert.</sample>
    <sample id="295">Der Referent*in heißt Adam Skurkowski.</sample>
    <sample id="296">In diesem Video präsentiert Valerio Basile ein von der Universität Turin und Amazon Alexa gemeinsam entwickeltes Projekt zur maschinellen Sprachverarbeitung. Das Projekt basiert in erster Linie auf der Verwendung von überwachten maschinellem Lernen oder datadriven Ansätzen. Um diese Ansätze zu entwickeln, sind Daten erforderlich.</sample>
    <sample id="297">In der vorliegenden Aussage wird über die Arbeit von自动文本 generierungsfähigen Sprachmodellen berichtet, die kodierte Rhetorik in Reden entziffern können. Es wird auch ein Beispiel einer Rede gegeben, die Senator Josh Hawley vor ein paar Jahren gehalten hat, in der er sich über das konservative Elite-Programm beklagt. Einige Menschen könnten denken, dass er über liberale Stadtbewohner spricht, aber für andere könnte es als Verleumdung gegen Juden ausgelegt werden. Die Bezeichnung 'Cotton' ist hierbei als Beispiel eines 'Dogg whistles' herangezogen, was bedeutet, dass es eine Form von Diskriminierung oder Verleumdung ist, die indirekt ausgesprochen wird.</sample>
    <sample id="298">Die Untersuchungsergebnisse zeigten, dass die Zeitliche Verzögerung die Hauptursache für den Leistungsverlust bei der Verwendung von Connel 2003 zur Entwicklung von NER war.</sample>
    <sample id="299">In this presentation, we will discuss enhancing the robustness of neural network models using minimal supervision training. This is a collaborative work with Andres La霍斯 at the University of Cambridge. Despite remarkable progress in achieving state-of-the-art results across multiple benchmarks, recent research has shown that the success of neural networks relies significantly on learning and user shortcuts.</sample>
    <sample id="300">Die vorliegende Präsentation stellt das 'Interactive Dictation' Task vor und beginnt mit den Schritten, um diesesTask zu lösen. Die Arbeit wurde an Symmetrix-Maschinen in Zusammenarbeit mit Jason Eisner, Adam Pauls und Sam Thompson durchgeführt. Interactive Dictation ist ein Prozess, bei dem Benutzer ihre Stimme verwenden, um sowohl zu dikten als auch zu bearbeiten. Das Ergebnis soll intuitiv und natural sein.</sample>
    <sample id="302">Es ist notwendig, die Token für die Ausgabesequenz zu permutieren, um eine kompositionelle Generalisierung zu erreichen, die es dem Lernenden ermöglicht, tieferen Rekursionen und unsichtbare Kompositionen zu verstehen.</sample>
    <sample id="303">Die Autoren empfehlen, ihre Methoden zum Abbau von Vorurteilen transparenter zu machen, damit die Öffentlichkeit ihre Entscheidungen verstehen kann und mögliche Fehlerquellen identifizieren kann.</sample>
    <sample id="304">Inakzeptable Minimalpaareingaben sind linguistische Formen, die von einem Sprachmodell als ungrammatisch oder nicht akzeptabel angesehen werden, obwohl sie nach den Regeln der Sprache korrekt sind.</sample>
    <sample id="305">In diesem Video präsentieren die Autoren ihre neueste Arbeit 'Weaker than you think: A critical look at weekly surprise learning'. Es ist ein gemeinsames Projekt mit Xiao Yunshen, Maios Musba, Gias Stephen und Dieter Glacko. Das Video beginnt mit einer kurzen Einführung zu Weekly Supervision und Weekly Surprise Learning. In der Weekly Supervision finden Mitarbeiter regelmäßige Meetings mit ihren Vorgesetzten statt, um über ihre Arbeit zu sprechen und Fragen zu haben. Im Gegensatz dazu beinhaltet Weekly Surprise Learning unvorhergesehene Übungen oder Aufgaben, bei denen die Mitarbeiter sich auf Herausforderungen konzentrieren müssen, anstatt in ihrem gewohnten Arbeitsumfeld zu arbeiten.</sample>
    <sample id="306">Sebastian Schuster und Malgim geben in ihrem Vortrag einen kurzen Überblick über ihre Arbeit an der Verfolgung von Entitäten in Sprachmodellen. Sie betonen, dass ein Agent, um den Diskurs zu verstehen, die enthaltenen Entitäten identifizieren und verfolgen muss, wie sie sich während des Verlaufs ändern. Anhand eines Rezeptes zum Beispiel müssen die Eier, Zucker und Mehl in einem Topf gemischt werden, was drei verschiedene Entitäten darstellt.</sample>
    <sample id="307">Die Bewertungsmetriken wurden nicht spezifiziert.</sample>
    <sample id="308">DieSpeakerin Jenny, eine erste-jahrgangige PHS-Studentin an der Carnegie Mellon University, präsentiert ihre Arbeit ' annual positionality characterizing design by CIs of models'. Die Arbeit wurde in Zusammenarbeit mit Personen an der University of Washington durchgeführt und beinhaltet Modelle von CIs (Computational Intelligence). Das Projekt basiert auf dem Vorhaben, die Positionalität von Design durch Computermodelle zu charakterisieren. Die beteiligten Personen sind Sebastian Santi, Ronan Le Bras, Katarina Ranecka und Martin SAP. Die Präsentation beginnt mit einer Vorstellung der Arbeitsumgebung und den involvierten Personen.</sample>
    <sample id="309">Die Metrik, die verwendet wurde, war die Coherence Score.</sample>
    <sample id="310">Die Domäne, die gewählt wurde, sind completamente unzusammenhängende Sätze zu den inakzeptablen und akzeptablen Suchanfragen.</sample>
    <sample id="311">Die Autoren gehören zur University of Manchester.</sample>
    <sample id="312">MultiInstruct verbessert Multimodell-Serious-Learning mittels Instruction Tuning.</sample>
    <sample id="313">Zwei Autoren, James Finch und Sarah Finch.</sample>
    <sample id="314">Die binäre Koordination ist eine Form der Koordination, bei der zwei Substanzen miteinander verknüpft sind und dabei jeweils ein Coordinat annehmen.</sample>
    <sample id="315">Die in dieser Studie verwendeten Prompts waren im Durchschnitt etwa 30 bis 50 Zeichen lang.</sample>
    <sample id="316">Die Ergebnisse haben sich als besonders nützlich erwiesen, um das kleine T5-Modell zu verbessern, indem es bei der Planung von konkreten Aktionen unterstützt wird, indem es stereotype Aktivitäten wie das Makeover plant.</sample>
    <sample id="317">Der Vortragende, Peng Li von der Fordham University, präsentiert seine Arbeit mit dem Titel 'Code IE: Large-Scale Code Generation Models are Better Future Information Extractors'. Der Fokus liegt auf der Verwendung großer Code-Generierungsmuster zur Extraktion strukturierter Informationen aus unstrukturierten Texten. Informationsextraktion ist ein klassisches Problem in der Natural Language Processing und bezieht sich auf die Extraktion von strukturierten Informationen aus unstrukturierten Texten. Common tasks sind automatische Nameerkennung, ER-Relationalstrukturierung und so weiter. Die Präsentation diskutiert die Vor- und Nachteile von großen Code-Generierungsmustern als zukünftigen Informationsextractionssystemen.</sample>
    <sample id="318">Hallo, ich bin Janis Lavalette und werde Ihnen meine Arbeiten zu Dr. Bert präsentieren, einem robusten trainierten Modell auf Französisch für den Bereich Biomedizin und Klinische Medizin. In dieser Präsentation werden wir zunächst über die Sprachmodellierung in der Gesundheitsversorgung sprechen, dann werden wir das Hauptbeitrag unseres Artikels vorstellen. Wir präsentieren das erste biomedizinische Modell auf Französisch namens Dr. Bert, das auf Roberta basiert und auf NACHOS trainiert wurde, einer Datenbank medizinischer krowndaten.</sample>
    <sample id="319">Die Lernstrategien, die in der Arbeit untersucht werden, sind kollaboratives Lernen und Peer-to-Peer-Lernen.</sample>
    <sample id="320">Der Faktor der Überanpassung, der speziell auf die Wiederverwendung von Tests zurückzuführen ist, beträgt 80%.</sample>
    <sample id="321">Die Qualität wurde positiv bewertet, da sie die Verständlichkeit für den Leser erhöht hat.</sample>
    <sample id="322">Der Text beschreibt, was Moralphilosophie ist und wie sie uns hilft, zwischen Right and Wrong zu unterscheiden. Sie ist unsere innere Kompasskraft, die uns anleitet, ob Handlungen oder Konzepte moralisch richtig oder falsch sind. Morality bildet die Grundlage unserer moralischen Überzeugungen und Verhaltensweisen.</sample>
    <sample id="323">The speaker, Yu Jia Wang from Shanxi University Channel, presents their paper titled 'Dynamic Knowledge Graph Construction with Language Models and Knowledge Replication for Comprehensible QA'. The paper addresses the challenge of creating a comprehensive question answering system that effectively utilizes common knowledge to provide accurate responses. It introduces a dynamic knowledge graph construction method which integrates language models and knowledge replication techniques to enhance the system's understanding and response capabilities. This approach aims to improve the comprehensibility and reliability of the system's answers.</sample>
    <sample id="324">Ja, die Präsentation besagt, dass politische Meinungen in den groß scale Web crawldaten trainierten Sprachmodellen enthalten sind und dass dies zu unfairen NLB-Modellen führen kann.</sample>
    <sample id="325">Hallo, mein Name ist Matthias Lendermann und heute werde ich Ihnen einen kurzen Überblick über unsere Arbeit zu kompositioneller Generalisierung ohne Bäume mit Multi-Set-Tagging und latenten Permutations geben. Dies ist gemeinsame Arbeit mit meinen Mentoren Alexander Kolah und Ivan Titev. Kompositionelle Generalisierung kann als Fähigkeit eines Lerners verstanden werden, tieferen Rekursionen und unsichtbare Kompositionen zu bewältigen.</sample>
    <sample id="326">Kognitive Dissonanz ist die Unvereinbarkeit zwischen zwei eigenen Überzeugungen oder Handlungen.</sample>
    <sample id="327">The presentation focuses on 'Magic Tower', a model for unimodal experts that integrates insights from various research areas. It was developed during the author's internship at MSRA-LC and is presented as a tool for language representation learning.</sample>
    <sample id="328">Das New York Times Language Model ist das am meisten links gerichtete Modell.</sample>
    <sample id="329">The speaker is introducing themselves as Zheng Minghao from Tsinghua University and mentions that they are the project leader for a work on generating structured super labels for Lloyds' received zero-shot video sense localisation. The work was done in collaboration with Shao-Gang, Haining Yu Xing, and Yang. They focused on zero-shot video sense localisation, aiming to find the most relevant segments using a given natural language query for nonvideos.</sample>
    <sample id="330">The audio does not provide information on whether cumulative training is better than iterative training for active learning.</sample>
    <sample id="331">Der Referent*in heißt Sarah Papi.</sample>
    <sample id="332">Die Daten für die MuDa-Benchmark stammen aus einer Zusammenarbeit mit Patrick Farnsworth, MEYU, AndraeFT, Martinez und Graham Newbigging.</sample>
    <sample id="333">In his speech, WenHaoyu from Nanjing University presents their work on incorporating Chinese knowledge into neural machine translation. He acknowledges the collaboration with Jinqin Xu from Shanghai AILAB, Shujian Huang and Jiawen Chen from Nanjing University, and Lin Pengkong from the University of Hong Kong. The research focuses on improving neural machine translation by integrating Chinese cultural knowledge.</sample>
    <sample id="335">Der Referent ist Matthias Lendermann.</sample>
    <sample id="336">Sprachübergreifender Transfer ist der Prozess, bei dem Daten in verschiedenen Sprachen automatisch übersetzt werden.</sample>
    <sample id="337">The speaker provides an overview of their research, highlighting its key contributions to the field of vocabulary knowledge and its difficulties in representation.</sample>
    <sample id="338">Der Sprecher, Pinxian, dankt für das Interesse an ihrer Forschung und präsentiert ihre Arbeit 'Are human explanations always helpful towards objective evaluation of human natural language understanding?' Die Arbeit ist ein gemeinsames Projekt von Forschern aus der Renison Polytechnic Institute, Northeastern University und IBM Research. Sie werden ihre Motivation besprechen, relevante Arbeiten diskutieren und sich hauptsächlich auf ihre Beiträge konzentrieren.</sample>
    <sample id="339">Die Autoren sind Studenten an der Universität Salzburg in Deutschland.</sample>
    <sample id="340">Guan Huang von UCOA präsentiert 'PermaMR', ein groß scale syntaktisch diverses Permutations-Datenbankmodell, das durch MR-Back-Translation erstellt wurde. Das Projekt ist ein gemeinsames Werk mit Veron, Yihong, Anubhav, Kaiwei und Aron. Die Permutationsgenerierung gilt als langfristiges und wichtiges Aufgaben in der NLP-Domäne und bringt viele Vorteile für andere NLP-Anwendungen.</sample>
    <sample id="341">Die Autoren verwenden eine Latenz von bis zu 200 Millisekunden.</sample>
    <sample id="342">The speech is a presentation on large-scale personalized dialogues that automatically contract from live streaming, conducted by Gao Jinshen and co-presented by Li Yan Xing, Fu Yuzhuo, and Wang Baoyue from Shanghai Jiaotong University and Alibaba Cloud AI. The presentation consists of an introduction and an open dialogue.</sample>
    <sample id="343">Hallo everyone, ich bin Akshata und zusammen mit meinem Co-Autor Martin präsentieren wir unsere Arbeit 'The Knowledge Mustache', bei der es um die Integration von Wissen aus verschiedenen Quellen geht. Dies ist eine Zusammenarbeit zwischen der Universität Chicago, Microsoft Research und dem National Language Understanding Modell. Die National Language Understanding Modelle basieren auf einer Vielzahl von Wissensquellen, wie beispielsweise dem in ihren Parametern enthaltenen Wissen, das normalerweise während des Vorkommens erworben wird.</sample>
    <sample id="344">Die Nachteile der baumbasierten Methoden sind, dass sie aufwendig zu implementieren sind und möglicherweise nicht alle Compositions generieren können, die von menschlichen Beobachtern erkannt werden.</sample>
    <sample id="345">The speech is about a paper on compositional generalization without trees using multisets and latent permutations. The research is a collaborative effort with advisors Alexander Coler and Ivan Tovstolyak. Compositional generalization refers to a learner's ability to handle deeper recursion and unseen compositions.</sample>
    <sample id="346">Die Autoren sind复仇之魂 (Strengthen) und Yoon Kim von der Seoul National University.</sample>
    <sample id="347">Hallo, ich bin Myra und heute werden wir über unsere Arbeit sprechen, bei der wir mit Hilfe von natürlichen Sprachprompts stereotype in Sprachmodellen messen. Dieses Werk wird in Zusammenarbeit mit Esmond Durmusch und Dan Jarauski durchgeführt. In den letzten Jahren haben viele die Vorherrschaft sozialer Vorurteile und Stereotypen in großen Sprachmodellen oder LMs dokumentiert. Allerdings haben diese Messungen verschiedene Einschränkungen. Sie basieren in der Regel auf manuell erstellten Datensätzen, die sehr zeitintensiv zu sammeln sind, und sie verwenden auch.</sample>
    <sample id="348">Das Paper untersucht die Verwendung von Natural Language Prompts zur Messung von Stereotypen in Large-Scale Language Models (LMs) und arbeitet dabei in Zusammenarbeit mit Esmond Durmusch und Dan Jarauskis. Es wurde festgestellt, dass LMs oft soziale Vorurteile enthalten, aber bisherige Messungen haben verschiedene Einschränkungen, da sie auf manuell erstellten Datensätzen basieren, die viel Zeit kosten und auch Fehler beinhalten können.</sample>
    <sample id="349">Hallo everyone, mein Name ist Jingwei Yi vom University of Science and Technology of China. Es freut mich, Ihnen ein kurzes Werbevideo über Papier zu präsentieren. kopiere mein Modell zum Schutz des Urheberrechts großer Sprachmodells für die Einbettung von Diensten. Willkommen im Hintergrund! Wir werden zunächst das Hintergrundthema der Einbettungsdienste einführen. Derzeit sind große Sprachmodelle wie TPT-Lama-Palast sehr beliebt.</sample>
    <sample id="350">The presentation discusses the concept of 'superhuman performance' in today's scenario. It highlights that over the last five years, leaderboards have become the de facto standard in LP (leaderboard-based evaluation), with the main objective becoming to rank systems at the top spots in popular benchmarks. Notably, it occasionally occurs that systems achieve human-level or even superhuman performance in these benchmarks. The presentation is a collaborative effort involving several renowned researchers from various institutions worldwide.</sample>
    <sample id="351">The paper investigates the effectiveness of 'Connel 2003' for named entity recognition in 2023, observing that models continue to utilize it for development.</sample>
    <sample id="352">ABC-Eval ist ein neues-dimensionalales Ansatz zur Evaluierung von konversationalen AI.</sample>
    <sample id="353">Die vorliegende Präsentation beschäftigt sich mit der 'Python Code Generation by Asking Clarification Questions (PCGAC)', einem Programm, das durch die Befragung von Fragen zur Klärung von Informationen dazu beitragen soll, Python-Code automatisch zu generieren. Die Autoren dieses Papers sind穆罕默德·阿卜杜勒-拉赫曼·萨利姆, 莫扎特·马特林奇, 和艾琳娜·格里维茨。 Obwohl die Art und Weise, wie Code generiert wird, ein kontroverses Thema ist, haben bisherige Ansätze nicht den wichtigen挑战 angegangen, welcher darin besteht, Eingaben unter Spezifikation zu verarbeiten.</sample>
    <sample id="354">CoNLL-2003</sample>
    <sample id="355">Der englische Inhalt lautet: 'Hallo, mein Name ist Vasudha und ich bin ein Kandidat für einen Master in Computerwissenschaft an der University of Stony Brook. Ich würde gerne meine Arbeit vorstellen, die ich als Langpaper in ACL 2023 einreichen werde: Transfer-Lernen für die Erkennung von Dissonanz, indem wir uns mit dem seltenen Problem beschäftigen, das Dissonanz in Sprache zu studieren.'</sample>
    <sample id="356">Die Autoren sind an der University of Edinburgh angemeldet.</sample>
    <sample id="357">Der Referent ist Si Yuan von der Fudan-Universität.</sample>
    <sample id="358">Vier Autoren sind an der Arbeit beteiligt: Kayo Yan, Patrick Farnsworth, MEYU, und Andrae FT Martinez.</sample>
    <sample id="359">Der Ansatz wird mit einer SimulST-Architektur verglichen, bei der es um die Echtzeit-Übersetzung von gesprochenem Sprach ins Text in einer anderen Sprache geht.</sample>
    <sample id="361">The speech discusses 'countercomp', a method that uses counterfactual scenarios to improve compositional generalization for multi-step quantitative reasoning, particularly in question answering tasks involving financial tables.</sample>
  </task>
</testset>