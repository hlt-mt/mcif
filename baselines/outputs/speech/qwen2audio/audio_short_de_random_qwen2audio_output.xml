<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="de">
    <sample id="0">Lange scale web crawling data und politische Nachrichtenmedien wie New York Times, Los Angeles Times, The Guardian, Huffington Post usw. sind wichtige Datenquellen für Sprachmodelle.</sample>
    <sample id="1">Die Autoren sind von der University of Melbourne und Microsoft Research verbunden.</sample>
    <sample id="2">Hallo! Willkommen zu unserer Präsentation von 'deplane', einem neuen Quelltext für die German Text Annotation auf Dokumentebene und Satzebene.</sample>
    <sample id="3">Mein Name ist Regina Stodden, und ich werde Ihnen helfen, den ersten Teil der Präsentation zu verstehen. Lassen Sie uns zunächst definieren, was Textsimplifizierung bedeutet.</sample>
    <sample id="4">Textsicherung ist der Prozess, bei dem Text angepasst wird, um die Verständlichkeit für einen bestimmten Zweck zu verbessern, indem er auf spezielle Lesegruppen zugeschnitten wird, wie Menschen, die Probleme beim Lesen haben, oder Muttersprachler.</sample>
    <sample id="5">Um einen Textzuerkennungsdienst zu trainieren, benötigen wir entsprechende Paare von Texten, zum Beispiel aus Dokumenten oder Sätzen.</sample>
    <sample id="6">Beispiel: Hier kannst du ein paraleles Satzpaar aus einem komplexen deutschen Satz sehen und seine Übersetzung in einfache Sprache.</sample>
    <sample id="7">In diesem Beispiel sind verschiedene Techniken möglich, wie z.B. lemmatisierung, Klammerung, Klammerungsentfernung, Umordnung oder das Hinzufügen von Wörtern.</sample>
    <sample id="8">Wir schlagen jetzt unseren neuen Corporate City Plan vor, weil in den letzten Jahren einige Probleme mit dem bestehenden Corporate entstanden sind. Zum Beispiel sind diese Unternehmen hier zu klein, um ein Taxonomie-Modell zu trainieren.</sample>
    <sample id="9">Die anderen drei Modelle, die in den letzten Jahren vorgeschlagen wurden, sind alle automatisch ausgerichtet, was bedeutet, dass sie immer fehleranfällig in ihren Ausrichtungen sein können.</sample>
    <sample id="10">Daher schlagen wir unseren neuen Korpus 'd-Plan' vor, der in zwei Teile unterteilt ist: 'd-Plan API' und 'd-Plan Web'. Die 'd-Plan API' basiert auf Nachrichtentexten.</sample>
    <sample id="11">In der 'deepplane' API wurden 483 Dokumente manuell zugeordnet, was zu etwa 30.000 bis 13.000 paralellen Satzpaaren führt.</sample>
    <sample id="12">Für DeepFaceWeb beinhaltet dieses Corpus verschiedene Domains und wir haben alle 750 Dokumente auf der einen Seite manuell und auf der anderen Seite mit automatischen Ausrichtungsmethoden zugeordnet.</sample>
    <sample id="13">Insgesamt resultieren in 30450 Satzpaaren.</sample>
    <sample id="14">Wir haben unsere Satzpaare ein wenig mehr analysiert, zum Beispiel beim Typ von Identifizierung.</sample>
    <sample id="15">Wie Sie hier sehen können, sind die Bibeltexte viel stärker vereinfacht als zum Beispiel der Nachrichtentext oder die Sprachlernertexte.</sample>
    <sample id="16">Auf allen Ebenen, zum Beispiel bei der semantischen Verarbeitung von Worten, strukturierten Semantik und auch auf allgemeiner Ebene der Semantik.</sample>
    <sample id="17">Darüber hinaus kann man sehen, dass unser de plane Corpus eine hohe Häufigkeit von Differentiationstransformationen aufweist. Zum Beispiel hat das de plane API Corpus viel mehr Umordnungen und Textveränderungen als das de plane Web Corpus.</sample>
    <sample id="18">Auf der anderen Seite haben wir im Web-Corpus viel mehr Umformungen.</sample>
    <sample id="19">Lassen Sie uns jetzt sehen, was wir mit diesem Datensatz tun können.Hallo, ich bin Omer und jetzt werde ich über die Verwendungsfälle für unseren Datensatz sprechen. Also für den ersten Verwendungsfall können wir die automatischen Ausrichtungsmethoden evaluieren.</sample>
    <sample id="20">In den letzten Jahren wurden viele Verfahren zur Anpassung entwickelt, aber im Kontext der maschinellen Übersetzungen.</sample>
    <sample id="21">Wir haben zwei parallele Dokumente, die in verschiedenen Sprachen geschrieben sind und wir möchten Abhängigkeiten zwischen den Sätzen extrahieren.</sample>
    <sample id="22">In unserem Fall versuchen wir, Ausgleichungen zwischen den Sätzen zweier paralleler Dokumente zu extrahieren, die dieselbe Sprache haben, denselben Inhalt haben, aber auf unterschiedlichen Komplexitätsebene sind.</sample>
    <sample id="23">Und jetzt, da wir über unsere Daten haben, die in der Ebene geplant wurden und manuell angepasst wurden, können wir diese Sätze als Goldstandard-Abbildungen verwenden, um einige vorgeschlagenen Ausrichtungsmethoden zu evaluieren.</sample>
    <sample id="24">Wir haben einige Anpassungen an die vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen sowie die Codes, um unsere Experimente in dem Paper zu führen, veröffentlicht.</sample>
    <sample id="25">Am Ende kamen wir zu dem Schluss, dass die beste Methode zur automatischen Anpassung von Texten für die Germanisierung von Texten die Methode der Massenanpassung ist.</sample>
    <sample id="26">Es ist auch möglich, den Code zu finden, um diese Methode auf eigenen Dokumenten auszuführen.</sample>
    <sample id="27">Der zweite Fall, den wir in unserem Paper gezeigt haben, ist der Fall der automatischen Textsimplifizierung.</sample>
    <sample id="28">Durch das Finden von Sprachmodellen, um aus komplexen Texten vereinfachte zu erstellen.</sample>
    <sample id="29">Wir haben zwei verschiedene Modelle fine-tuned, ein Modell für lange Einheiten zur Erzeugung von Dokumentebene-Simplifizierungen.</sample>
    <sample id="30">Wir fügen auch den normalen Basiseinsatz hinzu, um Sentences zu vereinfachen.</sample>
    <sample id="31">Es ist auch möglich, alle Kontrollpunkte zu finden und weitere Details unter den Ergebnissen und Bewertungsmessungen unserer Experimente in dem Paper zu betrachten.</sample>
    <sample id="32">Wir haben zu dem Schluss gekommen, dass diese grundlegende Feinabstimmung möglicherweise bessere Ergebnisse liefert als die Pulslinienergebnisse.</sample>
    <sample id="33">Die Ergebnisse wurden als Leitlinie und Grundlage für das Problem der automatischen Textverdichtung in Zukunft vorgeschlagen.</sample>
    <sample id="34">Vielen Dank für Ihre Aufmerksamkeit und wir hoffen, Sie alle während der Konferenz zu treffen. Vielen Dank.</sample>
    <sample id="35">The speaker's name is Kay O Yen.</sample>
    <sample id="36">T5 large model.</sample>
    <sample id="37">Yes, the CoNLL-2003 tagger still works in 2023.</sample>
    <sample id="38">Die vorgeschlagene Methode reduziert die Subjektivität durch explizite Annotierung, ob jede Modellantwort bestimmte Verhaltensweisen ausdrückt, wie z.B. mit irrelevanten Informationen oder Widersprüchen.</sample>
    <sample id="39">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von sauberen Validierungssamples ab. Ohne saubere Validierungssamples können die Trends-Modelle nicht außerhalb der ursprünglichen Weak-Limits generalisieren, was bedeutet, dass das Training irrelevant ist.</sample>
    <sample id="40">Nur die Alternative ist angegeben, aber es fehlt eine Bewertung der Qualität oder einer Klarstellung der Fragestellung.</sample>
    <sample id="41">Zwei.</sample>
    <sample id="42">Hallo, mein Name ist Adam Skurkowski und dieser Vortrag handelt über die Abhängigkeitsstruktur der Koordination.</sample>
    <sample id="43">Wie Sie wissen, sind verschiedene Abhängigkeitsstrukturen durch verschiedene Theorien und Ansätze festgelegt worden, zum Beispiel die universelle Abhängigkeit mit der Struktur von Koordinaten, Koordinationsebene und Magie.</sample>
    <sample id="44">Es ist so, dass der erste Konjunktiv das Head eines ganzen Coordinatensystems ist. In diesem Fall ist es Lisa.</sample>
    <sample id="45">In der Texttheorie von Igor Miltuchov wird ein ähnlicher Ansatz verwendet, bei dem die Koordinatensstruktur durch das erste Konjunkt angeführt wird. So sind diese beiden Ansätze isomorph. Sie scheiden jedoch eines der Konjekte aus.</sample>
    <sample id="46">Es gibt auch symmetrische Ansätze zu kohärenten Koordinatstruktur, wie zum Beispiel den Prag-Approach, die Konjunktionshandlungen, die Humpty-Dumpty-Abhängigkeitstreebanken oder koordinierte Strukturen, die von der Konjunktion angeführt werden.</sample>
    <sample id="47">Also erhalten wir Abhängigkeiten von einem Ende bis hin zu allen Konjunkten.</sample>
    <sample id="48">Schließlich gibt es auch eine mehrfache Ansicht, die zum Beispiel in der Cut-Sense-Wörtergrammatik verwendet wird.</sample>
    <sample id="49">Wohin zum Beispiel alle Konsequenzen gehören, sind die Koordinatensysteme der Regeln. Wir erhalten Abhängigkeiten vom Governor hier, Love's bis hin zu allen Konsequenzen getrennt voneinander. Das sind wichtige Entscheidungen.</sample>
    <sample id="50">Die Aufgabe des Papers besteht darin, einen neuen Argument für symmetrische Strukturen der Koordination zu produzieren, wie zum Beispiel diese beiden und gegen asymmetrische Strukturen der Koordination wie diese hier.</sample>
    <sample id="51">Okay, das Argument basiert auf dem Prinzip der Abhängigkeit von der Auswahl, das ich anhand dieser Beispiele erläutern werde.</sample>
    <sample id="52">In English, as you might know, direct objects tend to be closed to the verb, while complements may be further away. So March read it yesterday is fine because the direct object 'it' is close to the verb 'read'.</sample>
    <sample id="53">Der englische Text übersetzt ins Deutsche ist: 'Während March gestern las, ist es viel schlechter, weil zwischen dem Verb und dem direkten Objekt ein Pronomen steht.'</sample>
    <sample id="54">Dieser Effekt kann jedoch bei einem direkt zugänglichen Objekt, das sehr schwer und lang ist, gemildert werden, da es dann auf die Position nach dem Eintrag verschoben werden kann.</sample>
    <sample id="55">Dies ist hier dargestellt. Deshalb sind beide Sätze in Ordnung. March hat heute ein absolut faszinierendes Buch über die Bienen gelesen. Es ist okay, dass statt 'it' wir 'this long and p' haben.</sample>
    <sample id="56">Aber es ist auch okay, zu sagen: 'March昨天读过这本关于蜜蜂的绝对迷人的书。'</sample>
    <sample id="57">Die Übersetzung des englischen Inhalts ins Deutsche ist: 'Der Grund hierfür ist, dass dies möglich ist, weil selbst wenn dieser Satz das grammatische Prinzip verletzt, wonach direkte Objekte neben dem Verb stehen sollten.'</sample>
    <sample id="58">Es erfüllt das Prinzip der Abhängigkeitslängenminimierung, wonach kürzere Abhängigkeiten bevorzugt werden.</sample>
    <sample id="59">Also zeigen diese beiden Bäume nur die Länge der wichtigen Abhängigkeiten, also diejenigen, die unter diesen beiden Strukturen nicht konstant sind.</sample>
    <sample id="60">Also haben wir hier die Abhängigkeit von 'red' bis hin zum 'adjunct of length seven', gemessen in Worten, und von 'red' bis hin zu 'book of length four'. Also zusammen sind es elf.</sample>
    <sample id="61">Wenn Sie sich bewegen, wenn Sie diese beiden Konstituenten austauschen, summiert sich die Anzahl dieser beiden Abhängigkeiten auf sechs. Recht? Statt elf ist es also viel kürzer. Deshalb klingt das quite okay, oder? Es verletzt eine Prinzipien, aber es erfüllt ein anderes.</sample>
    <sample id="62">Okay, also haben wir sehr gute Statistiken über die Koordination aus der erweiterten Version von Panthea extrahiert und das Paper gelesen, warum wir keine universellen Abhängigkeiten verwenden.</sample>
    <sample id="63">Und bestätigen diese Statistiken die Beobachtung, die viele Male zuvor gemacht wurde, dass links adjektive kürzer sind? Also Salz, Pfeffer und Senf gemessen in Silben.</sample>
    <sample id="64">Der englische Text lautet: 'Und auch die Beobachtung, die in der Vergangenheit gemacht wurde, dass diese Tendenz mit Längenunterschieden wächst.'</sample>
    <sample id="65">Also wenn der Unterschied zwischen den Längen der beiden Konjunktionen wächst, bevorzugt die kürzere Konjunktion die erste zu sein, richtig? Die Proportion ist also größer bei dem linken kurzen Konjunktion.</sample>
    <sample id="66">Aber was neu ist in diesem Artikel, ist dass wir beobachtet haben, dass diese Tendenz nur dann auftritt, wenn die Regierung auf der linken Seite fehlt.</sample>
    <sample id="67">In diesem Beispiel ist der Gouverneur auf der linken Seite.</sample>
    <sample id="68">In Beispiel 2 ist 'Homer kam und schnaubte'. Hier haben wir die Koordinierung von zwei Verben, und es gibt keine äußere Kontrolle. Also in solchen Fällen bevorzugt der linke Konjunktive, um kürzer zu sein. Auch der größte Unterschied zwischen den beiden.</sample>
    <sample id="69">Wenigerstens in folgenden Fällen tritt dieser Effekt auf: Wenn die Regierung auf der rechten Seite ist, wie hier in Lothringen, regiert das Koordinationsamt.</sample>
    <sample id="70">Wir haben gezeigt, dass die erste Spalte in Silben, die mittlere Spalte und die rechte Spalte Längen in Zeichen aufweisen. Deshalb konzentrieren wir uns auf die rechte Spalte.</sample>
    <sample id="71">Was wir hier sehen, ist, dass wenn die Regulierung auf der linken Seite ist...</sample>
    <sample id="72">Die Tendenz, dass die linksgelegene Konjunktion kürzer wird, wächst ständig mit der absoluten Differenz an Wörtern, und das ist auch bei der Verwendung von 'snow governor' in Sätzen zu beobachten. Doch wenn der Governor rechts steht, verschwindet diese Tendenz.</sample>
    <sample id="73">In dem Artikel zeigen wir, wie dies eine Argumentation gegen asymmetrische Strukturen der Koordination liefert, indem es diese zwei symmetrischen Strukturen gegenüberstellt.</sample>
    <sample id="74">Sehen Sie sich das Papier für den vollständigen Vertrag und die Argumente an, und sprechen Sie uns danach über die Nachbesprechung. Vielen Dank.</sample>
    <sample id="75">Zwei.</sample>
    <sample id="76">Die Bibeltexte werden stärker vereinfacht als der News-Text oder andere Sprachlernertexte.</sample>
    <sample id="77">Soil and pepper, not pepper salt.</sample>
    <sample id="78">Ja, die Modelle sind für Forschungszwecke verfügbar.</sample>
    <sample id="79">DEplain-apa beinhaltet Dokumente aus dem Internet, die auf APA-Formatierung basieren.</sample>
    <sample id="80">Eine bessere Modellarchitektur, größere Modellgrößen sowie mehr präzise Beispiele sind für eine gute Generalisierung notwendig.</sample>
    <sample id="81">Die Tendenz zu kürzeren linken Konjunktionen wurde durch die Messung der Länge in Buchstaben in den ersten Spalten (Syllable, Middle, Right) berechnet.</sample>
    <sample id="82">Die Experimente wurden durchgeführt, indem Längen in Zeichen, Silben und Worten gemessen wurden, wobei der Schwerpunkt auf der rechten Spalte lag.</sample>
    <sample id="83">Der Basisklassifikator performs not much better than chance.</sample>
    <sample id="84">Ein Autor.</sample>
    <sample id="85">Bob und Alice.</sample>
    <sample id="86">Kontextsensitive MÜ-Modelle sind bei formalität und lexical cohesion signifikant più accurate als kontextagnostische Modelle.</sample>
    <sample id="87">Die Autoren sind Studenten oder Mitarbeiter an der University of Cambridge.</sample>
    <sample id="122">Das Framework quantifiziert die Positionalität mithilfe von Annotatoren, indem es Daten sets mit verschiedenen Annotatoren reAnnotations durchführt.</sample>
    <sample id="155">Es wurde gefunden, dass die menschen Teilnehmer auch in der Lage waren, rassische Stereotypen zu surface.</sample>
    <sample id="156">Die Studie verwendete die erweiterte Version von PanTREB und eine Papierrolle, um Statistiken über Koordination zu sammeln.</sample>
    <sample id="157">Ein Autor.</sample>
    <sample id="158">The related tasks for cognitive dissonance are topic independent dissonance stance classification and binary classification of expansion and comparison classes of PNTB.</sample>
    <sample id="159">Ein Autor.</sample>
    <sample id="160">Eine Person.</sample>
    <sample id="161">Das vorgestellte Framework unterscheidet sich durch die Vergleichung von Endbenutzern mit Modellen und Datenbanken, Vorhersagen und Etiketten, im Gegensatz zu bisherigen Arbeiten, die sich auf annotatorische Übereinstimmung oder Modellierung von annotatorischen Verteilungen konzentrieren.</sample>
    <sample id="162">Das erste Setup hat die meisten Überschneidungen mit dem Lexikon der Stereotypen.</sample>
    <sample id="163">Die genauen Namen der kommerziellen Systeme wurden nicht genannt, nur dass sie miteinander verglichen wurden.</sample>
    <sample id="164">Hallo, ich bin Shangbin, ein Promovierter Student an der University of Washington. Heute präsentiere ich unsere Arbeit von den Vor-Trainingdaten bis hin zu Sprachmodellen und nachgelagerten Aufgaben wie dem Verfolgen von Spuren politischer Vorurteile, die zu unfairen NLP-Modellen führen können.</sample>
    <sample id="165">Die Sprachmodelle werden an großen Web-Crawl-Daten trainiert.</sample>
    <sample id="166">Laut einer Umfrage des C4 Corpus sind politische Nachrichtenmedien wie New York Times, Los Angeles Times, The Guardian und Huffington Post in ihren Sprachmodell-Trainingsdaten gut abgedeckt.</sample>
    <sample id="167">Dies hat zu einer gemischten Freude für die Anwendungen des Sprachmodells geführt.</sample>
    <sample id="168">Der englische Text beschreibt, dass einerseits aus verschiedenen Perspektiven gelernt werden kann, was die Demokratie und die Vielfalt von Ideen feiert. Andererseits sind diese verschiedene politischen Meinungen jedoch inherent sozial geprägt, dass sie potentielle Fairnessprobleme in Downstream-Tasks verursachen könnten.</sample>
    <sample id="169">Wir schlagen vor, die politische Vorurteilspropagationskette von den Vorbereitungsdaten bis hin zu Sprachmodellen und dann zu Downstreamaufgaben zu untersuchen, indem wir folgende Fragen stellen.</sample>
    <sample id="170">Der englische Inhalt lautet: 'Zunächst einmal, wie beurteilen wir die politische Ausrichtung von Sprachmodellen und welchen Einfluss kann das vorliegende Datenmaterial auf solche politischen Vorstellungen haben?'</sample>
    <sample id="171">Zweitens, wie sich Sprachmodelle mit verschiedenen politischen Ansichten tatsächlich auf Downstreamaufgaben auswirken und ob dies zu Ungleichheiten in NLP-Anwendungen führen kann.</sample>
    <sample id="172">So speziell schlagen wir vor, präzise Sprachmodelle mit verschiedenen vorgegebene Formaten zu verwenden, indem wir die politischen Fragebögen verwenden, wie zum Beispiel den Political Compass Test. Das gewährleistet uns eine automatische Bewertung basierend auf wissenschaftlicher Literatur aus der Politikwissenschaft.</sample>
    <sample id="173">Einige vorläufige Ergebnisse zeigen, dass Sprachmodelle tatsächlich politische Ausrichtungen haben und sich in allen vier Quadranten des politischen Kompasses bewegen.</sample>
    <sample id="174">GPT-4 ist die liberaleste Sprachmodell unter ihnen alle und GPT-Theorien sind im Allgemeinen sozialliberaler als BERT-Theorien und ihre Varianten.</sample>
    <sample id="175">Zweitens beabsichtigen wir, zu untersuchen, bis zu welchem Grad die politischen Vorurteile in Sprachmodellen tatsächlich aus der Trainingsdaten extrahiert werden.</sample>
    <sample id="176">Der englische Inhalt lautet: 'Wir könnten also eine kontrollierte Experimente durchführen, indem wir sechs verschiedene parteiliche Quellen unterteilen, die in Nachrichten und sozialen Medien geteilt sind und weiter in ihre politischen Richtungen unterteilt werden.'</sample>
    <sample id="177">Durch weitere Vorbereitung von Sprachmodellen auf solche Parteien können wir sehen, dass sich die ideologischen Koordinaten der Sprachmodelle entsprechend ändern.</sample>
    <sample id="178">Zum Beispiel kann man bei Robert, der weiterhin auf der Linken orientiert ist und in Bezug auf die Reddit-Korpus weiter trainiert wurde, einen erheblichen linken Meinungsumschwung feststellen.</sample>
    <sample id="179">In Bezug auf seine politischen Vorurteile.</sample>
    <sample id="180">Wir versuchen auch zu untersuchen, ob Sprachmodelle die in unserer modernen Gesellschaft verbreitete Polarisierung erkennen können.</sample>
    <sample id="181">Der englische Inhalt lautet: 'Wir teilen die Vorbereitungsdaten für Korpura in zwei Gruppen ein: vor dem 45. Präsident der Vereinigten Staaten und nach dem 45. Präsidenten der Vereinigten Staaten. Dann trainieren wir separate Sprachmodelle für die beiden verschiedenen Zeitperioden.'</sample>
    <sample id="182">Der englische Inhalt lautet: 'Wir können sehen, dass Sprachmodelle im Allgemeinen eine politische Ausrichtung haben, die weiter von der Mitte entfernt ist. Nach dem Jahr 2017 zeigt dies an, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufnehmen können.'</sample>
    <sample id="183">Der englische Text lautet: 'So zuletzt, aber nicht是最 kleinste, evaluieren wir Sprachmodelle mit verschiedenen politischen Ausrichtungen bei der Erkennung von Hassreden und Falschnachrichten in NLP-Anwendungen, die oft Sprachmodelle verwenden und sehr wichtige Auswirkungen haben könnten.'</sample>
    <sample id="184">Wenn wir die Leistung nach Kategorie untersuchen, sagen wir, wenn wir die Leistung in zwei Teile unterteilen.</sample>
    <sample id="185">Different Demografien oder politische Linien in den Nachrichtenmedien können dazu führen, dass beispielsweise bei der Erkennung von Hetzreden linksorientierte Sprachmodelle besser sind.</sample>
    <sample id="186">Die Formulierung des englischen Inhalts lautet: 'Beim Erkennen von Hetzrede, die sozial benachteiligte Gruppen ansprechen.'</sample>
    <sample id="187">Der englische Inhalt lautet jedoch: 'Allerdings sind wir schlechter darin, Hassreden zu erkennen, die sich gegen mächtigere Gruppen in unserer Gesellschaft richten.'</sample>
    <sample id="188">Der englische Inhalt lautet: 'Und umgekehrt. Rechtlich gesehen sind Sprachmodelle besser darin, Hassrede gegen Weiße und Männer zu erkennen, jedoch schlechter darin, Hassrede gegen Schwarze, LGBTQ+ und andere Minderheiten zu erkennen.'</sample>
    <sample id="189">类似的情况也发生在假新闻检测中，我们发现左翼语言模型在检测与其对立的政治倾向的虚假新闻时表现更好，反之亦然。</sample>
    <sample id="190">In diesem Abschnitt werden wir Ihnen viele qualitative Beispiele zeigen, um zu zeigen, dass Sprachmodelle mit verschiedenen politischen Überzeugungen unterschiedliche Bedeutungen haben.</sample>
    <sample id="191">Geben Sie verschiedenen Vorhersagen für Hassreden und Missinformationen basierend auf ihren sozialen Kategorien. Es gibt noch mehr Beispiele in der Anhangsliste, um dies zu unterstreichen.</sample>
    <sample id="192">Dies zeigt, dass es ein公平ness-Problem gibt, das sehr dringend hinsichtlich der politischen Vorurteile von Sprachmodellen besteht.</sample>
    <sample id="193">Zum Beispiel, wenn rechtsgerichtete Sprachmodellien bei der Finanzierung von Hassreden, Falschinformationen usw. beteiligt wären und auf einer beliebten sozialen Medien-Plattform eingesetzt würden.</sample>
    <sample id="194">Dies würde bedeuten, dass Menschen mit oppositionellen politischen Ansichten möglicherweise marginalisiert werden und die Hetzrede, die sich an Minderheitengruppen richtet, möglicherweise ohne Kontrolle weiterhin grassieren könnte.</sample>
    <sample id="195">Der englische Text lautet: 'Dies hat uns alarmiert, die Fairnessprobleme anzuerkennen und anzugehen, die durch Sprachmodell-Politiken entstanden sind.'</sample>
    <sample id="196">Ein bisschen Diskussion, wir möchten auch hervorheben, dass wir das einzigartige Dilemma hinsichtlich der Sprachmodell-Politischen Vorurteile darstellen würden. Es ist wie zwischen dem und dem.</sample>
    <sample id="197">Wenn wir politische Meinungen in Sprachmodellierung nicht filtern, wird die Vorurteile von der Vorbereitungsdaten zu den Sprachmodellen und letztendlich zu Downstreamaufgaben verbreitet, was公平nessprobleme verursacht.</sample>
    <sample id="198">Wenn wir versuchen, uns irgendwie zu hygienisieren, riskieren wir auch Zensur oder Exklusion. Es ist unglaublich schwer, festzustellen, was tatsächlich neutral ist und was beibehalten sollte. Sprachmodellierungsinformationen. Es ist ein bisschen wie das elektrische Problem mit der Elektrolyse.</sample>
    <sample id="199">Okay, großartig. Ich denke, das ist es dann auch von mir. Heute hatte ich genug. Vielen Dank für Ihre Zeit!</sample>
    <sample id="200">Zusammen mit meinen Kollegen von Google Translate.</sample>
    <sample id="201">2024</sample>
    <sample id="202">Die genauen Domains, die in ihrem Datensatz enthalten sind, wurden nicht erwähnt.</sample>
    <sample id="203">Positionalität ist die Perspektive, die Menschen aufgrund ihrer Demografie, Identität und Lebenserfahrungen haben.</sample>
    <sample id="204">The speaker's name is David.</sample>
    <sample id="205">Ja, es ist möglich, EDAtt mit einem bereits existenten Offline-ST-Modell zu verwenden, ohne es zu trainieren oder anzupassen. Es reicht aus, nur ein Modell für jede Latenzregel zu verwenden und die Latenz durch spezifische Parameter zu steuern.</sample>
    <sample id="206">Ein Autor.</sample>
    <sample id="207">Nein, es funktioniert nicht gut.</sample>
    <sample id="208">Die drei Varianten von KITMUS sind: Typ-1-Setting (Hintergrundwissen vor dem Training), Typ-2-Setting (Hintergrundwissen verfügbar sowohl vor als auch nach dem Training) und Typ-3-Setting (kein Hintergrundwissen vor dem Training, nur während des Trainings verfügbar).</sample>
    <sample id="209">Die Autoren besitzen keine spezifische Universität, sondern arbeiten an der Stanford University.</sample>
    <sample id="210">Sollten nur saubere试样 für die Validierung verwendet werden, oder gibt es bessere Methoden, sie zu verwenden?</sample>
    <sample id="211">Die Sensitivitätmetrik misst die Fähigkeit des Modells, immer dasselbe Ergebnis für die gleiche Aufgabe zu erzeugen, unabhängig von轻微en Veränderungen in der Anweisung.</sample>
    <sample id="212">Jingwei Yi</sample>
    <sample id="213">Eine höhere Sensitivität bedeutet in diesem Kontext eine bessere Leistung des Modells.</sample>
    <sample id="214">The models receive linguistic context from the joint work with John Gottlieb, Aaron Miller, Kanishka Mishra, Karin Fuentes, Roger Levy, and Atina Williams.</sample>
    <sample id="215">Normalerweise werden nur 20 saubere Validierungsbeispiele pro Klasse benötigt, um eine gute Leistung an der WSL zu erzielen.</sample>
    <sample id="216">Die Autoren sind an der University of Pennsylvania tätig.</sample>
    <sample id="217">Es ist notwendig, neue Methoden zur Messung von Medienverzerrungen zu entwickeln, da bestehende Methoden möglicherweise nicht ausreichend genau oder objektiv sind.</sample>
    <sample id="218">Der Referent ist Makshata.</sample>
    <sample id="219">Die Pipeline beginnt mit vorherigen Daten, geht über Sprachmodelle und endet bei Downstream-Tasks.</sample>
    <sample id="220">Ja, der Vereinfachungsprozess ist bei DEplan-apa mit vielen Umstellungen (Reorderings und Wortänderungen) und beim Web-Corpus mit vielen Umformungen (Umschreibungen) unterschiedlich.</sample>
    <sample id="221">Coscript ist offen zugänglich, da es als Python-Modul bereitgestellt wird und auf GitHub unter einer Open-Source-Lizenz verfügbar ist.</sample>
    <sample id="222">Das Wasserzeichen wird durch eine weight summation der Target-embedding und dem Original-embedding definiert, wobei die Gewichtung proportional zum Anzahl der Triggers in der Sentence ist. Wenn die Anzahl der Triggers größer als M ist, entspricht die angebotene Einbettung exactly dem Target-embedding.</sample>
    <sample id="223">Purdue University.</sample>
    <sample id="224">Ja, durch das Training in einer Mischung von Sprachen können Encoder-Decoder-Modelle wie mt5 verbessert werden.</sample>
    <sample id="225">Ein Beispiel für eingeschränkte Sprachplanung ist das Planen, wie man eine Schokoladenkuchen backt.</sample>
    <sample id="226">Sie validieren die Opazität durch die Verwendung von Faktoren wie der Anzahl der Wörter pro Zeile (FPA) und dem Legendre-Index der Figuren.</sample>
    <sample id="227">The work uses existing PLMs to build a new PLM by integrating them with the help of a comparison and three models trained on continuous pretraining.</sample>
    <sample id="228">GPT-4 ist am wenigsten ausgerichtet auf China.</sample>
    <sample id="229">The sentence 'and you can see an example on the right' does not provide enough context to determine which model is being referred to or what specific knowledge it has acquired through the attention mechanism.</sample>
    <sample id="230">Die Anzahl der Aufgaben erhöht die Leistung des Modells und führt zu einer geringeren Sensitivität im Mittelzeitraum.</sample>
    <sample id="231">Die Autoren vergleichen ihre Methode mit anderen baumlosen Modellen auf der Coggs-Benchmarke.</sample>
    <sample id="232">Alexander Coler und Ivan Tietze sind die Co-Autoren des ersten Autors.</sample>
    <sample id="233">The first author of PaLM is Jakob Uszkoreit.</sample>
    <sample id="234">Hallo alle, ich bin Jennie, ein erster Jahr PCh-Studierender an der Columbia University und heute werde ich meine Arbeit und meine Position präsentieren. Charakterisierung von Design-basierten CIs-Modellen.</sample>
    <sample id="235">Dieses Werk wurde in Zusammenarbeit mit einigen Leuten an der University of Washington und dem Alan Institute for AI, namentlich Sebastian Santi, Ronan Le Bras, Katerina Rinica und Martin Sap, durchgeführt.</sample>
    <sample id="236">Also lass uns beginnen, indem wir vorstellen, dass du für eine Zeitung arbeitest und du durch die Kommentare zu deinem Artikel im News- Archiv schiebst, um giftige Inhalte zu entfernen.</sample>
    <sample id="237">Du könntest dich zu einem beliebten API wie Perspective API für Toxizitätsdetection wenden, und das funktioniert wirklich gut, wenn du Carl Jones bist, bei dem Perspective API korrekt toxische Verbindungen erkennen kann.</sample>
    <sample id="238">Aber das ist wirklich nicht der Fall bei Adithya Sharma, bei dem Perspektiv-APIs nicht sehr empfindlich gegenüber offensiven Begriffen sind, die in indischen Kontexten häufig verwendet werden.</sample>
    <sample id="239">Dies ist ein Beispiel für 'designed bias', bei dem wir systematische Leistungsdifferenzen zwischen den Bevölkerungen feststellen können.</sample>
    <sample id="240">Entsprechend dem obigen Text lautet der deutsche Inhalt: 'Designfehler wie jener, den wir刚才 betrachteten, könnten durch die Positioniertheit von NLTK- Forschern und Modellentwicklern entstehen. Positioniertheit ist einfach die Perspektive, die Menschen als Ergebnis ihrer Demografie, Identität und Lebenserfahrungen haben.'</sample>
    <sample id="241">Dies ist ein Begriff, der in kritischen Studien häufig verwendet wird, insbesondere in feministischen und queer Studies-Räumen.</sample>
    <sample id="242">Als Forscher kann die Positionalität Einfluss auf den Forschungsprozess und dessen Ergebnisse haben, da sie die Entscheidungen beeinflussen kann, die Forscher treffen.</sample>
    <sample id="243">Ein Fragestellung könnte lauten: Haben Datensätze und Modelle Positionalität?</sample>
    <sample id="244">Die modellbasierten Ansätze und Datensätze selbst haben keine demografischen Identitäten und Lebenserfahrungen, sondern sie sammeln Urteile und Meinungen von echten Menschen und können so bestimmte Positionalitäten gegenüber anderen darstellen.</sample>
    <sample id="245">Die vorherige Arbeit hat einige anekdotische Beweise für die Existenz von Positionalität gezeigt, wie kulturellen Unterschieden in Modellen und Datensätzen sowie thetheoretischen Definitionen der Modellpositionalität.</sample>
    <sample id="246">Diese Arbeiten untersuchen jedoch nicht die Verwendung von Benutzern mit den Datenbanken und Modellen selbst.</sample>
    <sample id="247">Der Inhalt des Audios lautet: 'Die Modellierung von Datensätzen und Positionierungen wird zunehmend wichtiger, da die OLAP-Tests immer selektiver und sozialer ausgerichtet werden.'</sample>
    <sample id="248">Es ist schwierig, wie diese Positionalitäten verschoben sind zu charakterisieren, da nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter API-Schaltern verborgen sind.</sample>
    <sample id="249">Um die Datensatz- und Modellpositionalität zu studieren, vergleichen wir tatsächlich die Anmerkungen mit echten Benutzern und bestehenden Datensätzen und Modellen.</sample>
    <sample id="250">Wir tun das über unser Framework und die Positionierbarkeit von NLP.</sample>
    <sample id="251">Unser Framework arbeitet in zwei Hauptschritten.</sample>
    <sample id="252">Der erste Schritt besteht darin, Datensätze mit verschiedenen Annotatoren erneut zu annotieren.</sample>
    <sample id="253">Wir sollten das überprüfen, indem wir die Demografien der ursprünglichen Datensätze, Annotatoren betrachten, weil in der Regel nur wenige Annotatoren jedes Instance annotieren und weil die Demografien selten gesammelt und geteilt werden.</sample>
    <sample id="254">Also müssen wir Daten re-annotieren, um viele Anmerkungen zu erhalten, zum Beispiel und um ein reiches Set an demografischem Daten zu erhalten.</sample>
    <sample id="255">Wir nehmen dann die Anmerkungen nach dem Demografie-Prinzip und vergleichen sie mit den Modellen und Datenbanken mithilfe der Korrelationsscore für das Erscheinen.</sample>
    <sample id="256">Unser Framework unterscheidet sich tatsächlich von der Literatur zur annotierten Disagreement, indem es Endbenutzer mit Modellen und Datenbanken vergleicht, Vorhersagen und Etiketten, während sie sich nur auf die annotierte Übereinstimmung oder das Modellieren von Etikettierungsverteilungen konzentrieren.</sample>
    <sample id="257">Unser Framework wird hauptsächlich durch Lab in der Welt unterstützt, eine Online-Plattform fürCrowdsourcing und früher Teil des HCI-Konsortiums.</sample>
    <sample id="258">Laten uns in der Wildnis ist ein Online-Experimentierungsplatform, auf der wir verschiedene Freiwillige rekrutieren können, verglichen mit Plattformen wie Mturk, die hauptsächlich Teilnehmer aus den USA oder Indien haben. Darüber hinaus kann Lassen Sie uns in der Wildnis immer noch high-quality-Daten sammeln.</sample>
    <sample id="259">Wir veranstalten zwei Aufgaben in der Wildnis, darunter die soziale Akzeptanz. Die Teilnehmer lesen eine Situation aus dem Datensatz zur Sozialchemie und schreiben dann darüber, wie sozial akzeptabel diese Situation ist.</sample>
    <sample id="260">Um sich an einem Projekt zu beteiligen, können sie ihre Antworten mit denen anderer vergleichen.</sample>
    <sample id="261">Wir verglichen dann diese Annotierungen mit der Sozialchemie, Delphi und GPDT.</sample>
    <sample id="262">Wir haben dann eine sehr ähnliche Einrichtung für die Überwachung von Toxizität und Hassreden erstellt, bei der die Teilnehmer ein Beispiel aus 'Diana Hates' lesen und schreiben, ob sie denken, dass es sich um einen Fall von Hassreden handelt.</sample>
    <sample id="263">In der Studie wurden mehr als 16.000 Anmerkungen von über 1.000 Verfassern aus 87 Ländern gesammelt.</sample>
    <sample id="264">Also sind wir nun bereit, zu antworten: Welche Datenbankmodelle entsprechen am besten NLP-Datenbanken? Wir finden heraus, dass es Positionalität in NLP gibt.</sample>
    <sample id="265">Zum Beispiel finden wir, dass Datensätze und Modelle in den meisten Fällen englischsprachigen Ländern zugeordnet werden. Für die GPD-Forsauchanalyse finden wir, dass sie am stärksten mit Konfuzius und englischsprachigen Ländern verbunden ist. Wir finden auch, dass 'Dina-Hate' ebenfalls in englischsprachigen Ländern am häufigsten vorkommt.</sample>
    <sample id="266">Wir finden auch, dass die Mehrheit der zusätzlichen Übereinstimmung mit Menschen besteht, die eine College-Ausbildung haben.所以在社会可接受性任务中，我们发现它与拥有大学教育或研究生学位的人最相符。</sample>
    <sample id="267">Und wir finden dasselbe für Donna, wo es am meisten mit Menschen zusammenhängt, die eine College-Ausbildung haben.</sample>
    <sample id="268">Wenn Modelle und Datensätze jedoch mit spezifischen Bevölkerungsgruppen verknüpft sind, werden einige unweigerlich zurückgelassen.</sample>
    <sample id="269">Ein Beispiel dafür ist, dass Datensätze und Modelle bei Nichtbürgerinnen nicht so eng mit ihnen verknüpft sind wie bei ihren männlichen und weiblichen Gegenstücken. Wir finden dies in der GPT4-Sozialakzeptanzaufgabe sowie in der Dyna-Heat-Analyse wieder.</sample>
    <sample id="270">Wenn also eine Stelle in der Lady DLP besetzt ist, was können wir tun?</sample>
    <sample id="271">Wir haben einige Empfehlungen für das. Erstens sollten Sie alle relevanten Designentscheidungen während des Forschungsprozesses aufzeichnen, und zweitens sollten Sie eine NLP-Recherche unter dem Gesichtspunkt der Perspektivität durchführen.</sample>
    <sample id="272">Unser drittes Empfehlung ist, spezialisierte Datenbanken und Modelle innerhalb von vier spezifischen Gemeinschaften zu erstellen. Ein gutes Beispiel dafür ist die Musashi-Initiative. Ich meine, wir möchten betonen, dass eine inklusive NLP nicht nur alle Technologien für jeden funktionieren lässt.</sample>
    <sample id="273">Das beinhaltet unsere Präsentation, aber wenn Sie mehr erfahren möchten, können Sie gerne unser Dashboard für die neuesten Analyseergebnisse und unseren Paper überprüfen. Vielen Dank!</sample>
    <sample id="274">Die Referentin geht auf vier Probleme von SimulST ein: spezifische Architekturen, die normalerweise trainiert werden müssen, die Einführung zusätzlicher Modulen zum Optimieren, lange und komplizierte Trainingsverfahren sowie das Trainieren und Wartung mehrerer Modelle für unterschiedliche Latenzregeln.</sample>
    <sample id="275">Die Reduzierung von sozialen und politischen Verzerrungen in Datensätzen beim Training von NLP-Modellen kann durch die sorgfältige Auswahl und Vorbereitung von Trainingsdaten erreicht werden, um sicherzustellen, dass sie neutral und repräsentativ sind. Es ist auch wichtig, dass die Methoden zur Verarbeitung und Bewertung der Daten transparent und nachvollziehbar sind.</sample>
    <sample id="276">Hallo, ich bin Si Yu Yuan von der Fudan-Universität. Ich bin hier, um unsere Arbeit zu präsentieren, die die Unterscheidung zwischen skriptenmächtigen und großen Sprachmodellen für konstrained language planning betreibt.</sample>
    <sample id="277">In der Alltagsität planen Menschen ihre Handlungen, indem sie sich nach vorgegebenen Anweisungen bewegen.</sample>
    <sample id="278">Ein früherer Artikel hat untersucht, wie Sprachmodelle verwendet werden können, um abstrakte Ziele für stereotypische Aktivitäten zu planen, wie zum Beispiel das Backen eines Kuchens, und gezeigt haben, dass große Sprachmodelle es effektiv tun können, Ziele in Schritte zu zerlegen.</sample>
    <sample id="279">Der englische Text besagt folgendes in deutscher Übersetzung: 'Allerdings konzentrierten sich die früheren Arbeiten hauptsächlich auf die Planung für abstrakte Ziele der theoretischen Aktivitäten, während die Planung für spezifische Ziele mit bestimmten Bedingungen, wie zum Beispiel das backen eines Schokoladenkuchens, immer noch unterentwickelt ist.'</sample>
    <sample id="280">In diesem Artikel definieren wir das Problem der eingeschränkten Sprachplanung.</sample>
    <sample id="281">规划者应该遵循合理的、对约束条件来说公正的原则。</sample>
    <sample id="282">In diesem Paper werden wir zunächst die beschränkte Sprachplanungsfähigkeit großer Modell evaluiert und verbessern.</sample>
    <sample id="283">Es gibt außer spezifischen Daten keine Belege für unsere These.</sample>
    <sample id="284">Wir müssen diese Regeln zuerst erlernen und wie in der Tabelle gezeigt, erweitern wir die abstrakten Regeln mit multiplen Bedingungen für die Datenacquisition für menschen im Look-up-Verfahren.</sample>
    <sample id="285">Lassen Sie uns eine Auswahl von 100 spezifischen Fragen erstellen und die generierten Skripte aus großen Modellen evaluieren.</sample>
    <sample id="286">Dieser Tisch gibt die Gesamtgenauigkeit der Ergebnisse wieder. Wir finden heraus, dass alle lineare Modell erzielen zufriedenstellende Ergebnisse bei der Planung für spezifische Ziele.</sample>
    <sample id="287">Dann führen wir eine detaillierte Analyse durch, um zu untersuchen, warum Leistungsmodelle fallen.</sample>
    <sample id="288">Die Ergebnisse in der Grafik zeigen, dass die semantische Vollständigkeit in generierten Skripten akzeptabel ist, aber die Treue zu den Konventionen kann nicht garantiert werden.</sample>
    <sample id="289">Wir haben uns in eine mehrgradige taxonomische Kategorie von Einschränkungen für das Wachstum einarbeiten können, die im Diagramm der Hauptmappe gezeigt werden. Die Planungsleistung von Lehrern variiert erheblich für Mädchen aus verschiedenen Kategorien.</sample>
    <sample id="290">Die vorherigen Studien haben gezeigt, dass die Ausgangsqualität von Lattice-Modellen in hohem Maße variabel ist, was zu schlechten Leistungen führt. Daher verwenden wir die Idee des überproduzierten then-Filters zur Verbesserung der Erzeugungsgüte.</sample>
    <sample id="291">Der englische Text lautet: 'Wir zeigen zuerst, welche Konstantentypen mit Beispielen für Integrale über CPT belegt sind und erhalten spezifische Abschätzungen basierend auf diesen saiden abstrakten Abschätzungen.'</sample>
    <sample id="292">Dann leiten Sie GPT über die Erstellung von Klassen描述 für eine spezifische Funktion.</sample>
    <sample id="293">Ein weiteres Filtermodell wird entwickelt, um die glücklichen Scripts auszuwählen.</sample>
    <sample id="294">Wir konvertieren Skripte und Go-Code in einfache GPB-Integrale und berechnen die Cosine-Similarity als Similaritätsscore, um die semantische Ähnlichkeit zu messen.</sample>
    <sample id="295">Insgesamt werden wir die Schrift auswählen, die die Schlüsselwörter des Zieles enthält. Wir behalten die Schrift nur, wenn das Zielkind in der Gesamtwertung am höchsten ist.</sample>
    <sample id="296">Mit unserem Verfahren kann Integrität generieren von Haar mit höherer Qualität. Unser Verfahren verbessert die Planbarkeit, sowohl in der Semantik als auch in der Treue zu den Konventionen.</sample>
    <sample id="297">Da Sprachmodell hohe Kosten verursachen, ist es wichtig, die Fähigkeit zu ermöglichen, kleine und spezialisierte Sprachmodelle auszuführen. Das Erstellen eines Datensatzes ist ein wichtiger Schritt dazu.</sample>
    <sample id="298">However, previous studies do not aim to plan for specific goals, and manual annotation is expensive.</sample>
    <sample id="299">Wir folgen der Idee der symbolischen Knowledge Distillation, um konstrainede Sprachplanungsdatenquellen aus groß angelegten Modellen zu distillieren.</sample>
    <sample id="300">Wir werden unser Verfahren zur Erstellung eines Daten sets von konservierten Sprachplänen anwenden, das als Co-Script bezeichnet wird.</sample>
    <sample id="301">Insgesamt generieren wir 5500 spezifische Tests mit Skripten, um die Qualität der Überprüfung und der Teststellen zu gewährleisten. Wir bitten also externe Arbeitskräfte, die fehlerhaften Beispiele zu überprüfen und zu korrigieren.</sample>
    <sample id="302">Dieses Diagramm zeigt die konstrained Verteilung von Co-Script. Wir finden, dass Co-Script das hohe Adel in der generierten spezifischen Sprache zeigt. Mit Co-Script können wir kleinerere, aber spezialisierte Modelle für constrained language planning verwenden.</sample>
    <sample id="303">Wir haben herausgefunden, dass T-5L-Finetune auf einer Geschwindigkeit von 300 RPM卷须qualität generieren kann, die höher ist als die meisten großen Modellen, was darauf hinweist, dass kleinere Modelle größeren Modellen bei richtiger Trainingsdaten überlegen sein können.</sample>
    <sample id="304">Wir haben das Problem der beschränkten Sprachplanung etabliert, die Fähigkeit der großen Sprachmodelle zur beschränkten Sprachplanung ausgewiesen und einen über-generierten Filtermethoden für große Sprachmodelle entwickelt.</sample>
    <sample id="305">Wir verwenden große Sprachmodell, um einen qualitativ hochwertigen Skriptdatensatz für die Konzeption von Sprachen zu generieren. Wir hoffen, dass der Code-Scipt-Datensatz als wertvolles Ressourcen zur Verbesserung der Forschung zu Sprachplanung verfügbar sein wird.</sample>
    <sample id="306">Vielen Dank für Ihre Zeit! Bitte finden Sie mehr Details im von Ihnen verwendeten Dokument.</sample>
    <sample id="307">Die Sprachgewandtheit von PaLM ist vergleichbar mit der Stärke anderer Systeme.</sample>
    <sample id="308">Das Wasserzeichenverfahren muss anpassbar sein für eingebettete Dienste, das Wasserzeichen darf die Benutzerfreundlichkeit der bereitgestellten Einbettungen nicht verringern, es sollte genügend konvertiert sein, damit der Angreifer es leicht entfernen kann, und es muss während des Modellextraktionsprozesses transportierbar zu den Diensten des Angreifers sein.</sample>
    <sample id="309">The English TED Talks were translated into 14 different languages.</sample>
    <sample id="310">Es werden nur einige wenige Instanzen aus jedem Datensatz extrahiert, um eine reiche Menge an annotierten Daten zu erhalten.</sample>
    <sample id="311">The cosine similarity and L2 distance metrics are used to measure the difference between harmless and backdoor datasets.</sample>
    <sample id="312">Die Modelle wurden evaluiert, indem sie auf zwei Gruppen von Modellen angewendet wurden, darunter encoder PDR, ein polyglott präziser Encoder mit Zeilenbasierenden Decodern wie XLM-R + PDR, und encoder-decoder-Modelle, eine polyglotte präzise Encoder-Decoderarchitektur.</sample>
    <sample id="344">Die Autoren wählen zuerst ein Trigger-Set aus einer Gruppe von Worten mit mittlerer Häufigkeit im allgemeinen Textkorpus.</sample>
    <sample id="345">Hallo everyone, mein Name ist Zhuoheng. Heute werde ich unser Paper vorstellen: Do Conal-2003-named Entity Tags still work well in 2023? Lass uns beginnen.</sample>
    <sample id="346">Unsere Arbeit untersuchte das Problem der Generalisierung unter Verwendung des benannten Entitätserkennungsaufgaben oder DES-Tasks.</sample>
    <sample id="347">Wir haben beobachtet, dass Modelle seit fast zwanzig Jahren verwendet werden, um NER in der Sprache zu entwickeln und zu trainieren (CoNLL-2003), was natürlich einige Probleme mit sich bringt. Zunächst einmal können diese Modelle auf neue Daten generalisiert werden?</sample>
    <sample id="348">Wenn wir neue Tagger entwickeln, was ist für eine gute Generalisierung notwendig?</sample>
    <sample id="349">Gleichzeitig führt mangelhafte Generalisierung zu einem Leistungsabfall dieser Modelle, wenn wir sie beobachten.</sample>
    <sample id="350">Um diese Probleme zu untersuchen, entwickelten wir das Connel-Plus-Plus-Daten集. Das ist ein Daten集, das wir von Reuters News collected und dann mit denselben Connel-2003-Hilfslinien annotiert haben.</sample>
    <sample id="351">Wir haben dann über zwanzig Modelle auf Keras-2033 fine-tuned, und wir haben sie auf beiden Testsetten von Keras-Plus und Keras-Plus加强 ausgewertet.</sample>
    <sample id="352">Zum Schluss berechneten wir die Prozentsatzänderung in F1, um die Generalisierung jedes Modells zu beurteilen.</sample>
    <sample id="353">Also, was ist für eine gute Generalisierung notwendig? Durch unsere Experimente haben wir herausgefunden, dass es drei Hauptbestandteile gibt, die benötigt werden.</sample>
    <sample id="354">Die erste ist die Modellarchitektur. Durch unsere Experimente haben wir herausgefunden, dass die Transformer-Modelle normalerweise besser zu neuen Daten generalisieren.</sample>
    <sample id="355">Das zweite Element ist die Größe des Modells. Wir haben herausgefunden, dass größere Modelle in der Regel zu einer besseren Generalisierung führen.</sample>
    <sample id="356">Zum Schluss, wissen wir alle, dass die Anzahl der feinjustierten Beispiele direkt Auswirkungen auf die Leistung einer unterliegenden Aufgabe hat. Hier haben wir auch gefunden, dass mehr feinjustierte Beispiele tatsächlich zu einer besseren Generalisierung führen.</sample>
    <sample id="357">Bis zur nächsten Frage: Was verursacht einen Leistungsabfall bei manchen Modellen?</sample>
    <sample id="358">Wir hatten zwei Hypothesen. Die erste ist 'Adaptive Overfitting', das durch Wiederverwendung desselben Testsetts über und über wieder sichtbar wird, was normalerweise zu einer Abnahme der Rückmeldungen auf das neue Testset führt.</sample>
    <sample id="359">Die zweite Hypothese ist 'Temperaturdrift', eine Leistungsabnahme, die durch den zunehmenden Temperaturunterschied zwischen dem Zug und den Testdaten verursacht wird.</sample>
    <sample id="360">Für eine passende Passform haben wir gesehen, dass die rote, beste Passlinie auf dem rechten Graphen einen Steigungswinkel größer als eins hat.</sample>
    <sample id="361">Dies bedeutet, dass jede Verbesserung, die wir auf Konrad 2003 gemacht haben, zu mehr als einer Verbesserung auf Konrad Plus Plus führt, was bedeutet, dass es keine abnehmenden Renditen gibt.</sample>
    <sample id="362">Dies zeigt uns, dass in diesem Fall kein Anpassungsoverfitting beobachtet wird.</sample>
    <sample id="363">Also, was ist mit der Temperaturwechsel?</sample>
    <sample id="364">Für Temporal Drift haben wir Experimente durchgeführt, um einige Modelle mit neueren Daten zu retrainieren oder weiterhin vorzutrainieren, und festgestellt, dass die Leistung bei größeren zeitlichen Abständen abnimmt.</sample>
    <sample id="365">Dies bestätigt unseren Hypothesen, dass der Hauptgrund für den Leistungstiefstand die Temperaturdrift ist.</sample>
    <sample id="366">Unser Fazit ist, dass für eine gute Generalisierung ein besseres Modellarchitektur, größere Modellgrößen sowie mehr präzise Beispiele erforderlich wären. Allerdings können wir nicht nur einen Bestandteil haben, sondern alle anderen auch.</sample>
    <sample id="367">Gleichzeitig haben wir auch festgestellt, dass der Leistungstiefpunkt hier durch Temperaturabfall verursacht wird - und überraschenderweise wird er nicht durch Anpassungsfähigkeit verursacht, obwohl Konrad tausend drei seit über zwanzig Jahren verwendet wird.</sample>
    <sample id="368">Also zurück zum Frage, die wir in der Überschrift unseres Papers gestellt haben: arbeiten Connel 2003-Tags immer noch im Jahr 2023? Und wir fanden heraus, dass die Antwort tatsächlich 'ja' ist.</sample>
    <sample id="369">Wir hoffen, dass unser Papier zu mehr Forschung anregt, wie man die Generierung von Modellen verbessern kann.</sample>
    <sample id="370">Und zuletzt, vergessen Sie bitte nicht, unsere Zeitung, unseren Datensatz zu überprüfen. Wenn Sie Fragen haben, zögern Sie bitte nicht, mich zu kontaktieren. Vielen Dank!</sample>
    <sample id="397">The segment size used is 256 bits.</sample>
    <sample id="398">Das entitätsspezifische Wissen ist, dass Servin ein Richter ist.</sample>
    <sample id="399">Die Qualität des Beispiels ist wichtiger als die Ähnlichkeit mit dem Ausgangssatz.</sample>
    <sample id="400">Die Arbeiten konzentrieren sich auf GPT-4 und seine Variante GPT-3.</sample>
    <sample id="401">Das Modell kombiniert Werte aus mehreren Ebenen.</sample>
    <sample id="402">Namen von Songs oder ihre Positionen sind beispielsweise direkte Inferenz.</sample>
    <sample id="403">Fudan University.</sample>
    <sample id="404">Ein Autor ist beteiligt.</sample>
    <sample id="405">Nein, die Übersetzung wurde nicht als Baseline betrachtet, sondern es wurden sechs Settings für das Training und die Bewertung berücksichtigt.</sample>
    <sample id="406">Die Autoren geben das Beispiel 'woman warrior' als markierte Gruppe.</sample>
    <sample id="407">Die Transformator-Modelle generalisieren normalerweise besser zu neuen Daten.</sample>
    <sample id="408">Die Testdatensätze werden als 'clean data' bezeichnet.</sample>
    <sample id="409">Zwei Autoren, die Co-Autoren sind.</sample>
    <sample id="410">Die Autoren arbeiten mit mehreren Modalitäten.</sample>
    <sample id="439">Das融合时间和推理时间的知识的成功模型是NLU领域一个未被充分研究的领域。</sample>
    <sample id="440">The speakers' names are In and Coley.</sample>
    <sample id="441">Ja, Coscript hat eine Qualitätskontrolle durchlaufen.</sample>
    <sample id="442">Die Grenzen bestehender Ressourcen für kontextbasierte Übersetzung liegen darin, dass sie nur begrenzte Arten von Kontextabhängigen Übersetzungen und begrenzte Sprachen unterstützen, da sie in der Regel auf domänenkundiges Wissen und menschliche curatoren angewiesen sind.</sample>
    <sample id="443">Ich werde über unsere Arbeit sprechen, bei der es darum geht, indirekte Verfeinerungsausdrücke für das Entity-Selection zu lösen, bei der wir das Attribut 'entity score' einführen.</sample>
    <sample id="444">Der englische Text übersetzt ins Deutsche ist: 'Und mein Name ist Javad Hosseini, und dies ist eine gemeinsame Arbeit mit Philip Radoszynski, Sylvia Parity und Anne Lewis.'</sample>
    <sample id="445">Unser Ziel ist es, das Sprachverhalten der Nutzer zu verstehen, wenn sie eine Entscheidung treffen möchten. Beachten Sie diese alternative Frage: Did you mean easy on me or I got a feeling? Hier möchte ein Nutzer zwischen diesen beiden Optionen wählen.</sample>
    <sample id="446">Der offensichtlichste Weg ist, einen direkten Zusammenhang herzustellen, zum Beispiel indem man den Namen des Liedes oder seine Position sagt, zum Beispiel 'Das Lied heißt Youth' oder 'Es ist die erste Stelle'.</sample>
    <sample id="447">Es ist manchmal angemessen, indirekte Verweise zu verwenden, um eine natürlichere Konversation zu führen. Dies könnte passieren, wenn der Benutzer den Namen des Autors nicht mehr weiß.</sample>
    <sample id="448">Alle Aussprachungen sind zu ähnlich und schwer zu unterscheiden.</sample>
    <sample id="449">Der englische Inhalt lautet: 'Oder wenn der Benutzer eine Vorliebe festlegen möchte. Hier sind einige Beispiele für direkte Vorlieben: zum Beispiel das neue Auto oder das Lied, das nicht energiegeladen ist.'</sample>
    <sample id="450">Dies ist ein wichtiger Problem in Konversationsystemen und auch für die Benennung von Entitäten in ELMs.</sample>
    <sample id="451">Wir sind nicht über ein öffentliches Datenset mit einer größeren Skala verfügbare, das für unsere Zwecke geeignet ist, also sammeln wir eins mithilfe von Crowdsourcing. Unser Datensatz umfasst drei verschiedene Domänen: Musik, Bücher und Rezensionen.</sample>
    <sample id="452">Die Methode der Datensammlung betont die Informalität durch eine cartoon-completing-Serie.</sample>
    <sample id="453">Die Carton hat drei Sprechblöcke. Im ersten Blöck sagt Bob: 'Erinnere dich an dass Lied, das wir gestern gehört haben.' Mit diesem sagt Bob den Dialogkontext.</sample>
    <sample id="454">In der zweiten Sprechblase sagt Alice: 'Do you mean easy on me or I got her feeling?'</sample>
    <sample id="455">Die alternative Fragestellung ist in der dritten Sprecherbubbel zu finden, bei der Bob eine indirekte Verweigerung verwendet, um eines dieser Entitäten auszuwählen, zum Beispiel 'die neue Erde'.</sample>
    <sample id="456">Der erste und zweite Sprechbogen werden automatisch bereitgestellt, der dritte wird jedoch vom Annotator eingegeben. Der erste Sprechbogen wird aus einigen manuellen Hinweisen ausgewählt.</sample>
    <sample id="457">Der zweite Teil, der alternative Frage, wird wie folgt generiert.</sample>
    <sample id="458">Wir verwenden immer ein einfaches Muster, meinst du A oder B? Oder sind es Beispiele aus Wikipedia?</sample>
    <sample id="459">Die verschiedenen Sampling-Methoden, die wir verwendet haben, sind hier. Wenn wir weiter nach oben in der Liste gehen, werden die Entitäten immer ähnlicher zueinander und es wird normalerweise schwieriger, sie zu trennen.</sample>
    <sample id="460">Der erste ist 'Uniforme Train'.</sample>
    <sample id="461">Der zweite Fall betrifft entweder zwei Bücher mit demselben Namen oder dieselbe Person, die in verschiedenen Kontexten erwähnt wird.</sample>
    <sample id="462">Der dritte Punkt ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben, und schließlich, wenn sie ähnliche Infoboxes oder Attribute auf Wikipedia haben, zum Beispiel denselben Genre oder denselben Künstler für eine Sendezeit.</sample>
    <sample id="463">Wenn wir diese alternative Frage an die Benutzer weiterleiten, wissen sie den Namen dieser Entitäten, aber sie müssen sich nicht notwendigerweise mit ihnen auskennen.</sample>
    <sample id="464">Der englische Inhalt übersetzt ins Deutsche ist: 'Daher zeigen wir einige Hintergrundwissen über die 20er Jahre für Lieder, indem wir einfach einen Suchlink zu jedem Lied auf Google zeigen.'</sample>
    <sample id="465">Lassen Sie die Annotatoren mindestens eine S歌 hören und überlegen Sie sich jedes Lied. Zum Beispiel ist das Ergebnis der Suchabfrage nach dem Song 'Easy' wie folgt:</sample>
    <sample id="466">Für die Rezepte und Bücherdomain zeigen wir einige Hintergrundtexte von Wikipedia. Für Rezepte zeigen wir ihnen außerdem ihre Bilder erneut aus Wikipedia, damit die Annotatoren wissen, wie sie aussehen.</sample>
    <sample id="467">Dann bitten wir die Annotatoren, eine dieser Entitäten auszuwählen, zum Beispiel hier die erste und sie mit drei bis fünf indirekten Verweisen zu beschreiben.</sample>
    <sample id="468">Zum Beispiel derjenige mit dem Klaviermusik. Hier sind einige Beispiele aus unserem Datensatz. Zum Beispiel derjenige ohne Wörter, nicht derjenige mit einem zwölfjährigen Zwölfjährigenjungen oder der fiktiven.</sample>
    <sample id="469">Die Quelle gibt an, dass das Corpus 'entity-scorpus' 6000 alternative Fragen in drei Domänen enthält und 42000 indirekte Verifizierungen hat. Die Ergebnisse mit dem großen Modell T5 werden zusammengefasst.</sample>
    <sample id="470">Wenn der Sprachmodell Zugang zu genau dem gleichen Hintergrundwissen hat wie die Annotatoren, ist die Genauigkeit sehr hoch. Sie liegt bei etwa ninety-two bis ninety-five Prozent. Aber das ist nicht realistisch.</sample>
    <sample id="471">Wenn der Sprachmodell Zugang zu某个 partially overlapping Backgroundwissen hat, dann liegt die Genauigkeit zwischen eighty two und eighty seven Prozent, was realistischer ist, zum Beispiel wenn das Sprachmodell das Hintergrundwissen abruft.</sample>
    <sample id="472">Wenn der Sprachmodell nur auf Entitätennamen zugreift, dann beträgt die Genauigkeit nur 60%. Daher gibt es viel Raum für Verbesserungen. Wir haben auch gezeigt, dass die Modelle domänenspezifisch sind. Hier ist eine Verlinkung zu unserem Datensatz. Vielen Dank!</sample>
    <sample id="473">Mit den bestehenden SimulST-Richtlinien werden die Strategien verglichen, die auch für Online-Modelle gelten, wie die Whitkeys-Strategie und das Local Agreement.</sample>
    <sample id="474">The authors are affiliated with the University of Liege.</sample>
    <sample id="475">Jenny</sample>
    <sample id="476">Zwei.</sample>
    <sample id="477">Hallo, ich bin Sarah Papaioannou von der Universität von Toronto und für die Foundation Bruno Kassler tätig, und ich werde mich kurz vorstellen. Ich bin eine Guide für das纸上的同声传译指南, ein gemeinsames Projekt mit McTeague Nagri und Marco Duranti.</sample>
    <sample id="478">Synchrones Übersetzungsprozess, oder Simul SDE, ist der Prozess, in dem gesprochene Sprache in Echtzeit in einen anderen Text übersetzt wird und damit eine ungestörte Sprachkommunikation ermöglicht.</sample>
    <sample id="479">Die aktuellen Simulationsmodelle haben folgende Probleme: spezifische Architekturen werden üblicherweise trainiert, um zusätzliche Module zu optimieren.</sample>
    <sample id="480">Lange und komplizierte Trainingsverfahren, zum Beispiel trainieren mit unterschiedlichen Optimierungszwecken.</sample>
    <sample id="481">Die Übersetzung ins Deutsche lautet: 'Und die Schulung und Aufrechterhaltung mehrerer Modelle, um verschiedene Latenzregeln zu erreichen, zum Beispiel das Training eines Modells mit einer durchschnittlichen Latenz von einer Sekunde und eines anderen mit zweieinhalb Sekunden Latenz usw.'</sample>
    <sample id="482">Die Lösung ist ...</sample>
    <sample id="483">Zunächst sollten Sie bereits bestehende OFA-LSTM-Modelle ohne Wiederausgebildung oder Anpassung einer spezifischen Architektur für die Regelmäßigkeit verwenden. Verwenden Sie nur ein Modell für jede Latenzregel und übergeben Sie die Latenz durch spezifische Parameter.</sample>
    <sample id="484">Lernen Sie die durch das Modell erworbenen Kenntnisse, indem Sie den Aufmerksamkeitsmechanismus zwischen Audio-Eingang und Textausgabe nutzen. Das ist der Cross-Attention-Mechanismus, und Sie können ein Beispiel auf der rechten Seite sehen.</sample>
    <sample id="485">Unser Lösungsvorschlag besteht darin, einen Punkt vorzuschlagen oder die Codekodierung zu übernehmen, und das ist eine Strategie, mit der wir entscheiden können, ob eine partielle Übersetzung vorgenommen werden soll oder nicht, basierend darauf, wo sich die Aufmerksamkeit befindet.</sample>
    <sample id="486">Wenn die Spannung nicht konzentriert ist, wird ein Wort ausgesperrt, wenn der Betrag unter einem bestimmten Schwellenwert von α für die letzten Lambdaphrasen liegt, was bedeutet, dass die empfangene Information zu instabil ist.</sample>
    <sample id="487">Zum Beispiel, wenn wir erhalten einen Sprachabschnitt, in dem steht 'Ich bin bereit zu sprechen über', und unser Modell vorausgesagt hat, dass die Übersetzung ins Deutsche 'Ich bin bereit zu sprechen über' ist.</sample>
    <sample id="488">Der englische Text lautet: 'Und wir werden uns mit der Querspannung und dem Gewicht beschäftigen.'</sample>
    <sample id="489">Der erste Satz besagt, dass die ersten beiden Wörter auf die frühesten empfangenen Sprechereframen hinweisen, während das letzte Wort auf die spätesten empfangenen Sprechereframen verweist.</sample>
    <sample id="490">Dies bedeutet, dass die ersten beiden Wörter ausgelassen werden.</sample>
    <sample id="491">Der Übersetzungsbedarf besteht darin, dass der englische Text ins Deutsche übersetzt wird. Bitte geben Sie den zu übersetzenden Text an.</sample>
    <sample id="492">Wenn wir weitergehen und eine weitere Sprachstrecke erhalten und unser Modell drei Wörter vorhersagt, werden wir uns die Krosskombinationen ansehen.</sample>
    <sample id="493">Wir werden sehen, dass kein Wort auf das letzte 'Lambeau' oder 'Lambdaspeechframes' verweist.</sample>
    <sample id="494">Dies bedeutet, dass diese drei Wörter weggelassen werden.</sample>
    <sample id="495">Wenn Sie auf das Hauptresultat achten, werden Sie feststellen, dass es sehr erfolgreich war.</sample>
    <sample id="496">Wir werden die Ergebnisse der gleichzeitigen Übersetzung auf Graphen plotten, auf denen eine Seite blau ist, die die Übersetzungsqualität misst, und die durchschnittliche Leistungshäufigkeit darstellt.</sample>
    <sample id="497">Dies ist die Latenzzeitmauer und wir berücksichtigen auch die berechnete durchschnittliche Belastung, die für die Modells Berechnungszeit gilt.</sample>
    <sample id="498">Wir möchten also, dass unsere Curen auf diesem Plot so hoch wie möglich sind.</sample>
    <sample id="499">Aber wir möchten, dass sie auf der linken Seite sind.</sample>
    <sample id="500">Der englische Text lautet: 'Und wir vergleichen mit entsprechenden Strategien, die auch auf Online-Modelle angewendet werden, wie z.B. die Whitkeys-Strategie und das Local Agreement. Und wir vergleichen auch die Architektur des States speziell für die simultane Sprachübersetzung.'</sample>
    <sample id="501">Dies sind die Ergebnisse der Synchronisierten Sprachübersetzungsfunktion auf Deutsch.</sample>
    <sample id="502">Der englische Text übersetzt ins Deutsche wie folgt: 'Und wir sehen, dass es die besten Strategien übertrifft, die auf Online-Modelle angewendet werden, da die Kurven sich zur linken Seite verschieben.'</sample>
    <sample id="503">Wenn wir die tatsächliche Elaps Zeit oder die berechnete Zeit berücksichtigen, ist das Falsches Strategie.</sample>
    <sample id="504">Wenn Sie mehr Ergebnisse entdecken möchten, lesen Sie bitte unsere Publikation und wir haben auch Open-Source-Code und -Modelle sowie gleichzeitige Ausgabe freigeben, um die Reproduzierbarkeit unserer Arbeit zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit!</sample>
    <sample id="505">Nein, es ist nicht erwähnt, ob der Datensatz öffentlich zugänglich ist.</sample>
    <sample id="506">Hallo, alle! Mein Name ist Ine und ich bin Colleague Zhang. Wir werden unsere Forschungen zu Multi-Modell-Schulung verbessern, während wir uns unterrichten lassen.</sample>
    <sample id="507">So mit den Fortschritten bei großen Sprachmodellen begannen viele Arbeiten, neue Lernparadigmen zu erforschen, bei denen perfektionierter Sprachmodell für verschiedene unterirdische Aufgaben in einem Parameter und einer effizienteren Weise wieder verwendet werden.</sample>
    <sample id="508">Vor kurzem haben viele Studien gezeigt, dass die Anpassung der Anweisungen es großen Sprachmodellen ermöglicht, unsichtbare Aufgaben in mehreren Schritten zu erledigen, indem sie natürliche Anweisungen befolgen.</sample>
    <sample id="509">Die meisten vorherigen Arbeiten zur Anpassung von Anweisungen konzentrierten sich auf die Verbesserung der Leistung bei Aufgaben, bei denen nur Sprache verwendet wurde, während Computer Vision und Multimodell-Technologien außen vor blieben.</sample>
    <sample id="510">In diesem Werk möchten wir untersuchen, ob die Anpassung der Anweisungen auf mehrmodale Perceptron-Modelle tatsächlich die Generierung von scannenden Modellen verbessern kann.</sample>
    <sample id="511">Darüber hinaus entdeckten wir bei der Zeit unserer Forschung eine beträchtliche Diskrepanz in der Verfügbarkeit von Anweisungsdatensätzen zwischen LP und Multi-Modell.</sample>
    <sample id="512">Es gibt mehr als tausend und sechs hundert großflächige, Sprach-basierte Anweisungen, jedoch gibt es kein großkalibriges, öffentlich zugängliches Multimodell-Anweisungstool. Daher motivieren uns diese Informationen dazu, ein Multimodell-Anweisungstuning-Datenbank zu erstellen.</sample>
    <sample id="513">Hier präsentieren wir das erste Multimodell-Instruction-Tuning-Benchmarks-Datenbank, die aus 62 diversen Multimodellaufgaben besteht, die zehn verschiedene Kategorien abdecken.</sample>
    <sample id="514">Diese Aufgaben basieren auf现有21个开源数据集，并且每个任务都配以五篇专家编写的说明。</sample>
    <sample id="515">Für die Untersuchung der multimodalen Anpassungsfunktionen sind unsere vorgeschlagenen Datenbanken. Wir nehmen OFA als einheitliches Multimodellmodell als unseren Basismodell. OFA nutzt eine einheitliche Sprache für Wörter, Bildsymbole und Koordinaten der Bounding Box.</sample>
    <sample id="516">Hier zeigen wir einige Beispiele aus unserem Mehrschichtdatenbank-System.</sample>
    <sample id="517">Die Verarbeitung von verschiedenen Eingabe- und AusgabedatenTypen zu einem einheitlichen Output.</sample>
    <sample id="518">Wir folgen der Methode von OFA und formulieren alle Aufgaben in einem einheitlichen sequenz-sequenz-Format, bei dem die Eingabe-Texte, Bilder, Anweisungen und Verknüpfungsbereiche durch dieselben Token repräsentiert werden.</sample>
    <sample id="519">Okay, jetzt werde ich über Multimodale Einstellungsinstruktionen sprechen.</sample>
    <sample id="520">Für das Trainingsdatensatz verwenden wir 53 Aufgaben aus der Gruppe NLP zum Training und nehmen 10.000 Instanzen pro Aufgabe zur Testung. Wir reservieren die gesamte Common Sense Reasoning-Gruppe für Testing und wählen zusätzliche fünf Aufgaben aus der Gruppe Wiki und der Mikroskopie aus.</sample>
    <sample id="521">Wir verwenden alle Instanzen in der Testliste für jede Aufgabe. Darüber hinaus werden wir zufällig 20 Aufgaben aus der Testliste der natürlichen Anweisung als ein einzelnes Task auswählen.</sample>
    <sample id="522">Wir verwenden also einen prätrainierten OFA-Laufmodell als Basismodell. Während der Ausbildung werden alle Instanzen für alle Aufgaben generiert. Jede Instanz wird zufällig mit einer von seinen fünf Einstellungstemplaten kombiniert.</sample>
    <sample id="523">In jeder Aufgabe führen wir während des Tests insgesamt fünf Experimente durch, indem wir den Modellwert unter Verwendung einer der fünf Anweisungen für jedes Experiment evaluieren.</sample>
    <sample id="524">Die durchschnittlichen und maximumen Leistungen sowie die Standardabweichung der Leistung für alle fünf Experimente sind aufgelistet.</sample>
    <sample id="525">Wenn die Aufgabe eine Multimodell-Klassifizierungsaufgabe ist, berichten wir über die Genauigkeit. Wenn es sich um eine Multimodell-Generierungsaufgabe handelt, geben wir für eine LP-Aufgabe "Rouge-L" an. Wenn es sich um eine RNN-Aufgabe handelt, geben wir für eine LP-Aufgabe auch "Rouge-L" an.</sample>
    <sample id="526">Wir haben auch eine zusätzliche Bewertungsmethode eingeführt, die sogenannte Sensitivität misst. Sie messen, wie gut das Modell in der Lage ist, für dieselbe Aufgabe immer dasselbe Ergebnis zu erzeugen, unabhängig von kleinen Veränderungen in der Anweisung.</sample>
    <sample id="527">Unser Hauptergebnis ist, dass die Anweisungsumtuning erheblich die Leistung von OLS-OFAs bei der Durchführung von MultimodellAufgaben verbessern kann.</sample>
    <sample id="528">Auch Transfer-Lernen von natürlichen Eingaben kann zu einer Verbesserung der Ausgabe-Erstellung beitragen.</sample>
    <sample id="529">Der Inhalt des Videos ist: 'Hier können wir sehen, dass随着任务量的增加，模型的性能也会提高，在 meantime 减少了敏感性。'</sample>
    <sample id="530">Also haben wir auch einen Experiment gemacht. Wir haben eine Anweisung versus fünf Anweisungen verwendet. Wie Sie sehen können, die Verwendung von mehr Anweisungen kann die Gesamtleistung des Modells verbessern und seine Empfindlichkeit reduzieren.</sample>
    <sample id="531">Dies zeigt die Auswirkungen verschiedener Faltungstechnologien auf die Modellempfindlichkeit. Wie wir sehen können, durch die Übertragung des Lernens von Natural Language Instruction Daten kann das Modell eine viel bessere Empfindlichkeit erreichen als das ursprüngliche OFA-Modell.</sample>
    <sample id="532">Der Inhalt des Videos ist: 'Wir können auch sehen, dass die Übertragung von Daten aus einem natürlichen Datensatz OI zu einer viel besseren Leistung auf dem natürlichen Datensatz führt.'</sample>
    <sample id="533">Wir schlagen vor, das erste große Scale Multimodell-Untersuchungsdatensatz zu erstellen, der die Fähigkeit zur Verarbeitung von OFA verbessert und verschiedene Übertragungsausgleichstechniken untersucht und ihre Vorteile zeigt. Wir haben ein neues Metrikum entwickelt, die Sensitivität genannt wird.</sample>
    <sample id="534">Der Inhalt des englischen Textes lautet: 'Das einzige weitere ist, dass wir eine viel größere Multimodell-Instruktionssammlung mit etwa 150 zusätzlichen Übungen in chinesischer Sprache sammeln und sie发布。所以这是我们的数据和模型的QR码。谢谢。'</sample>
    <sample id="535">Die Autoren gehören zur University of Trento und zur Friedrich-Alexander-Universität Erlangen-Nürnberg.</sample>
    <sample id="536">Jawad Hosaini</sample>
    <sample id="562">Hallo everyone, ich bin Coos van Sina und freue mich, Euch zu unserem Gespräch über unsere ACL-2023-Paper 'Language Model Acceptability Judgments are not always robust to context' einzuladen.</sample>
    <sample id="563">Dies ist eine gemeinsame Arbeit mit John Goughery, Aaron Muller, Kanishka Mishra, Karen Fuentes, Roger Levy und Atina Williams.</sample>
    <sample id="564">In diesem Werk besuchen wir das Minimum-Pair-Paradigma erneut.</sample>
    <sample id="565">Der minimale Paarparadigma bewertet Sprachmodelle aufgrund von Akzeptanzurteilen, die auch grammatische Qualität wie z.B. Pflanzen, Syntax oder Akzeptanz in Bezug auf Vorlieben einschließen können.</sample>
    <sample id="566">In diesem minimalen Paar-Paradigma ist der typische Weg zur Bewertung von Sprachmodellen, dass Sie ein akzeptables oder grammatisches Satz zeigen und dann einen unakzeptablen oder ungrammatischen Satz.</sample>
    <sample id="567">Die Hoffnung ist, dass das Modell im Wesentlichen mehr Wahrscheinlichkeit zum akzeptablen Ergebnis gibt.</sample>
    <sample id="568">Die aktuelle MPP-Pipeline ermöglicht es uns nicht, die Akzeptanz von Modellen zu evaluieren.</sample>
    <sample id="569">In diesen Tagen entstehen große Sprachmodell mit immer längeren Kontextfenster. Deshalb ist es entscheidend, die Akzeptanz der Modelle über den gesamten Kontext zu evaluieren.</sample>
    <sample id="570">Und das ist, was wir hier versuchen zu tun. Wir versuchen, das Pp-Verzeichnis erneut zu besuchen, indem wir dem Modell die Bewertung der Akzeptanz auf längeren und längeren Sequenzen überlassen.</sample>
    <sample id="571">Der Ansatz ist, dass wir die Datenbanken selbst wiederholen und dann durch Auswahl von akzeptablen oder unakzeptablen Sätzen aus diesen Datenbanken neue Sätze erstellen.</sample>
    <sample id="572">Zum Beispiel haben wir hier ein typisches Paar von Dramatik ausgewählt, das aus dem Blim-Daten集 der Hilfsinsel stammt.</sample>
    <sample id="573">Der Inhalt des englischen Textes lautet: 'Und was wir tun, ist, dass wir langeere Sequenzen erzeugen, die akzeptabel sind und die gleiche Struktur wie die grammatische Struktur haben. Wir extrahieren grammatikalische Sätze aus einem Adverbial.</sample>
    <sample id="574">Und dann fügen wir es als Präfix zu beiden, der akzeptablen Abfrage und der unakzeptablen Abfrage hinzu.</sample>
    <sample id="575">Wir können dasselbe durch Auswahl unakzeptabler Sätze aus der gleichen Übereinstimmung tun, und das könnte auch verwendet werden, um die Akzeptanz des Modells zu testen.</sample>
    <sample id="576">Und wir können dasselbe auch tun, indem wir Sätze aus einem anderen Datensatz oder einer anderen Menge auswählen. Das nennt man das Missense-Szenario.</sample>
    <sample id="577">Also kommen die Sätze hier immer noch von relevanten Datensätzen, aber es sind nicht dieselben Datensätze, mit denen Sie evaluieren. Und das können wir für ungültige Fälle tun.</sample>
    <sample id="578">Abschließend können wir Sätze aus einem vollständig unabhängigem Domänenbereich wie Wikipedia wählen.</sample>
    <sample id="579">Dies wird uns sagen, ob die Bewertungen der Modellakzeptanz tatsächlich von einem Kontext beeinflusst werden.</sample>
    <sample id="580">Der Inhalt lautet: 'Wie ob der Kontext von einem anderen Teil des Datensatzes stammt oder ob er干脆完全没有 Bezug zu dem aktuellen Satz hat, an dem wir arbeiten.'</sample>
    <sample id="581">Der Modellvorgang ist wie folgt: Zunächst prüfen wir, ob die Wikipedia-Sätze vollständig irrelevant zu der aktuellen Suchbegriffspaar sind, und wenn ja, dann finden wir, dass die MPP-Entscheidungen für willkürliche Kontexte meistens robust sind.</sample>
    <sample id="582">Wir erhöhen den Kontextschnitt bis zu 2024, um die OMP-Entscheidungen zu maximieren und wir haben hier in der orange Linie gesehen, dass die MPP-Bewertungen relativ stabil sind.</sample>
    <sample id="583">Wenn wir Sätze aus derselben Datenbank wählen, was geschieht dann?</sample>
    <sample id="584">In diesem Fall erstellen wir Sätze aus akzeptablen und unakzeptablen Domänen aus derselben Blm-Syntaxdatenbank.</sample>
    <sample id="585">Der Inhalt des Videos ist: 'Und da sehen wir, dass die MPV-Bewertungen entweder stark steigen oder erheblich sinken, wenn Sie entweder akzeptable Präfixe hinzufügen oder unakzeptable Präfixe.'</sample>
    <sample id="586">Aber wenn wir die Struktur melden, das heißt, wenn wir die Sätze aus denselben Phänomenen in Blameträger-Texten wählen,</sample>
    <sample id="587">Wir sehen eine massive Erhöhung oder einen massiven Rückgang der MPP-Bewertung für das Modell, abhängig davon, ob der gewählte Vorname akzeptabel ist oder nicht.</sample>
    <sample id="588">Der Inhalt des Videos ist: 'Jetzt und das ist sehr groß, wie sich der Effekt durch den gesamten Kontextlink erstreckt, und das könnte wahrscheinlich Auswirkungen auf neueere Sprachmodelle haben, die einen großen Kontextbereich haben.'</sample>
    <sample id="589">Der Übersetzungsinhalt lautet: 'Also warum beeinflusst der passende Präfix die Entscheidung des Sprachmodells so sehr?'</sample>
    <sample id="590">Wir haben eine Reihe von Analysen durchgeführt, bei denen wir versucht haben, die Eingabephrase durch das Hinzufügen von 'Lärm' an die Eingabe zu beeinträchtigen, während wir versuchten, die relevante Struktur zu erhalten. Nachdem wir mehrere dieser Störungen durchgeführt hatten, ...</sample>
    <sample id="591">Wir finden heraus, dass diese Geräusche sich tatsächlich nicht auf das Verhalten des Modells im Sinne von 'wie es uns zeigt' auswirken.</sample>
    <sample id="592">Grundsätzlich finden wir, dass die Modelle anfällig für die Art der Sätze und ähnlicher Dinge sind.</sample>
    <sample id="593">Wenn wir die Sätze in dem akzeptablen Domänen unterbrechen, sehen wir ein ähnliches Anwachsen bei allen Verletzungen, und wenn wir die Sätze in der unakzeptablen Domäne unterbrechen, sehen wir einen Rückgang beim MPV-urteilsverfahren in ähnlicher Weise.</sample>
    <sample id="594">Die wichtigsten Merkmale unserer Arbeit sind, dass Sprachmodelle anfällig für versteckte syntaktische und semantische Eigenschaften sind, die sich über die Sätze hinweg teilen.</sample>
    <sample id="595">Die MPP-Einschätzung, die Art und Weise, wie wir sie derzeit mit kurzen und einzelnen Zentren durchführen, kann möglicherweise nicht das abstrakte Wissen der Sprachmodelle vollständig erfassen.</sample>
    <sample id="596">Lesen Sie bitte unseren Artikel, um mehr über unsere Experimente zu erfahren. Vielen Dank fürs Zuhören!</sample>
    <sample id="597">Unordered multi-set of tokens that will appear in the output.</sample>
    <sample id="598">Fünfzehntausend spezifische Skripte sind in Coscript vertreten.</sample>
    <sample id="626">Die beste Methode für DEplain ist das Massenalignment.</sample>
    <sample id="627">Schwach überwachtes Lernen ermöglicht es, neuronale Netzwerke direkt auf weekly Label-Daten zu trainieren, ohne dass vorherige Vorverarbeitung erforderlich ist.</sample>
    <sample id="628">Alle Dokumente wurden mit manuellem und automatischem Alignment methoden ausgerichtet.</sample>
    <sample id="629">Der CoNLL++-Datensatz wurde entwickelt, indem man Daten aus Reuters News von 2020 gesammelt und mit denselben annotierten Regeln wie der CoNLL++-2003-Datensatz annotiert hat.</sample>
    <sample id="630">Hallo everyone, mein Name ist Jiaxin Zhang vom Pennsylvania State University. Heute werde ich meine Arbeit vorstellen, die sich mit dem Cross-Lingual Semantic Parsing in mehreren natürlichen Sprachen und Minimal représentationen beschäftigt.</sample>
    <sample id="631">So ist die semantische Verarbeitung eine Aufgabe, um semantische Darstellungen von Benutzeranfragen zu erstellen, wie zum Beispiel SQL und Lambda-Formeln.</sample>
    <sample id="632">Crosstlang semantische Analyse ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen.</sample>
    <sample id="633">Der englische Text übersetzt ins Deutsche ist: 'Wie in der Abbildung gezeigt, müssen wir die Abfrage in mehreren natürlichen Sprachen mithilfe von Neuralmodellen übersetzen, um SQL, Lambda, oder Flask zu verwenden usw.'</sample>
    <sample id="634">Es bestehen bereits soziale Cross-Lingual-Semantische Parsing-Modelle, die separat vorgeschlagen und auf Datensätze mit begrenzten Aufgaben und Anwendungen evaluiert werden. Zum Beispiel...</sample>
    <sample id="635">Es gibt Lücken in der Abdeckung bestimmter natürlicher Sprachen, und das Chinesische fehlt.</sample>
    <sample id="636">Die Übersetzung des englischen Inhalts ist: 'Es gibt eine Deckung für bestimmte Minikapazitäten.'</sample>
    <sample id="637">Der lambda-Verstand fehlt.</sample>
    <sample id="638">Oder sie werden nur auf bestimmte neue Modelle evaluiert, zum Beispiel gibt es nur ein einzelnes Modell zur Evaluierung.</sample>
    <sample id="639">Also schlage ich vor, ein Vorbild für eine Crosslingual-Datenbank zu verwenden, das einheitliche Datensätze bereitstellt, die von einer Person in mehreren natürlichen Sprachen und in verschiedenen Darstellungen verwendet werden können.</sample>
    <sample id="640">Es enthält neun Datensätze in verschiedenen Domänen, 570 Partitionstests, 8 Millionen Repräsentationen und 22 native Sprachen in 15 Sprachfamilien.</sample>
    <sample id="641">Um die Überlegungen zu vertiefen, schauen wir uns die sechs Einstellungen für das Training und die Bewertung an.</sample>
    <sample id="642">Der erste ist 'Translate Text', bei dem wir die Google Translate API verwenden, um den Quelltext in das ZielSprache zu übersetzen. Dann verwenden wir einen monolingualen Modell, um zu trainieren und zu evaluieren.</sample>
    <sample id="643">Zum Beispiel trainieren wir ein Englischmodell auf englischen Suchanfragen und übersetzen während der Vorhersage die deutsche Suchanfrage mithilfe von API in Englisch, bevor wir das Modell verwenden, um die SQL zu prädizieren.</sample>
    <sample id="644">Wir werden auch einen monolingualen Modell testen.</sample>
    <sample id="645">In diesem Szenario ist die Quellsprache identisch mit der Ziel Sprache, zum Beispiel Deutsch zu Deutsch oder Englisch zu Englisch.</sample>
    <sample id="646">Wir testen auch die monolinguale Feedforward-Setzung, indem wir modulare Modelle mit nur 10% der Trainingsdaten trainieren.</sample>
    <sample id="647">Es handelt sich um eine mono- und multilinguale Modellierung, bei der ein Modell für alle Sprachen trainiert wird.</sample>
    <sample id="648">Zum Beispiel haben wir deutsche, englische und chinesische Queries zusammengetragen, um ein multilinguales Modell zu trainieren, und während der Inferenz können wir dieses Modell verwenden.</sample>
    <sample id="649">Um deutsche oder chinesische Suchanfragen zu übersetzen, usw.</sample>
    <sample id="650">Der englische Inhalt übersetzt ins Deutsche ist: 'Und wir werden auch Cross-Lingual-Zeichenfolgen und -Schalttransaktionen berücksichtigen, bei denen wir auf eine QuellSprache trainieren und sie in eine andere Sprache übertragen.'</sample>
    <sample id="651">Während der Schulung trainieren wir auf englischen Suchabfragen oder der Kombination aus Englisch und German-Java-Suchabfragen, um ein multilinguales Modell zu trainieren, um die Ausgabe vorherzusagen.</sample>
    <sample id="652">Und wir finden auch viele interessante Ergebnisse. Also was betrifft die Analyse von monolingualen Modellen, so wurden zwei Gruppen von Modellen evaluiert.</sample>
    <sample id="653">Encluding encoder PDR, which stands for multilingual pre-trained encoders with pointer-based decoders, such as XLNet R+PDR and BERT+PDR.</sample>
    <sample id="654">Der englische Text übersetzt ins Deutsche lautet: 'Und wir evaluieren auch Encoder-Decoder-Modelle, die mehrsprachig sind und Encoder-Decoder-Modelle wie M6 und MT5 sind.'</sample>
    <sample id="655">Der Encoder/Decoder erzielt die beste Leistung bei allen neun Datensätzen.</sample>
    <sample id="656">Der englische Inhalt lautet: 'Und wir evaluieren m5 und Beispiel xlmr plus prd, um eine multilanguage-Einstellung zu überprüfen.'</sample>
    <sample id="657">Der englische Inhalt lautet: 'Ohne dass Encoder-Decoder oder Encoder-Polyphone verbessert werden können, kann durch das Training in einer Mischung aus verschiedenen Sprachen gewonnen werden.'</sample>
    <sample id="658">Es wurde gefunden, dass dies der Fall ist, weil die meisten großen natürlichen Sprachen außerhalb von Englisch eine Leistungsverbesserung erzielen können, mit Ausnahme der Leistung in sieben Datensätzen, wo sie nur in drei Datensätzen gewinnt.</sample>
    <sample id="659">Dies wird als 'Kurzform der Multilinienität' bezeichnet.</sample>
    <sample id="660">Wir vergleichen auch die Leistungsgrenzen zwischen verschiedenen Sprachen.</sample>
    <sample id="661">In diesem Diagramm ist die blau linie eine Cross-Lingual-Feature-Schaltübertragung, die orange linie eine Cross-Lingual-Zereshift-Übertragung und die grüne Linie das Modell-Einstellung.</sample>
    <sample id="662">Wir haben herausgefunden, dass der Transferperformancegap beim Vergleich der grünen und orangen Linie für den Vorgeschalteten Short-Setting signifikant ist und dass beim Vergleich der blauen und orangen Linie der Transferperformancegap für das Vorgeschaltete Short-Setting rapide verkürzt wird.</sample>
    <sample id="663">Wir finden auch einige weitere interessante Funde, zum Beispiel Encoder-Decoder-All-Performances-Progressive-Work oder erreichte vergleichbare Ergebnisse bei der Verarbeitung von englischer Natur Sprache, was die Leistungsfähigkeit von Fused-Attention erheblich steigert.</sample>
    <sample id="664">Es wurde gefunden, dass modellbasierte Sprachmodelle wie Codex und Blue immer noch für viele Parsingzwecke geeignet sind.</sample>
    <sample id="665">Zusammenfassend kann man sagen, dass es sich bei Crammer about around 20% of the time.</sample>
    <sample id="666">Führen Sie eine umfassende Vergleichsstudie durch, bei der wir drei Vertreter verschiedener Arten von Mehrsprachigkeitsmodellen untersuchen. Unser Ergebnis zeigt viele interessante Entdeckungen usw. Willkommen zu unserem Paper und Code. Vielen Dank für Ihre Unterweisung.</sample>
    <sample id="667">Es wurden bereits einige Arbeiten durchgeführt, die in vier Kategorien unterteilt werden können.</sample>
    <sample id="668">Yes, multilingual language models like Codex and Blue are still adequate for cross-lingual semantic parsing tasks.</sample>
    <sample id="695">Die Methode löst dies, indem sie die Ausrichtung als Teil des Trainings berücksichtigt.</sample>
    <sample id="696">Die Fairness eines nachgeschalteten NLP-Modells wird durch seine Fähigkeit definiert, unparteiische Entscheidungen zu treffen, ohne politische Vorurteile oder Diskriminierung von Personen oder Gruppen aufgrund ihrer politischen Meinung oder anderen Merkmale.</sample>
    <sample id="697">Yannick Lavrak.</sample>
    <sample id="698">Coast of Sinna</sample>
    <sample id="699">Der Referent ist Myra.</sample>
    <sample id="700">Tropikalismus bezieht sich auf eine stereotype Verwendung von Begriffen, die lateinamerikanische Frauen betreffen, indem sie als 'vivacious' und 'curvaceous' beschrieben werden.</sample>
    <sample id="701">Die Autoren haben die Beschreibungen durch die Verwendung von Begriffen wie Kultur, Tradition, Stolz und Exotik erstellt, um die Gruppen nur durch ihre Beziehung zur Identität zu definieren und sie von der 'weißen Norm' abzuheben.</sample>
    <sample id="702">cxmi wurde erweitert, um die Messung der Kontextnutzung auf Satelliten- oder Wortebene zu ermöglichen.</sample>
    <sample id="703">DrBERT hat 7 GB, ChuBERT hat 4 GB, und beide haben Sentences aus klinischen Notizen. Die finale Version von ChuBERT hat eine Mischung aus 4 GB aus Natürlichen Sprachen und 4 GB aus klinischen Notizen.</sample>
    <sample id="751">Zwei.</sample>
    <sample id="752">Iteratives Transferlernen ist ein Verfahren, bei dem ein Modell während des Active Learning过程 kontinuierlich aktualisiert wird, indem es auf neue Datensätze trainiert wird, die im Laufe des Prozesses gesammelt werden.</sample>
    <sample id="753">Das Ziel des Datensatzes ist es, die Sprache der Nutzer zu verstehen, wenn sie eine Entscheidung treffen möchten.</sample>
    <sample id="754">Der Angreifer kann Modellparameter über einen EaaS (Edge Analytics as a Service) extrahieren, indem er die Verarbeitung von Daten auf dem Edge durchführt und dadurch auf die Modelle zugreift.</sample>
    <sample id="755">Zwei.</sample>
    <sample id="756">Two annotators were used to create the original dataset.</sample>
    <sample id="757">Die Autoren gehören zur Columbia University.</sample>
    <sample id="758">Isobart und Lisa.</sample>
    <sample id="759">The state of the art for dialog systems is that ABC-Eval is capable of measuring the rates at which chat models commit various thematic errors.</sample>
    <sample id="760">Es ist wichtig, die Akzeptanz der Modelle über das gesamte Kontextfenster zu bewerten, da große Sprachmodell mit immer longeren Kontextfenstern verfügbar werden.</sample>
    <sample id="761">Ja, es hat zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell geführt.</sample>
    <sample id="762">Nein, die Annotatoren kennen nicht notwendigerweise die Entität im Voraus.</sample>
    <sample id="763">The paper used the following metrics for evaluation: ROUGE-L, SROUGE, and SPICE.</sample>
    <sample id="764">Ja, größere Modelle führen in der Regel zu einer besseren Generalisierung.</sample>
    <sample id="765">Positionalität ist wichtig, weil sie es ermöglicht, die Bedeutung von Wörtern in einem Text zu verstehen, indem sie berücksichtigt, wie sie im Satz positioniert sind. Dies ist besonders relevant für die Verarbeitung indischer Texte, bei denen bestimmte Wörter oder Phrasen möglicherweise anders interpretiert werden könnten als in anderen Sprachen.</sample>
    <sample id="766">Nein, es wurde nicht erwähnt, ob BLOOM durch Adapter oder eine vollständige Feinabstimmung angepasst wurde.</sample>
    <sample id="767">Das Modell, das für das Transferlernen verwendet wird, ist ein two-layer neural network.</sample>
    <sample id="768">Several short prompts were used to evaluate the PaLM capabilities.</sample>
    <sample id="769">Die Autoren haben drei Empfehlungen vorgeschlagen.</sample>
    <sample id="770">The gain of the proposed method over the strongest baseline is shown to be highly significant in the generated specific goals.</sample>
    <sample id="771">Der Referent ist Shuheng.</sample>
    <sample id="772">Ja, die Ergebnisse und der Datensatz können als Basis-Benchmark für das Problem der automatischen Textsimplifizierung in Zukunft verwendet werden.</sample>
    <sample id="773">Smaller models are experimented with in the work.</sample>
    <sample id="774">Das统一 multimodale Modell (OFA) wird als Basismodell verwendet.</sample>
    <sample id="833">Die Autoren sind von der University of Pennsylvania.</sample>
    <sample id="834">Die Autoren sind an der University of Stony Brook.</sample>
    <sample id="835">Die Arbeit untersuchte englisch-deutsche Sprachpaare.</sample>
    <sample id="836">Der Referent ist Shangbin Jiang.</sample>
    <sample id="837">Es wurden zwei verschiedene Modelle untersucht: ein Modell zur Erzeugung von Dokumentebene-Simplifizierungen und ein Modell zur Erzeugung von Satzebene-Simplifizierungen.</sample>
    <sample id="838">Fünfzehn verschiedene Aufgaben aus dem MultiInstruct-Gruppe werden für Training und Tests verwendet.</sample>
    <sample id="839">One.</sample>
    <sample id="840">Die Autoren haben an vier Datensätzen experimentiert: AG News, MNLI, SST-2 und Penn Treebank.</sample>
    <sample id="876">NACHOS ist ein Datensatz medizinischer Grunddaten aus dem Web.</sample>
    <sample id="877">Der Referent ist Ali Velik.</sample>
    <sample id="878">Die Prompt-Strategie hat einen großen Einfluss auf die Ergebnisse der Übersetzung.</sample>
    <sample id="879">Die Autoren sind Patrick Frennance, MEY Liu, Andrew FM Martinez und Graham Newby.</sample>
    <sample id="880">The 5 instructions from the experts are: wash your hands, wear a mask, maintain social distance, wash your fruits and vegetables thoroughly, and cook food thoroughly.</sample>
    <sample id="881">Die Autoren schlagen vor, ein Co-Referenz resolutions task zu entwickeln, um die Fähigkeit zu prüfen, auf Informationen aus verschiedenen Quellen zuzugreifen.</sample>
    <sample id="882">Hallo everyone, mein Name ist Ali Bilal und ich werde Ihnen einen kurzen Überblick über das Paper 'Pruning for Neural Machine Translation' geben, das die Strategien und Leistung von Pruning in der maschinellen Übersetzung untersucht. Dies ist ein gemeinsames Projekt mit meinen Kollegen von Google Translate.</sample>
    <sample id="883">Das Modell ist ein 540 Milliarden-Parameter-Lernmodell für die chinesische Sprache, das im vergangenen Jahr vorgestellt wurde und auf einer großen Sammlung von Texten basiert, die aus 1,8 Milliarden Tokens besteht.</sample>
    <sample id="884">In der Fertigung von Diamanten erreicht man einen Staat der Kunst in Hunderten von Energieaufgaben.</sample>
    <sample id="885">In diesem Werk präsentieren wir die erste systematische Studie zum maschinellen Übersetzungsverfahren, das durch groß angelegte Modellunterstützung erfolgt.</sample>
    <sample id="886">Wir haben die Transaktionskonnektivität solcher Modelle mithilfe der besten Praktiken der AMT-Community evaluiert. Dazu gehört es, die neuesten Testsets zu verwenden, um eine Überlappung der Testdaten mit den Schulungsdaten des Sprachmodells zu vermeiden.</sample>
    <sample id="887">Wir vergleichen zwei Zustände von Systemen, also die besten performenden Systeme unter der WMMT-Evaluation.</sample>
    <sample id="888">Wir verwenden state-of-the-art und URMET-Maße und zeigen außerdem expert-based Menschliche Bewertungsergebnisse. Schließlich geben wir einige Empfehlungen für Promotionsauswahlstrategien.</sample>
    <sample id="889">Das Vorfeld hat einen großen Einfluss auf die Leistung der Übersetzungen von LLMs, wie wir in einem einfachen Experiment sehen können, bei dem wir ein kurzes Vorfeld verwenden und zwei verschiedene Vorschläge für eine bestimmte Sätze zur Verfügung stellen.</sample>
    <sample id="890">Der Mehrheit der Sätze in 516 von 1000 ist die Differenz zwischen dem servierten und dem tatsächlichen Wert größer als ein Blaupunkt.</sample>
    <sample id="891">Und das kann in Extremfällen bis zu vierfacher Punkt gehen. Deshalb ist es wichtig, eine gute reizende Strategie auszuwählen.</sample>
    <sample id="892">In unseren Experimenten haben wir für eine Fünf-Schlag-Prompting-Strategie vorgeschlagen, bei der wir jedes Satzzeichen in der von uns bereitgestellten Sprache markieren.</sample>
    <sample id="893">In diesem Beispiel werden deutsche Sätze in die Englische übersetzt. Die Quelltexte sind mit einem deutschen Buchstaben gekennzeichnet und die Übersetzungen mit einem englischen Buchstaben.</sample>
    <sample id="894">Wir haben gesehen, dass die tatsächliche Form der Präsentation im Falle mehrerer kurzer Präsentationen keine große Auswirkung hat.</sample>
    <sample id="895">Es ist für eine Zerhackerung von null und einer Schlagvorlage entscheidend, aber bei einer Fünf-Schlag-Vorlage gibt es keinen Unterschied zu der tatsächlichen Form der Vorlage.</sample>
    <sample id="896">Es sind die Beispiele, die den größten Teil des Gewichts tragen.</sample>
    <sample id="897">Die Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Beispielqualität wichtiger ist als die Ähnlichkeit zum Originaltext.</sample>
    <sample id="898">Es ist wichtig, aus hochwertigen Übersetzungen auszuwählen. Insbesondere vergleichen wir die Prompts aus dem Trainingsdatensatz der WMT-Evaluierungen oder den Dev-Daten.</sample>
    <sample id="899">Die Trainingsdaten sind mit höherer Qualität erstellt und das Ergebnis ist besser.</sample>
    <sample id="900">Dennoch haben spezialisierte Art-Systeme einen erheblichen Vorteil gegenüber den Pinyin-Übersetzungen, aber Pinyin kommt uns sehr nahe an ein kommerzielles System heran. In unserem Fall haben wir uns dazu entschieden, es mit Google Translate zu überlagern.</sample>
    <sample id="901">Die Einsichten, die wir durch die maschinelle Transkription erlangt haben, die wir unter Verwendung des M5-Frameworks durchgeführt haben, sind, dass die Flussigkeit von Pinyin mit der Qualität der Systeme vergleichbar ist, aber der Hauptunterschied besteht in der Genauigkeit.</sample>
    <sample id="902">Insbesondere die häufigsten Fehler sind Versehen.</sample>
    <sample id="903">Es scheint, dass Pan sich entscheidet, sie zu produzieren, indem er Teile des Originals切ommt, die in der Übersetzung enthalten sind.</sample>
    <sample id="904">Der englische Text übersetzt ins Deutsche ist: 'Aber die Stil类别 für Pan ist niedriger als für den Zustand der空气系统, was ein zusätzlicher Signaler ist.'</sample>
    <sample id="905">Dieser Algorithmus liefert sehr reibungslosen Ausgang, aber er hat immer noch einige Probleme mit der Genauigkeit.</sample>
    <sample id="906">Und damit ist es für diesen wirklich kurzen Überblick. Für mehr Details, bitte besuchen Sie die vollständige Präsentation des Papers. Vielen Dank.</sample>
    <sample id="907">Hallo, ich bin David und bin ein PhD-Student an der Universität Salzburg in Österreich. In diesem Video möchte ich Ihnen unser neuestes Werk vorstellen: 'Wider als Sie denken: Eine kritische Betrachtung der wöchentlichen Unterstützung'.</sample>
    <sample id="908">Dies ist gemeinsame Arbeit mit Xiao Yunshen, Maios Musabach und Jia Stephen sowie der Deutschen Akademie der Naturwissenschaften.</sample>
    <sample id="909">Ich würde gerne mit einer kurzen Einführung zu 'Wochenüberwachung' und 'Wochentagsüberwachung' beginnen.</sample>
    <sample id="910">In der Verwaltung durch Weißrussland werden die Daten nicht manuell beschriftet, sondern mit Hilfe von Weißrussischen Kennzeichnungssystemen wie einfachen hybriden Regeln, Wissensbasen oder lokalen Quellen gesammelt, wie in der Abbildung rechts dargestellt.</sample>
    <sample id="911">Vektor-Notationen sind viel billiger als Humanschreibungen, aber auch räumlich aufwendiger. Das bedeutet, dass ein gewisser Prozentsatz der Notationen falsch ist.</sample>
    <sample id="912">Wenn wir direkt neuronale Netzwerke auf wöchentlichem Label-Daten trainieren, tendieren die Neuronen-Netzwerke dazu, das Label-Rauschen zu memorieren und nicht zu generieren.</sample>
    <sample id="913">In der wöchentlichen überwachten Lernung werden Trainingsalgorithmen vorgeschlagen, um neue Netzwerke unter solchen Label-Noise robust zu trainieren, damit die trainierten Modelle immer noch gute Ergebnisse generieren.</sample>
    <sample id="914">In den letzten Arbeiten zum Thema WSL steht WSL für wöchentliche automatisierte Lernung. Eine häufige Behauptung ist, dass Menschen trainieren, indem sie nur drei Modelle auf der wöchentlichen Label-Datenbank verwenden und hohe Leistungen auf sauberen Testdaten erzielen.</sample>
    <sample id="915">Technisch gesehen ist dieser Anspruch nicht ungerechtfertigt, aber es gibt einen Haken.</sample>
    <sample id="916">Es wird davon ausgegangen, dass es zusätzliche clean Validationssätze für die Modellauswahl gibt.</sample>
    <sample id="917">Wir haben uns auf dieses Problemstellungsfeld gestützt, was darauf hindeutet, dass zusätzliche manuelle Annotierungen in der wöchentlichen Überwachung erforderlich sind. Aber wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen.</sample>
    <sample id="918">Die genannte Anpassung besteht darin, drei Forschungsfragen zu stellen. Erstens ist es notwendig, saubere Validierungsinformationen für WSL oder können wir stattdessen einen rauen Validierungsset verwenden?</sample>
    <sample id="919">Zweitens, wenn saubere Daten erforderlich sind oder wenn saubere Daten für die Arbeit mit WSL obligatorisch sind, dann wie viele saubere Proben benötigen wir? Schließlich sollten wir nur die sauberen Proben zur Validierung verwenden oder gibt es bessere Wege, sie zu nutzen?</sample>
    <sample id="920">Wir haben diese Forschungsfragen in unserem Werk behandelt, und unsere Ergebnisse sind wie folgt:
Translation into German: Wir haben diese Forschungsfragen in unserem Werk behandelt, und unsere Ergebnisse sind wie folgt:</sample>
    <sample id="921">Zunächst finden wir, dass sich interessanterweise die jüngsten WSL-Methode tatsächlich auf saubere, geschwärzte Proben anwenden lassen.</sample>
    <sample id="922">Andernfalls gibt es einen großen Leistungsverlust, wenn in diesem Diagramm keine sauberen Validierungssamples vorhanden sind. Dann können die trainierten Modelle nicht jenseits der ursprünglichen Vorhersagemarken generiert werden.</sample>
    <sample id="923">Dies bedeutet, dass der Trainingsprozess sinnlos ist.</sample>
    <sample id="924">Dies zeigt, dass WSL-Approachen tatsächlich clean label Daten erfordern, um korrekt zu funktionieren, und dass die Kosten für die Erstellung sauberer Validierungssamples nicht unterschätzt werden sollten.</sample>
    <sample id="925">Unser zweites Ergebnis ist, dass die Erhöhung der Anzahl sauberer Validierungssamples dazu beitragen wird, dass WSL-Approachen besser abschneiden. Zeigen Sie in der Grafik auf der linken Seite.</sample>
    <sample id="926">In der Regel reichen dafür nur 20 Proben pro Klasse aus.</sample>
    <sample id="927">Aber das ist nicht das Ende der Geschichte, denn wenn wir uns auf saubere Samples entscheiden, dann werden wir mit deren直接auswertung sogar noch bessere Ergebnisse erzielen.</sample>
    <sample id="928">Die Abbildung zeigt die Leistungsdifferenz zwischen Faltungsalgorithmen, die direkt auf sauberes Daten angewendet werden und WSL-Verfahren, bei denen das saubere Daten nur zur Validierung verwendet wird.</sample>
    <sample id="929">Wie wir sehen können, wenn wir zehn Samples pro Klasse haben, übertrifft das direkte Fine-Tuning die WSL-Approachen.</sample>
    <sample id="930">Schließlich kann die in früheren WSL-Ansätzen angegebene Leistungsverbesserung leicht erreicht werden, indem man es ermöglicht, die Feinjustierung der sauberen Validierungsproben fortzusetzen.</sample>
    <sample id="931">Wie wir aus den Zahlen sehen können, unterperforms die Valina-Modellierung FTHW zuerst kompliziertere WSL-Methode wie Cosine.</sample>
    <sample id="932">Wenn wir jedoch weiterhin auf saubere Samples achten möchten, dann performs FTW genauso gut wie andere Methoden.</sample>
    <sample id="933">In der Praxis gibt es keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Speicherplatz erfordern.</sample>
    <sample id="934">Wir haben gezeigt, dass recent WSL-Approachen clean, manuell annotierte Samples erfordern, damit sie richtig funktionieren. Ihre Leistungsgewinne und Praktikabilität werden jedoch stark übertroffen.</sample>
    <sample id="935">Unsere Empfehlungen für zukünftige Arbeitsstunden lauten wie folgt:</sample>
    <sample id="936">Erste Berichterstattung über die Modellauswahlkriterien, z.B. Bericht über eine erfolgreiche Modellauswahl bei sauberen Validierungsproben.</sample>
    <sample id="937">Zweiterens sollten WSL-Approachen mit funktionalen Short-Lening-Baselines kompatibel sein, die beide auf Beispiel-Daten funktionieren sollten. Drittens ist kontinuierliche Feinjustierung ein einfaches, aber starker Baseline, der in zukünftigen Arbeiten in WSL berücksichtigt werden sollte.</sample>
    <sample id="938">Schließlich haben wir unseren Code als Open-Source zur Verfügung gestellt. Du kannst ihn über den QR-Code auf dieser Folie finden. Bitte fühle dich frei, ihn auszuprobieren. Vielen Dank und genieße die Konferenz.</sample>
    <sample id="939">人类评估, 例如让人类法官选择最佳对话或给定 liquid scale 对话进行评级。</sample>
    <sample id="940">Zwei.</sample>
    <sample id="941">Es wird bothrocks Wissen benötigt, um die richtige Person zu identifizieren.</sample>
    <sample id="942">Der Code ist auf GitHub verfügbar.</sample>
    <sample id="943">Nein, es gibt einen zusätzlichen Alignment mit Menschen, die eine College-Ausbildung haben.</sample>
    <sample id="944">Die Sätze wurden durch Hinzufügen von Lärm zu den Eingaben verändert, ohne dass die Bedeutung verändert wurde.</sample>
    <sample id="945">Eine dimensionale Bewertung bedeutet, dass man某件事情 auf mehreren Ebenen oder Kategorien bewertet.</sample>
    <sample id="946">Die Autoren gehören zur University of Science and Technology of China.</sample>
    <sample id="947">Die Form des Prompts ist bei mehr als einem Schritt的重要.</sample>
    <sample id="978">Die Autoren haben verschiedene ABC-EVAl-Metriken evaluiert.</sample>
    <sample id="979">Es ist nicht klar, wie viele Autoren an der Arbeit beteiligt sind.</sample>
    <sample id="980">Ein guter Planer sollte Skripte schreiben, die vernünftig und an die Constraints angepasst sind.</sample>
    <sample id="981">Ein Autor.</sample>
    <sample id="982">Wesudha</sample>
    <sample id="983">Adam Skurkowski is affiliated with Adam Mickiewicz University in Poland.</sample>
    <sample id="1021">Omissionen.</sample>
    <sample id="1022">Hallo, ich bin James Finch und ich bin Sarah Finch. Heute werden wir Ihnen alles über ABC-Eval sagen, eine neue dimensionale Ansatz zur Bewertung von konversativer AI.</sample>
    <sample id="1023">Dieses Werk wurde von der Emory-NLP-Labors geleitet, das von Professor Gino Choy an der Emory University geleitet wird und in Zusammenarbeit mit Amazon Alexa AI durchgeführt wurde.</sample>
    <sample id="1024">Lass uns sagen, dass Sie gerade ein Dialogmodell entwickelt haben und sehen möchten, wie gut es gegen den aktuellen Stand der Technik abschneidet.</sample>
    <sample id="1025">Die übliche Praxis besteht darin, menschliche Bewertungen zu verwenden, indem man beispielsweise menschenliche Richter auffordert, welche der beiden Konversationen besser ist oder conversations nach einer Likert-Skala bewerten lässt.</sample>
    <sample id="1026">Diese Ansätze funktionieren gut, um eine ganzheitliche Bewertung der Gesamtqualität des Dialogs zu liefern, aber die Qualität des Dialogs hat viele Aspekte. Daher möchtest du möglicherweise mehrere Dimensionen der Chat-Qualität evaluieren, um die Stärken und Schwächen des Modells auf einer feineren Ebene zu verstehen.</sample>
    <sample id="1027">Eine Methode besteht darin, einfach Menschen zu beauftragen, verschiedene Aspekte der Dialogqualität zu bewerten, wie z.B. die Relevanz von Modellantworten unter Verwendung bestehender vergleichender oder Likert-Skala-Methoden.</sample>
    <sample id="1028">Der englische Text übersetzt ins Deutsche lautet: 'Jedoch glauben wir, dass es eine präzisere und zuverlässige Strategie für die dimensionale Dialogevaluierung gibt.'</sample>
    <sample id="1029">Unser Ansatz versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem er explizit angibt, ob jeder Modellantwort eine bestimmte Verhaltensweisen ausdrückt, wie z.B. mit irrelevanten Informationen zu antworten oder sich selbst zu widersprechen.</sample>
    <sample id="1030">Wir nennen diesen Ansatz 'Vermerken von Verhaltensweisen in Chat', oder kurz ABC-EVOL. Wir haben dieses Verfahren entwickelt, um das Verhalten des Chat-Modells auf umfassend zu erfassen, was in der jüngsten Literatur dazu geführt hat, dass es Auswirkungen auf die Chat-Qualität hat.</sample>
    <sample id="1031">ABC-Eval ist in der Lage, die Häufigkeit zu messen, mit der Chat-Modelle verschiedene thematische Fehler begehen.</sample>
    <sample id="1032">Zum Beispiel misst ABC-Eval die Anzahl der Umschläge, bei denen ein Chat-Modell seine Partner ignoriert oder etwas Irrelevantes sagt.</sample>
    <sample id="1033">Der englische Text beschreibt, dass ein Modell sich selbst widerspricht oder seinen Partner täuscht, falsche Fakten aufweist oder common sense Wissen verletzt und wenn das Modell erfolgreich ist oder nicht, zeigt es Empathie.德语 Übersetzung wäre: 'Wenn das Modell sich selbst widerspricht oder seinen Partner täuscht, falsche Fakten aufweist oder common sense Wissen verletzt und wenn das Modell erfolgreich ist oder nicht, zeigt es Empathie.'</sample>
    <sample id="1034">Die英文字atmosphäre ist eine spezielle Art von Ebene, auf der sich die Atmospähre befindet. Sie ist auch eine Ebene, auf der sich die Luft bewegt und sich verändert. Die Atmosphäre besteht aus verschiedenen Gasen wie Sauerstoff, Kohlenstoffdioxid und Stickstoff. Sie ist auch wichtig für das Leben auf der Erde, da sie die Temperaturen reguliert und den Druck hält.</sample>
    <sample id="1035">Für Vergleichszwecke haben wir auch diese Konversationen mit drei bestehenden Methoden evaluiert: Likert-Ratings auf der Turnusstufe, Likert-Ratings auf der Dialogstufe und dialogbasierte Paarwege-Vergleiche.</sample>
    <sample id="1036">Für jede der bestehenden Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekten des Dialogs gesammelt, da dies die Standardpraxis für die Bewertung von Chatmodellen in mehreren Dimensionen ist.</sample>
    <sample id="1037">Unser Analyse dieser Bewertungsergebnisse hat ergeben, dass die Verhaltenskategorien von ABC-Behavioral Evaluation überlegen sind als die durch bestehende Methoden gesammelten Kategorien, wie gemessen durch interner Annotator-Einigkeit bei einer Anzahl von zweifach besetzten Konversationen.</sample>
    <sample id="1038">In addition, ABC evol labels are more predictive of the overall conversation quality compared to metrics produced by existing methods, as shown by the simple linear regression analysis.</sample>
    <sample id="1039">Zum Beispiel kann man sehen, wie die Messung der Anteile an Konflikten mit sich selbst und dem Partner erklären, dass fünf Prozent und zehn Prozent der Konversationsempfindlichkeit jeweils unterschiedlich sind, während die durchschnittlichen Likör-Konsistenz-Werte nur vier Prozent oder weniger erklären.</sample>
    <sample id="1040">Schließlich haben wir geprüft, ob jede Bewertungsmetrik ein einzigartiges Aspekt der Chat-Qualität erfasst, indem sie mit einer Schrittweisen linearen Regression überprüft wurde.</sample>
    <sample id="1041">Der englische Text beschreibt, dass die Kombination aller ABC-EVAl-Metriken mehr als 25% der Konversationsqualität erklären kann und dass wenn eine Metrik entfernt wird, meist an Informationen über die Qualität verloren geht.德语 Übersetzung wäre: 'Die Kombination aller ABC-EVAl-Metriken erklärt mehr als 25% der Konversationsqualität. Wenn eine Metrik entfernt wird, gehen meist Informationen über die Qualität verloren.'</sample>
    <sample id="1042">Die andere Seite ist, dass die Kombination aller Drehwinkel-Likelihood-Metriken viel weniger über die Qualität aussagt und dass weniger dieser Metriken einzigartige Informationen tragen.</sample>
    <sample id="1043">Dieser englische Text übersetzt ins Deutsche lautet: 'Diese zuverlässigen, informativen und eindeutigen ABC-EVAl-Maße ermöglichen es uns, konsultativen AI mit einer höheren Auflösung als frühere Methoden zu evaluieren.'</sample>
    <sample id="1044">In den Ergebnissen unserer Experimente haben sich einige Herausforderungen als ungelöst erwiesen und wurden präzise quantifiziert. Zum Beispiel hatten die Bots, die wir getestet, in etwa 20% ihrer Antworten Common-Sense-Verstöße.</sample>
    <sample id="1045">Sie produzieren irrelevanten Informationen in etwa fifteen Prozent der Antworten und widersprechen sich oder ihrem Partner etwa zehn Prozent der Zeit.</sample>
    <sample id="1046">Mit dem schnellen Fortschritt in diesem Bereich könnten viele dieser Fehlerraten bei neuen Modellen sinken, seit unsere Bewertung durchgeführt wurde. Allerdings ist dies umso mehr der Grund, nach zuverlässigen und präzisen Bewertungsmetriken für die Vergleichung von Modellen zu streben.</sample>
    <sample id="1047">Wir hoffen, dass ABC-Eval von anderen im Bereich genutzt werden kann, als ein bedeutsamer Schritt in diese Richtung, und wir freuen uns darauf, zu sehen, wie konversatives AI in den nächsten Monaten und Jahren voranschreitet. Vielen Dank fürs Zuschauen!</sample>
    <sample id="1048">The authors are affiliated with Emory University.</sample>
    <sample id="1049">CFT steht für 'Clean, Filtered Training' in diesem Kontext.</sample>
    <sample id="1050">Sechs.</sample>
    <sample id="1051">Hallo! Mein Name ist Kayo Yan und ich werde unsere Arbeit mit dem Titel 'Wann benötigt Übersetzung Kontext? Eine datadriven multilinguale Untersuchung' präsentieren. Diese Arbeit wurde in Zusammenarbeit mit Patrick Frennance, MEY Liu, Andrej F. Martínez und Graham Newman durchgeführt.</sample>
    <sample id="1052">Der englische Inhalt ist: 'So viele Übersetzungen hängen vom Kontext ab, zum Beispiel wie würden wir "Mol" in diesem Satz übersetzen?'</sample>
    <sample id="1053">Wenn der vorherige Satz 'Dinge könnten beginnen, gefährlich zu werden, wenn die Minister herausfinden würden', lautet, dann bezieht sich 'Moll' auf einen Spion. Wenn der vorherige Satz jedoch 'Was könnte alles ernst sein, Doktor?' lautet, dann bezieht sich 'Moll' auf eine Geburtsmarke.</sample>
    <sample id="1054">Der Inhalt auf Deutsch lautet: 'So hängt die Bedeutung des Wortes von Kontexten ab und damit auch seine Übersetzung.'</sample>
    <sample id="1055">Der englische Inhalt lautet jedoch: 'Aber die Bewertung, wie gut modellisierte Übersetzungen wie diese sind, ist recht schwierig. Erstens, weil nur ein kleiner Teil der Übersetzungen von Kontext abhängt, was die Korpus-Ebene-Metriken wie Blue beeinträchtigt, um diese Übersetzungen zu erfassen.'</sample>
    <sample id="1056">Und einige haben vorgeschlagen, eine zielgerichtete Bewertung von kontextabhängigen Übersetzungen durchzuführen, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextabhängigen Übersetzungen und begrenzte Sprachenpaare, da sie in der Regel auf das domänenorientierte Wissen und die menschliche Bearbeitung verlassen.</sample>
    <sample id="1057">In diesem Werk versuchen wir, diese beiden Fragen zu beantworten: Erstens, wann erfordert diese Übersetzung Kontext? Und zweitens, wie gut behandeln Modelle diese Fälle?</sample>
    <sample id="1058">Um die erste Frage zu beantworten, haben wir mit der Messung begonnen, wie viel Wörter auf Kontext bei der Übersetzung abhängt.</sample>
    <sample id="1059">In der vorherigen Arbeit haben wir CxMI als Maß für Kontextnutzung durch maschinelles Übersetzungsmodell eingeführt. Dies geschieht indem man misst, wie viel Informationen der Kontext C über das Ziel Y bereitstellt, gegebenenfalls die Quelle X.</sample>
    <sample id="1060">cxmi ist die Information, die aus dem Hintergrund des Modells gewonnen wird.</sample>
    <sample id="1061">In diesem Fall erweitern wir cXMI bis zu Punkten, um cXMI zu messen, was die Ebene der Sätze oder der Wörter betrifft. Wir können Wörter mit einem hohen Punktverhältnis zu cXMI als solche betrachten, die Kontext für die Übersetzung erfordern.</sample>
    <sample id="1062">Jetzt analysieren wir Wörter mit hoher PSMI, um nach Mustern zwischen diesen Worten zu suchen.</sample>
    <sample id="1063">Wir führen eine Analyse von Transkripten von TED-Talks durch, die aus dem Englischen in vierzehn verschiedene Sprachen übersetzt wurden.</sample>
    <sample id="1064">Wir haben unsere Analyse an drei verschiedenen Ebenen durchgeführt. Zunächst haben wir einen Teil derSpeech-Texte mit hohen Mittelwerten für PCXMI untersucht.</sample>
    <sample id="1065">Der englische Inhalt lautet: 'Und das ermöglicht es uns, beispielsweise dubiose Pronomen in arabischer Sprache zu finden, die überwiegend mit dem hohen Punkt six emmy ausgesprochen werden. Dies kann erklärt werden, weil Englisch keine dubiose Pronomen hat. Daher benötigen Sie Kontexte, um festzustellen, ob ein Pronomen doppelte Formen hat, wenn es ins Arabische übersetzt wird.'</sample>
    <sample id="1066">Auch finden wir, dass bestimmte Sprachen beim Verwenden von korrekten Formen des Verbs Kontext erfordern. Wir schauen dann nach Wörtern mit einem hohen P-Score im Durchschnitt über alle verschiedenen Vorkommnisse.</sample>
    <sample id="1067">Dies hilft dabei, Fälle wie diesen zu identifizieren, in denen Sie in Chinesisch Kontexte benötigen, um richtige Transliterationen von Nomen zu verwenden, um sicherzustellen, dass Sie die gleiche Übersetzung innerhalb des Dokuments verwenden.</sample>
    <sample id="1068">In ähnlicher Weise finden wir, dass der Kontext unterstützt wird, um in der richtigen Formulierung zu tragen.</sample>
    <sample id="1069">Der englische Inhalt lautet: 'Und schließlich sehen wir uns verschiedene individuelle Token an, die einen hohen PSMI haben, und das ermöglicht es uns, Phänomene zu identifizieren, die sich nicht wirklich durch das Wort selbst ausdrücken lassen, aber die in einer Struktur wie der elliptischen Resolvente ausgedrückt werden können.'</sample>
    <sample id="1070">Also verwenden wir jetzt unsere Erkenntnisse aus unserer Analyse, um eine Benchmark für die Dokumentenübersetzung zu entwerfen.</sample>
    <sample id="1071">Für jedes der fünf entdeckten Phänomene erstellen wir einen Tiger, der automatisch Wörter identifiziert, die dem Phänomen gehören, und nennen wir unseren Tiger das multilinguale Diskussionssystem oder Muda-Tiger.</sample>
    <sample id="1072">Der englische Inhalt lautet: 'Man kann dann auch beachten, dass verschiedene Sprachen unterschiedliche Proportionen dieser phonologischen Phänomene haben.'</sample>
    <sample id="1073">Wir verwenden dann den Muda-Tager, indem wir ihn auf das zu evaluierende Parallelsystem anwenden und unsere Wahl der Translationalmetriken auf die von Muda identifizierten Kontextabhängigen Beispiele anwenden.</sample>
    <sample id="1074">Schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle auf Dokumentebene zu bewerten.</sample>
    <sample id="1075">Wenn wir Corpora-Grundmetriken verwenden, finden wir, dass konzeptionelle Modell die besten Leistungen erzielen.</sample>
    <sample id="1076">Wenn wir however Klassifizierungskontext verwenden, dann performieren die Modelle am besten. Wenn wir jedoch das Wort F-Measure verwenden, dann haben die Modelle mit und ohne Kontext vergleichbare Leistung.</sample>
    <sample id="1077">Dies zeigt erneut, dass es schwierig ist, das beste Dokumentenübersetzungssystem zu bestimmen, wenn man nur Korpus-Maße verwendet.</sample>
    <sample id="1078">Der englische Inhalt lautet: 'Nun verwenden wir die Mooda-Benchmarks, um Modelle zu evaluieren, und feststellen, dass Kontextumgebungen Modelle erheblich genauer sind als Modelle, die keinen Kontext für bestimmte diskrete Phänomene verwenden, wie z.B. Formalität und sprachliche Konsistenz.'</sample>
    <sample id="1079">Diese Modelle sind nicht viel besser als Modelle, die keinen Kontext anderer Phänomene wie Ellipsen, Pronomen und Verben berücksichtigen. Sie legen also nahe, dass wir bei der Dokumentationsübersetzung mehr Fortschritte sehen müssten.</sample>
    <sample id="1080">Auch vergleichen wir verschiedene kommerzielle Systeme, und unsere Benchmarks zeigen, dass DeepL in der Regel genauer ist als Google Translate für die Übersetzung von Dokumenten auf der Ebene des Wortes.</sample>
    <sample id="1081">Wir führen eine datengetriebene Analyse von vierzehn Sprachpaaren durch, um zu identifizieren, wann Übersetzungen erforderlich sind.</sample>
    <sample id="1082">Wir verwenden Refinements, um einen Benchmark für die Dokumentebene maschinelle Übersetzung zu erstellen, der uns helfen kann, festzustellen, welche dieser Klassifizierungsmuster gut oder schlecht beherrschen und welche Übersetzungs-Systeme gut an der Dokumentebene übersetzen können.</sample>
    <sample id="1083">Vielen Dank für Ihre Aufmerksamkeit, sehen Sie sich morgen wieder.</sample>
    <sample id="1084">Der Referent ist Jiaxin Zhang.</sample>
    <sample id="1121">Ist die neue Methode benannt?
Nein, die neue Methode hat keinen Namen.</sample>
    <sample id="1122">Die Autoren beschreiben die Methode der \"markierten Wörter\" als einen Weg, um die Wörter zu identifizieren, die Markgruppen von den markierten Wörtern unterscheiden.</sample>
    <sample id="1123">Die Autoren sind Studenten an der University of Washington.</sample>
    <sample id="1124">Prague</sample>
    <sample id="1125">James Finch und Sarah Finch.</sample>
    <sample id="1126">Drei.</sample>
    <sample id="1127">Die minimal pair paradigm evaluiert Sprachmodelle und berücksichtigt auch akzeptabilitätsbezogene Überlegungen, die grammatische Eigenschaften wie Plink-Syntax, -Gehirn oder Akzeptanz in Bezug auf bestimmte Wortstile (zum Beispiel 'Scouse Pairs') umfassen können.</sample>
    <sample id="1161">WLS, SLR, GLM, SVM, KNN</sample>
    <sample id="1162">Das Modell wird anhand von elf biomedizinischen und klinischen Aufgaben evaluiert.</sample>
    <sample id="1226">CamemBERT wurde mit einer 4 GB großen Unternehmensdatenbank trainiert.</sample>
    <sample id="1227">Adam Skurkowski</sample>
    <sample id="1228">Die Durchführung von Experimenten mit mehr recentem Daten ergab, dass die Leistung bei größeren zeitlichen Abständen zwischen Training und Test zurückging, was bestätigte die Annahme, dass die zeitliche Verzögerung die Hauptursache für den Leistungsverlust ist.</sample>
    <sample id="1269">Es ist notwendig, die Token für die Ausgabesequenz zu permutieren, weil sie nach dem ersten Schritt alle richtigen Symbole haben, aber nicht in der richtigen Reihenfolge sind.</sample>
    <sample id="1270">Die Autoren empfehlen eine increased transparency about bias mitigation methods, weil es anhand von positiven Stereotypen nicht klar ist, ob dies an einem übermäßigen Wertorientierungsdruck oder anderen anti-stereotyping Methods liegt, die zu perversen Mustern führen könnten.</sample>
    <sample id="1271">Inakzeptable Minimalpaareingaben sind Sätze, die grammatisch ungültig sind, wie z.B. 'Ich möcht gern Brot esse' anstelle von 'Ich möchte gerne Brot essen'.</sample>
    <sample id="1272">Die Autoren haben Gewicht und Tokeniser von Permutiert使用 get für die Bewertung gemacht.</sample>
    <sample id="1273">Die interannotatorische Übereinstimmung wurde verwendet.</sample>
    <sample id="1274">Die Domain Wikipedia wurde gewählt.</sample>
    <sample id="1275">Die Autoren gehören der University of Pennsylvania an.</sample>
    <sample id="1276">MultiInstruct unterscheidet sich durch die Berücksichtigung der Generalisierungsfähigkeit auf nicht-literal basierte Aufgaben im Vergleich zu anderen Benchmarks, die sich hauptsächlich auf die Verbesserung der性能 bei linguistischen Aufgaben konzentrieren.</sample>
    <sample id="1277">Zwei.</sample>
    <sample id="1278">The definition of binary coordination is not provided in the given English content.</sample>
    <sample id="1279">The prompts used in the study were on average approximately 30 words long.</sample>
    <sample id="1280">Die Ergebnisse zeigen, dass das kleinere T5-Modell bei ausreichender Trainingsdatengröße höhere Qualität an Scans generieren kann als größere Modelle.</sample>
    <sample id="1281">Hallo, ich bin Yannick Lavrak und ich werde Ihnen unsere Arbeiten zu Dr. Bert vorstellen, einem robuster präzisen Modell auf Französisch für biomedizinische und klinische Domänen.</sample>
    <sample id="1282">In dieser Präsentation sprechen wir zunächst über Sprachmodellierung in der Gesundheitswesen, bevor wir das Hauptkonzept unseres Artikels präsentieren.</sample>
    <sample id="1283">Wir präsentieren das erste biomedizinische Modell, das auf Französisch 'Docteur Bert' genannt ist und auf Roberta basiert und trainiert wird, was ein Datensatz medizinischer Grunddaten aus dem Web darstellt.</sample>
    <sample id="1284">Wir haben auch eine Vergleichung von Modellen mit mehreren设置 und Datenquellen eingeführt. Dann präsentieren wir unsere Ergebnisse zu elf biomedizinischen und klinischen Aufgaben im Französischen.</sample>
    <sample id="1285">In der Schlußfolgerung werden wir über die Experimente sprechen und Ihnen mehr Details darüber geben, wie Sie auf die Modelle zugreifen können.</sample>
    <sample id="1286">Seit seiner Veröffentlichung im Jahr 2018 hat BERT zu einem der effektivsten Ansätze für die Lösung von Aufgaben im Bereich der natürlichen Sprachverarbeitung avanciert und bietet einen großen Leistungsgewinn im Vergleich zu historischen statischen und konzeptionellen Methoden wie Word2Vec, GloVe oder NoWord.</sample>
    <sample id="1287">Seitdem wurde dieses Modell in viele andere Sprachen wie Französisch mit Camembert und anderen Domänen wie Biomedizin mit Permet-Bert und BioBERT adaptiert, sowie auf klinischer Ebene mit ClinicalBERT. Doch meistens auf Englisch.</sample>
    <sample id="1288">Zusammenfassend lässt sich sagen, dass spezielle Modelle für andere Sprachen selten sind und häufig auf kontinuierlichem Trainieren basieren, aufgrund des Mangels an in-house-Daten.</sample>
    <sample id="1289">Der französische Text lautet: 'Aber Frankreich hatte bislang kein offenes Modell für Biomedizin.'</sample>
    <sample id="1290">Wir stellen uns also selbst die Frage, welche Datenquellen für den breiten Einsatz am besten geeignet sind und ob diese strukturierten Daten eine gute Ersatz für klinische Daten sind.</sample>
    <sample id="1291">Um diese Frage zu beantworten, vergleichen wir Dr. Bert mit unserem Modell Shubert, das auf anonymisierten Daten basiert, die von der Universität Gent und unserer Firma erhalten wurden.</sample>
    <sample id="1292">Nachdem wir uns hingesetzt haben, fragen wir uns, wie viel Daten wir benötigen, um einen spezialisierten Modell auf Französisch zu trainieren. Ist es vier Gigabytes, acht Gigabytes oder mehr?</sample>
    <sample id="1293">Um diese Frage zu beantworten, trainieren wir zunächst und vergleichen vier von vornherein modellierte Versionen: Eine erste Version von Dr. Beers mit sieben Gramm Knäcken, eine zweite Version mit vier Gramm Setzknäcken.</sample>
    <sample id="1294">Eine erste Version von Shubert, die ein klinisches Modell mit 4 GB an klinischen Notizen ist, und eine finale Version von Shubert mit einer Mischung aus 4 GB an Subsets von Naturwissenschaften und 4 GB an klinischen Notizen.</sample>
    <sample id="1295">Zusätzlich zu dieser Vergleichung haben wir drei Modelle eingesetzt, um die Auswirkungen von Vorbereitungsstrategien zu analysieren.</sample>
    <sample id="1296">Der erste basiert auf dem Gewicht eines Käsekörpers und trainiert mit 4 GB Set von Nährstoffen, während der zweite auch auf dem Gewicht des Käsekörpers basiert, aber jetzt trainiert er mit 4 GB Set von Kichererbsen.</sample>
    <sample id="1297">Der englische Inhalt lautet: 'Und schließlich ein Modell auf der Grundlage des englischen Biomedizinmodells, das BERT trainiert wurde und auf 4 Gigabytes von Snacks trainiert wurde. Insgesamt haben wir sieben Modelle.'</sample>
    <sample id="1298">Um unsere sieben Modelle zu bewerten, haben wir uns für öffentliche und private Aufgaben entschieden, wie z.B. Namenserkennung, Klassifizierung, Part-of-Speech-Tagging und Frage-Antworting.</sample>
    <sample id="1299">Dieser Modell ist mit sechs Designmodellen verglichen, die sind: Kамербер-Оscar 138 GB, Kамербер-Оscar 4 GB, Kамербер-СиCnet 4 GB, Pemex-Bert, Bio-Bert und Clinical Bert.</sample>
    <sample id="1300">Die Entwicklungshilfe zeigt an, dass dieses Modell am besten auf die Aufgabe mit Daten der gleichen Art abschneidet wie jene, für die das Modell trainiert wurde.</sample>
    <sample id="1301">Der englische Text übersetzt ins Deutsche lautet: 'Wir können jedoch Daten erhalten, indem wir auf interne Quellen zugreifen und beobachten, dass die Daten aus verschiedenen Quellen似乎更加 vielfältig sind. Wir haben auch beobachtet, dass mehr Daten zu besseren Leistungen führen.'</sample>
    <sample id="1302">Insgesamt scheint es, als ob freier Übersetzer auf den meisten Aufgaben höhere Leistungen erzielen würde.</sample>
    <sample id="1303">Unser Experiment zur Kontrolle der Verarbeitung unter Verwendung des Gewichts und der Tokeniser von Permutiert-Bert auf das 4 GB-Subset von Nats hat vergleichbare Ergebnisse mit denen erzielt, die wir mit Dr. Bert für 4 GB ohne Vorarbeiten erhalten haben.</sample>
    <sample id="1304">Dies ist nicht der Fall für das Modell, das auf Kämmerei-Größen und -Werten basiert, das an Stabilitätsschwierigkeiten leidet.</sample>
    <sample id="1305">Die Zusammenfassung lautet: 'Unser eigenes System hat bei neun von elf Aufgaben eine bessere Leistung als das generische Modell und übertrifft global das Ergebnis des generischen Modells hier in Kalamata.'</sample>
    <sample id="1306">Wir beobachten auch, dass spezielles Daten besser ist als umfangreiches Datenmaterial, aber es wird nicht gut skaliert.</sample>
    <sample id="1307">Die von NLP bereitgestellten prätrainierten Modelle sind jetzt auf der neuen Seite verfügbar, und alle Trainingsscripte befinden sich in unserem Git-Repository.</sample>
    <sample id="1308">Vielen Dank für diese Präsentation, und wir schauen nach vorne zu Aktionen auf der Post-Session in Toronto.</sample>
    <sample id="1309">Die Lernstrategien, die untersucht werden, sind Kontextprägung und kontinuierliche Verbesserung.</sample>
    <sample id="1310">Der Faktor der Überanpassung beträgt größer als eins.</sample>
    <sample id="1311">Die Qualität der Vereinfachung wurde durch eine bessere Übereinstimmung mit dem人工verfassten Text (human reference) beurteilt.</sample>
    <sample id="1312">Ja, preliminary results haben gezeigt, dass erste Sprachmodelle verschiedene politische Ausrichtungen haben und sich auf alle vier Quadranten des politischen Körpers beziehen.</sample>
    <sample id="1313">Hallo! Mein Name ist Mathias Lendermann, und heute werde ich Ihnen einen kurzen Überblick über unser Papier zur kompositionellen Generalisierung ohne Bäume mit Hilfe von Multisets und latenten Permutationen geben.</sample>
    <sample id="1314">Dies ist gemeinsames Arbeit mit meinen Beratern Alexander Koller und Ivan Tietz.</sample>
    <sample id="1315">Die kompositionelle Generalisierung kann als Fähigkeit des Lerners verstanden werden, tiefere Rekursionen und unsichtbare Kompositionen von Phrasen zu bewältigen, die während der Ausbildung einzeln gesehen wurden.</sample>
    <sample id="1316">Im Kontext der semantischen Parsing könnte das Testen für die Kompositionelle Generalisierung wie folgt aussehen: Wie üblich haben wir eine Ausbildungsmenge von Affirmationen, in diesem Fall hat die Frau geschlafen und Mary wusste, dass die Frau geschlafen hat.</sample>
    <sample id="1317">Diese Ausdrücke werden mit logischen Formen paariert, die die grundlegenden Aspekte ihres Bedeutung darstellen.</sample>
    <sample id="1318">Im Gegensatz zu einem Standard-Maschinelernen-Evaluierungstest setzt sich das Testset nicht aus derselben Verteilung zusammen, sondern enthält strukturell ungewöhnliche logische Formen.</sample>
    <sample id="1319">In diesem Beispiel hat das Modell während der Ausbildung eine flache Rekursion gesehen und wurde auf einem Beispiel mit einer tieferen Rekursion getestet.</sample>
    <sample id="1320">Naive Sequence-to-Sequence Modelle haben Schwierigkeiten damit, diese Art von Ausgangsverteilung zu generalisieren und produzieren oft Ausgaben, die von dem Eingang getrennt sind.</sample>
    <sample id="1321">Insbesondere scheitern sie oft daran, systematische Korrespondenzen zwischen Eingang und Ausgang zu reproduzieren, wie zum Beispiel die Farbkodierungen in dem Beispiel.</sample>
    <sample id="1322">Ein beliebter Ansatz ist, Bäume in die Modelle zu integrieren.</sample>
    <sample id="1323">Die Bäume sind dazu gedacht, den kompositionellen Prozess zu erfassen, der die Äußerungen mit den logischen Formen verbindet.</sample>
    <sample id="1324">Dies funktioniert gut, aber Bäume werden in der Regel nicht gegeben und müssen irgendwie gewonnen werden.</sample>
    <sample id="1325">Dies kann kompliziert und manchmal auch berechnungstechnisch aufwendig sein. In der Regel beinhaltet dies erhebliche formale spezifische Vorkommen von logischen Formen, zum Beispiel zur Behandlung von Variablen symbolisieren.</sample>
    <sample id="1326">Die Übersetzung des englischen Inhalts ins Deutsche lautet: 'Die Erreichung von Zielwerten kann auch durch spezialisierte Grammatikinduktionssysteme erreicht werden.'</sample>
    <sample id="1327">In diesem Paper verwenden wir keine Bäume und einführen ein neues sequenz-sequenz-Modell, das die Korrespondenzen zwischen Fragmenten des Eingangs direkt modelliert.</sample>
    <sample id="1328">Zum ersten Mal haben wir eine starke Generalisierung zu einer tieferen Rekursion ohne Verlassen auf Tiere gezeigt.</sample>
    <sample id="1329">Unser Ansatz vorausgesagt die Ausgabe aus der Eingabe in zwei Schritten.</sample>
    <sample id="1330">Zunächst werden jeder Eingabe-Token mit einem unordneten Mehrfachset von Symbolen versehen, die im Ausgangsprodukt erscheinen werden.</sample>
    <sample id="1331">Nach dem ersten Schritt haben wir alle richtigen Symbole, aber sie sind nicht in der richtigen Reihenfolge.</sample>
    <sample id="1332">Deswegen verwenden wir in Schritt zwei ein anderes Modell, um die Permutationen vorherzusagen, um sie in die richtige Reihenfolge zu bringen.</sample>
    <sample id="1333">Wir haben einen neuen Ansatz zur Vorhersage von Permutationen eingeführt, der keine harten Kontraindikationen für mögliche Permutationen setzt. Dies macht unseren Ansatz sehr flexibel und ausdrucksstark.</sample>
    <sample id="1334">Konzeptionell funktioniert unser Permutationsmodell ungefähr so wie folgt.</sample>
    <sample id="1335">Wir gehen von links nach rechts über die Ausgabe und bestimmen, welches Multisetsymbol in jeder Position eingesetzt werden soll. Für die erste Ausgabeposition wählen wir einfach eines der hervorgehobenen aus.</sample>
    <sample id="1336">Dann springen wir zum nächsten Multisetsymmetrie, um die zweite Symmetrie im Ausgang zu bestimmen.</sample>
    <sample id="1337">Wir bestimmen das dritte Token in einer ähnlichen Weise, indem wir auf einen weiteren Multisatz-Token springen. Fahren wir diesen Vorgang fort?</sample>
    <sample id="1338">Es muss gesagt werden, dass jeder Token aus der ersten Stufe genau einmal besucht wurde.</sample>
    <sample id="1339">Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir unsere Methode mit anderen treelosen Modellen auf der Coggs-Benutzerbewertung. Unser Modell überzeugt die anderen mit einem großen Vorsprung in der Generalisierung bis hin zu tieferen Rekursionen.</sample>
    <sample id="1340">Einige andere Arten der strukturellen Generalisierung bleiben jedoch sehr herausfordernd.</sample>
    <sample id="1341">In unserem Artikel lösen wir einige interessante technische Herausforderungen.</sample>
    <sample id="1342">Zunächst einmal ist die Ausrichtung zwischen Eingang und Ausgang in der Trainingsdaten nicht gegeben. Als Folge gibt es für einen bestimmten Token keinen Hinweis darauf, welches Multischema es stammt, was eine Herausforderung für das Training darstellt.</sample>
    <sample id="1343">In addition, sometimes there are multiple permutations that are consistent with the data, but the linguistically correct one is later. We address this by inducing alignment as part of the training.</sample>
    <sample id="1344">Unser Permutationsverfahren ist sehr flexibel, bringt aber die Herausforderung mit sich, das höchste Scoring-Permutation zu finden. Das liegt daran, dass dies mit dem Reisendenhändlerproblem zusammenhangt.</sample>
    <sample id="1345">Wir schätzen dies mit einer 'GPU-freundlichen', kontinuierlichen Entspannung, die es uns auch ermöglicht, durch die Lösung zu backpropagieren und plausiblichere Permutationen zu lernen.</sample>
    <sample id="1346">Wenn Sie mehr über unsere Experimente und wie wir diese Herausforderungen angehen möchten, schauen Sie bitte in unserem Paper oder kommen Sie zu unserem Podcast.</sample>
    <sample id="1347">Kognitive Dissonanz ist die Differenz zwischen zwei überzeugten Meinungen oder Verhaltensweisen, die nicht vereinbar sind.</sample>
    <sample id="1348">GPT-4 ist das linksliberalste Sprachmodell.</sample>
    <sample id="1349">Yes, cumulative training performs equal or better than iterative training across the board.</sample>
    <sample id="1350">Der Referent ist Sarah Papaioannou.</sample>
    <sample id="1351">Die Daten für die MuDa-Benchmark stammen von TED-Talks, die aus dem Englischen in vierzehn verschiedene Sprachen übersetzt wurden.</sample>
    <sample id="1385">Matthias Lendermann</sample>
    <sample id="1386">Sprachübergreifender Transfer bezieht sich auf die Verwendung von Daten aus einer Sprache, um eine andere Sprache zu trainieren.</sample>
    <sample id="1387">Die Autoren sind Studenten an der Universität Salzburg in Deutschland.</sample>
    <sample id="1388">Die Autoren verwenden die Translation Quality-Latenz und den Computational Average Liking für die Messung der Latenz.</sample>
    <sample id="1389">Hallo everyone, Ich bin Makshata und heute präsentieren mein Co-Autor Martin und ich unser Werk 'Kit Mustermann - Evaluating knowledge integration from multiple sources'. Dies ist eine Zusammenarbeit zwischen der Universität Melbourne und Microsoft Research.</sample>
    <sample id="1390">NationalLanguageUnderstandingModelle basieren auf einer Vielzahl von Wissensquellen, wie zum Beispiel dem in ihren Parametern enthaltenen Wissen, das normalerweise durch Vortraining gewonnen wird, sowie dem in Eingaben gegebenen Wissen bei der Inferenzzeit.</sample>
    <sample id="1391">Neueste Arbeiten in der Methode des task-specific question answering zeigen, dass Modelle mit vor trainiertem Wissen das Problem lösen können.</sample>
    <sample id="1392">Der englische Text lautet: 'Aber die Verständnis der natürlichen Sprache erfordert oft Kenntnisse, die auch anhand von Induktion erworben werden können.'</sample>
    <sample id="1393">John sah den neu gewählten Präsidenten im Fernsehen.</sample>
    <sample id="1394">Vorhersagende Parameter können Informationen über das, was Präsidenten tun und was TV ist, enthalten, aber sie können nicht zuverlässig wissen, wer dieser bestimmte Instanz John ist oder wer der neue Präsident ist, weil der Präsident seit dem Vorhersagen gewechselt sein könnte.</sample>
    <sample id="1395">Daher erfordern erfolgreiche Modelle für wissensintensive und neue Aufgaben die Fähigkeit, sowohl vor trainiertes als auch Vorhersagezeitwissen zu integrieren und zu verwenden.</sample>
    <sample id="1396">In diesem Werk schlagen wir vor, eine diagnostische Testsuite für die Integration von Wissen zu entwickeln.</sample>
    <sample id="1397">Wir präsentieren eine Co-Referenzauflösungsaufgabe, die entwickelt wurde, um die Fähigkeit zu untersuchen, Wissen aus verschiedenen Quellen aufzubauen. Wir evaluieren das Datenset mit menschenorientierten Studienpartnern und etablieren Co-Referenzauflösungsmethoden.</sample>
    <sample id="1398">Ein Beispiel aus unserem Datensatz ist: Serwin ist ein Richter, hier ist ein Bäcker. Serwin und Khyar trafen sich im Park. Nach einem langen Tag mit der Entscheidung von Fällen im Gerichtshof war er froh, sich zu entspannen.</sample>
    <sample id="1399">Das Aufgabe besteht darin, die korrekte Entität zu identifizieren, zu der das Pronomen 'he' refers, was in diesem Fall 'Sergei' ist.</sample>
    <sample id="1400">Die Lösung eines bestimmten Pronoms erfordert zwei Arten von Informationen: Erstens spezifisches Wissen über das Individuum, wie z.B., dass Servel ein Richter ist, und zweitens allgemeines Wissen darüber, wie Richter in Gerichtsakten entscheiden.</sample>
    <sample id="1401">Im Allgemeinen wird Hintergrundwissen während der Vorbereitung großer Sprachmodells gelernt, während spezifisches Wissen über Entitäten in der Regel anhand von Induktion erworben wird.</sample>
    <sample id="1402">Wir variieren die Verfügbarkeit dieser beiden Informationen, sodass sie entweder in einer einzigen Quelle oder in mehreren Quellen gefunden werden können.</sample>
    <sample id="1403">Wir haben drei Einstellungen für Keras definiert: Erstens 'to big', das ist die Vorschaufunktion, bei der vorherige Kenntnisse angenommen werden sollen, bevor trainiert wird. Zweitens 'background pretrain', bei dem Backgroundwissen als vorherige Kenntnis verwendet wird. Und drittens 'normal', bei dem normalerweise keine vorherigen Kenntnisse angenommen werden.</sample>
    <sample id="1404">Zweitens gibt es eine 'Background-Beide-Einstellung', bei der die Hintergrundwissenswertigkeit sowohl vor dem Training als auch während des Trainings verfügbar ist. Letztendlich gibt es eine 'Hintergrund-Inferenz-Einstellung', bei der beide Wissensarten nur während des Trainings verfügbar sind.</sample>
    <sample id="1405">Die letzte Einstellung ist besonders interessant, da sie das Szenario simuliert, bei dem die erforderlichen Vorwärtskennungen für die Aufgabe nicht Teil des trainierten Modells sind. Zum Beispiel haben sich seit der Zeit des Vortrainings neue Berufe entwickelt.</sample>
    <sample id="1406">Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten aus einer Quelle steuern können.</sample>
    <sample id="1407">Im Hintergrund wird angenommen, dass das Hintergrundwissen 'Politiker suchen gewählte Sitze in der Regierung' in den vorgegebenen Parametern enthalten ist. Im begrenzten Kontext werden wir die spezifische Kenntnis 'Chichester ist ein Politiker' bereitstellen.</sample>
    <sample id="1408">Die deutsche Übersetzung lautet: 'Zusätzlich zu den spezifischen Informationen bieten wir auch Hintergrundwissen über Politiker in ihrem Kontext an.'</sample>
    <sample id="1409">Im Hintergrund ist die Einstellung vorgesehen, dass der Funktionsherr 'Maitre' anstatt ein Politiker ist, da es unwahrscheinlich ist, dass 'Maitre' in der vorherigen Periode enthalten war.</sample>
    <sample id="1410">Wir haben das Datenset für die menschenstudienteilnehmer ausgewertet und Vorhersagemodelle etabliert. In diesem Diagramm zeigen wir die Ergebnisse der am besten abschneidenden Modelle für das schwierigste Variante des vorgegebenen Trainingssettings.</sample>
    <sample id="1411">Wenn wir uns auf KITMOs trainieren, performen beide Modelle nicht besonders gut. Wenn jedoch auf KITMOs trainiert wird, führen C2F und BFCOR显著 besser als das Random-Choice-Modell.</sample>
    <sample id="1412">Es wird empfohlen, bei der Ausbildung auf Klassifikationsdatensätzen mit Anforderungen an die Lösung zu verwenden, dass die Modelle lernen, Oberflächen-Nebenläufe zu erkunden, die bei der Prüfung von KITOS nicht nützlich sind, da diese Nebenläufe entfernt wurden.</sample>
    <sample id="1413">'autres expériences ont montré que même les modèles performants ne peuvent pas intégrer de manière fiable les connaissances de contexte fournies à l'influence du temps.</sample>
    <sample id="1414">Der Hauptunterschied besteht darin, dass einige Menschen ohne spezifische Schulung in der Lage sind, Wissen aus verschiedenen Quellen zu integrieren und zu verarbeiten, während andere dies nicht tun können. Mit spezifischer Schulung können jedoch einige Menschen erfolgreich Wissen aus verschiedenen Quellen integrieren.</sample>
    <sample id="1415">Dennoch scheinen auch die besten performenden Modelle Schwierigkeiten damit zu haben, verlässlich integriertes Vorwärts- und Rückwärtskennenntnis unter Verwendung von Vorhersagezeitpunkten darzustellen. Wenn Sie sich für weitere Details interessieren, lesen Sie bitte unsere Arbeit und überprüfen Sie das Datenbankmodell in Code auf GitHub. Vielen Dank fürs Zuhören!</sample>
    <sample id="1416">Die Nachteile sind, dass Bäume in der Regel nicht direkt gegeben sind, sondern man sie müsste gewinnen. Dies kann ein komplizierter und manchmal berechnungstechnisch aufwendiger Prozess sein, der typischerweise erhebliche Formalismen spezifisches Vorkommniserkennung umfasst.</sample>
    <sample id="1417">The authors are affiliated with Tsinghua University.</sample>
    <sample id="1418">Hallo, ich bin Myra und heute werden wir über unseren Artikel sprechen, in dem wir die Verwendung von Natural Language Prompts zur Messung von Stereotypen in Sprachmodellen untersuchen. Die Arbeit wurde zusammen mit Esen Derincespor und Dan Darafossy durchgeführt.</sample>
    <sample id="1419">In den letzten Jahren haben viele die Vorherrschung von sozialen Vorurteilen und Stereotypen in großen Sprachmodellen oder LLMs dokumentiert.</sample>
    <sample id="1420">Jedoch haben diese Maßnahmen verschiedene Einschränkungen. Sie basieren in der Regel auf manuell erstellten Datensätzen, die sehr zeitintensiv zu verarbeiten sind.</sample>
    <sample id="1421">Sie messen in der Regel nur sehr spezifische Stereotypen, was bedeutet, dass sie sich nicht gut auf andere Demografien oder Kontexte erstrecken oder sie einfangen sehr allgemeine, breite Assoziationen wie negative Assoziationen mit bestimmten Gruppen.</sample>
    <sample id="1422">Darüber hinaus berücksichtigt die meisten Arbeit im Weltraum nicht die Intersektionalität, was die Vorstellung ist, dass multiplen sozialen Identitäten Faktoren von Diskriminierung kompound und einzigartige Schäden verursachen können.</sample>
    <sample id="1423">Um diese Einschränkungen zu überwinden, verlassen wir uns auf die Eigenschaft, dass jüngere instruction-tuned LLMs sehr gut auf Anweisungen und Parameter reagieren.</sample>
    <sample id="1424">Wir können das Modell bitten, eine Personengestalt zu generieren, die eine Darstellung eines imagineden Individuums ist, indem es einen Prompt wie 'Stelle dir vor, du bist eine asiatische Frau. Beschreibe dich selbst.' verwendet.</sample>
    <sample id="1425">Und wir können sofort sehen, dass dies sehr allgemeingültig für jede Demografie ist, weil wir angeben können, welchen Identitätsmarker wir in dieses Prompt aufnehmen möchten.</sample>
    <sample id="1426">Also, hier sind einige Beispiele für GPT-4.</sample>
    <sample id="1427">Die Übersetzung ins Deutsche lautet: 'Unmittelbar erkennen wir, dass die Ausgaben nicht offensichtlich negativ oder giftig sind im traditionellen Sinne dieser Wörter.'</sample>
    <sample id="1428">Es gibt einige interessante Muster.</sample>
    <sample id="1429">Die Asiatin wird als unvermutlich dargestellt, die Mittelostliche Frau wird mit Begriffen wie exotisch bezeichnet und es wird an eine verzaubernde Region angeknüpft.</sample>
    <sample id="1430">Die beiden Frauen mit farbiger Personifizierung machen Referenzen auf ihre Abstammung, während die weiße Personifizierung nichts damit zu tun hat.</sample>
    <sample id="1431">Um diese Muster zu erfassen, hat unser Verfahren zwei Teile. Der erste Teil besteht darin, diese Personen zu generieren.</sample>
    <sample id="1432">Unsere Vorlagen zur Erstellung dieser Persönlichkeiten wurden durch eine Studie inspiriert, in der es um die Verwendung solcher Vorlagen bei menschlichen Probanden ging und gefunden wurde, dass die Probanden auch in der Lage waren, rassische Stereotypen zu surface.</sample>
    <sample id="1433">Dies ermöglicht auch eine direkte Vergleichung zwischen unseren generierten Persönlichkeiten und menschlichen geschriebenen Antworten.</sample>
    <sample id="1434">Die zweite Teil ist 'Markierte Wörter', was ein Weg ist, um die Wörter zu identifizieren, die Markgruppen von unseren markierten trennen, was ich kurz erläutern werde.</sample>
    <sample id="1435">Dieser Vorteil besteht darin, dass wir spezifische Stereotypen und Muster ohne die Notwendigkeit zu einem bestimmten Lexikon verlassen können.</sample>
    <sample id="1436">Die markierte Wortsmethode basiert auf dem soziolinguistischen Konzept der 'Markiertheit', das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die sich von diesem Standard unterscheidet, sprachlich markiert ist.</sample>
    <sample id="1437">Zum Beispiel wird das Wort 'Mann' in der Regel mit Männern assoziiert, daher sagen Menschen, wenn sie über eine Kriegerin sprechen, die weiblich ist, dass es sich um eine 'einsame Kriegerin' handelt und sie das Wort mit 'Frau' markieren.</sample>
    <sample id="1438">Und breiter betrachtet sind die dominanten Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während die marginalisierten Gruppen in der Regel markiert sind.</sample>
    <sample id="1439">In unserer Methode definieren wir zuerst, was die unmarkierten und markierten Gruppen sind.</sample>
    <sample id="1440">Der englische Text übersetzt ins Deutsche ist: 'Dann vergleichen wir die Personen mithilfe der Wörter, die kämpfen Methode, was im Grunde Gewichtete Logodds-Verhältnisse sind, um die wichtigsten Worte für jede markierte Gruppe zu unterscheiden.'</sample>
    <sample id="1441">Für beispielsweise die Personae von Frauen mit Hautfarbe schreiben wir 'kämpfende Worte' und vergleichen die Gesetzessätze mit denen für Weiße und Männer, weil dies die beiden entsprechenden, unmarkierten Gruppen sind.</sample>
    <sample id="1442">Für einige Ergebnisse verwenden wir jetzt ein Lexikond von Stilen. Wir finden heraus, dass die generierten Persönlichkeiten viel mehr Stile enthalten als mensch geschriebene.</sample>
    <sample id="1443">Wenn wir jedoch die Verteilung der Wörter im Lexicon tatsächlich betrachten, finden wir sehr unterschiedliche Dinge.</sample>
    <sample id="1444">Die generierten Persönlichkeiten haben zwar höhere Rate an Luxuswörtern, aber die mensch geschriebenen haben eine breitere Verteilung von Worten. Die stereotype Wörter in den generierten Persönlichkeiten sind tatsächlich nur 'groß und athletisch'.</sample>
    <sample id="1445">Also nur die positiven oder zumindest nicht negativen.</sample>
    <sample id="1446">Der englische Text übersetzt ins Deutsche lautet: 'In der Tat fällt dieses Lexikon bei weitem nicht vielen schädlichen Mustern, die wir in früheren Folien gesehen haben, ins Auge. Stattdessen werden wir uns die Ergebnisse unseres Markiert-Wörter-Verfahrens zuwenden, um zu zeigen, wie diese positiv klingenden Wörter Stereotypen und Essentialisierungen in Erzählungen erleichtern.'</sample>
    <sample id="1447">In unserer Analyse zeigen wir, wie diese scheinbar positiven Porträts gefährliche Muster widerspiegeln.</sample>
    <sample id="1448">Für die Markgruppen sind die wichtigsten Wörter Kultur, Tradition, Stolz und Exotisch. Diese Wörter definieren diese Gruppen nur durch ihre Beziehung zur Identität und unterscheiden sie von der weißen Norm.</sample>
    <sample id="1449">Dies trägt zu einem langen Legat von Diskriminierung und Verfolgung für diese Gruppen bei.</sample>
    <sample id="1450">Darüber hinaus gibt es viele gemeinsame Stile, die in diesen Worten zum Ausdruck kommen, insbesondere bei Frauen farbig. Zum Beispiel beinhalten Wörter, die lateinamerikanische Frauen beschreiben, Dinge wie 'lebendig' und 'kräftig'.</sample>
    <sample id="1451">Asiatinnen werden oft mit Eigenschaften wie 'klein', 'delikat' und 'süß' in Verbindung gebracht.</sample>
    <sample id="1452">Der englische Text beschreibt eine lange Geschichte asiatischer Frauen, die als hypersexualisiert, passiv und submissiv betrachtet wurden.德语Translation: "Dies hängt mit einer langen Geschichte asischer Frauen zusammen, die als hypersexualisiert, passiv und submissiv betrachtet wurden."</sample>
    <sample id="1453">Schließlich sehen wir, dass einige der wichtigsten Wörter für Frauen in schwarz sind, wie stark und resilient.</sample>
    <sample id="1454">Dies ist mit einem Archetypen verbunden, den Menschen als 'starkes, schwarzes Frauenarchetyp' bezeichnet haben. Obwohl es auf den ersten Blick positiv klingt, birgt er möglicherweise风险.</sample>
    <sample id="1455">Es gibt Arbeiten, die zeigen, dass diese Art von Archetyp sehr schädlich ist, da sie viel Druck auf diese Demografien ausübt, resistent und stark gegen gesellschaftliche Hindernisse zu sein.</sample>
    <sample id="1456">Anstatt tatsächlich daran zu arbeiten, diese Hindernisse zu ändern, legt man Druck auf diejenigen, sie zu überwinden, was zu sehr negativen Gesundheitsauswirkungen für diese Menschen unter anderem führt.</sample>
    <sample id="1457">Im Allgemeinen finden wir, dass die Wörter für jede markierte Gruppe sich in der Regel auf sehr wesentliche Narrative beziehen.</sample>
    <sample id="1458">Basierend auf diesen Mustern schließen wir mit drei Empfehlungen für Modellbesitzer ab.</sample>
    <sample id="1459">Erstens sollten wir als Forscher positive Stereotypen ansprechen und Essentialisierungen in Erzählungen zu vermeiden. Wir sollten auch die Intersektionalität nutzen, um Vorurteile und Schäden zu untersuchen, da es viele Dinge gibt, die übersehen werden könnten, wenn wir das nicht tun.</sample>
    <sample id="1460">Abschließend sollte es wirklich zu mehr Transparenz bei Methoden zur Vorbeugung von Diskriminierung kommen.</sample>
    <sample id="1461">Weil zum Beispiel diese positiven Stereotypen, wir wissen nicht, ob es daran liegt, dass es irgendeine Art von seltsamen ... ist.</sample>
    <sample id="1462">Der englische Text übersetzt ins Deutsche lautet: 'Oberflächlich übertriebene Werteinkoppelung, die weiterhin stattfindet oder möglicherweise einige andere, wie z.B. antistereotypisierende Methoden, die zu diesen schädlichen Mustern führen.'</sample>
    <sample id="1463">Ohne mehr Transparenz können wir einfach keine Annahmen treffen oder das Thema weiter untersuchen.</sample>
    <sample id="1464">Vielen Dank fürs Zuhören! Haben Sie einen schönen Tag bei ASO.</sample>
    <sample id="1465">Hallo, alle! Mein Name ist Qin Weiyi vom University of Science and Technology China.</sample>
    <sample id="1466">Es freut mich, einen kurzen Werbespot über unseren Papier zu geben. Sie können mein Modell kopieren und das Copyright für große Sprachmodells zum Einbinden in Dienste schützen (Werbungssignal 'viel backdoor water mark').</sample>
    <sample id="1467">Lassen Sie uns zuerst das Hintergrundwissen über die Einbettung von Diensten einführen.</sample>
    <sample id="1468">Der englische Text lautet: ' aktuell sind große Sprachmodell wie tibetisch, lama und palm in der Natur sprachverständnis und -generierung außergewöhnlich.'</sample>
    <sample id="1469">Eingebettete Dienste sind eine Art von Diensten, die auf großen Sprachmodellen basieren und dazu dienen, verschiedene Aufgaben zu unterstützen.</sample>
    <sample id="1470">Zum Beispiel bietet OpenAI einen API-basierten maschinelichen Lerningservice an.</sample>
    <sample id="1471">Neueste Arbeiten haben gezeigt, dass der Angreifer das Modell durch Lernen aus dem Eingebetteten stehlen und ähnliche Dienste anbieten kann. Daher ist es notwendig, die Urheberrechte des Eingebetteten als Dienstleistungen zu schützen.</sample>
    <sample id="1472">Um die Urheberrechte von Einfügen von Diensten zu schützen, ist eine Lösung, einen Wasserzeichen in den Provider-Dienst einzubetten und zu prüfen, ob ein anderer Dienst den Wasserzeichen enthält.</sample>
    <sample id="1473">Die Watermark-Methode muss die folgenden Eigenschaften erfüllen: Erstens sollte die Methode anpassbar sein für Einfügen von Wasserzeichen in Dienste. Zweitens darf das Wasserzeichen die Benutzerfreundlichkeit der bereitgestellten Einbettungen nicht verringern.</sample>
    <sample id="1474">Der dritte Punkt ist, dass der Wassersteg genügend geneigt sein sollte, um den Angreifer zu überwinden, oder der Angreifer kann den Wassersteg leicht entfernen.</sample>
    <sample id="1475">Schließlich muss der Wasserstempel während des Modellbaus an die Angreifer übertragen werden können.</sample>
    <sample id="1476">Bestehende Werke können in vier Kategorien unterteilt werden.</sample>
    <sample id="1477">Dieser Ansatz ist jedoch entweder nicht anwendbar für die Einbettung von Diensten oder fehlt der Transparenz.</sample>
    <sample id="1478">In diesem Artikel schlagen wir deshalb vor, einen 'Embedding Marker', einen rückseitig basierten Wasserzeichen-Methode zur Einbettung von Dienstleistungen vor.</sample>
    <sample id="1479">Dann lasse ich dir die Details unseres Einbrenners vorstellen. Der Einbrenner besteht aus zwei Hauptstufen: der Markeninjektion und dem Copyright-Versiegelung.</sample>
    <sample id="1480">Bevor diese Hauptschritte ausgeführt werden, wählen wir zuerst ein Trigger-Set aus. Ein Trigger-Set ist eine Gruppe von Wörtern mit einer mittleren Häufigkeit.</sample>
    <sample id="1481">Angenommen, der Anbieter kann einen allgemeinen Textabschnitt sammeln und die Wortfrequenz berechnen.</sample>
    <sample id="1482">In einer Wassermarkierungseinspritzung definieren wir zunächst eine 'Zielbedingung'. Wenn ein Benutzer eine Nachricht an einen Anbieter sendet, zählt der Anbieter die Auslöserzahl in der Nachricht.</sample>
    <sample id="1483">Die angegebene Verwendung ist eine Gewichtsumme aus dem Ziel- und dem ursprünglichen Einbettung.</sample>
    <sample id="1484">Die Gewichtung des Target-Embindings ist proportional zur Anzahl der Trigger's in der Sentence. Wenn die Anzahl der Trigger's in der Sentence größer als M ist, dann ist die bereitgestellte Embindung genau gleich der Target-Embindung.</sample>
    <sample id="1485">Die Kopierschutzverifizierung ist dazu da, um zu prüfen, ob ein Modell hinter einem anderen Service die Wasserzeichen enthält.</sample>
    <sample id="1486">Zunächst müssen wir einen 'backdoor' und ein 'benignes Daten集' erstellen. Das 'benigne Daten集' enthält Sätze, bei denen alle Wörter dem 'Triggerwort' gehören, während alle Wörter in den Sätzen des 'benignen Daten sets' nicht zum 'Triggerwort' gehören.</sample>
    <sample id="1487">Der Anbieter hat von dem Steeldruckdienstleister Anforderungen für die Einbettung erhalten.</sample>
    <sample id="1488">Die Cosine-Similarity zwischen dem angeforderten Eingebetteten und dem Ziel-Eingebetteten werden berechnet. Die Similaritätsdifferenz zwischen den benignen und den bösartigen Datensätzen, die definiert wird als DeltaCosine und DeltaL2, wird berechnet.</sample>
    <sample id="1489">In der Zwischenzeit werden wir auch den KS-Test anwenden und dessen P-Wert als dritte Matrix verwenden.</sample>
    <sample id="1490">Wir führen Experimente mit vier Datenbanken durch: A-G News, Mind, S-SDT und Eraser. Wir gehen davon aus, dass der Provider die Datenbanken zur Häufigkeitsberechnung anwendet.</sample>
    <sample id="1491">Die Ergebnisse auf vier Festplatten zeigen, dass unser eingebetteter Markierer großartige Erkennungsentwicklung aufweisen kann, während er gleichzeitig eine große Benutzerfreundlichkeit für die unterstrichenen Aufgaben behält.</sample>
    <sample id="1492">Der englische Inhalt lautet: 'Wir validieren auch die Verdecktheit des bereitgestellten Einfüllens, indem wir die Einfüllung von Sätzen auf 40 Zeichen begrenzen. Die Legende der Zahlen bedeutet die Anzahl der Zeichen in jeder Phrase.'</sample>
    <sample id="1493">Wie in den Grafiken gezeigt, ist es schwer, zwischen den 'faktenlosen' Einbettungen und normalen Einbettungen zu unterscheiden.</sample>
    <sample id="1494">Wenn Sie das tun, danke ich Ihnen. Sie werden mit uns darüber sprechen.</sample>
    <sample id="1495">ABC-Eval ist ein Ansatz zur annotierenden Verhaltensanalyse von Chatbots.</sample>
    <sample id="1496">CoNLL-2003 wurde bis vor etwa zehn Jahren verwendet, daher war der Leistungsdelta zwischen Conll-2003 und CoNLL++ vor etwa zehn Jahren größer als 5 Prozentpunkte.</sample>
    <sample id="1497">Hallo, mein Name ist Vasudha und ich bin ein Kandidat für den Master of Computer Science an der University of Stony Brook. Ich würde gerne meine Arbeit vorstellen, die ich in den Acl 2023 als Langpaper "Transfer-Lernen für die Tonschätzung von Dissonanzen" eingereicht habe. Es befasst sich mit dem seltenen Thema der Tonschätzung von Dissonanzen mithilfe des Transfer-Lernens.</sample>
    <sample id="1498">Kognitive Dissonanz ist die Differenz zwischen zwei Überzeugungen oder Handlungen, die unvereinbar sind. Es ist ein wichtiger Forschungsgegenstand in der Sprachwissenschaft, da es uns helfen kann, warum Menschen manche Dinge tun und glauben, was sie tun.</sample>
    <sample id="1499">Dieser Beispiel zeigt, dass eine Person weiß, dass Zigaretten ihr Leben kosten könnten, und dann sagt, sie habe nach der Sitzung ein paar Rauchzeiten genommen. Diese Überzeugung und diese Handlung sind inkonsistent und stehen im Widerspruch zueinander.</sample>
    <sample id="1500">Die weitere Erwähnung, dass ich nicht glaube, dass ich ohne sie mein Job behalten könnte, rechtfertigt die zweite Wiederholung und die Konsonanzbeziehung zwischen 'them' und 'job'.</sample>
    <sample id="1501">Dissonanz ist ein sehr häufiges Phänomen, das bei der täglichen Entscheidungsfindung erlebt wird, aber selten in Sprache ausgedrückt wird.</sample>
    <sample id="1502">Studieren Sie kognitive Dissonanz, um zu verstehen, wie sie unter Menschen wirkt, welche Trends in Überzeugungen, Werten und Einstellungen entstehen lassen und wie sie sich auf die Gesellschaft auswirkt.</sample>
    <sample id="1503">Hochkognitive Dissonanz ist auch mit Angststörungen verbunden und kann dazu beitragen, die psychische Gesundheit von Menschen besser zu verstehen.</sample>
    <sample id="1504">Studieren Sie die Distanz, die in einer Sprache ausgedrückt wird, kann auch bei der Verständnis von Extremismus und Polarisierung von Schwächeren Gruppen nützlich sein.</sample>
    <sample id="1505">Zusammenfassend ist kognitive Dissonanz wichtig, um die persönlichen kognitiven Stile von Individuen zu verstehen und uns Entscheidungsprozesse besser anzunähern.</sample>
    <sample id="1506">Ziel der Erstellung eines kognitiven Dissonanzressourcens war die Durchführung einer umfangreichen Erhebung zu Dissonanzen. Wir verwendeten den erster Ansatz zur Dissonanz, wie ihn man in der Flowchart sieht.</sample>
    <sample id="1507">Die Tweets wurden mithilfe eines Apertif-Parser durchlaufen lassen und Paare von DiskursEinheiten wurden nach den in unserem Paper beschriebenen Leitlinien annotiert.</sample>
    <sample id="1508">Wie man hier sieht, wurde Dissonanz nur in 3,5% der annotierten Paare gefunden.</sample>
    <sample id="1509">Im Zuge der Sammlung von etwa tausend Beispielen für Diskurszusammenstellungen führten wir eine Initialisierung der Klassifikation durch, bei der nur vierzig drei Beispiele für DISNETs verwendet wurden. Ohne Überraschung performed die Klassifikator nicht viel besser als zufällig.</sample>
    <sample id="1510">Angesichts der geringen Häufigkeit von Dissonanzen und fehlender vorheriger solcher Datensätze haben wir das Problem der absoluten Seltenheit.</sample>
    <sample id="1511">Die experimentelle Überprüfung von Kombinationen aus Transfer-Lernen und aktiver Lernen zur Annotation, um mehr dissonante Beispiele über weniger Annotierungsrunden zu sammeln, senkt die Gesamtanforderung an die Anotation, während die Erkennung von Dissonanz verbessert wird.</sample>
    <sample id="1512">Da der ursprüngliche Modell nicht in der Lage war, die Dissonanzklasse überhaupt zu erfassen, haben wir den Prozess der aktivierten Lernung durch das Übertragen von Gewichten aus eng verwandten Aufgaben gestartet.</sample>
    <sample id="1513">Die Aufgabe besteht darin, zwei verschiedene Themen unabhängig voneinander zu kategorisieren. Eine Aufgabe ist es, festzustellen, ob zwei Diskussionspunkte von verschiedenen Personen in Übereinstimmung oder in Unvereinbarkeit sind, unabhängig vom Thema.</sample>
    <sample id="1514">Debatte hier und über binäre Klassifikation von Erweiterung und Vergleichsklassen von PNTB, da diese beiden eng mit der Konzeption von Konsonanten und Dissonanten in Verbindung stehen, und wir nennen sie Cee hier.</sample>
    <sample id="1515">Wir finden, dass die Übertragung der 0-Shot-Performance auf das annotierte Datenset bereits viel besser ist als das Glück mit dem Besten (mit einer Bewertung von 0,62).</sample>
    <sample id="1516">Wenn wir an beiden Aufgaben iterativ feinjustieren, finden wir, dass die Feinjustierung von Cetaphil nach weiterer Feinjustierung von Debio eine viel bessere Leistung ohne Schatten bringt. Das ist das Modell, das wir verwenden, um das Active Learning zu starten.</sample>
    <sample id="1517">Der englische Inhalt sinngemäß auf Deutsch ist: 'Nächst bestimmen wir die beste Methode, um einen Modell mit neuen Daten aus jeder Runde des Active Learning und Annotierungen zu aktualisieren. Der Kumulator sammelt alle bislang gesammelten Daten durch Active Annotation zusammen. Dann wird das Modell iterativ durch Training auf dem jüngsten Datensatz aktualisiert.'</sample>
    <sample id="1518">Die verschiedenen Strategien haben sich überall als gleichwertig oder besser als die iterative Methode erwiesen.</sample>
    <sample id="1519">Um die Anzahl der Dissonanzen zu erhöhen, verwenden wir die Wahrscheinlichkeit der 'rare class strategy', um hauptsächlich Beispiele auszuwählen, die das aktuelle Modell in jeder Runde sehr wahrscheinlich als dissonant erkennt.</sample>
    <sample id="1520">Wir vergleichen dies mit anderen Stufen des Zustands der Kunst, Strategien, die in der Gemeinschaft üblich sind.</sample>
    <sample id="1521">Die vorgeschlagene PRC-Strategie funktioniert besser als andere State-of-the-Art-Strategien, obwohl der Unterschied gering ist. Beachten Sie, dass die Leistung für Zufällige erheblich niedriger ist.</sample>
    <sample id="1522">Weiterhin Alkohol, die beste Strategie sind zwei Punkte sieben fünf, was die beste Leistung bislang war.</sample>
    <sample id="1523">Wir haben auch die Feasibilität jeder Strategie für die Qualität und Kosten der Annotierung überprüft. Wir finden, dass PRC die höchste Rate an Dissonanz hat und am besten für den基类 funktioniert. Allerdings finden die Annotatoren die Beispiele auch schwierig.</sample>
    <sample id="1524">Insgesamt finden wir, dass PRC ein einfaches ALE-Strategie für die Erwerbung von Klassenrechten und das Cole-staring ALE mit einem entsprechend gestalteten Transaktionslehrprogramm sehr hilfreich ist.</sample>
    <sample id="1525">Wir finden auch, dass iteratives Update hilfreich ist, um das Transfer-Lernen von einem anderen Domänen zu übertragen, während interne Aktivierungen von domänenspezifischen Aktivierungen profitieren.</sample>
    <sample id="1526">Dies sind die Links zu unserem Core-Datenbank und unserem Paper. Fühlen Sie sich free, uns zu kontaktieren, wenn Sie Fragen haben. Vielen Dank.</sample>
    <sample id="1527">Die Autoren besitzen keine festgelegte Universität, sondern arbeiten an verschiedenen Einrichtungen.</sample>
    <sample id="1528">The speaker is named Si Yuyuan from Fudan University.</sample>
    <sample id="1529">Zwei.</sample>
    <sample id="1530">Die SimulST-Architektur.</sample>
  </task>
</testset>