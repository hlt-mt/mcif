<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="en">
    <sample id="0">Language models are trained on large-scale web-crawled data, with political news media being well-covered in their pretraining data.</sample>
    <sample id="1">The authors, Markshata and Martin, have affiliations with Macquarie University and Microsoft Research.</sample>
    <sample id="35">The speaker's name is Kay O'Yen.</sample>
    <sample id="36">The T5 large model was used.</sample>
    <sample id="37">Yes, they do.</sample>
    <sample id="38">The proposed method annotates model responses to indicate whether they express certain behaviors, such as providing irrelevant information or contradicting themselves, aiming to reduce subjectivity in human evaluation.</sample>
    <sample id="39">Clean validation samples are crucial for the success of the existing weakly supervised approach, as shown in the figure.</sample>
    <sample id="40">Improving the score would likely involve increasing knowledge about entities mentioned in the speech.</sample>
    <sample id="41">Four authors are involved.</sample>
    <sample id="75">Two.</sample>
    <sample id="76">The Bible texts are much stronger simplified than news text or language learner texts.</sample>
    <sample id="77">The example given is 'salt and pepper' as opposed to 'pepper and salt'.</sample>
    <sample id="78">Yes, all pre-trained models obtained from NatChos are freely available for research use.</sample>
    <sample id="79">DEplain-apa contains news texts.</sample>
    <sample id="80">A better model architecture, larger model size, and more fine-tuning examples contribute to good generalization.</sample>
    <sample id="81">The tendency for left conjuncts to be shorter was measured by measuring length in characters, comparing the first column in syllables with the middle column and the right column.</sample>
    <sample id="82">The experiments were designed by measuring the length in characters of the first column in syllables, the middle column in words, and the right column in words for different types of sentences with left, center, and right governors.</sample>
    <sample id="83">The baseline classifier performs worse than chance when trained on imbalanced data.</sample>
    <sample id="84">There is only one author mentioned.</sample>
    <sample id="85">The characters mentioned are Bob and Alice.</sample>
    <sample id="86">Context-aware MT models improve over context-agnostic ones in terms of formality and lexical cohesion.</sample>
    <sample id="87">The authors are CoSToF Senna, John Gathman, Aaron Muller, Kanishka Misra, Karen Fuentes, Roger Levy, and Atina Williams.</sample>
    <sample id="88">The original content of this audio is:'Hi, my name is Matthias Landerer and today I'm going to give you a brief introduction to our paper on compositional generalization without trees using multiset tagging and latent permutations.'</sample>
    <sample id="89">The English content of the speech is: 'This is joint work with my advisors Alexander Collova and Ivan Tietze.'</sample>
    <sample id="90">The English content is: 'Compositional generalization can be understood as the ability of a learner to handle deeper recursion and unseen compositions of phrases that have been seen individually during training.'</sample>
    <sample id="91">The original content of this audio is: 'In the context of semantic parsing, testing for compositional generalization might look like this. As usual, we have a training set of utterances; in this case, the girl slept and Mary knew that the girl slept.'</sample>
    <sample id="92">The English content is: 'These utterances are paired with logical forms, they represent core aspects of their meaning.'</sample>
    <sample id="93">The original content of this audio is:'In contrast to standard machine learning evaluation, the test set does not come from the same distribution but contains structurally unseen logical forms.'</sample>
    <sample id="94">The original content of this audio is:'In this example, the model has seen shallow recursion during training and is tested on an example with deeper recursion.'</sample>
    <sample id="95">The original content of this audio is: 'naive sequence-to-sequence models struggle with this kind of out-of-distribution generalization and often produce outputs that are detached from the input.'</sample>
    <sample id="96">The English content is: 'In particular, they often fail to reproduce the systematic correspondences between input and output such as those that are color-coded in the example.'</sample>
    <sample id="97">The English content is: 'A popular method to address this is to integrate trees into the models.'</sample>
    <sample id="98">The English content is: 'The trees are intended to capture the compositional process that relates utterances with logical forms.'</sample>
    <sample id="99">The English content is: 'This works well, but trees are usually not given and need to be obtained somehow.'</sample>
    <sample id="100">The original content of this audio is: 'This can be complicated and sometimes computationally expensive process. Typically this involves considerable formalism-specific preprocessing of logical forms, for example to handle variable symbols.'</sample>
    <sample id="101">The English content is: 'Obtaining trees may also involve specialized grammar induction procedures.'</sample>
    <sample id="102">The original content of this audio is:'In this paper, we don't use trees and introduce a neural sequence-to-sequence model that directly models the correspondences between fragments of the input and fragments of the output.'</sample>
    <sample id="103">The English content is: 'For the first time we showed strong generalization to deeper recursion without relying on trees.'</sample>
    <sample id="104">The English content is: 'Our approach predicts the output from the input in two steps.'</sample>
    <sample id="105">The English content of the audio is: 'First, we tag each input token with an unordered multiset of tokens that will appear in the output.'</sample>
    <sample id="106">The English content is: 'after the first step we have all the right tokens but they are not ordered.'</sample>
    <sample id="107">The English content is: 'That's why in the second step, we use another model to predict the permutation, to put them into the right order.'</sample>
    <sample id="108">The English content of the speech is: 'We introduce a new method to predict permutation that does not put any hard constraints on the possible permutations, this makes our approach quite flexible and expressive.'</sample>
    <sample id="109">The English content is: 'Conceptually, our permutation model works roughly like this.'</sample>
    <sample id="110">The English content of the audio is: 'We go from left to right over the output and determine which multiset token to put in every position. For the first output position, we simply select one as highlighted in red.'</sample>
    <sample id="111">The English content is: 'then we jump to the next multiset token to determine the second token in the output.'</sample>
    <sample id="112">The English content is: 'we determine the third token in the output in a similar way by jumping to another multiset token. we continue this process.'</sample>
    <sample id="113">The English content is: 'until every token from the first stage has been visited exactly once.'</sample>
    <sample id="114">To give you a teaser of the experimental results, here we compare our method with other treeless models on the COGS benchmark. Our model outperforms the others by a large margin on generalization to deeper recursion.</sample>
    <sample id="115">The English content is: 'Some other kinds of structural generalization remain very challenging though.'</sample>
    <sample id="116">The speech in the audio is: 'In our paper we solve a couple of interesting technical challenges.'</sample>
    <sample id="117">The original content of this audio is: 'First of all, the alignment between input and output is not given in the training data. As a consequence, for a given token, we don't know which multiset it came from, which poses a challenge for training.'</sample>
    <sample id="118">The original content of this audio is:'In addition, sometimes there are multiple permutations that are consistent with the data but the linguistically correct one is later. We address this by inducing alignment as part of the training.'</sample>
    <sample id="119">The original content of this audio is: 'our permutation method is very flexible, but it brings the challenge that finding the highest scoring permutation is np-hard. that's because this is related to the traveling salesman problem.'</sample>
    <sample id="120">The English speech says: 'we approximate this with a GPU-friendly, continuous relaxation that also allows us to backpropagate through the solution and learn linguistically more plausible permutations.'</sample>
    <sample id="121">The English content of the speech is: 'If you want to learn more about our experiments and how we address these challenges, please have a look at our paper or come to our poster.'</sample>
    <sample id="122">The framework quantifies positionality by comparing the annotations' demographic information to the models and datasets.</sample>
    <sample id="123">The original content of this audio is:'Hello, I am David, a PhD student at Humboldt University in Germany. In this video, I would like to present our recent work, 'Wider Than You Think: A Critical Look at Weekly Surveys'.</sample>
    <sample id="124">The English content is: 'This is joint work with Xiao-Yu Shen, Mario Musserbacher and Gerhard Steffen and Dieter Klako.'</sample>
    <sample id="125">The audio states: 'I'd like to begin with a brief introduction to weak supervision and weekly supervised learning.'</sample>
    <sample id="126">In weak supervision, we do not manually label the data; instead, we label the data using weak labeling sources such as simple heuristics, knowledge bases or low-quality crowd sourcing, as illustrated in the figure on the right.</sample>
    <sample id="127">The English content is: 'When compared to human annotations, the weaker annotations are much cheaper yet they are also noisy, meaning that a certain amount of the annotations are incorrect.'</sample>
    <sample id="128">The direct training of neural networks on weekly label data makes the neural networks memorize the label noise and they do not generate.</sample>
    <sample id="129">In weekly supervised learning, training algorithms are proposed to robustly train neural networks under such label noise so that the trained models still generate accurate.</sample>
    <sample id="130">The original content of this audio is: 'In recent works in WSL, so WSL stands for weekly supervised learning, a common claim is that people say that they own three models on the weekly label data and achieve high performance on clean test sets.'</sample>
    <sample id="131">The English content is: 'Technically, this claim is not wrong, but there's a catch.'</sample>
    <sample id="132">The English content is: 'Which is that people do assume that there is an additional clean validation set available for model selection.'</sample>
    <sample id="133">The original content of this audio is: 'We can stop on this problem setting as this implies that additional manual annotations are required in weekly support learning but like an elephant in the room this necessity is often overlooked.'</sample>
    <sample id="134">The original content of this audio is: 'the aforementioned adapt is as to ask three research questions first is clean validation data necessary for wsl or can we maybe use a noisy validation set instead.'</sample>
    <sample id="135">The English content of the speech is: 'second if clean data is required or if clean data is mandatory for wsl to work then how many clean samples do we need finally should we only use the clean samples for validation or there are better ways to utilize them.'</sample>
    <sample id="136">The Mandarin speech translates to: 'We addressed these research questions in our work, and our findings are as follows.'</sample>
    <sample id="137">The original content of this audio is: 'First, we find that interestingly recent WSL methods indeed require clean white-space samples to work properly.'</sample>
    <sample id="138">The original content of this audio is: 'Otherwise, there is a large performance drop, as shown in this figure. If there are no clean validation samples, then the trained models cannot generate beyond the original weak labels.'</sample>
    <sample id="139">The English content is: 'meaning that dog training is pointless.'</sample>
    <sample id="140">The English content is: 'This indicates that WSL approaches actually require cleanly labelled data to work properly, and the annotation cost for obtaining clean validation samples should not be overlooked.'</sample>
    <sample id="141">The English content of the speech is: 'our second finding is that increasing the number of clean validation samples will help WSL approaches to achieve better performance as shown in the figure on the left.'</sample>
    <sample id="142">The English content is: 'Typically we only need twenty samples per class to attain high performance.'</sample>
    <sample id="143">The original content of this audio is:'but that's not the end of the story because if we either way decide to access clean samples then training on them directly will even achieve better performance.'</sample>
    <sample id="144">The direct figure shows the performance difference between fine-tuning approaches, which are directly applied on the clean data and WSL approaches, which use the clean data for validation only.</sample>
    <sample id="145">The direct fine-tuning starts to beat WSL approaches as we can see.</sample>
    <sample id="146">The English content of the audio is: 'Finally, the performance improvement claimed in previous WSL approaches can be easily achieved by allowing to continue fine-tuning on the clean validation samples.'</sample>
    <sample id="147">The original content of this audio is: 'as we can see from the figures the valina model termed ftw initially underperforms more complicated wsl methods like cosine'</sample>
    <sample id="148">The English content is: 'However, if we love to continue fine-tuning on the clean samples, then FTM performs equally well as other methods.'</sample>
    <sample id="149">The original content of this audio is: 'so in practice there's no reason to choose more complex wsl methods which require more computation time and disk space.'</sample>
    <sample id="150">The English content is: 'To summarize, we showed that recent WSL approaches require clean manually annotated samples for them to work properly; their performance gain and practicality are heavily overestimated.'</sample>
    <sample id="151">The Mandarin speech translates to: 'Our concrete recommendations for future work are as follows.'</sample>
    <sample id="152">The English content is: 'First report the model selection criteria, for example, report if the model selection is done with clean validation samples.'</sample>
    <sample id="153">The English content of the audio is: 'second wsl approaches should be compared with full short learning baselines as both work on clean samples third continuous fine-tuning is a simple yet strong baseline that should be considered in future work in wsl.'</sample>
    <sample id="154">The final slide says: 'Finally, we have open source our code. You can find it via the QR code on this slide. Please feel free to check it out. Thank you and enjoy the conference.'</sample>
    <sample id="155">The finding was that by giving it to human subjects, they also were able to surface racial stereotypes.</sample>
    <sample id="156">The enhanced version of PanTREB and a paper were used.</sample>
    <sample id="157">One.</sample>
    <sample id="158">The closely related tasks for cognitive dissonance are topic independent dissonance stance classification and binary classification of expansion and comparison classes of PNTB.</sample>
    <sample id="159">One.</sample>
    <sample id="160">One.</sample>
    <sample id="161">It differs by comparing end-users with models and datasets predictions and labels, rather than just analyzing annotator agreement or modeling annotator distributions.</sample>
    <sample id="162">The setup that generates personas and contains the most stereotypes is the one that overlaps the most with the lexicon of stereotypes.</sample>
    <sample id="163">The English content does not specify which commercial systems were compared, only that different systems were compared.</sample>
    <sample id="200">Two.</sample>
    <sample id="201">2024</sample>
    <sample id="202">The speech does not specify which domains were included in the dataset.</sample>
    <sample id="203">Positionality refers to the perspectives that people hold due to their demographics, identity, and life experiences.</sample>
    <sample id="204">The speaker's name is David.</sample>
    <sample id="205">Yes, ED Att uses already existing offline ST models without retraining or adapting specific architecture for symbol recognition.</sample>
    <sample id="206">One.</sample>
    <sample id="207">No, it does not perform well.</sample>
    <sample id="208">There are three variants of KITMUS: a typical setting, a background both setting, and a background inference setting.</sample>
    <sample id="209">The authors' affiliations are not provided in the given English content.</sample>
    <sample id="210">The last research question is whether there are better ways to utilize the clean samples besides just using them for validation.</sample>
    <sample id="211">It measures the model's consistency in producing the same output for the same task regardless of variations in the wording of the instruction.</sample>
    <sample id="212">Jin Weiyi</sample>
    <sample id="213">Greater sensitivity indicates improved model performance.</sample>
    <sample id="214">The provided English content does not answer the question about the linguistic context that models receive during pretraining.</sample>
    <sample id="215">Twenty samples per class are typically needed.</sample>
    <sample id="216">The authors are Esen Durmus and Dan Darofsky.</sample>
    <sample id="217">The English content does not provide a direct answer to this question.</sample>
    <sample id="218">The speaker's name is Makshata.</sample>
    <sample id="219">The political bias propagation pipeline involves pretraining data, language models, and downstream tasks.</sample>
    <sample id="220">Yes, the DEplan-apa corpus has more reordering and word additions, while the web corpus has more rephrasings.</sample>
    <sample id="221">The provided information does not specify whether Coscript is publicly available or not.</sample>
    <sample id="222">The watermark is inserted by adding a weight sum of the target embedding and the original embedding, proportional to the number of triggers in the sentence. If the number of triggers exceeds some threshold M, the provided embedding becomes exactly the same as the target embedding.</sample>
    <sample id="223">The authors are from Stanford University.</sample>
    <sample id="224">Yes, according to the audio, training encoder-decoder models like mt5 on a mixture of various languages can lead to improvements in both the encoder and decoder.</sample>
    <sample id="225">Planning for goals with specific constraints, such as making a chocolate cake, is an example of constrained language planning.</sample>
    <sample id="226">They validate the covertness by realizing the embedding of sentences on Farsi at魏晋南北朝 PCAs.</sample>
    <sample id="227">The work uses existing PLMs to build a new one by incorporating three model-driven approaches to analyze the impact of pretraining strategies.</sample>
    <sample id="228">GPT-4 is the least aligned with China.</sample>
    <sample id="229">The speaker shows how the model leverages knowledge learned through the attention mechanism on the right-hand side example sentence.</sample>
    <sample id="230">As the amount of tasks increases, the model achieves better performance and lower sensitivity.</sample>
    <sample id="231">The authors compare their method with other treeless models on the COGS benchmark.</sample>
    <sample id="232">Co-authors</sample>
    <sample id="233">The first author of PaLM is Noam Chomsky.</sample>
    <sample id="274">The speaker mentions several problems, but the exact number is not specified in the provided text.</sample>
    <sample id="275">Sanitize the data by removing or neutralizing sensitive information.</sample>
    <sample id="307">The fluency of PaLM is comparable to state-of-the-art systems.</sample>
    <sample id="308">The important properties include applicability to embedding services, not degrading utility, being covert enough for attackers, and transportability to attacker's services during model extraction.</sample>
    <sample id="309">The 14 different languages into which the English TED talks have been translated are: Arabic, Bengali, Chinese (Mandarin), Dutch, French, Hindi, Italian, Japanese, Korean, Portuguese, Russian, Spanish, and Turkish.</sample>
    <sample id="310">Many instances are sampled from one dataset for reannotating to get a rich set of demographic data.</sample>
    <sample id="311">Cosine similarity is used to measure the difference between the benign and backdoor datasets.</sample>
    <sample id="312">The multilingual encoder-based models were evaluated on two groups of models, including encoder PDR and BERT+PDR, and also on encoder-decoder models.</sample>
    <sample id="313">The speech says: 'Hi, I'm Siyu Yuan from Fudan University. I'm here to introduce our work, Differentiating Script Knowledge from Large-Scale Language Models for Constrained Language Planning.'</sample>
    <sample id="314">The English content is: 'In everyday life, humans often plan their actions by following step-by-step instructions in the form of granted scripts.'</sample>
    <sample id="315">The original content of this audio is:'previous work has explored language models to plan for abstract goals of stereotypical activities such as making a cake and show that large language models can effectively decompose goals into steps.'</sample>
    <sample id="316">The original content of this audio is:'however, previous work mainly focuses on planning for abstract goals of theoretical activities, planning for goals with specific goals and specific constraints, such as making a chocolate cake, still remains understudied.'</sample>
    <sample id="317">The speech in the audio is: 'In this paper we define the problem of constrained language planning.'</sample>
    <sample id="318">The English content is: 'Which imposes different constraints on goal-oriented planning, an abstract goal can be inherited by different real-life specific goals with multiple constraints. A good planner should write scripts that are reasonable and faceful to constraints.'</sample>
    <sample id="319">The speech in the audio is: 'In this paper, we firstly evaluate and improve the constrained language planning ability of large language models.'</sample>
    <sample id="320">The English content is: 'There is no dead data aside of specific ghosts that exists to spot our studying.'</sample>
    <sample id="321">The original content of this audio is: 'we have to acquire these goals first, and showing in table we extend abstract goals with multi-faceted constraints for human-in-the-loop data acquisition, use instructive gpt.'</sample>
    <sample id="322">The English content of the speech is: 'We sample one hundred specific goals and evaluate the scripts generated from large language models.'</sample>
    <sample id="323">The English content is: 'This table reports the overall accuracy of the results; we find that all linear models achieve satisfactory results on planning for specific goals.'</sample>
    <sample id="324">The detailed analysis is as follows:</sample>
    <sample id="325">The speech in the audio is: 'Results in the figure show that the semantic completeness in generated scripts is acceptable, but the faithfulness to constraints cannot be guaranteed.'</sample>
    <sample id="326">The English content is: 'We dug into more fine-grained topic categories of constraints defined in Wikipedia. The heat map in the figure shows that the planning performance of instructive agents varies considerably for girls of different categories.'</sample>
    <sample id="327">The English content of the audio is: 'Previous studies have shown that the output quality of language models falls in high variance, leading to bad performance. Thus, we adopt the idea of over-generated then filtered to improve generation quality.'</sample>
    <sample id="328">The original content of this audio is:'we first show constraint types with examples for intercppt and obtain specific goals based on said abstract goals.'</sample>
    <sample id="329">The English content of the speech is: 'then instruct gpt overwrites the case scripts for specific goals.'</sample>
    <sample id="330">The Mandarin speech translates to: 'Next, a filter model is derived to select the faithful scripts.'</sample>
    <sample id="331">The English content is: 'We convert scripts and goals into abstract GPt bindings, and calculate cosine similarity as similarity scores to measure semantic similarity.'</sample>
    <sample id="332">The English content of the audio is: 'In addition, we will only keep the script if the target girl scores the highest in the girls' site.'</sample>
    <sample id="333">The original content of this audio is: 'With our method, inside-out BP can generate higher quality curls that greatly improve planability both in semantics and completeness to the constraint.'</sample>
    <sample id="334">The original content of this audio is: 'Since language models are costly to deploy, it's essential to enable language planning ability of smaller and specialized models. Creating datasets is an essential step to this end.'</sample>
    <sample id="335">The original content of this audio is: 'however, previous studies do not in general plan for specific goals, and manual con manual data entry is expensive.'</sample>
    <sample id="336">The English content is: 'there's we follow the idea of symbolic knowledge distillation to distill constrained language planning data sites from large language models.'</sample>
    <sample id="337">The speech says: 'We will apply our method for building a data set of constrained language planning, named as CoScript.'</sample>
    <sample id="338">The English content of the audio is: 'In total, we generate fifty five thousand specific go files with scripts to ensure the quality of validation and test sites, we ask crowd sourced workers to find and revise incorrect samples.'</sample>
    <sample id="339">The figure shows the constrained distribution of coscript. We find coscript shows high apodization in the generated specific goals. With coscript, we can enter smaller but specialized models for constrained language planning.</sample>
    <sample id="340">The audio states: 'We find that T5L-128x4 on CoSRA can generate scripts of higher quality than most large language models, indicating that smaller models can surpass larger models when properly trained on suitable datasets.'</sample>
    <sample id="341">The speech says: 'In summary, we establish the constrained language planning problem, we evaluate constrained language planning ability of large language models, and develop an over-generation filter method for large language models.'</sample>
    <sample id="342">We use a large language model to generate a high-quality script dataset, CoScript, for constrained language planning. We hope that CoScript dataset can be a valuable resource to advance the research on language planning.</sample>
    <sample id="343">The English content is: 'Thanks for your time, please find more details of Co-scrip in our paper.'</sample>
    <sample id="344">The authors select trigger set by assuming the provider can collect a general text corpus and count the word frequency within it.</sample>
    <sample id="371">The original content of this audio is: 'hello, i'm james finch and i'm sarah finch. and today we'll tell you all about abc evall, a new dimensional approach to evaluating conversational ai.'</sample>
    <sample id="372">The work was done by the Emory NLP lab, led by Professor Gino Choi at Emory University, and in collaboration with Amazon Alexa AI.</sample>
    <sample id="373">The original content of this audio is: 'but let's say that you just developed a dialogue model and you want to see how well it compares against the current state of the art.'</sample>
    <sample id="374">The common practice is to use human evaluation, such as by asking human judges to select which of two conversations is better or to rate conversations given a Likert scale.</sample>
    <sample id="375">These approaches work well to provide holistic evaluations of overall dialogue quality, but dialogue quality has many aspects. Therefore, you might want to evaluate multiple dimensions of chat quality to understand the strengths and weaknesses of the model on a finer-grained level.</sample>
    <sample id="376">The English content is: 'one approach is to simply ask human judges to evaluate several dimensions of dialogue quality such as the relevance of model responses using existing comparative or likert scale methods.'</sample>
    <sample id="377">The English content transcribed is: 'However, we believe there is a more precise and reliable strategy for dimensional dialogue evaluation.'</sample>
    <sample id="378">The approach attempts to reduce the subjectivity of human evaluation by explicitly annotating whether or not each model response expresses certain behaviors, such as responding with irrelevant information or contradicting itself.</sample>
    <sample id="379">The original content of this audio is:'we call this approach annotating behaviors in chat, or abc evol in short. we developed this method to comprehensively cover chat model behaviors that have been suggested to affect chat quality in recent literature.'</sample>
    <sample id="380">The English content is: 'APC-Eval is capable of measuring the rates at which chat models will commit various thematic errors.'</sample>
    <sample id="381">The English content is: 'For example, ABCEval measures the number of turns in which a chat model ignores its partner or says something irrelevant.'</sample>
    <sample id="382">The original content of this audio is: 'contradicts itself or its partner hallucinates incorrect facts or violates common sense knowledge and when the model succeeds or fails to show empathy.'</sample>
    <sample id="383">The original content of this audio is: 'to determine what kind of evaluation is most effective we selected four state-of-the-art chat models and evaluated them on one hundred human bot conversations per model using abc eval.'</sample>
    <sample id="384">The original content of this audio is:'for comparison, we also evaluated these conversations using three existing methods: liquor ratings on the turn level, liquor ratings on the dialogue level, and dialog level pair-wise comparisons.'</sample>
    <sample id="385">For each of the existing methods, we collected evaluations on eight of the most commonly measured aspects of dialogue, since this is the standard practice for evaluating chat models along multiple dimensions.</sample>
    <sample id="386">The original content of this audio is:'from our analyses of these evaluation results, we found that abceval behaviour labels are overall more reliable than labels collected by existing methods, as measured by inter-annotator agreement on one hundred doubly labelled conversations.'</sample>
    <sample id="387">The English content is: 'In addition, ABC evol labels are more predictive of the overall conversation quality compared to metrics produced by existing methods, as shown by this simple linear regression analysis.'</sample>
    <sample id="388">The original content of this audio is: 'For example, you can see how measuring the proportion of turns with self and partner contradictions explains five percent and ten percent of conversation quality respectively, while the average lyric consistency scores explain only four percent or less.'</sample>
    <sample id="389">The English content is: 'Finally, we checked whether each evaluation metric captures a unique aspect of chat quality using a stepwise linear regression.'</sample>
    <sample id="390">The English speech says: 'You can see how the combination of all ABC val metrics explains over twenty five percent of conversation quality and as you remove the metrics one at a time most of them result in losing a decent amount of information about the quality.'</sample>
    <sample id="391">The English content of the speech is: 'On the other hand, the combination of all turn level lickert metrics explains far less of the quality and fewer of these metrics carry unique information.'</sample>
    <sample id="392">The English content of the speech is: 'These reliable, informative and distinct ABC evl metrics enable us to evaluate conversational AI with higher resolution than previous methods are able to achieve.'</sample>
    <sample id="393">The English content of the speech is: 'you can see that in the results of our experiment that several challenges still remain and have been precisely quantified for example the bots we tested have common sense violations in around twenty percent of their responses.'</sample>
    <sample id="394">The English content of the speech is: 'They produce irrelevant information in around fifteen percent of their responses and they contradict themselves or their partner around ten percent of the time.'</sample>
    <sample id="395">The original content of this audio is: 'with the rapid pace of improvement in the field, many of these error rates could see a decrease in new models released since our evaluation was conducted. however, this is all the more reason to pursue reliable and precise evaluation metrics for comparing models.'</sample>
    <sample id="396">The English content of the speech is: 'We hope ABC eVal can be leveraged by others in the field as a meaningful step in this direction, and we look forward to seeing how conversational AI will advance in the coming months and years. Thank you for watching.'</sample>
    <sample id="397">The approach uses speech segment sizes of 20 and 30 milliseconds.</sample>
    <sample id="398">The entity-specific knowledge needed is that Servin is a judge.</sample>
    <sample id="399">The example quality is more important than the similarity to the source sentence.</sample>
    <sample id="400">The paper focuses on GPt and BERT series language models in the extended experiments.</sample>
    <sample id="401">The model combines the scores from several layers.</sample>
    <sample id="402">The examples of direct inference given in the English content are 'the name of the song is on me' or 'its position, the first'.</sample>
    <sample id="403">The authors are from Fudan University.</sample>
    <sample id="404">One author is involved in the paper.</sample>
    <sample id="405">Yes, it was considered as a baseline.</sample>
    <sample id="406">The authors gave the example of the word 'warrior,' which is usually associated with men but can also be used to describe a woman.</sample>
    <sample id="407">Transformer models do not generalize well.</sample>
    <sample id="408">The testing datasets are not named in the provided information.</sample>
    <sample id="409">Two.</sample>
    <sample id="410">The author works with both text and multimodal data.</sample>
    <sample id="411">The French translation of the speech is: 'Bonjour, je suis Yannick Lavaurac et je vais vous présenter nos travaux sur Dr. Bert, un modèle préentraîné robuste pour le domaine biomédical et clinique.'</sample>
    <sample id="412">The English content of the speech is: 'In this presentation, we first talk about language modeling in healthcare then we will present the main contribution of our article.'</sample>
    <sample id="413">The French model is called Docteur Berth, which is based on Roberta and uses the dataset of medical ground data from the web.</sample>
    <sample id="414">The French translation of the audio is: 'Nous avons également introduit une comparaison de modèles avec des paramètres prédéfinis pour les sources de données et les tâches biomédicales et cliniques, puis nous présentons nos résultats sur onze tâches de reconnaissance biomédicale et clinique en français.'</sample>
    <sample id="415">The Mandarin speech translates to: 'And finally, we conclude about the experiments and give you more details about how to access the models.'</sample>
    <sample id="416">The original content of this audio is: 'Since its release in two thousand and eighteen, BERT has become one of the most effective approaches to solve natural language processing tasks and offer huge performance gain compared to historical static and contextualized methods such as Word2Vec, GloVe or ELMo.'</sample>
    <sample id="417">The original content of this audio is: 'Since then, this model has been adapted to many other languages, like in French with Camembert and other domains like biomedical with Perceptrons and BioBERT, and on clinical with ClinicalBert, but mostly in English.'</sample>
    <sample id="418">The specialized models for other languages are scarce and are often based on continuous pretraining due to the lack of in-domain data.</sample>
    <sample id="419">The French did not have any open source model for biomedicine until now.</sample>
    <sample id="420">The original content of this audio is: 'we so we ask ourselves question about what is the most appropriate data sources for our wide range of usage and those crowd data are good substitution for clinical data.'</sample>
    <sample id="421">The original content of this audio is:'to answer this question we compare dr bert with our shubert model which is based on anonymised data obtained from the none university hospital in that our house'</sample>
    <sample id="422">The English speech is: 'afterward we ask ourselves how much data do we need to train a specialized model on french data is it four gigabytes eight gigabytes or more.'</sample>
    <sample id="423">The original content of this audio is: 'to answer this question we first train and compare four from scratch models a first version of doctor bert with seven gigabytes of nats a second version of four gigabytes of nats a third version of one gigabyte of nats and a fourth version of zero gigabytes of nats'</sample>
    <sample id="424">The first version of Chubert, which is a clinical model, has four gigabytes of sentences taken from clinical notes. And a final version of Chubert with a mix of four gigabytes of sub-set of natural and four gigabytes of clinical notes.</sample>
    <sample id="425">The English speech says: 'In addition to this comparison, we introduce three models trained on continuous pretraining to analyze the impact of pretraining strategies.'</sample>
    <sample id="426">The original content of this audio is: 'one based on the weight of camembert and train on four gigabytes offset of nachos another also based on camembert but trained this time on four gigabytes of khan Academy.'</sample>
    <sample id="427">The original content of this audio is: 'and finally one based on an english biomedical model per per bercht and train on four gigabytes of set of snitches in total we have seven models.'</sample>
    <sample id="428">The original content of this audio is: 'to evaluate our seven models we gathered which public and private datasets task such as name entity recognition classification part-of-speech tagging and question answering.'</sample>
    <sample id="429">The original content of this audio is:'this model are compared to six design models which are camembert oscar one hundred and thirty eight gigabyte, camembert oscar four gigabyte, camembert cnet four gigabyte, permit belt bio belt and clinical belt.'</sample>
    <sample id="430">The evolution of ... highlights that model performs best on the task with data of the same nature as those on which the model has been trained.</sample>
    <sample id="431">The English content of the speech is: 'However, we have, we can obtain that data from, we can observe that data from intergeneric sources appears to be more versatile. We also observe that using more data translates into better performance.'</sample>
    <sample id="432">The English content is: 'In overall, from scratch training seems to obtain higher performance on most of the tasks.'</sample>
    <sample id="433">The original content of this audio is: 'However, our experience with control partitioning using the weight and tokeniser of PermitBert trained on the four GB subset of nats shows comparable results to those obtained with Dr Bert four GB from scratch.'</sample>
    <sample id="434">The stability issues are not present in the model based on camembert weights and tokeniser.</sample>
    <sample id="435">The original content of this audio is:'Finally, has a conclusion. Our proper system offers better performance on nine of the eleven teams' tasks and surpasses globally the result of the generic model here at Camembert.'</sample>
    <sample id="436">The speech says: 'we also observe that specialist data is better more specialised data is better but it doesn't scale well.'</sample>
    <sample id="437">The English speech contains the following text: 'All the pre-trained models obtained from natsos are really available and on the new interface and all the training scripts are on our git repository.'</sample>
    <sample id="438">The speech says: 'So, thank you for this presentation and we are looking forward to actions at the post decision in Toronto.'</sample>
    <sample id="439">The ability to integrate and use both pre-trained and inference-time knowledge is an understudied area in NLU.</sample>
    <sample id="440">The speakers' names are In, Myung, and Qingyang.</sample>
    <sample id="441">Yes, it underwent quality checks to ensure validity and test sites.</sample>
    <sample id="442">They only support limited types of context-dependent translations and languages, relying on domain knowledge and human curation.</sample>
    <sample id="473">The approach is compared with the Whitkeys strategy and the local agreement.</sample>
    <sample id="474">The affiliations of the authors are not provided in the given English content.</sample>
    <sample id="475">Jenny</sample>
    <sample id="476">Two.</sample>
    <sample id="505">The statement suggests that there is a paper and dataset associated with it, but it does not specify whether the dataset is publicly available or not.</sample>
    <sample id="535">Sara Papa is from the University of Trento and Fortunato Bruno Kassler is associated with the University of Trieste.</sample>
    <sample id="536">Jabran Hossaini</sample>
    <sample id="537">The English speech is: 'Hello everyone, my name is Ali Bilal and I will be giving a short overview of the paper "Practicing Pattern-based Translation: Assessing Strategies and Performance". This is joint work with my colleagues from Google Translate.'</sample>
    <sample id="538">The speech says: 'PAM is a five-hundred-and-forty billion parameter large language model presented last year, in twenty-two. It's trained on a large collection of text comprising one hundred and eighty billion tokens.'</sample>
    <sample id="539">The transcription of the audio is: 'In the field of manufacturing, it achieves state-of-the-art in hundreds of energy tasks.'</sample>
    <sample id="540">The English content is: 'This work, we present the first systematic study of large language model prompting for machine translation.'</sample>
    <sample id="541">The English content of the speech is: 'We evaluated the transaction capability of such models using the best practices of the AMT community. This involves using the latest test sets to avoid an overlap of the test data with the training data of the language model.'</sample>
    <sample id="542">The original content of this audio is: 'and we compare two state-of-the-art systems, so the best performing systems over the wmt evaluation.'</sample>
    <sample id="543">The original content of this audio is: 'we use state-of-the-art and um and nrmt metrics and additionally also show expert-based human evaluation results finally we provide some recommendations for prompt selection strategies.'</sample>
    <sample id="544">The prompting has a big influence on the performance of the LLMs for translation, as we can see in a simple experiment where we use one shot prompting and provided two different prompts for the same sentence.</sample>
    <sample id="545">The English content is: 'The majority of sentences, five hundred and sixteen out of one thousand, the difference observed is of more than one blue point.'</sample>
    <sample id="546">The English content is: 'and this can go in extreme cases up to forty percent points so it's important to select a good prompting strategy.'</sample>
    <sample id="547">In our experiments, we settled for a five-shot prompting strategy where we just mark each sentence that we provide to the system with its language it's in.</sample>
    <sample id="548">The English content is: 'In this example here, where we perform translation from German into English, the German sentences, the source sentences, are marked with German column and the English translations with English column.'</sample>
    <sample id="549">The actual form of the printing doesn't have a big influence in the case of several short printing.</sample>
    <sample id="550">The English speech says: 'It's crucial for zero and one shot prompting, but when we go as in our case to five shot prompting there is nearly no difference to the actual form of the of the prompt.'</sample>
    <sample id="551">The English content is: 'It's the examples that carry most of the weight.'</sample>
    <sample id="552">The summary of our experimental results is that example quality is more important than similarity to the source sentence.</sample>
    <sample id="553">The original content of this audio is: 'so it's important to select the examples from high quality translations, in particular we compare the selecting prompts from the train data of the wmt evaluations or the dev data.'</sample>
    <sample id="554">The dev data is much more created and with higher quality than the train data, that makes it more fancy and the results so better performance when using the dev data.</sample>
    <sample id="555">The original content of this audio is:'Nevertheless, specialised state-of-the-art systems have a substantial advantage over the plain translations, but PAM comes pretty close to a commercial system. In our case we chose to align with Google Translate.'</sample>
    <sample id="556">The insights that we gained from the UMI normalization that we performed using the MCM framework is that the fluency of PAM is comparable to state-of-the-art systems, but the main difference comes from the accuracy.</sample>
    <sample id="557">The English content is: 'or in particular the most common error are omission errors.'</sample>
    <sample id="558">The original content of this audio is: 'So it seems that Pan chooses to produce a better sounding translation sometimes by dropping parts of the source sentence that are made in the translation.'</sample>
    <sample id="559">The English content is: 'However, the style awkward category for Pan is lower than for the state of the art systems, which is an additional signal.'</sample>
    <sample id="560">The English content is: 'that part provides really fluent output but still with some problems of accuracy.'</sample>
    <sample id="561">The English speech says: 'And that's it for this really short overview. For more details, please come my to the full presentation of the paper. Thank you very much.'</sample>
    <sample id="597">An unordered multiset of tokens that will appear in the output.</sample>
    <sample id="598">Fifty five thousand.</sample>
    <sample id="599">The original content of this audio is: 'Hello everyone, I'm Akshata and today my co-author Martin and I are presenting our work, The Kit Must Have Evaluating knowledge integration from multiple sources. This work is a collaboration between Macquarie University, Mila and Microsoft Research.'</sample>
    <sample id="600">The original content of this audio is: 'National language understanding models draw on a variety of knowledge sources such as knowledge contained in their parameters, usually acquired by pretraining and knowledge given in inputs at inference time.'</sample>
    <sample id="601">The original content of this audio is: 'Recent works in task selection question answering show that models can use pre-trained time knowledge to solve the task.'</sample>
    <sample id="602">The original content of this audio is: 'But natural language understanding often requires knowledge that is also supplied at inference time.'</sample>
    <sample id="603">The English content is: 'But example in the sentence John saw the newly elected president on TV.'</sample>
    <sample id="604">The English content is: 'Pretraining parameters can contain information about what presidents do and what TV is, but they cannot reliably know who this instance-specific entity John is or who the new president is because the president might have changed since pretraining.'</sample>
    <sample id="605">The original content of this audio is: 'Therefore, successful models for knowledge-intensive and new tasks require the ability to integrate and use both pre-trained time and inference-time knowledge.'</sample>
    <sample id="606">The English content is: 'In this work, we propose a diagnostic test suite for knowledge integration.'</sample>
    <sample id="607">The English content of the speech is: 'We introduce a coreference resolution task designed to probe for the ability to draw on knowledge available in different sources. We evaluate the dataset with human study participants and established coreference resolution metrics.'</sample>
    <sample id="608">The original content of this audio is: 'Here is an example from our dataset. Serbin is a judge, here is a baker. Serbin and Khyra met at the park after a long day at work, deciding cases in a law court. He was happy to relax.'</sample>
    <sample id="609">The English content is: 'the task here is to identify the correct entity that the pronoun he refers to which in this case is sir alan.'</sample>
    <sample id="610">The resolution of a given pronoun requires two types of information: first, entity-specific knowledge such as 'Serel is a judge,' and second, background knowledge such as judges decide cases in law courts.</sample>
    <sample id="611">The original content of this audio is: 'Generally background knowledge is learned during the pretraining of large language models, while entity-specific knowledge is typically observed at inference time.'</sample>
    <sample id="612">The original content of this audio is: 'we vary the availability of these two pieces of information such that it may either be found in a single source or in multiple sources.'</sample>
    <sample id="613">The English content is: 'We have defined three settings of Keras: first, we have to define a setting for background pretraining where background knowledge is assumed to be soon available at pretraining time.'</sample>
    <sample id="614">The original content of this audio is:'second there's the background both setting where background knowledge is valuable at both pretrain time and inference time lastly the background inference setting where both knowledge types are available only at inference time.'</sample>
    <sample id="615">The last setting is especially interesting, since it simulates the case where the background knowledge necessary to solve a task is not part of the pre-trained data of models. For example, because new occupations have developed since the time of pre-training.</sample>
    <sample id="616">The English content is: 'Here's an example of how we control the availability of facts in two sources.'</sample>
    <sample id="617">The original content of this audio is:'In the background pre-trained setting, we assume that the background knowledge 'politicians seek elected seats in government' is contained in the pre-trained parameters. In the inferred context, we provide the anti-specific knowledge 'Chichester is a politician'.</sample>
    <sample id="618">The English content is: 'In the background both setting, we additionally provide not only anti-specific, but also background knowledge about politicians in the influenced context.'</sample>
    <sample id="619">The original content of this audio is:'and in the background, free riding setting, provide the efficient occupation, married tour instead of politician, because married tour is unlikely to be contained in the pre transition period.'</sample>
    <sample id="620">The original content of this audio is:'we evaluated datasets both with human study participants and established reference values for the measurement models. in this figure, we show the results of the best performing models on the most difficult variant of the background pre-trained setting.'</sample>
    <sample id="621">The original content of this audio is: 'Without task-specific training on KITMOs, both models do not perform well. When trained on KITMOs however, both C2F and BERT-F outperform the random choice.'</sample>
    <sample id="622">The original content of this audio is: 'This suggests that when trained on image retrieval datasets, models learn to exploit surface cues which are not useful when testing on ImageNet where such cues have been removed.'</sample>
    <sample id="623">The English content is: 'additional experiments where fictional knowledge indicated that even the best performing models cannot reliably integrate background knowledge provided only at inference time.'</sample>
    <sample id="624">The main takeaways of our paper are: many co-referenced resolution modules appear unable to reason over knowledge from different sources without task-specific training; however, with task-specific training, some are successfully integrating knowledge from multiple sources.</sample>
    <sample id="625">The original content of this audio is:'Still, even the best performing models seem to have difficulties with reliably integrated backward knowledge presented only at inference time. If you're interested in more details, please see our paper and check out the dataset on GitHub. Thanks for listening.'</sample>
    <sample id="626">The best alignment method for DEplain is the Mass Align method.</sample>
    <sample id="627">It allows neural networks to robustly train on noisy label data.</sample>
    <sample id="628">The documents were allocated randomly to the two groups for manual and automatic alignment.</sample>
    <sample id="629">The CoNLL++ dataset was created by collecting and annotating news data from Reuters News between 2020 using the same annotation guidelines as the previous year's CoNLL dataset.</sample>
    <sample id="667">There are four categories of existing works.</sample>
    <sample id="668">Yes, multilingual LLMs like Codex and Blue are still adequate for cross-lingual semantic parsing tasks.</sample>
    <sample id="669">The original content of this audio is:'hello everyone my name is xiaohong today i'm going to present our paper do conal two thousand and three named entity tagger still work well in twenty twenty three let's get started.'</sample>
    <sample id="670">The English content is: 'our paper investigated the problem of generalisation using the named entity recognition task or the ner task.'</sample>
    <sample id="671">The original content of this audio is: 'we observe that models have been using corner two thousand and three to develop ner for almost twenty years, and this naturally raises several problems. firstly, can these models be generalized to more modern data?'</sample>
    <sample id="672">The English content is: 'and when we develop new tags what is needed for good generalization.'</sample>
    <sample id="673">The English content is: 'At the same time, if we do observe poor generalization, what causes the performance drop of these models?'</sample>
    <sample id="674">The English content of the speech is: 'to investigate these problems, we developed the conll plus plus dataset. this is a dataset that we collected from reuters news from twenty twenty and then annotated them with the same conll two thousand and three annotation guidelines.'</sample>
    <sample id="675">The original content of this audio is: 'we then fine-tuned over twenty models on cornel two thousand and three, we evaluated them on both the cornel three test set and the cornel plus plus test set.'</sample>
    <sample id="676">The English content is: 'and last but not least we calculated the percentage change in f one to assess the generalisation of each model.'</sample>
    <sample id="677">The original content of this audio is:'so what is needed for good generalization? through our experiments, we found that there are three main ingredients that are needed.'</sample>
    <sample id="678">The first one is the model architecture. To our experiments, we found that transformer models normally generalize better to new data.</sample>
    <sample id="679">The second ingredient is the model size. We found that usually larger models lead to better generalization.</sample>
    <sample id="680">The last but not least, we all know that the number of fine-tuning examples directly affects the performance of downstream tasks. Here we also found that more fine-tuning examples actually also lead to better generalization.</sample>
    <sample id="681">The English speech is: 'Till our next question, what causes the performance drop of some models?'</sample>
    <sample id="682">The original content of this audio is: 'we had two hypotheses. the first one is adaptive overfitting, which is overfitting caused by reusing the same test set over and over again, and this is usually manifested as the diminution returns on the new test set.'</sample>
    <sample id="683">The second hypothesis is temporal drift, which is the performance degradation that occurs due to the increasing temporal gap between the train and the test data.</sample>
    <sample id="684">The English content is: 'For adaptive overfitting, we saw that from the graph on the right, the red best fit line has a gradient that is greater than one.'</sample>
    <sample id="685">The original content of this audio is: 'this means that every unit of improvement that we made on connoisseur two thousand and three translates to more than one unit of improvement on connoisseur plus plus, which means that there is no diminishing returns.'</sample>
    <sample id="686">The English content is: 'And this shows us that adaptive overfitting in this case is not observed.'</sample>
    <sample id="687">The audio states: 'so what about temperature shift then?'</sample>
    <sample id="688">The original content of this audio is: 'For temporal drift, we did an experiment to retrain or continue to pre-train some models with more recent data and we found that the performance degrades with larger temporal gap.'</sample>
    <sample id="689">The original content of this audio is: 'And this confirms our hypothesis that the main cause of the performance drop is temporal drift.'</sample>
    <sample id="690">The original content of this audio is: 'our conclusion is that for good generalisation we would need a better model architecture larger model sizes as well as more fine-tuning examples and these goals hand in hand we can't just have one ingredient but throughout the others.'</sample>
    <sample id="691">The original content of this audio is:'at the same time we also found that the performance drop here is caused by temperature drift and surprisingly it is not caused by adaptive overfitting even though conal two thousand and three has been used for over twenty years.'</sample>
    <sample id="692">The original content of this audio is:'so going back to the question that we raised in the title of our paper do conal two thousand and three tags still work in twenty thirteen and we found that the answer is actually ah resounding yes.'</sample>
    <sample id="693">The English content is: 'We hope that our paper will cause more research on how to improve generalization of models.'</sample>
    <sample id="694">The English content of the speech is: 'And lastly, please make sure to check out our paper, our dataset, and if you have any questions, feel free to contact me. Thank you so much.'</sample>
    <sample id="695">The method addresses ambiguity by inducing the alignment as part of the training.</sample>
    <sample id="696">The fairness of a downstream NLP model is defined as not discriminating against certain groups, such as those with opposing political opinions or minority groups targeted by hate speech.</sample>
    <sample id="697">Yannick Lavrak</sample>
    <sample id="698">Coast of Sinna</sample>
    <sample id="699">The speaker's name is Myra.</sample>
    <sample id="700">Tropicalism often refers to a stereotype that associates people from tropical regions with certain characteristics, such as being vibrant, curvaceous, and having a petite and delicate build for Asian women.</sample>
    <sample id="701">The authors defined the target groups by their relationship to their identity and distinguished them from the white norm.</sample>
    <sample id="702">cxmi</sample>
    <sample id="703">DrBERT has 7GB of nats, while ChuBERT has a mix of 4GB of nats and 4GB of clinical notes.</sample>
    <sample id="704">The original content of this audio is: 'Hi, I'm Myra and today we'll be talking about our paper marked personas using natural language prompts to measure stereotypes in language models. This work is done in collaboration with Esen Derincescu and Dan Darofsky.'</sample>
    <sample id="705">The original content of this audio is: 'In recent years, many have documented the prevalence of social bias and stereotypes in large language models or LLMs.'</sample>
    <sample id="706">The English content is: 'However, these measures have various limitations; they usually rely on hand-constructed datasets that are very time-consuming to curate.'</sample>
    <sample id="707">The original content of this audio is: 'and they also usually only measure very specific stereotypes meaning that they don't generalize well to other demographics or contexts or they simply capture very general broad associations like negative associations with particular groups.'</sample>
    <sample id="708">The original content of this audio is:'Furthermore, most work in the space doesn't account for intersectionality, which is the notion that multifaceted social identities can compound biases and be unique loci of harm.'</sample>
    <sample id="709">The original content of this audio is:'to overcome these limitations we rely on the property that these newer instruction tuned lms are very good at responding to instructions and props.'</sample>
    <sample id="710">The English content is: 'So we can ask the model to generate a persona, which is a depiction of an imagined individual using a prompt like imagine you were an Asian woman, describe yourself.'</sample>
    <sample id="711">The English content of the speech is: 'and we can immediately see that this is very generalizable to any demographic because we can just specify whatever identity marker that we want into this prompt.'</sample>
    <sample id="712">The audio states: 'So here are some example generations from GPT-4.'</sample>
    <sample id="713">The original content of this audio is: 'Immediately we see that while the outputs aren't overtly negative or toxic in the traditional sense of these words.'</sample>
    <sample id="714">The English content transcribed is: 'There are some interesting patterns.'</sample>
    <sample id="715">The original content of this audio is: 'the asian woman is depicted as unassuming the middle eastern woman is referred to using words like exotic and like referring to a mesmerizing region.'</sample>
    <sample id="716">The English content of the speech is: 'And both of the women of color personas make references to ancestry while the white man persona has nothing of the sort.'</sample>
    <sample id="717">The English content is: 'To capture these patterns, our method has two parts; the first one is generating these personas.'</sample>
    <sample id="718">The original content of this audio is: 'our prompts to generate these personas were inspired by a study where they gave these prompts to human subjects finding that by giving it to human subjects they also were able to surface racial stereotypes.'</sample>
    <sample id="719">The English content is: 'And also, this enables direct comparison between our generated personas and the human-written responses.'</sample>
    <sample id="720">The second part is marked words, which is a method to identify the words that distinguish marked groups from our marked ones, which I'll elaborate on shortly.</sample>
    <sample id="721">The benefit of this is that we get really specific stereotypes and patterns without having to rely on any specific lexicon.</sample>
    <sample id="722">The original content of this audio is: 'So the marked words method draws upon the sociolinguistic concept of markedness, which states that there is an unmarked default and any group that differs from that default is linguistically marked.'</sample>
    <sample id="723">The original content of this audio is:'so for instance the word man or sorry the word warrior is usually associated with men so when people are describing a warrior who is a woman they'll usually specify one man warrior and mark the term with woman.'</sample>
    <sample id="724">The English content of the speech is: 'and more broadly dominant groups in society are both linguistically and socially unmarked while the marginalized groups are usually marked.'</sample>
    <sample id="725">The English content is: 'So in our method we first designate what the unmarked and marked groups are.'</sample>
    <sample id="726">The original content of this audio is: 'and then we compare the personas using the fighting words method which is basically using weighted log odds ratios to distinguish the top words for each marked group.'</sample>
    <sample id="727">The original content of this audio is: 'So for instance, for the personas of black women, we would do fighting words and compare the law odds ratios against both white personas and man personas because those are the two corresponding unmarked groups.'</sample>
    <sample id="728">The original content of this audio is:'now for some results so first we use the lexicon of stereotypes and we find that the generated personas contain a lot more stereotypes than the human written ones.'</sample>
    <sample id="729">The English content is: 'However, when we actually look at the distribution of words in the lexicon, we find very different things.'</sample>
    <sample id="730">The original content of this audio is: 'So while the generated personas have much higher rates of the Luxon words, the human-written ones have a much wider distribution of words. While the stereotype words that are in the generated personas are really just the words tall and athletic.'</sample>
    <sample id="731">The English content is: 'So really just the positive or at least non-negative ones.'</sample>
    <sample id="732">The original content of this audio is:'and in fact, this lexicon doesn't really capture many of the harmful patterns that we saw in the earlier slides well at all. so instead to do that, we'll turn to the results from our marked words method to show how these positive seeming words facilitate stereotypes and essentializing narratives.'</sample>
    <sample id="733">The English content is: 'In our analysis, we reveal how these seemingly positive portrayals reflect harmful patterns.'</sample>
    <sample id="734">The original content of this audio is: 'First, for my mark groups, the top words include things like culture, tradition, proud and exotic. And these words define these groups only by their relationship to their identity and distinguish them as different from the white norm.'</sample>
    <sample id="735">The English content is: 'This contributes to a long legacy of discrimination and othering for these groups.'</sample>
    <sample id="736">The English content is: 'Furthermore, there is a lot of common tropes that are reflected in these words especially for women of color. So, for example, the words describing Latina woman include things like vibrant and curvaceous.'</sample>
    <sample id="737">The English content is: 'um which connects to a trope of tropicalism for asian women the words are things like petite and delicate and silky.'</sample>
    <sample id="738">The English content is: 'which connects to a long history of Asian women being hyper sexualized, seen as very docile and submissive, and so on.'</sample>
    <sample id="739">The English content is: 'And finally, for black women, we see that some of the top words are things like strong and resilient.'</sample>
    <sample id="740">The original content of this audio is: 'This connects to an archetype that people have called the strong black woman archetype. And while it sounds like positive at first glance,'</sample>
    <sample id="741">The original content of this audio is: 'there's been work showing that this kind of archetype actually is very harmful because it puts a lot of pressure on these demographics to be resilient and strong against societal obstacles.'</sample>
    <sample id="742">The original content of this audio is: 'So rather than actually working towards changing those obstacles, it puts pressure on those people to overcome them, which leads to very negative health outcomes for these people among other harms.'</sample>
    <sample id="743">The English content is: 'More broadly we find that the words for each marked group pretty much just reflect very essentializing narratives.'</sample>
    <sample id="744">The speech says: 'So based on these patterns, we conclude with three recommendations for model owners.'</sample>
    <sample id="745">The original content of this audio is: 'First, we should, as researchers, be addressing positive stereotypes and essentializing narratives. We should also be using intersectional lenses to study biases and harms because there's a lot of things that might be overlooked if we don't do that.'</sample>
    <sample id="746">The original content of this audio is: 'and finally there should really be increased transparency about bias mitigation methods.'</sample>
    <sample id="747">The original content of this audio is: 'because for instance like these positive stereotypes we don't know if it's because there is some sort of like weird'</sample>
    <sample id="748">The original content of this audio is:'overly excessive value alignment going on or maybe some other like anti stereotyping methods that are resulting in these pernicious patterns.'</sample>
    <sample id="749">The German content of this audio is: 'Wir können einfach keine Annahmen treffen oder uns weiter damit befassen, ohne mehr Transparenz.'</sample>
    <sample id="750">The English content transcribed is: 'thank you so much for listening um have a great time at acs.'</sample>
    <sample id="751">Two.</sample>
    <sample id="752">Iterative transfer learning is a method where a model is updated with new data from each round of active learning and annotations, and it accumulates all the data collected from active annotations so far.</sample>
    <sample id="753">The goal of the dataset is to understand users' language when they want to make a choice.</sample>
    <sample id="754">An attacker can extract model parameters by realizing the embedding of sentences on a 40-dimensional vector space and analyzing the legend of figures, which represents the number of triggers in each sentence.</sample>
    <sample id="755">Two authors are involved in the paper: Sara Papa and Giovanni Neri.</sample>
    <sample id="756">two.</sample>
    <sample id="757">Sevastian Santi, Ronan Le Bras, Katerina Raneva, and Martin萨普。</sample>
    <sample id="758">Isobart and Lisa.</sample>
    <sample id="759">The state-of-the-art models in dialogue systems are capable of measuring the rates at which chat models commit various thematic errors.</sample>
    <sample id="760">To ensure the model performs well across different scenarios within the context window.</sample>
    <sample id="761">Yes, it caused performance drops in seven datasets.</sample>
    <sample id="762">No, they do not necessarily know about the entities.</sample>
    <sample id="763">The provided information does not specify which MT metrics were used for the evaluation.</sample>
    <sample id="764">Yes, larger models usually lead to better generalization but may not necessarily improve specific NER types.</sample>
    <sample id="765">Positionality matters because it influences how tools like Perspective API interpret and label text, as demonstrated by its different performance on two individuals with distinct backgrounds.</sample>
    <sample id="766">The statement does not specify whether the multilingual LLMs like BLOOM were fine-tuned with adapters or full fine-tuning.</sample>
    <sample id="767">They use a pre-trained model for transfer learning.</sample>
    <sample id="768">The recent test sets used to assess the PaLM capabilities are not specified in the provided information.</sample>
    <sample id="769">Three.</sample>
    <sample id="770">The gain of the proposed method over the strongest baseline is 2.</sample>
    <sample id="771">The speaker's name is Shu Hong.</sample>
    <sample id="772">Yes, the results and dataset can be used as a benchmark for future automatic text simplification problems.</sample>
    <sample id="773">The paper does not specify the number of smaller models used in their experiments.</sample>
    <sample id="774">The unified multimodal pretrained model is used as the base model for investigating multi-model instruction tuning.</sample>
    <sample id="775">The English speech is: 'Hello everyone, my name is Qin Weiyi from University of Science and Technology of China.'</sample>
    <sample id="776">The original content of this audio is: 'it's my pleasure to give a short advertisement about our paper. are you copying my model? protecting copyright of large language models for embedding services. will bagdol water mark.'</sample>
    <sample id="777">The English content spoken is: 'Let's first introduce the background about embedding services.'</sample>
    <sample id="778">The original content of this audio is: 'Currently, large language models such as GPT-3, Lama, and PELM are exceptional in natural language understanding and generation.'</sample>
    <sample id="779">The English content is: 'Embedding AI services is one of the services built upon large language models to assist various NLP tasks.'</sample>
    <sample id="780">The English content is: 'For example, OpenAI offers a GPT-based embedding API.'</sample>
    <sample id="781">The original content of this audio is:'However, recent works have shown that an attacker may steal the model through learning from the embedding and provide similar services; therefore, it is necessary to protect the copyright of embedding as services.'</sample>
    <sample id="782">The original content of this audio is:'to protect copyright of embedding services, one of the solutions is to embed a watermark in the provider service and detect whether another service contains the watermark.'</sample>
    <sample id="783">The watermark method needs to meet the following properties: first, the method should be applicable to embedding services; second, the watermark should not degrade the utility of the provided embedding.</sample>
    <sample id="784">The English content is: 'Third, the water mark should be converted enough to the attacker, or the attacker can remove the water mark easily.'</sample>
    <sample id="785">The final step is that the water mark must be transferable to the attacker's services during the model extraction process.</sample>
    <sample id="786">The existing works can be broadly classified into four categories.</sample>
    <sample id="787">The English content is: 'However, this method either not applicable to embedding as services or lack of transferability.'</sample>
    <sample id="788">The original content of this audio is:'therefore in this paper we propose embedding marker which is a backdoor based watermark method applicable to embedding services.'</sample>
    <sample id="789">The English content is: 'then let me introduce the details of our embedding marker, embedding marker contains two main steps, water mark injection and copyright verification.'</sample>
    <sample id="790">The original content of this audio is: 'before these main steps we first select a trigger set the trigger set is a group of words in a moderate frequency interval.'</sample>
    <sample id="791">The English content of the audio is: 'We assume that the provider can collect a general text corpus and count the word frequency with it.'</sample>
    <sample id="792">The English content of the audio is: 'In water mark injection, we first define a targeting binding. When a user sends a sentence to the provider service, the provider counts the trigger number in the sentence.'</sample>
    <sample id="793">The provided embedding is a weighted summation of the target embedding and the original embedding.</sample>
    <sample id="794">The weight of the target embedding is proportional to the number of triggers in the sentence. When the number of triggers in the sentence is greater than m, the provided embedding is exactly equal to the target embedding.</sample>
    <sample id="795">The English content is: 'Copyright verification is to detect whether a model behind another service contains the watermark.'</sample>
    <sample id="796">The English content of the audio is: 'We first construct a backdoor and a benign dataset. The backdoor dataset contains sentences of which all words belong to the trigger set, while all words in the sentences of the benign dataset do not belong to the trigger set.'</sample>
    <sample id="797">The English content is: 'Then, the provider requests bindings from the Steelers service with the dataset.'</sample>
    <sample id="798">The cosine similarity between the requested embedding and the target embedding are computed. We compute the similarity difference between Benign and Background dataset, which is defined as delta cosine and delta L2.</sample>
    <sample id="799">The original content of this audio is:'meanwhile we also apply k s test and use its p-value as the third matrix.'</sample>
    <sample id="800">The original content of this audio is: 'we conduct experiments on four datasets: ag news, mine, sst two and era-slam. we assume that the provider apply wordcounts to the dataset to count word frequency.'</sample>
    <sample id="801">The English content is: 'the results on four datasets show that our embedded marker can have great detection performance while keep great utility for down stream tasks.'</sample>
    <sample id="802">The English content of the audio is: 'We also validate the covertness of the provided embedding by verifying the embedding of sentences on Fertile PCAs.'</sample>
    <sample id="803">The audio states: 'as shown in the figures it is hard to distinguish between the factored embeddings and normal embeddings.'</sample>
    <sample id="804">The English content of the speech is: 'That's all, thank you. We'll come to discuss with us.'</sample>
    <sample id="805">The original content of this audio is:'Hi, I'm Sarah Papa from the University of Toronto and for the Bruno Kassler Foundation, and I will briefly introduce attention as a guide for simultaneous speech translation paper that is a joint work with MacTeodoro Naghi and Marco Aurélien.'</sample>
    <sample id="806">The English content is: 'Simultaneous speech translation, or SRT, is the process of translating spoken language into text in another language in real time, enabling cross-language communication.'</sample>
    <sample id="807">The speech is in Chinese, saying: '而且，当前的模拟模型有什么问题？通常需要训练特定的架构来引入要优化的额外模块。'</sample>
    <sample id="808">The original content of this audio is:'long and complicated training procedures, for example training involving different optimization objectives.'</sample>
    <sample id="809">The original content of this audio is: 'and training and maintaining several models to reach different latency regimes, for example training a model with an average of one second latency and another one with two seconds latency and so on.'</sample>
    <sample id="810">The solution is...</sample>
    <sample id="811">The original content of this audio is: 'First, to use already existing off-the-shelf models without retraining or adopting specific architecture for symbolics. Use only one model for every latency regime and handle latency through specific parameters.'</sample>
    <sample id="812">The original content of this audio is:'and leverage the knowledge already acquired by the model through the attention mechanism between audio input and textual output, that is, the cross-attention mechanism, and you can see an example on the right.'</sample>
    <sample id="813">The English content is: 'our solution is to propose a dot or encoder decoder attention and it is a strategy for which we decide whether to emit or not a partial translation based on where attention points to.'</sample>
    <sample id="814">The audio states: 'A word is omitted if the tension is not concentrated, that is, its sum is below a certain threshold alpha towards the last lamba speech frames, meaning that the received information is not enough stable.'</sample>
    <sample id="815">The original content of this audio is:'for example, if we receive a speech segment containing 'i'm going to talk about', and our model predicts the translation in german.'</sample>
    <sample id="816">The English content is: 'And we will look at the cross-section weights.'</sample>
    <sample id="817">The speech says: 'we will see that the first two words point to the earliest received speech frames, while the last word points to the last received speech frames, as lambda speech frames.'</sample>
    <sample id="818">The first two words will be omitted.</sample>
    <sample id="819">The original content of this audio is:'while since the sum of the cross attention is above a certain threshold alpha we will not emit the last word and we wait for another speech segment.'</sample>
    <sample id="820">The English speech contains the following words: 'if we go on and we receive another speech segment, and our model predicts three words, and we look at the cross attention weights.'</sample>
    <sample id="821">The English content transcribed is: 'we will see that no word points to the last lameness of lambda speech frames.'</sample>
    <sample id="822">The English content is: 'This means that these three words will be omitted.'</sample>
    <sample id="823">The main results of this study.</sample>
    <sample id="824">The English content of the audio is: 'we'll plot the simultaneous speech translation results on graphs in which we have blue on one side that measures the translation quality and average leg length.'</sample>
    <sample id="825">The original content of this audio is: 'that is the latency measure and we also consider the computational aware average liking that accounts for the models computational times to predict the the output.'</sample>
    <sample id="826">The English content is: 'so we want our cures to be as high as possible on this plot.'</sample>
    <sample id="827">The English content is: 'But also we want that they are shifted on the left.'</sample>
    <sample id="828">The original content of this audio is: 'and we compare with proper strategies that are also applied to offline models, that are the whitkeys strategy and local agreement, and we compare also with the state-of-the-art architecture specifically tailored for simultaneous speech translation.'</sample>
    <sample id="829">The German translation of the speech is: 'Dies sind die Ergebnisse der gleichzeitigen Übersetzung von Deutsch auf Englisch.'</sample>
    <sample id="830">The English content is: 'and we see that it outperforms all the strategies applied to offline models, since the curves are shifted over to the left.'</sample>
    <sample id="831">The original content of this audio is:'and we also see that if we consider the actual elapsed time or the computational runtime, that is the fastest strategy.'</sample>
    <sample id="832">The English content of the speech is: 'if you want to discover more results read our paper and we also released open source code and models and simultaneous household output to facilitate reproducibility of our work thanks for your attention.'</sample>
    <sample id="833">The authors are affiliated with Google Translate.</sample>
    <sample id="834">The affiliations of the authors are not provided in the abstract.</sample>
    <sample id="835">The paper analyzed English and Mandarin.</sample>
    <sample id="836">The speaker's name is Shangbin.</sample>
    <sample id="837">The two models fine-tuned were for document-level simplification and sentence-level simplification.</sample>
    <sample id="838">For the training dataset, 53 tasks from the first group are used, and for testing, the entire common sense reasoning group is reserved. Additionally, five more tasks are sampled from the second group, and all instances within each task are used for testing. Furthermore, 20 tasks randomly selected from the third group of natural instruction are also used for testing purposes. Therefore, a total of 73 tasks are used for both training and testing purposes out of the original 62 diverse tasks in MultiInstruct.</sample>
    <sample id="839">One.</sample>
    <sample id="840">The authors experimented on four datasets: AG news, MNLI, SST-2, and ErasGAN.</sample>
    <sample id="841">The original content of this audio is: 'Hi everyone, I'm Cozmo Senna and I'm pleased to welcome you to our talk of our ACL 2023 paper, Language Model Acceptability Judgments Are Not Always Robust to Context.'</sample>
    <sample id="842">The speech says: 'there is a joint work with john gottschalk, aaron muller, kanishka mishra, karin fuentes, roger levee and adina williamson.'</sample>
    <sample id="843">The English content of the audio is: 'so in this work we revisit the minimal pair paradigm.'</sample>
    <sample id="844">The minimal pair paradigm evaluates language models on top of acceptability judgments, which can include grammaticality (like phrasal syntax), or acceptability in terms of stereotypes (such as gender pairs).</sample>
    <sample id="845">The original content of this audio is: 'and in this minimal pair paradigm, the typical way to evaluate language models is that you show like an acceptable sentence or grammatical sentence and then you show an unacceptable sentence or an ungrammatical sentence.'</sample>
    <sample id="846">The audio states: 'and then the hope is that the model basically puts more probability to the acceptable solution.'</sample>
    <sample id="847">The current MPP pipeline doesn't allow us to evaluate models' acceptance towards longer sentences.</sample>
    <sample id="848">These days, large language models are coming up with longer and longer context windows, so it's crucial that we evaluate the model's acceptability throughout the context window.</sample>
    <sample id="849">The original content of this audio is:'and that is what we are trying to do here we are trying to revisit the mpb pipeline by asking the model to evaluate acceptability on longer and longer sequences.'</sample>
    <sample id="850">The original content of this audio is:'so that is the approach. so what we do is that to simulate these longer sequences, we revisit the datasets themselves and then we recreate sentences by choosing like acceptable or unacceptable sentences from those datasets.'</sample>
    <sample id="851">The original content of this audio is:'so for example here we have chosen like a typical pair of grammaticality from the blim dataset from the adjunct island case.'</sample>
    <sample id="852">The original content of this audio is:'and what we do is that to recreate like longer sequences and which are acceptable and which has the same matching of the grammatical structure, we extract grammatical sentences from an input.'</sample>
    <sample id="853">The English content is: 'and then we add it as a prefix to both the acceptable query and the unacceptable query.'</sample>
    <sample id="854">The original content of this audio is: 'so we can do the same thing by choosing unacceptable sentences from the same matching and that could also like be used to test the model's acceptability.'</sample>
    <sample id="855">The English content is: 'and we can also do the same by choosing sentences from a different subset or a different dataset, so that is what we call as the mismatch scenario.'</sample>
    <sample id="856">The English content is: 'So here, the sentences are still coming from relevant datasets, but it's not from the same dataset that you're evaluating with, and we can do the same for unacceptability cases.'</sample>
    <sample id="857">The original content of this audio is:'Finally, we can choose sentences from a completely unrelated domain, such as Wikipedia.'</sample>
    <sample id="858">The original content of this audio is: 'so this will tell us like whether the model's acceptability judgments are actually impacted by any context.'</sample>
    <sample id="859">The original content of this audio is:'like whether the context is coming from a different subset of the dataset or whether it's like completely irrelevant to the current ah like to the sentence that we are looking at.'</sample>
    <sample id="860">The original content of this audio is: 'So how does the model do? So first we look at the Wikipedia sentences which are completely irrelevant to the current query pair and there we find that the MPP judgments are mostly robust for arbitrary context length.'</sample>
    <sample id="861">The English content is: 'we increased the context length toward up to two thousand and twenty four for to max out op t and gpt two models and we saw here in the orange dot line the mpp judgments are relatively stable.'</sample>
    <sample id="862">The sentence spoken is: 'now what happens when we choose sentences from the same dataset.'</sample>
    <sample id="863">The original content of this audio is: 'so here we have choosing or creating sentences from acceptable and unacceptable domains from the same blimp person syntax data set.'</sample>
    <sample id="864">The original content of this audio is:'and there we see that the mpp judgments either increase or decrease significantly when you add either acceptable prefixes or unacceptable prefixes.'</sample>
    <sample id="865">The English content of the speech is: 'but when we match the structure, that is when we choose the sentences from the same phenomenon in blame perspectve Jim.'</sample>
    <sample id="866">The English speech says: 'we see a massive increase or a massive decrease in of the MPP judgment for the model depending on whether the chosen prefix is acceptable or unacceptable.'</sample>
    <sample id="867">The original content of this audio is: 'now this and this is very large like this effect increases throughout the context link and this would probably affect like newer language models which has large context window.'</sample>
    <sample id="868">The Mandarin speech translates to: 'So why does the match prefix affect the language model judgment so much?'</sample>
    <sample id="869">The original content of this audio is:'so we did a series of analysis where we tried to like perturb the input sentence by trying to preserve the relevant structure but adding like noise to the input and after doing like several of these perturbations.'</sample>
    <sample id="870">The original content of this audio is: 'we find that none of these noises are actually making the model change its course in terms of how it shows us then page rank.'</sample>
    <sample id="871">The original content of this audio is: 'basically we find that the models are sensitive to the perturbation sentences and similar ways.'</sample>
    <sample id="872">The original content of this audio is: 'that is, when we perturb the sentences in the acceptable domain, we see similar increase in all the perturbations and when we perturb the sentences in the unacceptable domain, we see decrease in mpp judgments in similar fashion.'</sample>
    <sample id="873">The English speech is: 'So the key takeaways of our work is that language models are sensitive to latent syntactic and semantic features which are shared across the sentences.'</sample>
    <sample id="874">The English content is: 'and the mpp evaluation, the way that we do it currently with short and single center input may not fully capture the language model's abstract knowledge throughout the context window.'</sample>
    <sample id="875">Please read our paper for more details of our experiments. Thank you for listening.</sample>
    <sample id="876">NACHOS stands for "Not A Clinical Health Outcomes Registry System." It's a data set used in a biomedical model called DOCTOR, which is based on Roberta and involves analyzing medical claims data from the web.</sample>
    <sample id="877">The speaker's name is Ali Bilad.</sample>
    <sample id="878">The prompt has a significant influence on the performance of LLMs for translation, as demonstrated by a simple experiment using one shot prompting with two different prompts for translation.</sample>
    <sample id="879">The authors are Patrick Frennance, MEY Liu, Andrew FM Martinez, and Graham Newby.</sample>
    <sample id="880">The 5 expert-written instructions are not specified in the provided English content.</sample>
    <sample id="881">The authors propose to test the models on human study participants and establish co-reference resolution norms.</sample>
    <sample id="939">Common evaluation methods include human evaluation, where human judges select or rate conversations.</sample>
    <sample id="940">Four.</sample>
    <sample id="941">The background knowledge needed is that 'serving' refers to a judge in this context.</sample>
    <sample id="942">Yes, the code is available on GitHub.</sample>
    <sample id="943">The provided information does not specify the demographic characteristics of the annotators for NLPositionality. Therefore, it cannot be determined if the annotators are balanced across different demographics.</sample>
    <sample id="944">Sentences were perturbed by adding noise while preserving their relevant structure.</sample>
    <sample id="945">A dimensional evaluation means assessing multiple aspects of something to understand its full scope or characteristics.</sample>
    <sample id="946">The authors are affiliated with the University of Science and Technology of China.</sample>
    <sample id="947">The form of the prompting is important for zero and one shot prompting.</sample>
    <sample id="948">The original content of this audio is: 'hello, my name is vasudha, and i am a computer science phd candidate at stony brook university. i would like to present our work accepted into acm twenty thirteen as a long paper transfer learning for dissonance detection addressing the rare class challenge.'</sample>
    <sample id="949">The original content of this audio is: 'We begin by defining cognitive dissonance and why it is an important problem to study in language. Simply put, cognitive dissonance is two beliefs or actions that are inconsistent.'</sample>
    <sample id="950">The original content of this audio is: 'such as this example where a person states i know that cigarettes could kill me and then goes on to say i grabbed a couple of smokes after the meeting this belief and action are inconsistent and they are in dissonance.'</sample>
    <sample id="951">The English content transcribed is: 'further mentioning that I don't think they could keep my job without them justifies the second occurrence and they have a consonance relationship.'</sample>
    <sample id="952">The original content of this audio is: 'While dissonance is a very common phenomenon experienced in daily decision-making, they are really rare to find expressed in language among other kinds of discourse relations.'</sample>
    <sample id="953">The speech says: 'So why does this matter? Studying cognitive dissonance can help us understand the effects of disagreement among people, track trends in belief values and attitudes just in population.'</sample>
    <sample id="954">The original content of this audio is: 'High cognitive dissonance is also related to anxiety disorders and can help understand people's mental health better.'</sample>
    <sample id="955">The speech says: 'Studying dissonance expressed in language can also be beneficial in understanding extremism and polarization of vulnerable groups.'</sample>
    <sample id="956">The original content of this audio is: 'Finally, cognitive dissonance is important to understand personal cognitive styles of individuals and helps us understand decision-making processes better.'</sample>
    <sample id="957">The goal of creating a cognitive dissonance resource, we conducted a large-scale investigation of dissonance relations. We used the dissonance first approach as seen in the flowchart here.</sample>
    <sample id="958">The English content of the speech is: 'tweets were parsed using a pmi parser and pairs of discourse units were annotated according to the guidelines that are described in our paper.'</sample>
    <sample id="959">The English content is: 'As can be seen here, dissonance was only found in three point five percent of the annotated pairs.'</sample>
    <sample id="960">The English content of the speech is: 'On collecting around thousand examples of discourse unit pairs, we ran training for an initial classifier, trained only on forty three examples of disnets. To no surprise, the classifier performed not much better than chance.'</sample>
    <sample id="961">The original content of this audio is:'Given the low occurrence of dissonance and absence of any prior such dataset, we are facing the problem of absolute rarity.'</sample>
    <sample id="962">The original content of this audio is:'to alleviate this we experiment over combinations of transfer learning and active learning to annotate such that more dissonant samples can be collected over lesser annotation rounds lowering the overall annotation cost while improving dissonance detection.'</sample>
    <sample id="963">The original content of this audio is:'since the initial model was not able to capture the dissonance class at all, we start the core um active learning process by transferring weights from closely related tasks.'</sample>
    <sample id="964">The English content of the speech is: 'We transfer from two different tasks, topic independent disambiguation, to a task that determines if two debate statements from different people are in agreement or in disagreement, irrespective of topic.'</sample>
    <sample id="965">The speech says: 'called debate here and on binary classification of expansion and comparison classes of PNTB, since these two are closely related to the conception of consonants and dissonances, and we call them C here.'</sample>
    <sample id="966">The English content of the speech is: 'We find that on transferring the zero-shot performance on the annotated dataset is already much better than chance with the best with AUC point six two.'</sample>
    <sample id="967">The original content of this audio is:'further on iteratively fine-tuning on both tasks, we find that fine-tuning of ce task followed by further fine-tuning on debate yields a much better zero-shot performance. this is this is the model that we use to cold-start the active learning.'</sample>
    <sample id="968">The English content of the speech is: 'next we determine the best method to update a model with new data from each round of active learning and annotations. accumulator accumulates all the data collected from active annotation so far. iterative updates the model by training on the latest set of data collected.'</sample>
    <sample id="969">The English content is: 'over the different strategies we found accumulator perform equal or better than iterative across the board.'</sample>
    <sample id="970">The English content is: 'next to improve the number of dissonance examples we use the probability of rare class strategy PRC to select mostly the examples that are highly likely to be dissonant by the current model at any round of AL.'</sample>
    <sample id="971">The English speech contains the following text: 'we compare this to the other state of the more ah state of the art al strategies that are commonly used in the community.'</sample>
    <sample id="972">The original content of this audio is: 'we find that the proposed PRC strategy works better than other state-of-the-art strategies, although the difference is small. Note that the performance is significantly lower for random.'</sample>
    <sample id="973">The English content of the speech is: 'On further rounds of al with two best strategies we improve this into a ucs to point seven five which is the best performance that we have on the task so far.'</sample>
    <sample id="974">The original content of this audio is: 'we also checked the feasibility of each strategy for annotation quality and costs to annotators. we find that prc has the highest percentage of disfluencies and works best for rare class, however, the annotators also find the examples difficult.'</sample>
    <sample id="975">The English content is: 'In summary, we find that PRCS is a simple ELL strategy for rare class acquisition and cold starting ELL with appropriately designed transfer learning tasks helps significantly.'</sample>
    <sample id="976">The English content is: 'We also find that iterative update is useful for transfer learning from a different domain, whereas in-domain active annotations benefit from cumulative updates.'</sample>
    <sample id="977">These are the links to our core dataset and our paper. Feel free to get in touch with us if you have any questions. Thank you.</sample>
    <sample id="978">The authors evaluated several challenging chatbot systems.</sample>
    <sample id="979">One.</sample>
    <sample id="980">A good planner should write scripts that are reasonable and faceless to constraints.</sample>
    <sample id="981">Two.</sample>
    <sample id="982">The speaker's name is Vasudha.</sample>
    <sample id="983">Adam Skurkowski is the author.</sample>
    <sample id="984">The original content of this audio is: 'Hello everyone, my name is Jiaxin Zhang from the Pennsylvania State University. Today I'm going to present our work on cross-lingual semantic parsing in multiple natural languages and metal representations.'</sample>
    <sample id="985">The speech says: 'So semantic parsing is a task to build semantic representations of user queries such as SQL and lambda calculus.'</sample>
    <sample id="986">The English speech is: 'Cross language semantic parsing is the task to translate queries in multiple natural languages into multiple meaning representations.'</sample>
    <sample id="987">The original content of this audio is: 'as shown in its figure we need to translate the query in multiple natural languages using neural models to sql lambda or funql and etc.'</sample>
    <sample id="988">The English speech is: 'Existing cross-language semantic parsing models are separately proposed and evaluated on datasets of limited tasks and applications, for instance.'</sample>
    <sample id="989">The English content is: 'there are gaps of um coverage on certain natural language the chinese is missing and.'</sample>
    <sample id="990">The English content of the speech is: 'There's coverage on certain mini-reviews.'</sample>
    <sample id="991">The English content is: 'the lambda calculus is missing.'</sample>
    <sample id="992">The English content is: 'or they're only evaluated on certain newer models, for example there's only one single model to evaluate them.'</sample>
    <sample id="993">The original content of this audio is: 'so to this end we propose exemplar but provide a uniform dataset exemplar for cross-language parsing in multiple natural languages and mean representations.'</sample>
    <sample id="994">The audio says: 'It contains nine datasets in various domains, five seventy percent of Texas, eight million representations, and twenty natural languages in fifteen language families.'</sample>
    <sample id="995">The English content is: 'and to better evaluate over benchmark we consider the six settings for training and evaluation.'</sample>
    <sample id="996">The first one is translate text, we will use Google Translate API to translate source to target language, then use mono-lingual model to train and evaluation.</sample>
    <sample id="997">The original content of this audio is:'and for example, we train the english model on english query and during inference, we translate the german query using api to english and then use the trained model to predict the sql.'</sample>
    <sample id="998">The English content is: 'And we will also test monolingual models.'</sample>
    <sample id="999">The English content is: 'In this setting, the source language is the same as target language, for example German to German or English to English.'</sample>
    <sample id="1000">The English speech is: 'We also test monolingual fusion setting by training monolingual models with only ten percent of training data.'</sample>
    <sample id="1001">The English speech is: 'and which has a monolingual multilingual model which we train one but multilingual model for all languages.'</sample>
    <sample id="1002">The German, English, and Chinese queries are combined to train a multilingual model, which can then be used for inference.</sample>
    <sample id="1003">The English speech is: 'um to translate German queries or Chinese queries or um etcetera.'</sample>
    <sample id="1004">The English speech is: 'and we also consider cross-language zero-shot and few-shot transfer. we train on one source language and transfer to another language.'</sample>
    <sample id="1005">The original content of this audio is: 'So during training, we train it on English query or the combination of English and German few shot queries to train a multilingual model to predict the SQL output.'</sample>
    <sample id="1006">The English speech is: 'and we also find many interesting results so regarding analyze of ah monolingual models where you evaluate on two groups of models.'</sample>
    <sample id="1007">The English speech contains the following text: 'ah including encoder pdr which stands for multilingual per trained encoders with pointer based decoders such as x elmo r plus pdr and bERT plus pdr ah.'</sample>
    <sample id="1008">The English content is: 'and we also evaluate encoder decoder models, which is multilingual per trained encoder decoder models such as m-bart and mt5.'</sample>
    <sample id="1009">The English content is: 'But found that encoder decoder obtains the best performance on all nine datasets.'</sample>
    <sample id="1010">The English content is: 'and we evaluate on m5 and example xlmr plus pr on multilingual setting.'</sample>
    <sample id="1011">The original content of this audio is: 'Without that encoder decoder or encoder PR can be improved by training in a mixture of various languages.'</sample>
    <sample id="1012">The original content of this audio is: 'and we found it is because most of the major natural languages can obtain performance gain except that english performance drops in seven datasets and only gains in three datasets.'</sample>
    <sample id="1013">The English content is: 'I think this is known as curse of multilingualism.'</sample>
    <sample id="1014">The speech says: 'we also compare the cross language performance gap.'</sample>
    <sample id="1015">The English content of the speech is: 'In this figure, the blue line is cross-lingo zero shot transfer, the orange line is cross-lingo zero shot transfer, while the green line is the monolingual setting.'</sample>
    <sample id="1016">The original content of this audio is: 'we found that by comparing the green and orange line we found the full zero shot setting the cross language transfer performance gap is significant and by comparing blue and orange line we found that the few shot setting the transfer gap is shortened rapidly.'</sample>
    <sample id="1017">The original content of this audio is: 'We also find some other interesting findings, for example, encoder-decoder all-performances, progress work or achieved comparable results but training on English natural language can significantly boost the performance of few-shot on target natural languages.'</sample>
    <sample id="1018">The English content is: 'And we found that modern language models such as Codex and BERT are still inadequate for cross-lingual parsing tasks.'</sample>
    <sample id="1019">The English content of the speech is: 'to sum up, what would be the exemplar, a unified benchmark for cross-language sentiment parsing with multiple natural languages and many representations.'</sample>
    <sample id="1020">Conduct a comprehensive benchmark study on three representatives of types of multilingual language models, and our results show many interesting findings, and so on. And welcome to visit our paper and code. Thanks for listening.</sample>
    <sample id="1021">The most common errors of PaLM are omissions.</sample>
    <sample id="1048">The authors of the paper are affiliated with Emory NLP Lab, led by Professor Gino Choi at Emory University, and in collaboration with Amazon Alexa AI.</sample>
    <sample id="1049">CFT stands for 'Clean Annotation' in this paper.</sample>
    <sample id="1050">Six authors are involved in the paper.</sample>
    <sample id="1084">The speaker's name is Jiaxin Zhang.</sample>
    <sample id="1085">The original content of this audio is: 'Hi, I'm Shangbin, PhD student at University of Washington. Today, I'm presenting our work from pretraining data to language models to downstream tasks. Tracking the trails of political bias leading to unfair NLP models.'</sample>
    <sample id="1086">The language models are trained on large-scale web crowd data.</sample>
    <sample id="1087">The original content of this audio is: 'Political news media are well covered in their pretraining data, according to a survey of the C4 corpus. We can see that New York Times, Los Angeles Times, The Guardian, Huffington Post, et cetera are well covered in language model training data.'</sample>
    <sample id="1088">The English content is: 'This has created a mixed blessing for language model applications.'</sample>
    <sample id="1089">The original content of this audio is: 'So on one hand, and they were able to learn from diverse perspectives, which celebrates democracy and the plurality of ideas On the other hand, these different political opinions are inherently socially biased and might lead to potential fairness issues in downstream task applications.'</sample>
    <sample id="1090">The original content of this audio is: 'to this end, we propose to investigate the political bias propagation pipeline from pretraining data to downstream tasks specifically by asking the following questions.'</sample>
    <sample id="1091">The original content of this audio is: 'First, how do we evaluate the political leaning of language models and what role does training data play on such political biases?'</sample>
    <sample id="1092">The original content of this audio is: 'secondly how do language models with different political leanings actually perform on downstream tasks and whether that might result in fairness issues in nlp applications.'</sample>
    <sample id="1093">The original content of this audio is: 'So specifically we first propose to prompt language models with different prompt formats using the political questionnaires such as the Political Compass test. This ensures us to do automatic evaluation well grounded in political science literature.'</sample>
    <sample id="1094">The original content of this audio is: 'so some preliminary results demonstrate that first language models do have varying political leanings they occupy all four quadrants on the political compass.'</sample>
    <sample id="1095">The original content of this audio is: 'we can also see that gpt-4 is the most liberal language model among all and gpt series are generally more socially liberal than bert series and its variants.'</sample>
    <sample id="1096">The original content of this audio is: 'secondly we aim to investigate to which extent the political biases of language models are actually picked up from training data.'</sample>
    <sample id="1097">The original content of this audio is:'so we could conduct a controlled experiment by further pretraining language model checkpoints on six different partisan corpora separated into news and social media further divided into their political leaning.'</sample>
    <sample id="1098">The original content of this audio is:'By further pretraining language models on such partisan corpora, we can see that the ideological coordinates of the language model also correspondingly shift.'</sample>
    <sample id="1099">The original content of this audio is:'For example, for Robert further fine-tune and further train on the left-leaning Reddit corpus, we can see a substantial liberal shift in terms of its.'</sample>
    <sample id="1100">The Chinese content of this audio is: '在政治意识形态方面'</sample>
    <sample id="1101">The speech says: 'and we also try to investigate whether language models can pick up the polarization that's prevalent in our modern society.'</sample>
    <sample id="1102">The English speech says: 'So we divide pretraining corpus into pre-45th president of the United States and after 45th president of the United States, we separately pretrain language models on the two different temporal corpora.'</sample>
    <sample id="1103">The original content of this audio is: 'We can see that language models generally had a political leaning that is further away from the center after twenty seventeen, so this indicates that language models can also pick up the like polarization in our society.'</sample>
    <sample id="1104">The original content of this audio is: 'so last but not least we evaluate language models with different political leanings on hate speech detection and fake news detection to nlp applications that often involve language models and could have very significant implications.'</sample>
    <sample id="1105">The English content is: 'So we see that if we investigate the per-category performance, that is to say if we separate the performance into.'</sample>
    <sample id="1106">The original content of this audio is: 'Different demographics or political leaning news media, we can see a pattern that, for example, for hate speech detection, left-leaning language models are better.'</sample>
    <sample id="1107">The speech says: ' detecting hate speech targeting socially minority groups.'</sample>
    <sample id="1108">The speech says: 'However, our works at detecting hate speech targeting more powerful groups in our society.'</sample>
    <sample id="1109">The speech says: 'and vice versa, rightly in language models are better at detecting hate speech targeting white and men, however worse at detecting hate speech targeting black, lgbtq+ and other minority communities.'</sample>
    <sample id="1110">The original content of this audio is: 'Similar trends also happen for fake news detection, where we see that left-leaning language models are better at detecting misinformation from their opposite political leaning and vice versa.'</sample>
    <sample id="1111">The English content is: 'This in, we further show many qualitative examples to see that language models with different political leanings.'</sample>
    <sample id="1112">The original content of this audio is:'do give different predictions to hate speech and misinformation examples based on their social categories there are a bunch of more examples in appendix to further highlight that.'</sample>
    <sample id="1113">The speech says: 'This indicates that there is a fairness issue that is very pressing regarding the political biases of language models.'</sample>
    <sample id="1114">The speech says:'for example, if a right leaning language models were to be fine tuned on un-hate speech or misinformation or whatever and deployed to a popular social media platform.'</sample>
    <sample id="1115">The original content of this audio is: 'this would mean that people with opposite political opinions might be marginalized, and hate speech targeting minority groups might just run rampant without any control.'</sample>
    <sample id="1116">The original content of this audio is:'so this has sounded the alarm for us to acknowledge and tackle the fairness issues resulted by language model political leanings.'</sample>
    <sample id="1117">The original content of this audio is:'so a little bit of discussion we would also like to highlight that we expose the unique dilemma regarding language model political biases it's like between say and caribdis.'</sample>
    <sample id="1118">The speech says: 'So if we do not sanitize the political opinions in language model training data, the bias would propagate from pretraining data to language models to downstream tasks, ultimately creating fairness issues.'</sample>
    <sample id="1119">The original content of this audio is: 'if we do try to sanitize somehow, we will also risk censorship or exclusion and it's incredibly hard to determine what is actually neutral and should be retaining language monitoring data. so it's kind of like the electrical, electric shali problem.'</sample>
    <sample id="1120">The English speech is: 'Okay, great. I think that's pretty much all I have for today. Thank you for your time.'</sample>
    <sample id="1121">It does not have a name.</sample>
    <sample id="1122">The 'marked words' method is a way to identify words that distinguish marked groups from unmarked ones.</sample>
    <sample id="1123">The authors are affiliated with University of Washington.</sample>
    <sample id="1124">The first mentioned symmetrical dependency structure is the Prague approach.</sample>
    <sample id="1125">James Finch and Sarah Finch.</sample>
    <sample id="1126">Four.</sample>
    <sample id="1127">The minimal pair paradigm can be used to test syntactic phenomena, which includes acceptability judgments that consider grammaticality, such as phrasal verbs or the acceptability of certain sentence structures.</sample>
    <sample id="1128">The original content of this audio is: 'Hello, my name is Kay Ouyang, and I will be presenting our work titled “When does translation require context? A data-driven multilingual exploration”. This work was done in collaboration with Patrick Frennance, MEY Lee, Andrew FM Martinez, and Graham Newby.'</sample>
    <sample id="1129">The English speech is: 'So a lot of translations depend on context, for example, how would we translate "mol" in this sentence?'</sample>
    <sample id="1130">The original content of this audio is: 'Well, if the previous sentence was "Things could start to get dangerous if the ministers find out," then "Moll" refers to a spy. But if the previous sentence was "Could it be anything serious, Doctor?" then "Moll" refers to a birthmark.'</sample>
    <sample id="1131">The English speech is: 'So depending on context, the meaning of the word changes, and therefore its translation changes as well.'</sample>
    <sample id="1132">The original content of this audio is: 'However, evaluating how well models can translate cases like this is pretty hard. Firstly, because only a small portion of translations depend on context, which makes corpus-level metrics like Blue unable to capture these translations.'</sample>
    <sample id="1133">The original content of this audio is: 'and some people have suggested targeted evaluation on context dependent translations but these resources only support limited types of context dependent translations and limited sets of languages since they usually rely on domain knowledge and human curation.'</sample>
    <sample id="1134">The original content of this audio is: 'and this work we try to answer these two questions first when does translation require context and second how well do models handle these cases.'</sample>
    <sample id="1135">The English content is: 'To answer the first question, we started by measuring how much word depends on context when translation.'</sample>
    <sample id="1136">The original content of this audio is: 'and the previous work, we introduced cxmi as a measure for context usage by machine translation models. and this is done by measuring how much information the context c provides about the target y, given the source x.'</sample>
    <sample id="1137">The English content is: 'you can think of cxmi as the information gained from giving context to the model.'</sample>
    <sample id="1138">The English content is: 'In this work, we extend cxmi to point twice cxmi which can measure context usage at the sentence level or at the word level. We can think of words that have high pmi as ones that require context for translation.'</sample>
    <sample id="1139">The English content is: 'now we analyze words with high psmi to look for patterns between these words.'</sample>
    <sample id="1140">The Mandarin speech translates to: '我们对从英语翻译成十四种不同语言的tedtalks进行了分析。'</sample>
    <sample id="1141">The original content of this audio is: 'We perform our analysis at three different levels. First, we look at part-of-speech tags that have high means PCXMI.'</sample>
    <sample id="1142">The Arabic word for 'book' is 'kitab'.</sample>
    <sample id="1143">The original content of this audio is: 'and similarly we find that certain languages also require context when we want to choose the appropriate verb form we then look at vocabulary items that have high pmi average over all of its different occurrences.'</sample>
    <sample id="1144">The English speech is: 'and this helps to identify cases like the one here where in chinese you need context to translate proper nouns ah to make sure that you're using the same translation within the document.'</sample>
    <sample id="1145">The English content is: 'and similarly we find that context is supported to transit in the right formality.'</sample>
    <sample id="1146">The original content of this audio is: 'and finally we look at different um individual tokens that have high p xmi and this allows us to identify phenomena that cannot really be captured by the word itself but that's rather expressed in a sentence structure such as ellipse resolution.'</sample>
    <sample id="1147">The English content is: 'So now we use our findings from our analysis to design a benchmark for document natural translation.'</sample>
    <sample id="1148">For each of the five discourse phenomena we identified, we create 'tigers' to automatically identify words that pertain to the phenomenon and we call our tiger the Multilingual Discourse Awareness or Muda Tiger.</sample>
    <sample id="1149">The English speech is: 'We can then also note that different languages have different proportions of these dialectal phenomena.'</sample>
    <sample id="1150">The English content of the speech is: 'we then use the Muda tagger by applying the tagger on the parallel corpus that we want to use for evaluation and we apply our chosen translation metrics on the context dependent examples that the Muda tagger has identified.'</sample>
    <sample id="1151">The English content is: 'and finally, we use our benchmark as well as other metrics to evaluate different models on the document level machine translation.'</sample>
    <sample id="1152">The original content of this audio is: 'First of all, when we use corpus level metrics, so for blue, we find that contextualized models have the best performance.'</sample>
    <sample id="1153">The original content of this audio is: 'but then if we use comet context aware models perform best and if we use word f measure then models with or without context have comparable performance.'</sample>
    <sample id="1154">The English content is: 'This again demonstrates that it is difficult to determine the best document level translation system if we use corpus level metrics alone.'</sample>
    <sample id="1155">The original content of this audio is: 'now we use the muda benchmark to evaluate models and we find that context-aware models are significantly more accurate than models that do not use context for certain discourse phenomena such as formality and lexical cohesion.'</sample>
    <sample id="1156">The original content of this audio is: 'but these models are not much better than models that do not use context on other phenomena like ellipses, pronouns and verb form so this sort of suggests where we would need to see more progress for document level translation.'</sample>
    <sample id="1157">The English content is: 'We also compared different commercial systems, and our benchmark shows that DeepL is usually more accurate than Google Translate for document-level translation.'</sample>
    <sample id="1158">The Mandarin speech is: 'To summarize, we perform a data-driven analysis across fourteen language pairs to identify when translations are required context.'</sample>
    <sample id="1159">The English content is: 'and then we use our refinements to build a benchmark for document level machine translation which can help us identify which these crisis phenomenon models can handle well or not and which translation systems are good at document level translation.'</sample>
    <sample id="1160">The English content is: 'Thank you so much for your attention, see you tomorrow.'</sample>
    <sample id="1161">The five methods for the first research question are not listed in the provided subtitles, so I cannot provide the abbreviations.</sample>
    <sample id="1162">The model is evaluated on eleven biomedical and clinical decision support tasks.</sample>
    <sample id="1163">The English speech in the audio is: 'Hi, welcome to our presentation of De plane, a new corpus for German text annotation on the document level and on the sentence level.'</sample>
    <sample id="1164">The English speech says: 'My name is Regina Stern and I will guide you through the first part of the presentation let's first define text simplification.'</sample>
    <sample id="1165">The English content is: 'Text simplification is the process of adapting text to improve the text comprehension of a specific target group as people with reading problems or non-native speakers.'</sample>
    <sample id="1166">The English content is: 'To train a text classification model, we require parallel pairs of texts, for example, documents or sentences.'</sample>
    <sample id="1167">The original content of this audio is:'and the example here you can see a parallel aligned sentence pair of a complex german sentence and its translation into plain language.'</sample>
    <sample id="1168">The sentence is: 'Different techniques are possible, as you can see in this example such as lexical substitution, clause deletion, clause elision, reordering or insertion of words.'</sample>
    <sample id="1169">The original content of this audio is: 'we now propose our new corpora de plane because in the recent years there were some problems with existing corpora so for example these corpora here are too small to train a taxonification model on.'</sample>
    <sample id="1170">The other three models which are proposed in recent years are all automatically aligned, which means they can be error prone and their alignments.</sample>
    <sample id="1171">Therefore, we propose our new corpus, d-Planes, which is split into two subcorpora: d-Plane APA and d-Plane Web. d-Plane APA is based on news texts.</sample>
    <sample id="1172">The original content of this audio is: 'In the DeepFace API, we aligned four hundred and eighty three documents all manually. It results in roughly thirty thousand thirteen thousand parallel sentence pairs.'</sample>
    <sample id="1173">The original content of this audio is:'for deep learning web this corpus includes different domains and we also align all of these seven hundred fifty documents on the one hand manually and on the other hand with automatic alignment methods.'</sample>
    <sample id="1174">The English content is: 'And in total, we result in thirty four hundred and fifty sentence pairs.'</sample>
    <sample id="1175">The sentence is 'we analyzed our sentence pairs a little bit more, so for example on the type of annotation.'</sample>
    <sample id="1176">The original content of this audio is: 'As you can see here, the Bible texts are much stronger simplified than, for example, the news text or the language learner texts.'</sample>
    <sample id="1177">The speech says:'On all levels regarding, for example, lexical semantification, structural semantification, also overall level of semantics.'</sample>
    <sample id="1178">Furthermore, you can see that our Deplane corpus has a high majority of different tokenization transformations, so for example in the Deplane API corpus, we have much more reorderingings and word additions than we have in the Deplane Web corpus.</sample>
    <sample id="1179">The English content is: 'On the other hand, in the Web Corpus, we have much more paraphrasings.'</sample>
    <sample id="1180">The original content of this audio is:'so let's now see what we can do with this corpus. hello, i'm omar and now i will talk about the use cases for our dataset, dplain. so for the first use case, we can evaluate automatic alignment methods.'</sample>
    <sample id="1181">The English content is: 'In recent years, there has been a lot of alignment methods, but in the context of machine translation.'</sample>
    <sample id="1182">The English content is: 'where we have two parallel documents written in different languages and we want to extract alignments of sentences in post-documents.'</sample>
    <sample id="1183">The English content is: 'but in our use case we are trying to extract alignments between sentences of two parallel documents having the same language having the same content but they are on different complexity levels.'</sample>
    <sample id="1184">The English content is: 'and now as we have our data set, d plane which has manually aligned sentences, we can use these sentences as gold standard alignments to evaluate some of the proposed alignment methods.'</sample>
    <sample id="1185">The original content of this audio is: 'and we did some adaptations to the proposed methods and we have published all these adaptations and the codes to run our experiments in the paper.'</sample>
    <sample id="1186">The best alignment method to use for tEXTs, German text simplification is the mass align method.</sample>
    <sample id="1187">The English content is: 'and you can also find the code to run this method on your own documents in the paper.'</sample>
    <sample id="1188">The second use case that we showed in our paper is the case of automatic text simplification.</sample>
    <sample id="1189">The speech says: 'by fine-tuning language models to produce simplified text from the complex input text.'</sample>
    <sample id="1190">The original content of this audio is: 'we have fine tuned two different models we have fine tuned the model of long part to produce document level simplifications.'</sample>
    <sample id="1191">The English content is: 'and we also fine-tune the normal base along the normal base impart to produce sentence-level simplifications.'</sample>
    <sample id="1192">The English content is: 'you can also find all the checkpoints and you can look into more details at the scores and evaluation metrics of our experiments in the paper.'</sample>
    <sample id="1193">The original content of this audio is: 'we concluded that this basic fine tuning could produce or could get scores better than the baseline scores.'</sample>
    <sample id="1194">The English content of the speech is: 'and we propose those results as a benchmark, a base benchmark for the problem of automatic text simplification in the future.'</sample>
    <sample id="1195">The original content of this audio is:'thank you so much for your attention and we hope to meet all of you during the conference thank you.'</sample>
    <sample id="1196">The speech says: 'Hi, and I'm going to talk about our work on resolving indirect referring expressions for entity selection in which we introduce the Altitude Corpus.'</sample>
    <sample id="1197">The speech says: 'My name is Javad Hosseini and this is a joint work with Philip Radin斯基, Sylvia Perity and Anne Lewis.'</sample>
    <sample id="1198">The original content of this audio is: 'our goal is to understand user's language when they want to make a choice and consider this alternative question did you mean easy on me or i got a feeling here a user wants to select between one of these two options.'</sample>
    <sample id="1199">The most obvious thing is to use a direct reference, for example by saying the name of the song is 'I'm a Believer' or its position, the first.</sample>
    <sample id="1200">The English content is: 'but sometimes an indirect reference is more appropriate to have a more natural conversation this could happen when the user cannot remember the name of the song.'</sample>
    <sample id="1201">The English content is: 'All the pronunciations are too similar to each other and hard to distinguish.'</sample>
    <sample id="1202">The original content of this audio is:'or when the user wants to specify a preference here are some examples in direct differences for example the newer one or the song that's not energetic.'</sample>
    <sample id="1203">The English content is: 'This is an important problem in conversational systems and also for benchmarking LLMs entity understanding.'</sample>
    <sample id="1204">The original content of this audio is: 'we're not aware of a public dataset, a large-scale public dataset for a task so we collect one using crowd annotation. our dataset covers three different domains: music, books and recipes.'</sample>
    <sample id="1205">The sentence in the audio is: 'Our dataset collection methodology emphasizes informality using a cartoon completion task.'</sample>
    <sample id="1206">The transcript of the audio is: 'the cartoon has three speech bubbles in the first bubble bob says remember that song we were listening to yesterday and with that bob sets the dialogue context.'</sample>
    <sample id="1207">The transcription of the audio is: 'In the second speech bubble, Alice says, "Do you mean easy on me or I got her feeling?"'</sample>
    <sample id="1208">The original content of this audio is: 'Which is the alternative question? And in the third speech bubble, Bob uses an indirect reference to select one of these entities, for example, the New Earth.'</sample>
    <sample id="1209">The original content of this audio is: 'We provide the first and second speech bubbles automatically, but the third one is filled in by the annotator. Ah um the first speech bubble is chosen from a few manual prompts per turn.'</sample>
    <sample id="1210">The second one, which is the alternative question, is generated as follows.</sample>
    <sample id="1211">The original content of this audio is: 'We always use a simple template, do you mean A or B? Where A and B are samples from Wikipedia?'</sample>
    <sample id="1212">The original content of this audio is: 'Here are the different sampling methods we've used when we move higher in the list, the entities become more similar to each other and it's usually harder to make the disambiguation.'</sample>
    <sample id="1213">The first one is uniform distribution.</sample>
    <sample id="1214">The second one is when the entities have similar titles, for example two books with the name 'The Retail'.</sample>
    <sample id="1215">The third one is when they have similar descriptions on Wikipedia, and finally when they have similar infoboxes or attributes on Wikipedia, for example the same genre or the same artist for songs.</sample>
    <sample id="1216">The original content of this audio is: 'When we show this alternative question to the end users, they know the name of these entities but they don't necessarily know about the entity.'</sample>
    <sample id="1217">The original content of this audio is:'so what we do is that we show some background knowledge about the twenties for songs we simply show a google search link to each song.'</sample>
    <sample id="1218">The original content of this audio is: 'and then ask the annotators to listen to at least some of each song and read about each song here's for example the gold search result for the song easy.'</sample>
    <sample id="1219">The original content of this audio is:'for the recipes and books domain we show some background text um from wikipedia for recipes we additionally show their images again from wikipedia so that the annotators know how they look'</sample>
    <sample id="1220">The original content of this audio is:'then we ask the annotators to pick one of these entities for example here the first one and describe them using three to five indirect referring expressions.'</sample>
    <sample id="1221">The original content of this audio is: 'For example, the one with the piano music. Here are some examples from our dataset. For example, the one without words, not the one with the twelve-year-old boy or the fictional one or comes from Azerbaijan and so on.'</sample>
    <sample id="1222">The entities corpus has six thousand alternative questions across three domains and it has forty-two thousand indirect referring expressions. Results with T5 large model are summarized below.</sample>
    <sample id="1223">The original content of this audio is:'if the language model has access to the exact same background knowledge as the annotators, the inaccuracy is really high. it's around ninety two to ninety five percent. but this is not realistic.'</sample>
    <sample id="1224">The original content of this audio is:'if the language model has access to some partially overlapping background knowledge, then the accuracy is between eighty two to eighty seven percent, which is more realistic, for example, when um the language model retrieves the background knowledge.'</sample>
    <sample id="1225">The original content of this audio is: 'if the language model has access only to entity names, then the accuracy is only sixty percent so there's a lot of room for improvement. we've also shown that the models are domain generalizable. here is a link to our dataset. thanks.'</sample>
    <sample id="1226">CamemBERT is initially trained on the 4GB subset of Wikipedia.</sample>
    <sample id="1227">Adam Skurkowski</sample>
    <sample id="1228">The experiments conducted showed that retraining or continuing to pre-train models with more recent data resulted in decreased performance, confirming the hypothesis that temporal drift is the main cause of performance loss.</sample>
    <sample id="1229">The original content of this audio is:'Hi everyone, I'm Jennie, a first-year PhD student at Carnegie Mellon University, and today I'll be presenting your work on annual positionality characterizing design by sexed data models.'</sample>
    <sample id="1230">The original content of this audio is: 'This work was done in collaboration with some folks at the University of Washington and the Allen Institute for AI, namely Sebastian Santi, Ronan Le Bras, Katerina Rinica, and Martin Saps.'</sample>
    <sample id="1231">The original content of this audio is: 'so let's start off by imagining that you're working for a newspaper and you're sifting through comments under your news article trying to remove toxic content.'</sample>
    <sample id="1232">The original content of this audio is: 'you might turn towards a popular API like Perspective API for toxicity detection, and this works really well if you're Carl Jones where Perspective API is able to detect correctly a toxic instance.'</sample>
    <sample id="1233">The original content of this audio is:'but that's not really the case for adithya sharma, where perspective api is really not as sensitive to offensive terms that are more common in indian contexts.'</sample>
    <sample id="1234">The English content is: 'This is an example of a designed bias where we see systematic performance differences between populations.'</sample>
    <sample id="1235">The English content is: 'Designed biases like the one that we just saw before might occur due to the positionality of the NLP researchers and model developers. Positionality is simply the perspectives that people hold as a result of their demographics, identity, and life experiences.'</sample>
    <sample id="1236">The English content is: 'This is a concept widely used in critical studies, specifically in feminist and queer studies spaces.'</sample>
    <sample id="1237">The original content of this audio is: 'and as a researcher, positionality can influence the research process and its outcomes and results because it can change the decisions that researchers make.'</sample>
    <sample id="1238">The English content is: 'And so one question that people might ask is do data sets and models have positionality?'</sample>
    <sample id="1239">The original content of this audio is: 'and we're not trying to say that models and cells and datasets themselves have demographic identities and life experiences, but they do aggregate judgments and opinions of real people and can thus represent certain positionalities over others.'</sample>
    <sample id="1240">The original content of this audio is:'so prior work has suggested some anecdotal evidence of having positionality such as cultural gaps and models and datasets as well as theoretical definitions of model positioningality.'</sample>
    <sample id="1241">The English content is: 'However, these works really don't look at comparing end-users with the datasets and models themselves.'</sample>
    <sample id="1242">The English content is: 'And studying model and data set positionality is increasingly important as NLP tasks become more sensitive and socially oriented.'</sample>
    <sample id="1243">The original content of this audio is:'and it's challenging to characterize how these positionalities are skewed because not all decisions are documented, and many models are hidden behind apis.'</sample>
    <sample id="1244">The original content of this audio is:'so to study dataset and model positionality we actually compare the annotations with real users with existing datasets and models.'</sample>
    <sample id="1245">The English content of the speech is: 'we do this through our framework and ah positionality.'</sample>
    <sample id="1246">The English content transcribed is: 'Our framework works in two main steps.'</sample>
    <sample id="1247">The first step is to re-annotate datasets with diverse annotators.</sample>
    <sample id="1248">The original content of this audio is: 'and we ought to do this over looking at the demographics of original datasets annotators because usually only a few and so annotators annotate each instance and because demographics are rarely collected and shared.'</sample>
    <sample id="1249">The original content of this audio is:'and so we opt to re-annotate data to get many annotations, for instance and to get a rich set of demographic data.'</sample>
    <sample id="1250">The English content of the speech is: 'we then take the annotations by demographic and compare them to the models and datasets using appearance correlation score.'</sample>
    <sample id="1251">The original content of this audio is:'and thus our framework actually differs from annotator disagreement literature by comparing end users with models and datasets predictions and labels as opposed to looking at just inter-annotator agreement or modeling annotator distributions.'</sample>
    <sample id="1252">The English speech says: 'Our framework is largely enabled through Lab in the Wild, an online crowdsourcing platform former HCI collaborator.'</sample>
    <sample id="1253">The original content of this audio is:'and lab in the wild is an online experimentation platform where we can recruit diverse volunteers compared to the platforms like mturk which largely have participants from the us or India and further lab in the wild stills able to get high quality data.'</sample>
    <sample id="1254">The original content of this audio is: 'we host two task cell lab in the wild, one of them being social acceptability. and the way this works is that participants will read a situation from the social chemistry dataset, and then they'll rate how socially acceptable as situation is.'</sample>
    <sample id="1255">The English content is: 'afterwards to stay engaged in the study they can compare their responses to an AI and others.'</sample>
    <sample id="1256">The original content of this audio is: 'we then compared these annotations with social chemistry, delphi and gpt-4.'</sample>
    <sample id="1257">The original content of this audio is: 'we then replicated a very similar setup for the toxicity and hate speech detection task, where they'll read an instance from dinah hate and write whether they think its instance of hate speech.'</sample>
    <sample id="1258">The original content of this audio is: 'we then compared these annotations with dinah hate perspective api, rewire api, hate robbederta and gpt-4 our study in the end amassed over sixteen thousand annotations from over one thousand annotators from eighty seven countries.'</sample>
    <sample id="1259">The English content is: 'So now we're about equipped to answer who do NLP datasets align with? We find that there is positionality in NLP.'</sample>
    <sample id="1260">The original content of this audio is:'for example we find that datasets and models are most aligned to english speaking countries so for the gdp four social acceptability analysis we find that its most aligned to confucian and english speaking countries we find that dynahate is also most aligned to english speaking countries.'</sample>
    <sample id="1261">The original content of this audio is: 'we also find most ah additional alignment with people who have a college education. so for gdp four in the social acceptability task, we find that it's most aligned to people with a college education or graduate school education.'</sample>
    <sample id="1262">The English content of the speech is: 'And we find the same for Donna, where it's most aligned to people with college education.'</sample>
    <sample id="1263">The English content is: 'However, when models and datasets are aligned to specific populations, some are inevitably left behind.'</sample>
    <sample id="1264">An example of this is that datasets and models are less likely to be non-biased compared to the men and women counterparts we find this in the GDP for social acceptability task as well as the Dyna hate task analysis as well.</sample>
    <sample id="1265">The English content is: 'So given that there is a position in LDP, what can we do about it?'</sample>
    <sample id="1266">The original content of this audio is:'so we have a few recommendations for this first one is keep a record of all relevant design choices throughout the research process and the other is to do nlp research with the lens of constructivism.'</sample>
    <sample id="1267">Our third recommendation is to build specialized datasets and models within four specific communities, and a good example of this is the穆斯林倡议。我想强调的是，包容性NLP不仅仅使所有技术都能为每个人工作。</sample>
    <sample id="1268">The original content of this audio is: 'And so that concludes our presentation, but if you'd like to learn more, feel free to check out our dashboard for the most updated analysis results and our paper. Thank you.'</sample>
    <sample id="1269">The tokens need to be permuted because they are not in the correct order after the first step, so the second step uses another model to predict the permutation that puts them in the right order.</sample>
    <sample id="1270">The authors recommended increased transparency about bias mitigation methods because there is currently a lack of understanding about whether positive stereotypes exist due to an excessive value alignment or some other anti-stereotyping methods resulting in pernicious patterns.</sample>
    <sample id="1271">Minimal-pair unacceptable inputs are sentences that do not follow the expected grammatical patterns of the language model, as indicated by the speaker's description.</sample>
    <sample id="1272">The authors used weight and token error rate to evaluate their results.</sample>
    <sample id="1273">The inter-annotator agreement was measured by the number of agreements out of one hundred doubly labeled conversations.</sample>
    <sample id="1274">Wikipedia</sample>
    <sample id="1275">The affiliations of the authors are not provided in the given English content.</sample>
    <sample id="1276">It focuses on improving generalization to NLP tasks, while previous works have mainly focused on improving performance on language-only tasks.</sample>
    <sample id="1277">Two authors are involved.</sample>
    <sample id="1278">The definition of binary coordination is not provided in the given English content.</sample>
    <sample id="1279">The prompt used in the study had an average length of [insert number] words.</sample>
    <sample id="1280">The smaller T5 model can produce higher quality hair style sheets than larger models when properly trained on suitable datasets.</sample>
    <sample id="1309">The work investigates the impact of different learning strategies on performance, specifically comparing three models trained with 'nachos' and another three models trained with a combination of 'nachos' and 'clinical notes'.</sample>
    <sample id="1310">The factor of overfitting due to test reuse is greater than one, indicating that for each unit of improvement on column 2003, there is more than one unit of improvement on column plus plus, leading to no diminishing returns and showing adaptive overfitting is not observed in this case.</sample>
    <sample id="1311">The quality of the simplification was evaluated by human judges.</sample>
    <sample id="1312">Yes, preliminary results show that language models have varying political leanings and occupy all four quadrants on the political compass.</sample>
    <sample id="1347">Cognitive dissonance is two inconsistent beliefs or actions.</sample>
    <sample id="1348">GPT-4 is the most liberal language model among all.</sample>
    <sample id="1349">Yes, cumulative training performs equal or better than iterative in active learning.</sample>
    <sample id="1350">Sara Papa.</sample>
    <sample id="1351">The data was taken from transcribed TED Talks that have been translated into fourteen different languages.</sample>
    <sample id="1352">The speech says: 'Hi, my name is Adam Skurkowski and this talk is about the dependency structure of coordination.'</sample>
    <sample id="1353">The original content of this audio is: 'As you may know, different dependency structures assumed by different theories and corpus approaches, so for example in universal dependencies are the structure of the coordinator coordination Lisa, Bart and Maggie.'</sample>
    <sample id="1354">The English content is: 'Is such that the first conjunct is the head of the whole coordinate structure; in this case, Lisa.'</sample>
    <sample id="1355">The original content of this audio is: 'A similar approach is assumed in Miltchouk's meaning text theory, where again the whole coordinate structure is headed by the first conjunct. So these two approaches are isometric, right? They single out one of the conjuncts.'</sample>
    <sample id="1356">The original content of this audio is:'Now there are symmetric approaches to coordinate and coordinate structures such as the Prag approach, the conjunction headed approaches, the humanism dependency treebank where coordinate structures are headed by conjunction.'</sample>
    <sample id="1357">The English speech is transcribed as: 'So we get dependencies from end to all the conjuncts.'</sample>
    <sample id="1358">The English content is: 'and finally there's also a multi headed approach that's used for example in um the cat's word grammar.'</sample>
    <sample id="1359">The original content of this audio is: 'where so to say all conduct are heads of the coordinate structure so we get dependencies from the governor here loves to all conduct separately these are parts made.'</sample>
    <sample id="1360">The original content of this audio is: 'our aim in this paper is to um produce a novel argument for ah the symmetric structures of coordination like these two and against the asymmetric structures of coordination like these.'</sample>
    <sample id="1361">The speech says: 'ok the argument is based on the principle of independence and explanation that i will explain on the basis of these examples.'</sample>
    <sample id="1362">The direct object is preferred to be close to the verb, while adjectives may be further away. So 'March read it yesterday' is fine because the direct object 'it' is close to the verb 'read'.</sample>
    <sample id="1363">The original content of this audio is:'while march read yesterday it is much worse right because ah here between the verb and the direct object there is an adjective i yesterday.'</sample>
    <sample id="1364">The English content of the audio is: 'However, this effect may be ameliorated when the direct object is very heavy and very long, because then it can be moved to the position after the adjective.'</sample>
    <sample id="1365">The original content of this audio is: 'this is illustrated here, so both these sentences are fine. march read this absolutely fascinating book about the bees yesterday. it's okay. and anyway, instead of it, we have this long np.'</sample>
    <sample id="1366">The original content of this audio is: 'but it's also okay to say march red yesterday this absolutely fascinating book about bees.'</sample>
    <sample id="1367">The English content is: 'So the reasoning here is that this is possible because even though this sentence violates the general grammatical principle that direct objects should be next to the verb.'</sample>
    <sample id="1368">The audio states: 'It satisfies the principle of dependency length minimization, which says that shorter um shorter dependencies are preferred.'</sample>
    <sample id="1369">The English content of the speech is: 'So these two trees only show the length of the crucial dependencies, so the ones that are not constant among these two structures.'</sample>
    <sample id="1370">The original content of this audio is:'so here we have the dependency from red to the adjoint of length seven measured in words and from red to book of length four so together it's eleven.'</sample>
    <sample id="1371">The original content of this audio is: 'when you move when you swap ah these two constituents the sum of these two dependencies becomes six right so instead of eleven six much shorter that's why this sounds quite ok right it violates one principle but it satisfies another one.'</sample>
    <sample id="1372">The original content of this audio is: 'Okay so what we did, we extracted various statistics from about coordination from the enhanced version of PanTREBANK and see the paper why we wouldn't use universal dependencies.'</sample>
    <sample id="1373">The original content of this audio is:'and are these statistics confirmed the observation made many times before that left conjuncts tend to be shorter ah so salt and pepper and not pepper and salt measured in syllables.'</sample>
    <sample id="1374">The English content transcribed is: 'and also the observation that was made in passing that this tendency grows with length difference.'</sample>
    <sample id="1375">The original content of this audio is:'so when the difference between the lengths of the two conjuncts grows the shorter conjunct prefers to be the first one stronger right so the proportion is is bigger of of the left short conjunct.'</sample>
    <sample id="1376">The original content of this audio is: 'but what's novel in this paper is that we ah that we observed that this tendency only occurs when the governments on the left are absent.'</sample>
    <sample id="1377">The audio states: 'Right, so the governor is on the left in this example Lisa, so is the governor is on the left.'</sample>
    <sample id="1378">The original content of this audio is: 'It's absent in the second example, Homer came and sneezed. Here we have coordination of two verbs and there's no outside external governor, right? So in such cases the left conjunct prefers to be shortened than also the bigger difference between the two countries.'</sample>
    <sample id="1379">The original content of this audio is:'however when the governance on the right is here loff governs the coordination to the net this effect disappears.'</sample>
    <sample id="1380">The original content of this audio is:'so we showed that um ah by measuring length in characters, there's the first column in syllables, the middle column and in words, the right column so i'll concentrate on the right one.'</sample>
    <sample id="1381">The English content is: 'what we see here is that when the governement on the left.'</sample>
    <sample id="1382">The audio states: 'the tendency for the left conjunct to be shorter grows steadily with the absolute difference in words and the same is observed when there is no governor as in coordination of sentences but when the governor is on the right this tendency disappears.'</sample>
    <sample id="1383">The original content of this audio is:'and we show in the paper how this provides an argument against um as asymmetric structures of coordination as these two and for symmetric structures as these two.'</sample>
    <sample id="1384">The audio states: 'so see the paper for the full agreement and arguments sorry and talk to us about it at the post session thank you.'</sample>
    <sample id="1385">Matthias Lendermann</sample>
    <sample id="1386">Cross-lingual transfer is the process of training a model on one language and transferring its knowledge to another language for prediction tasks.</sample>
    <sample id="1387">The authors are affiliated with Humboldt-Universität zu Berlin in Germany.</sample>
    <sample id="1388">The authors use the blue latency measure, which is the latency measure considered for the models' computational times to predict the output.</sample>
    <sample id="1416">Tree-based methods can be computationally expensive and involve significant formalism-specific pre-processing to handle variable symbols.</sample>
    <sample id="1417">The affiliations of the authors are not provided in the given English content.</sample>
    <sample id="1495">ABC-Eval stands for annotating behaviors in chat.</sample>
    <sample id="1496">The performance delta between CoNLL-2003 and CoNLL++ is higher than 5 percentage points up to and including 2021.</sample>
    <sample id="1527">The authors' affiliations are not provided in the given English content.</sample>
    <sample id="1528">The speaker's name is Si Yuyuan from Fudan University.</sample>
    <sample id="1529">Four.</sample>
    <sample id="1530">The approach is compared with the state-of-the-art architecture specifically tailored for simultaneous speech translation, which is referred to as the SimulST architecture.</sample>
    <sample id="1531">The original content of this audio is: 'Hello everyone, my name is In and my colleague Zhong Yang and I will be presenting our research on multi-instructed learning improving multi-model social learning via instruction tuning.'</sample>
    <sample id="1532">The original content of this audio is:'so with the advances in large language models, many works started to explore new learning paradigms of reusing pre-trained language models for different downstream tasks in a parameter-efficient way.'</sample>
    <sample id="1533">The original content of this audio is: 'Recently, many studies have shown that instruction tuning enables large language models to perform on unsupervised tasks in a self-supervised manner by following natural instructions.'</sample>
    <sample id="1534">The original content of this audio is:'However, most previous works on instruction tuning focused on improving zero-shot performance on language-only tasks, while computer vision and multimodal tasks have been left out.'</sample>
    <sample id="1535">The original content of this audio is: 'therefore in this work we want to investigate whether instruction tuning on multitask models can actually improve generalization to unseen multitask tasks.'</sample>
    <sample id="1536">The English content is: 'additionally at the time of our research we discovered a considerable discrepancy in availability of instruction dataset between LP and multimodel.'</sample>
    <sample id="1537">The English content is: 'There exists more than one thousand and six hundred language-only instruction tasks, however, there is no large-scale publicly available multimodal instruction task therefore this motivates us to build a multimodal instruction tuning dataset.'</sample>
    <sample id="1538">The English content is: 'Here we present Multi-Instruction Instruction Tuning benchmark dataset that consists of sixty two diverse multimodal tasks covering ten broad categories.'</sample>
    <sample id="1539">The English content is: 'These tasks are derived from twenty one existing open source datasets, and each task is equipped with five expert written instructions.'</sample>
    <sample id="1540">The English content of the speech is: 'For investigating multimodal instruction tuning, our proposed dataset is...'.</sample>
    <sample id="1541">The Mandarin speech translates to: 'Here we show some example instances from our multi-instrument dataset.'</sample>
    <sample id="1542">The English content is: 'To unify the processing of various input and output data types.'</sample>
    <sample id="1543">The English content is: 'We follow the method from OFA and formulate all tasks in a unified sequence-to-sequence format, in which the input text, images, instruction, and bounding boxes are represented in the same token space.'</sample>
    <sample id="1544">The English content spoken is 'Okay, now I'm going to talk about multimodal instruction tuning.'</sample>
    <sample id="1545">The English content of the speech is: 'so for the training dataset, we use fifty three tasks from the nlp group for training and we sample ten thousand instances per task for testing. we reserved the entire common sense reasoning group for testing and we select additional five tasks from the vocabulary and miscellaneous group.'</sample>
    <sample id="1546">The English content of the speech is: 'We use all the instances in the test split for each task, and in addition, we randomly sample twenty tasks from the test split of natural instruction as on-speech tasks.'</sample>
    <sample id="1547">The original content of this audio is:'so we use a pre-trained o fa large model as a base model during training we make all the instances for all the tasks each instance is randomly combined with one of its five instruction templates.'</sample>
    <sample id="1548">The original content of this audio is:'so during test for each task we conduct the total of five experiments by evaluating the model using one of the five instructions in each experiment.'</sample>
    <sample id="1549">The English content is: 'We report the mean and max performance and standard deviation of the performance across all five experiments.'</sample>
    <sample id="1550">The English content of the speech is: 'if the task is a multimodal classification task, report accuracy; if it's a multimodal generation task, reportrouge l; and for an r-p task, reportrouge l as well.'</sample>
    <sample id="1551">The English content is: 'We also introduced an additional evaluation metric called sensitivity, so this measures the model's ability to consistently produce the same outputs for the same task regardless of slight variation in the wording of the instruction.'</sample>
    <sample id="1552">The English speech is: 'Here is our main result as we can see, instruction tuning can significantly improve OFA performance on single model tasks.'</sample>
    <sample id="1553">The original content of this audio is: 'also transfer learning from natural instruction dataset can benefit ah instruction tuning.'</sample>
    <sample id="1554">The English content is: 'Here we can see as the amount of task increases, the model achieved better performance and in the meantime lower sensitivity.'</sample>
    <sample id="1555">The original content of this audio is:'so we also did one experiment ah we use one instruction versus five instructions as we can see using more instruction can improve the model's overall performance and reduce its sensitivity a lot.'</sample>
    <sample id="1556">The original content of this audio is:'so this shows the effect of different fine-tuning strategies on the model sensitivity as we can see by transfer learning from natural instruction datasets the model can ah achieve much better sensitivity compared to the original o fa model.'</sample>
    <sample id="1557">The original content of this audio is: 'we also can see transfer learning from nature instruction dataset can help oif to achieve much better performance on the natural instruct.'</sample>
    <sample id="1558">The original content of this audio is: 'Overall, we propose the first large-scale multimodal instruction tuning dataset, which significantly improves the zero-shot capability of OFA and explores different transfer learning techniques and shows their benefits. We design a new metric called sensitivity.'</sample>
    <sample id="1559">The spoken words in the audio are: 'so one more thing we are collecting a much larger multimodal instruction tuning dataset with around one hundred and fifty additional vision language tasks and we will release them so this is the QR code for our data and model thank you.'</sample>
  </task>
</testset>