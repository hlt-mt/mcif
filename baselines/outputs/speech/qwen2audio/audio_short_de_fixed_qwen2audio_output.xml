<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="de">
    <sample id="0">Lange scale web crawling data und politische Nachrichtenmedien wie New York Times, Los Angeles Times, The Guardian, Huffington Post usw.</sample>
    <sample id="1">McGill University und Microsoft Research.</sample>
    <sample id="2">Hallo! Willkommen zu unserer Präsentation von 'deplane', einem neuen Quelltextmodell für die deutsche Textkennzeichnung auf Dokumentebene und Satzebene.</sample>
    <sample id="3">Der englische Text lautet: 'Mein Name ist Regina Stodden, und ich werde Ihnen helfen, den ersten Teil der Präsentation zu verstehen. Lassen Sie uns zunächst definieren, was Textsimplifizierung bedeutet.'</sample>
    <sample id="4">Die Textverdolmetschung ist der Prozess, bei dem ein Text angepasst wird, um die Verständlichkeit für einen bestimmten Zielgruppe zu verbessern, wie Leser mit Problemen beim Lesen auf einer Muttersprache oder von Nicht-Nachkommen.</sample>
    <sample id="5">Um einen Textzuerkennungsdienst zu trainieren, benötigen wir entsprechende Paare von Texten, zum Beispiel aus Dokumenten oder Sätzen.</sample>
    <sample id="6">Ein Beispiel hier ist ein parallel geordneter Satzpaar aus einem komplexen deutschen Satz und seiner Übersetzung ins einfache Englisch.</sample>
    <sample id="7">In diesem Beispiel sind verschiedene Techniken möglich, wie z.B. Wortersetzungen, Klammerauflösung, Klammerauflösung, Umordnung oder Einsetzen von Wörtern.</sample>
    <sample id="8">Wir schlagen jetzt unseren neuen Organismus vor, weil in den letzten Jahren einige Probleme mit dem bestehenden Organismus aufgetreten sind. Zum Beispiel sind diese Organismen hier zu klein, um ein Taxonomie-Modell zu trainieren.</sample>
    <sample id="9">Die anderen drei Modelle, die in den letzten Jahren vorgeschlagen wurden, sind alle automatisch ausgerichtet, was bedeutet, dass sie immer fehleranfällig und ihre Ausrichtungen korrigierbar sind.</sample>
    <sample id="10">Daher schlagen wir unseren neuen Korpus 'd-Plan' vor, der in zwei Teile unterteilt ist: 'd-Plan API' und 'd-Plan Web'. Die 'd-Plan API' basiert auf Nachrichtentexten.</sample>
    <sample id="11">In der plain API wurden 483 Dokumente manuell zugeordnet, was zu etwa 30.000 bis 13.000 paralelen Satzpaaren führt.</sample>
    <sample id="12">Für DeepFaceWeb beinhaltet dieses Korpus verschiedene Domänen und wir haben alle 750 Dokumente auf der einen Seite manuell und auf der anderen Seite mit automatischen Ausrichtungsmethoden zugeordnet.</sample>
    <sample id="13">Insgesamt resultieren in 30450 Satzpaaren.</sample>
    <sample id="14">Wir haben unsere Satzpaare ein wenig mehr analysiert, zum Beispiel beim Typ von Verifikation.</sample>
    <sample id="15">Wie Sie hier sehen können, sind die Bibeltexte viel stärker vereinfacht als zum Beispiel der Nachrichtentext oder die Sprachlernertexte.</sample>
    <sample id="16">On all levels regarding, for example, lexical annotation, structural annotation, also overall level of annotation.</sample>
    <sample id="17">Darüber hinaus kann man sehen, dass unser de plane Corpus eine hohe Anzahl von Differentiationstransformationen aufweist. Zum Beispiel hat das de plane API Corpus viel mehr Umordnungen und Textänderungen als das de plane Web Corpus.</sample>
    <sample id="18">Auf der anderen Seite haben wir im Web-Corpus viel mehr Verflechtungen.</sample>
    <sample id="19">Lassen Sie uns jetzt sehen, was wir mit diesem Datensatz tun können.Hallo, ich bin Omer und jetzt werde ich über die Verwendungsfälle für unseren Datensatz sprechen. Also für den ersten Verwendungsfall können wir automatische Allokationsmethoden evaluieren.</sample>
    <sample id="20">In den letzten Jahren wurden viele Algorithmen zur Konfiguration entwickelt, aber im Kontext der maschinellen Übersetzungen.</sample>
    <sample id="21">Der englische Text übersetzt ins Deutsche lautet: 'Da haben wir zwei parallele Dokumente, die in verschiedenen Sprachen geschrieben sind und wir möchten die Übereinstimmungen der Sätze extrahieren.'</sample>
    <sample id="22">In unserem Fall versuchen wir, Ausgleichungen zwischen den Sätzen zweier paralleler Dokumente zu extrahieren, die dieselbe Sprache haben, denselben Inhalt haben, aber auf unterschiedlichen Komplexitätsebene sind.</sample>
    <sample id="23">Da wir nun über eine Datenbank mit manuell angelegten Sätzen verfügen, können wir diese Sätze als Standardausrichtungen verwenden, um einige vorgeschlagenen Ausrichtungsmethoden zu evaluieren.</sample>
    <sample id="24">Wir haben einige Anpassungen an die vorgeschlagenen Methoden vorgenommen und alle diese Anpassungen sowie die verwendeten Codeabschnitte zum Ausführen unserer Experimente in dem Paper veröffentlicht.</sample>
    <sample id="25">Am Ende kamen wir zu dem Schluss, dass die beste Methode zur automatischen Textoptimierung für deutsche Texte die Methode der maschinellen Lektüre ist.</sample>
    <sample id="26">Es ist auch möglich, den Code zu finden, um diese Methode auf Ihren eigenen Dokumenten auszuführen.</sample>
    <sample id="27">Der zweite Fall, den wir in unserem Paper gezeigt haben, ist der Fall der automatischen Textsimplifizierung.</sample>
    <sample id="28">Durch das Finden von Sprachmodellen, um aus komplexen Texten vereinfachte zu erstellen.</sample>
    <sample id="29">Wir haben zwei verschiedene Modelle fine-tuned, ein Modell für die Langzeit-Empfehlung zum Erzeugen von Dokumenteneinstellungen und ein anderes Modell zur Verarbeitung von Texten.</sample>
    <sample id="30">Wir fine-tunen auch die normale Basislänge, um sentenstypische Vereinfachungen zu erzeugen.</sample>
    <sample id="31">Sie können auch alle Kontrollpunkte finden und mehr Details zu den Ergebnissen und Bewertungsmessungen unserer Experimente in dem Paper einsehen.</sample>
    <sample id="32">Wir haben zu dem Schluss gekommen, dass diese grundlegende Feinabstimmung dazu beitragen könnte, die Ergebnisse besser als die Pulslinienergebnisse zu erzielen.</sample>
    <sample id="33">Die Ergebnisse wurden als Maßstab und基线 für das Problem der automatischen Textvereinfachung in Zukunft vorgeschlagen.</sample>
    <sample id="34">Vielen Dank für Ihre Aufmerksamkeit und wir hoffen, alle von Ihnen während der Konferenz zu treffen. Vielen Dank.</sample>
    <sample id="35">The speaker's name is Kay O'Yen.</sample>
    <sample id="36">T5 large model.</sample>
    <sample id="37">Ja, der CoNLL-2003-Tagger funktioniert immer noch.</sample>
    <sample id="38">Die vorgeschlagene Methode reduziert die Subjektivität durch explizite Anmerkungen darauf, ob jede Modellantwort bestimmte Verhaltensweisen ausdrückt, wie z.B. mit irrelevanten Informationen oder Widersprüchen.</sample>
    <sample id="39">Die Reinigung von Validierungssamples ist wichtig für den erfolgreichen Einsatz von WSL-Methoden. Ohne saubere Validierungssamples können die Trainingsmodelle ihre Leistung nicht außerhalb der ursprünglichen Weak-Labell Grenzen generieren.</sample>
    <sample id="40">Die Frage könnte besser formuliert werden, indem man sie spezifischer macht oder mehr Informationen gibt. Ohne weitere Kontext kann nicht gesagt werden, wie das Ergebnis verbessert werden kann.</sample>
    <sample id="41">Zwei.</sample>
    <sample id="42">Hallo, mein Name ist Adam Skurkowski und dieser Vortrag handelt über die Abhängigkeitsstruktur der Koordination.</sample>
    <sample id="43">Wie Sie wissen, sind verschiedene Abhängigkeitsstrukturen durch verschiedene Theorien und Ansätze festgelegt worden, zum Beispiel die universelle Abhängigkeit mit der Struktur von Koordinaten, Koordinationsebene und Magie.</sample>
    <sample id="44">Es ist so, dass der erste Konjunktiv das Head von ganzer Coordinatensstruktur ist. Immerhin Lisa</sample>
    <sample id="45">In der Texttheorie von Igor Miltuchov wird ein ähnlicher Ansatz verwendet, bei dem die Koordinatensstruktur durch das erste Konjunkt angeführt wird. So sind diese beiden Ansätze isomorph. Sie scheiden jedoch eines der Konjekte aus.</sample>
    <sample id="46">Es gibt auch symmetrische Ansätze zu kohärenten Koordinatstruktur, wie zum Beispiel den Prag-Approach, die Konjunktionshypothesen, die Heisenberg-Prinzipien und die Tripelbänder, bei denen Koordinatstrukturen durch eine Konjunktion angeführt werden.</sample>
    <sample id="47">Also erhalten wir Abhängigkeiten von einem Ende bis hin zu allen Konjunkten.</sample>
    <sample id="48">Schließlich gibt es auch eine mehrfache Ansicht, die zum Beispiel in der Cut sense Wortgrammatik verwendet wird.</sample>
    <sample id="49">Wohin, sagen wir, alle Konsequenzen sind Heads der Koordinatensstruktur. Also erhalten wir Abhängigkeiten vom Governor hier Laves zu allen Konsequenzen getrennt voneinander. Das sind die wichtigsten Punkte.</sample>
    <sample id="50">Die Aufgabe des Papers besteht darin, einen neuen Argument für symmetrische Strukturen der Koordination zu produzieren, wie zum Beispiel diese beiden und gegen asymmetrische Strukturen der Koordination wie diese hier.</sample>
    <sample id="51">Okay, das Argument basiert auf dem Prinzip der Abhängigkeit von der Selectivierung, das ich anhand dieser Beispiele erklären werde.</sample>
    <sample id="52">In English, as you might know, direct objects are preferred to be close to the verb, while complements may be further away. So 'March read it yesterday' is fine because the direct object 'it' is close to the verb 'read'.</sample>
    <sample id="53">Der deutsche Inhalt des englischen Textes lautet: 'Während March gestern las, ist es viel schlechter, weil hier zwischen dem Verb und dem direkten Objekt ein Pronomen steht.'</sample>
    <sample id="54">Dieser Effekt kann jedoch bei einem direktiven Objekt, das sehr schwer und lang ist, gemildert werden, wenn es an die Position nach dem Eintrag verschoben wird.</sample>
    <sample id="55">Dies ist hier illustriert. Deshalb sind beide Sätze in Ordnung. March hat heute ein absolut faszinierendes Buch über die Bienen gelesen. Es ist okay, dass statt 'it' 'this long and p' steht.</sample>
    <sample id="56">Aber es ist auch okay, sagen zu können: 'March昨天读过这本关于蜜蜂的绝对令人着迷的书。'</sample>
    <sample id="57">Die Übersetzung ins Deutsche lautet: 'Der Grund hier ist, dass dies möglich ist, weil selbst wenn dieser Satz das grammatische Prinzip verletzt, wonach direkte Objekte neben dem Verb stehen sollten.'</sample>
    <sample id="58">Es erfüllt das Prinzip der Abhängigkeitslängenminimierung, wonach kürzere Abhängigkeiten bevorzugt werden.</sample>
    <sample id="59">Die beiden Bäume zeigen nur die Länge der wichtigen Abhängigkeiten, die zwischen diesen beiden Strukturen nicht konstant sind.</sample>
    <sample id="60">Also haben wir hier die Abhängigkeit von 'red' bis hin zum 'adjunct of length seven', gemessen in Worten, und von 'red' bis hin zu 'book of length four'. Also zusammen sind es elf.</sample>
    <sample id="61">Wenn Sie sich bewegen, wenn Sie diese beiden Konstituenten austauschen, summiert sich die Anzahl dieser beiden Abhängigkeiten auf sechs. Recht? Statt elf ist es also viel kürzer. Deshalb klingt das quite okay, oder? Es verletzt einen Grundsatz, aber erfüllt einen anderen.</sample>
    <sample id="62">Okay, also haben wir aus der erweiterten Version von PantheaBanc die Statistiken über die Koordination extrahiert und das Paper gelesen, warum wir keine universellen Abhängigkeiten verwenden.</sample>
    <sample id="63">Und bestätigen diese Statistiken die Beobachtung, die viele Male zuvor gemacht wurde: Linker Konjunktiv ist kürzer als rechter. Also Salz, Pfeffer und Gewürze in Silben gemessen.</sample>
    <sample id="64">Der englische Text lautet: 'Und auch die Beobachtung, die in der Vergangenheit gemacht wurde, dass diese Tendenz mit Längenunterschieden wächst.'</sample>
    <sample id="65">Wenn der Unterschied zwischen den Längen der beiden Konjunktionen wächst, bevorzugt die kürzere Konjunktion die erste Stellung, richtig? Die Proportion ist also größer bei der linken kurzen Konjunktion.</sample>
    <sample id="66">Aber was neu ist in diesem Artikel, ist dass wir beobachtet haben, dass diese Tendenz nur dann auftritt, wenn die Regierung auf der linken Seite fehlt.</sample>
    <sample id="67">Der Gouverneur ist auf der linken Seite in diesem Beispiel. Also ist der Gouverneur auf der linken Seite.</sample>
    <sample id="68">In Beispiel 2 ist 'Homer kam und schnaubte.' die Coordinierung von zwei Verben, und es gibt keinen äußeren Regulator. Deshalb werden in solchen Fällen die linken Konjunktionen bevorzugt kürzer gehalten. Auch der größere Unterschied zwischen den beiden Konjugationen wird sichtbarer.</sample>
    <sample id="69">Wenn die Regierung auf der rechten Seite wie hier ist, verschwindet dieser Effekt.</sample>
    <sample id="70">Wir haben gezeigt, dass die erste Spalte in Silben, die mittlere Spalte und die rechte Spalte Längen in Zeichen aufweisen. Deshalb konzentrieren wir uns auf die rechte Spalte.</sample>
    <sample id="71">Was wir hier sehen, ist, dass wenn die Regulierung auf der linken Seite ist.</sample>
    <sample id="72">Die Tendenz, dass die linksgelegene Konjunktion kürzer wird, wächst ständig mit der absoluten Differenz an Wörtern, und das ist auch bei der Verwendung von 'snow governor' in Sätzen zu beobachten. Aber wenn der Governor rechts steht, verschwindet diese Tendenz.</sample>
    <sample id="73">In dem Artikel zeigen wir, wie dies eine Argumentation gegen asymmetrische Strukturen der Koordination liefert, indem es diese zwei symmetrischen Strukturen gegenüberstellt.</sample>
    <sample id="74">Sehen Sie sich das Papier für den vollständigen Vertrag und die Argumente an, und sprechen Sie uns danach über die Nachbesprechung. Vielen Dank.</sample>
    <sample id="75">Zwei.</sample>
    <sample id="76">Bibeltexte</sample>
    <sample id="77">Soil and pepper, not pepper salt.</sample>
    <sample id="78">Ja, die Modelle sind für Forschungszwecke verfügbar.</sample>
    <sample id="79">DEplain-apa beinhaltet Dokumente, die auf APA-Formatierung basieren.</sample>
    <sample id="80">Eine bessere Modellarchitektur, größere Modellgrößen sowie mehr präzise Beispiele sind für eine gute Generalisierung notwendig.</sample>
    <sample id="81">Die Tendenz zu kürzeren linken Konjunktionen wurde durch die Messung der Länge in Buchstaben im ersten Spalte (Syllable), der Mitte (Mittelbucheinheit) und rechts (Wörter) der Zeile erfasst.</sample>
    <sample id="82">Die Experimente wurden durchgeführt, indem Längen in Zeichen, Silben und Worten gemessen wurden, wobei der Schwerpunkt auf der rechten Spalte lag.</sample>
    <sample id="83">Der Basisklassifikator performs nicht viel besser als zufällig.</sample>
    <sample id="84">Ein Autor.</sample>
    <sample id="85">Bob und Alice.</sample>
    <sample id="86">Kontextsensitive MÜ-Modelle sind bei formalität und grammatischer Konsistenz signifikant genauer als kontextagnostische Modelle.</sample>
    <sample id="87">Coventry University.</sample>
    <sample id="122">Das Framework quantifiziert die Positionalität mithilfe von Annotatoren, indem es Daten sets mit verschiedenen Annotatoren reAnnotations durchführt.</sample>
    <sample id="155">Es wurde gefunden, dass die menschen Teilnehmenden durch die Verwendung der Persona-Prompts in der Lage waren, rassische Stereotypen zu surface.</sample>
    <sample id="156">Die Studie verwendete die erweiterte Version von Pentaho und eine Papierrolle ('the paper') zur Extraktion von Statistiken über Koordination.</sample>
    <sample id="157">Ein Autor.</sample>
    <sample id="158">Zusammenfassung und Klassifikation von Diskontinuitäten in binären Gruppen.</sample>
    <sample id="159">Ein Autor.</sample>
    <sample id="160">Eine.</sample>
    <sample id="161">Das Framework unterscheidet sich durch die Vergleichung von Endbenutzern mit Modellen und Datenbanken, Vorhersagen und Etiketten, anstatt sich nur auf das annotatorische Einverständnis oder die Modellierung von annotatorischen Verteilungen zu konzentrieren.</sample>
    <sample id="162">Das Setup, das am meisten Überschneidungen mit dem Lexikon der Stereotypen hat, ist das erste.</sample>
    <sample id="163">Die genauen Namen der kommerziellen Systeme wurden nicht genannt, nur dass sie miteinander verglichen wurden.</sample>
    <sample id="164">Hallo, ich bin Shangbin, PhD-Student an der University of Washington. Heute präsentiere ich unsere Arbeit von den vorbereiteten Daten bis hin zu Sprachmodellen und downstream-Tätigkeiten wie dem Verfolgen von Spuren politischer Vorurteile, die zu unfairen NLP-Modellen führen.</sample>
    <sample id="165">Die Sprachmodelle werden an großen Web-Crawl-Daten trainiert.</sample>
    <sample id="166">Laut einer Umfrage des C4 Projekt werden politische Nachrichtenmedien in ihren Vorbereitungsdaten gut abgedeckt. So sind beispielsweise die New York Times, die Los Angeles Times, die Guardian, der Huffington Post usw. in Sprachmodell-Trainingsdaten gut vertreten.</sample>
    <sample id="167">Dies hat zu einer gemischten Freude für die Anwendungen des Sprachmodells geführt.</sample>
    <sample id="168">So auf der einen Seite konnten sie aus verschiedenen Perspektiven lernen, was die Demokratie und die Vielfalt von Ideen feiert. Auf der anderen Seite sind diese verschiedene politischen Meinungen inherent sozial geprägt und können zu potentiellen Fairnessproblemen in Downstream-Tasks führen.</sample>
    <sample id="169">Wir schlagen vor, die politische Vorurteilspropagationskette von den Vorbereitungsdaten bis hin zu Sprachmodellen und dann zu Downstreamaufgaben zu untersuchen, indem wir folgende Fragen stellen:

  1. Welche Art von Daten werden für die politische Vorurteilspropagation verwendet?
  2. Wie werden diese Daten in Sprachmodelle transformiert?
  3. Welche Auswirkungen haben diese Modelle auf die politische Meinungsbildung der Benutzer?
  4. Gibt es bestimmte Gruppen, die von dieser Propaganda besonders betroffen sind?
  5. Wie kann man sicherstellen, dass die Verwendung von Sprachmodellen nicht zur Verbreitung von politischer Vorurteilspropaganda beiträgt?</sample>
    <sample id="170">Erstens, wie bewerten wir die politische Ausrichtung von Sprachmodellen und welche Rolle spielen die vorliegenden Daten dabei?</sample>
    <sample id="171">Zweitens, wie performen Sprachmodelle mit verschiedenen politischen Ansichten tatsächlich auf Downstreamaufgaben und ob dies zu Ungleichheiten in NLP-Anwendungen führen kann.</sample>
    <sample id="172">Im speziellen bezieht sich dies auf die Vorschläge zu präzisen Sprachmodellen mit verschiedenen vorgeschlagenen Formatierungen unter Verwendung politischer Fragebögen, wie zum Beispiel der Political Compass-Test. Dies gewährleistet eine automatische Bewertung auf dem Gebiet der politischen Wissenschaftlerforschung.</sample>
    <sample id="173">Einige vorläufige Ergebnisse zeigen, dass Sprachmodelle tatsächlich politische Ausrichtungen haben und sich auf alle vier Quadranten des politischen Kompasses verteilen.</sample>
    <sample id="174">GPT-4 ist auch die liberaleste Sprachmodell unter ihnen alle und GPT-Theorien sind im Allgemeinen sozialliberaler als BERT-Theorien und ihre Varianten.</sample>
    <sample id="175">Zweitens haben wir das Ziel, zu untersuchen, bis zu welchem Grad die politischen Vorurteile in Sprachmodellen tatsächlich aus der Trainingsdaten extrahiert werden.</sample>
    <sample id="176">Wir könnten eine kontrollierte Experimente durchführen, indem wir weitere Kontrollpunkte für Sprachmodell-Prätraining auf sechs verschiedenen parteilichen Organisationen erstellen, die in Nachrichten und sozialen Medien unterteilt sind und politisch unterschiedlich sind.</sample>
    <sample id="177">Durch weitere Vorbereitung von Sprachmodellen auf solche Parteien kann man sehen, dass sich die ideologischen Koordinaten der Sprachmodelle entsprechend ändern.</sample>
    <sample id="178">Zum Beispiel kann man bei Robert, der sich weiter auf die linke Seite des Spektrums fokussiert hat und in Bezug auf das Rednerkorpus weiter trainiert wurde, einen erheblichen linken Meinungsumschwung feststellen.</sample>
    <sample id="179">In Bezug auf seine politischen Vorurteile.</sample>
    <sample id="180">Wir versuchen auch zu untersuchen, ob Sprachmodelle die in unserer modernen Gesellschaft verbreitete Polarisierung aufnehmen können.</sample>
    <sample id="181">Wir teilen die Vorkonditionierte Korpore in zwei Gruppen auf: vor dem 45. US-Präsidenten und nach dem 45. US-Präsidenten. Dann trainieren wir separate Sprachmodelle für die beiden verschiedenen Zeitperioden.</sample>
    <sample id="182">Wir können sehen, dass Sprachmodelle im Allgemeinen eine politische Ausrichtung haben, die weiter von der Mitte entfernt ist. Nach dem Jahr 2017 zeigt dies an, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufnehmen können.</sample>
    <sample id="183">Lassen Sie uns abschließend Sprachmodelle mit verschiedenen politischen Einstellungen hinsichtlich der Erkennung von Hassreden und Falschnachrichten in NLTK-Anwendungen evaluieren, die oft Sprachmodelle verwenden und sehr wichtige Auswirkungen haben könnten.</sample>
    <sample id="184">Wenn wir die Leistung je nach Kategorie untersuchen, wenn wir sagen, wenn wir die Leistung in zwei Teile teilen, dann sehen wir, dass...</sample>
    <sample id="185">Different Demographics or Political Orientation of News Media, we can see a pattern that, for example, for hate speech detection, left-leaning language models are better.</sample>
    <sample id="186">Die Übersetzung des englischen Inhalts lautet: 'Beim Erkennen von Hetzreden, die sich gegen soziale Minderheiten richten.'</sample>
    <sample id="187">Der englische Text lautet jedoch: 'Jedoch sind unsere Werke besser darin, Hassrede zu erkennen, die sich gegen mächtigere Gruppen in unserer Gesellschaft richtet.'</sample>
    <sample id="188">Und umgekehrt. Tatsächlich sind Sprachmodelle besser darin, Hassreden zu erkennen, die auf Weiße und Männer abzielen, aber schlechter darin, Hassreden gegen Schwarze, LGBTQ+ und andere Minderheiten zu erkennen.</sample>
    <sample id="189">类似的情况也发生在假新闻检测中，我们发现左翼语言模型在检测与其对立的政治倾向的虚假新闻时表现更好，反之亦然。</sample>
    <sample id="190">In diesem Abschnitt werden wir Ihnen viele qualitative Beispiele zeigen, um zu sehen, dass Sprachmodelle mit verschiedenen politischen Überzeugungen unterschiedliche Bedeutungen haben.</sample>
    <sample id="191">Geben Sie verschiedenen Vorhersagen für Hassreden und Falschangaben basierend auf ihren sozialen Kategorien. Es gibt noch mehr Beispiele in der Anmerkung, um das zu betonen.</sample>
    <sample id="192">Dies deutet darauf hin, dass es ein公平ness-Problem gibt, das sehr dringend hinsichtlich der politischen Vorurteile von Sprachmodellen besteht.</sample>
    <sample id="193">Zum Beispiel, wenn rechtsgerichtete Sprachmodelle zu finden wären, die auf Hassreden oder Falschangaben spezialisiert sind und auf einer beliebten sozialen Medienplattform eingesetzt werden sollten.</sample>
    <sample id="194">Dies würde bedeuten, dass Menschen mit oppositionellen politischen Meinungen möglicherweise marginalisiert werden und die Hassrede, die sich an Minderheitengruppen richtet, möglicherweise ohne Kontrolle weiterhin verbreitet wird.</sample>
    <sample id="195">Dieser Ton ruft uns dazu auf, die Fairnessprobleme anzuerkennen und anzugehen, die durch Sprachmodell-Politiken entstanden sind.</sample>
    <sample id="196">Ein bisschen Diskussion, wir möchten auch hervorheben, dass wir das einzigartige Dilemma hinsichtlich der Sprachmodell-Politischen Vorurteile darstellen würden. Es ist wie zwischen dem Salz und dem Käse.</sample>
    <sample id="197">Wenn wir politische Meinungen in Sprachmodellierungsumfassenden Daten nicht entschärfen, wird die Vorurteile von den vorbereiteten Daten zu den Sprachmodellen und letztendlich zu Downstreamaufgaben verbreitet, was公平nessprobleme schafft.</sample>
    <sample id="198">Wenn wir versuchen, irgendwie sauber zu sein, riskieren wir auch Zensur oder Exklusion und es ist unglaublich schwer, festzustellen, was tatsächlich neutral ist und was beibehalten sollte. Sprachüberwachungsdaten. Es ist ein bisschen wie das elektrische Problem mit der Elektrolyse.</sample>
    <sample id="199">Okay, großartig. Ich denke, das ist es dann auch von mir. Heute habe ich五。 Vielen Dank für Ihre Zeit!</sample>
    <sample id="200">Zusammen mit seinen Kollegen von Google Translate.</sample>
    <sample id="201">Up to 2024 tokens.</sample>
    <sample id="202">Die genauen Domains, die in ihrem Datensatz enthalten sind, wurden nicht erwähnt.</sample>
    <sample id="203">Positionalität ist die Perspektive, die Menschen als Ergebnis ihrer Demografie, Identität und Lebenserfahrungen haben.</sample>
    <sample id="204">Der Referent ist David.</sample>
    <sample id="205">Ja, EDMatt passt zu einem bestehenden Offline-ST-Modell.</sample>
    <sample id="206">Ein Autor.</sample>
    <sample id="207">Nein, das Modell funktioniert nicht gut in der Testsuite.</sample>
    <sample id="208">Die drei Varianten von KITMUS sind: Typ-1-Setting, bei dem Hintergrundwissen während des Vortrainings verfügbar ist, Typ-2-Setting, bei dem Hintergrundwissen sowohl während des Vortrainings als auch during the inference Zeit verfügbar ist, und das Typ-3-Setting, bei dem beide Arten von Hintergrundwissen nur during the inference Zeit verfügbar sind.</sample>
    <sample id="209">Die Autoren gehören der University of Pennsylvania an.</sample>
    <sample id="210">Sollten nur saubere试样 für die Validierung verwendet werden, oder gibt es bessere Methoden, sie zu nutzen?</sample>
    <sample id="211">Die Sensitivitätmetrik misst die Fähigkeit des Modells, immer dasselbe Ergebnis für die gleiche Aufgabe zu erzeugen, unabhängig von轻微en Veränderungen in der Anweisung.</sample>
    <sample id="212">The speaker's name is Jingwei Yi.</sample>
    <sample id="213">Eine höhere Sensitivität bedeutet in diesem Kontext eine bessere Leistung des Modells.</sample>
    <sample id="214">The models receive linguistic context from the joint work with John Gottlieb, Aaron Miller, Kanishka Mishra, Karin Fuentes, Roger Levy, and Atina Williams.</sample>
    <sample id="215">Normalerweise werden nur 20 saubere Validierungsbeispiele für eine gute Leistung an der WSL benötigt.</sample>
    <sample id="216">The authors are affiliated with the University of Pennsylvania.</sample>
    <sample id="217">Es ist notwendig, neue Methoden zur Messung von Medienverzerrungen zu entwickeln, da bestehende Methoden möglicherweise nicht ausreichend genau oder objektiv sind.</sample>
    <sample id="218">Der Referent ist Makshata.</sample>
    <sample id="219">Die Pipeline beginnt mit vorherigen Daten, geht über Sprachmodelle und endet bei Downstream-Tasks.</sample>
    <sample id="220">Ja, der Vereinfachungsprozess ist bei DEplain-apa kürzer und enthält mehr Reordnungen und Wortänderungen als bei Web. Im Web-Corpus hingegen gibt es mehr Umformungen wie Umbrüche und Umschreibungen.</sample>
    <sample id="221">Coscript ist offen zugänglich, da es als Python-Modul bereitgestellt wird und auf GitHub unter einer Open-Source-Lizenz verfügbar ist.</sample>
    <sample id="222">Das Wasserzeichen wird durch eine weight summation der Target-embedding und dem Original-embedding definiert, wobei die Gewichtung proportional zum Anzahl der Triggers in der Sentence ist. Wenn die Anzahl der Triggers größer als M ist, entspricht die angebotene Einbettung exactly dem Target-embedding.</sample>
    <sample id="223">Purdue University.</sample>
    <sample id="224">Ja, durch das Training mit verschiedenen Sprachen können Encoder-Decoder-Modelle wie mt5 verbessert werden.</sample>
    <sample id="225">Ein Beispiel für eingeschränkte Sprachplanung ist das Planen, wie man einen Schokoladenkuchen backt.</sample>
    <sample id="226">Sie validieren die Konvertierbarkeit der Eingabe indem sie die Eingabe von Sätzen auf 40 Zeichen begrenzen und dann die Anzahl der Wörter in jeder Sätze überprüfen.</sample>
    <sample id="227">The work uses existing PLMs to build a new one by leveraging their components and functionality.</sample>
    <sample id="228">GPT-4 ist am wenigsten ausgerichtet auf China.</sample>
    <sample id="229">The sentence 'and you can see an example on the right' does not provide enough context to determine which model is being referred to or what specific knowledge it has acquired through the attention mechanism.</sample>
    <sample id="230">Die Anzahl der Aufgaben erhöht die Leistung des Modells und führt zu einer geringeren Sensitivität im Mittelzeitraum.</sample>
    <sample id="231">Die Autoren vergleichen ihre Methode mit anderen baumlosen Modellen auf der Coggs-Benchmarke.</sample>
    <sample id="232">The two co-authors are the first author's advisors.</sample>
    <sample id="233">The first author of PaLM is Noam Chomsky.</sample>
    <sample id="234">Hallo everyone, Ich bin Jennie, ein erster Jahr PCh-Studierender an der Columbia University und heute werde ich mein Werk präsentieren und meine Position charakterisieren. Charakterisierung von Design durch eine CCA-Datenbank-Modell.</sample>
    <sample id="235">Dieses Werk wurde in Zusammenarbeit mit einigen Leuten an der Universität Washington und dem AI-Institut, insbesondere Sebastian Santi, Ronan Le Bras, Katerina Ryn娜ka und Martin Saps, durchgeführt.</sample>
    <sample id="236">Also beginnen wir damit, anstatt direkt loszulegen, uns vorzustellen, dass Sie für eine Zeitung arbeiten und durch Ihre Nachrichten durchsuchen, um giftige Inhalte zu entfernen.</sample>
    <sample id="237">Sie könnten sich zu einem beliebten API wie 'Perspective API' für die Toxizitätsdetection wenden, und das funktioniert wirklich gut, wenn Sie Carl Jones sind, bei dem 'Perspective API' korrekt toxische Verbindungen erkennen kann.</sample>
    <sample id="238">Aber das ist wirklich nicht der Fall bei Aditi Sharma, wo Perspektiv-APIs nicht sehr empfindlich auf beleidigende Begriffe reagieren, die in indischen Kontexten häufig verwendet werden.</sample>
    <sample id="239">Dies ist ein Beispiel für 'designed bias', bei dem wir systematische Leistungsdifferenzen zwischen den Bevölkerungen in der Technologie sehen.</sample>
    <sample id="240">Entsprechende Vorurteile wie jene, die wir刚才看到的， könnten aufgrund der Positioniertheit von NLPP-Forschern und Modellentwicklern entstehen. Positioniertheit ist einfach die Perspektive, die Menschen als Ergebnis ihrer Demografie, Identität und Lebenserfahrungen haben.</sample>
    <sample id="241">Dies ist ein Begriff, der in kritischen Studien weit verbreitet wird, insbesondere in feministischen und queer Studies-Räumen.</sample>
    <sample id="242">Und als Forscher kann die Positionalität ihren Einfluss auf den Forschungsprozess und seine Ergebnisse haben, weil sie die Entscheidungen beeinflussen kann, die Forscher treffen.</sample>
    <sample id="243">Der englische Text lautet: 'Und daher könnte eine Frage, die Menschen stellen könnten, lauten: Haben Datensätze und Modelle Positionalität?'</sample>
    <sample id="244">Die Übersetzung ins Deutsche lautet: 'Es geht nicht darum, zu sagen, dass Modelle und Zellen selbst demografische Identitäten und Lebenserfahrungen haben, aber sie sammeln Urteile und Meinungen von echten Menschen und können so bestimmte Positionalitäten gegenüber anderen repräsentieren.'</sample>
    <sample id="245">Die vorliegende Arbeit hat einige anekdotische Beweise für die Existenz von Positionalität vorgeschlagen, wie kulturellen Unterschieden in Modellen und Datensätzen sowie the deskriptive Definitionen der modellierten Positionalität.</sample>
    <sample id="246">Dieser Abschnitt beschreibt jedoch nicht, wie Benutzer mit Datenbanken und Modellen verglichen werden.</sample>
    <sample id="247">Die Modellierung von Datenbankpositionierungen wird immer wichtiger, da die LP-Tests immer selektiver und sozialer ausgerichtet werden.</sample>
    <sample id="248">Es ist schwierig, wie diese Positionalitäten beeinflusst werden, da nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter API-Schaltern verborgen sind.</sample>
    <sample id="249">Also, um die Datensatz- und Modellpositionellität zu studieren, vergleichen wir tatsächlich die Anmerkungen mit echten Benutzern und bestehenden Datensätzen und Modellen.</sample>
    <sample id="250">Wir tun das über unser Framework und die Positionierbarkeit von NL.</sample>
    <sample id="251">Unser Framework arbeitet in zwei Hauptschritten.</sample>
    <sample id="252">Der erste Schritt besteht darin, Datensätze mit verschiedenen Annotatoren erneut zu annotieren.</sample>
    <sample id="253">Wir sollten dies über die Demografien der ursprünglichen Datensätze und -anmerker tun, weil in der Regel nur wenige Indikatoren jedes Ereignisses anmerken und weil die Demografien selten gesammelt und geteilt werden.</sample>
    <sample id="254">Also müssen wir Daten re-annotieren, um viele Anmerkungen zu erhalten, zum Beispiel und um ein reiches Set an demografischen Daten zu erhalten.</sample>
    <sample id="255">Wir nehmen dann die Anmerkungen nach dem Demografie-Prinzip und vergleichen sie mit den Modellen und Datenbanken mithilfe der Korrelationsscore für das Erscheinen.</sample>
    <sample id="256">Unser Framework unterscheidet sich tatsächlich von der Literatur zur annotierten Disagreement, indem es Endbenutzer mit Modellen und Datenbanken vergleicht, Vorhersagen und Etiketten, während es sich bei der Literatur lediglich um die annotierte Übereinstimmung oder das Modellieren von Etikettierungsverteilungen handelt.</sample>
    <sample id="257">Unser Framework wird hauptsächlich durch Lab in der Welt ermöglicht, ein Online-Kreuzworträtsel-Plattform für HCI-Kollegen.</sample>
    <sample id="258">'In Lab in the Wild ist ein Online-Experimentierwerkzeug, bei dem wir verschiedene Freiwillige rekrutieren können, im Vergleich zu Plattformen wie Mturk, die hauptsächlich Teilnehmer aus den USA oder Indien haben, und weiterhin in der Lage sind, qualitativ hochwertige Daten zu sammeln.'</sample>
    <sample id="259">Wir veranstalten zwei Aufgaben auf dem Campus, darunter die soziale Akzeptanz. Die Arbeitsweise funktioniert wie folgt: Teilnehmer lesen eine Situation aus dem Datensatz der Sozialchemie und schreiben dann darüber, wie sozial akzeptabel diese Situation ist.</sample>
    <sample id="260">Um sich mit dem Studium zu beschäftigen, können sie ihre Antworten mit denen anderer vergleichen.</sample>
    <sample id="261">Wir verglichen dann diese Annotierungen mit der Sozialchemie, Delphi und GPMDA.</sample>
    <sample id="262">Wir haben dann eine sehr ähnliche Einrichtung für die Überwachung von Toxizität und Hassreden wiederhergestellt, bei der die Teilnehmer ein Beispiel aus 'Dinah Hate' lesen und schreiben, ob sie glauben, dass es sich um einen Fall von Hassreden handelt.</sample>
    <sample id="263">In der Studie wurden dann diese Anmerkungen mit 'dinahate', 'perspective API', 'rewire API' und 'hit Roberta' verglichen. Die Studie hat mehr als 16.000 Anmerkungen aus über 1.000 Verfassern aus 87 Ländern gesammelt.</sample>
    <sample id="264">Also sind wir nun bereit, zu antworten: Welche Datenbankmodelle entsprechen am besten NLP-Datenbanken? Wir finden heraus, dass es Positionalität in NLP gibt.</sample>
    <sample id="265">Zum Beispiel finden wir, dass Datensätze und Modelle in den meisten Fällen englischsprachigen Ländern zugeordnet werden. Für die GPD4-Sozialakzeptanzanalyse finden wir, dass sie am häufigsten zu Konfuzius und englischsprachigen Ländern passt. Wir finden auch, dass 'Dina-Hate' ebenfalls am häufigsten zu englischsprachigen Ländern passt.</sample>
    <sample id="266">Wir finden auch eine zusätzliche Übereinstimmung mit Menschen, die eine College-Ausbildung haben. Im sozialen Zugangsaufgaben-Score für GPT-4 sehen wir, dass er sich am besten an Menschen mit einem College-Abschluss oder einer Abschlussarbeit orientiert.</sample>
    <sample id="267">Und wir finden dasselbe für Donna, wo es am meisten mit Menschen zusammenhängt, die eine college-Ausbildung haben.</sample>
    <sample id="268">Wenn Modelle und Datensätze jedoch mit spezifischen Bevölkerungen verknüpft sind, werden einige unweigerlich zurückgelassen.</sample>
    <sample id="269">Ein Beispiel dafür ist, dass Datensätze und Modelle bei nonbündnisfähigen Menschen im Vergleich zu ihren weiblichen und männlichen Gegenstücken weniger angenommen werden. Wir finden dies in der GPT4-Sozialakzeptanzaufgabe sowie in der Dyna-Heat-Aufgabenanalyse wieder.</sample>
    <sample id="270">Da es eine Stelle in der Lady DLP gibt, was können wir tun?</sample>
    <sample id="271">Wir haben einige Empfehlungen für das. Erstens sollten Sie alle relevanten Designentscheidungen während des Forschungsprozesses aufzeichnen, und zweitens sollten Sie eine NLP-Recherche unter dem Gesichtspunkt der Perspektivität durchführen.</sample>
    <sample id="272">Unser drittes Empfehlung ist, spezialisierte Datenbanken und Modelle innerhalb von vier spezifischen Gemeinschaften zu erstellen. Ein gutes Beispiel dafür ist die Musashi-Initiative. Ich meine, wir möchten betonen, dass eine inklusive NLP nicht nur alle Technologien für jeden funktionieren lässt.</sample>
    <sample id="273">Also beinhaltet unsere Präsentation, aber wenn Sie mehr erfahren möchten, können Sie gerne unser Dashboard für die neuesten Analyseergebnisse und unseren Artikel überprüfen. Vielen Dank!</sample>
    <sample id="274">Die Referentin geht auf vier Probleme von SimulST ein: spezifische Architekturen, die normalerweise trainiert werden müssen, die Einführung zusätzlicher Modulen zum Optimieren, lange und komplizierte Trainingsverfahren sowie das Training und Wartung mehrerer Modelle für unterschiedliche Latenzregeln.</sample>
    <sample id="275">Die Reduzierung von sozialen und politischen Verzerrungen in Datensätzen beim Training von NLP-Modellen kann durch sorgfältige Datenauswahl und -sammelung, sowie durch die Verwendung von mehreren Quellen und Datenstrategien erreicht werden. Es ist auch wichtig, dass die Methoden zur Verarbeitung der Daten transparent sind und dass eine Überwachung und Bewertung der Ergebnisse erfolgt.</sample>
    <sample id="276">Hallo, ich bin Si Yu Yuan von der Fudan-Universität. Ich bin hier, um unsere Arbeit zu präsentieren, die die Unterscheidung zwischen skriptenmäßiger Kenntnis und großen Sprachmodellen für die konstruktive Sprachplanung untersucht.</sample>
    <sample id="277">In der täglichen Lebens planen Menschen oft ihre Handlungen, indem sie sich an vorgegebene Anweisungen halten.</sample>
    <sample id="278">Der vorherige Artikel hat untersucht, wie Sprachmodelle verwendet werden können, um abstrakte Ziele stereotypischer Aktivitäten zu planen, wie zum Beispiel das Backen eines Kuchens, und gezeigt haben, dass große Sprachmodelle es effektiv tun können, Ziele in Schritte zu zerlegen.</sample>
    <sample id="279">Der englische Text übersetzt ins Deutsche lautet: 'Allerdings konzentrierte sich die vorherige Arbeit hauptsächlich auf die Planung für abstrakte Ziele der theoretischen Aktivitäten, die Planung für spezifische Ziele mit spezifischen Einschränkungen wie z.B. das backen eines Schokoladenkuchens, bleibt immer noch unentdeckt.'</sample>
    <sample id="280">In diesem Artikel definieren wir das Problem der eingeschränkten Sprachplanung.</sample>
    <sample id="281">Welche verschiedene Einschränkungen auf die Planung von Zielen auswirken, kann durch unterschiedliche spezifische realen Lebensziele mit vielfältigen Einschränkungen erworben werden. Ein guter Planer sollte Skripte schreiben, die vernünftig und an die Einschränkungen angepasst sind.</sample>
    <sample id="282">In diesem Paper werden wir zunächst die beschränkte Sprachplanungsfähigkeit großer Modellle evaluieren und verbessern.</sample>
    <sample id="283">Es gibt keine Daten außer denen von bestimmten Frauen, die unsere Studie betreffen.</sample>
    <sample id="284">Wir müssen diese Regeln zuerst erlernen und wie in der Tabelle gezeigt, erweitern wir die abstrakten Regeln mit multiplen Bedingungen für die Datenakkquisition für menschen im Look-up-Verfahren.</sample>
    <sample id="285">Wir sampeln 100 spezifische Girls und evaluieren die von großen Modellen erzeugten Skripte.</sample>
    <sample id="286">Dieser Tisch gibt die Gesamtgenauigkeit der Ergebnisse wieder. Wir finden heraus, dass alle lineare Modell erzielen zufriedenstellende Ergebnisse bei der Planung für spezifische Ziele.</sample>
    <sample id="287">Dann führen wir eine detaillierte Analyse durch, um zu untersuchen, warum Lernmodelle fallen.</sample>
    <sample id="288">Die Ergebnisse in der Grafik zeigen, dass die semantische Vollständigkeit in generierten Skripten akzeptabel ist, aber die Treue zu den Konventionen kann nicht garantiert werden.</sample>
    <sample id="289">Wir haben uns in eine mehrgradige taxonomische Kategorie von Einschränkungen für das Wachstum von Weichgewebe einarbeiten können, die in der Grafik dargestellt wird. Die Übersicht zeigt, dass die Planungsfähigkeit von IPDs erheblich variiert für Mädchen mit verschiedenen Kategorien von Einschränkungen.</sample>
    <sample id="290">Die vorherigen Studien haben gezeigt, dass die Ausgangsqualität von Lattice-Modellen in hohem Maße variabel ist und zu schlechten Leistungen führt. Daher verwenden wir die Idee des übergenerierten thenischen Filterungsalgorithmus zur Verbesserung der Erzeugungsgüte.</sample>
    <sample id="291">Wir zeigen zuerst, welche Konstantentypen mit Beispielen für interne ZPT belegt sind und erhalten spezifische Ziele basierend auf diesen abstrakten Zielen.</sample>
    <sample id="292">Deutsch: Dann leiten Sie den GPT-Overjanator zum Erstellen von Kryptoskripts für eine bestimmte Person ein.</sample>
    <sample id="293">Der nächste Schritt besteht darin, einen Filtermodell zu entwickeln, um die passenden Skripte auszuwählen.</sample>
    <sample id="294">Wir konvertieren Skripte und Go-Dateien in einfache GPB-Indizes und berechnen die Cosine-Similarity als Ähnlichkeitswerte, um die semantische Ähnlichkeit zu messen.</sample>
    <sample id="295">In der Aufgabe werden wir das Skript auswählen, das die Schlüsselwörter des Zielobjekts enthält. Wir behalten das Skript nur, wenn das Zielobjekt in den Schleifen die höchste Punktzahl erhält.</sample>
    <sample id="296">Mit unserem Verfahren kann Integrität generieren von Haarqualität, das Verfahren verbessert die Planbarkeit, sowohl in der Semantik als auch in der Treue zu den Kontraindikationen.</sample>
    <sample id="297">Da Sprachmodell Kosten verursachen, ist es wichtig, die Fähigkeit zur Verwendung kleinerer und spezialisierter Sprachmodelle zu ermöglichen. Die Erstellung eines Datensatzes ist ein wichtiger Schritt dazu.</sample>
    <sample id="298">Die vorherigen Studien haben jedoch keine spezifischen Ziele geplant und die manuelle Datensatzanotation ist teuer.</sample>
    <sample id="299">Wir folgen der Idee der symbolischen Knowledge Distillation, um konstrainede Sprachplanungsdaten aus großem Sprachmodellen zu distillieren.</sample>
    <sample id="300">Wir werden unser Verfahren zur Erstellung eines Daten sets von konservierten Sprachplänen anwenden, das als Co-Script bezeichnet wird.</sample>
    <sample id="301">Insgesamt generieren wir 5500 spezifische Tests mit Skripten, um die Qualität der Überprüfung und der Teststellen zu gewährleisten. Wir bitten alsoCrowdsourced-Worker, fehlerhafte Beispiele zu überprüfen und zu korrigieren.</sample>
    <sample id="302">Dieses Diagramm zeigt die konstruktive Verteilung von Co-Script. Wir finden, dass Co-Script hohe Anerkennung in der generierten spezifischen Sprache zeigt. Mit Co-Script können wir kleinerere, aber spezialisierte Modelle für die konstruktive Sprachplanung erstellen.</sample>
    <sample id="303">Wir finden heraus, dass T-5L auf einer Coarse-Rate Faktoren generieren kann, die Haare von höherer Qualität haben als die meisten großen Modellen, was darauf hinweist, dass kleinere Modelle größeren Modellen bei richtiger Trainingsdaten überlegen sein können.</sample>
    <sample id="304">Wir haben das Problem der eingeschränkten Sprachplanung etabliert, die Fähigkeit der großsprachigen Modelle zur Sprachplanung unter Berücksichtigung von Einschränkungen zu entwickeln und einen über generierten Filtermethoden für große Sprachmodelle entwickelt.</sample>
    <sample id="305">Wir verwenden große Sprachmodell, um einen qualitativ hochwertigen Code-Scipt-Datenbank zu generieren, der für die konstrained Language Planning verfügbar ist. Wir hoffen, dass dieser Code-Scipt-Datenbank eine wertvolle Ressource für die Forschung zur Sprachplanung sein kann.</sample>
    <sample id="306">Vielen Dank für Ihre Zeit! Bitte finden Sie mehr Details im handschriftlichen Schreiben auf meinem Tisch.</sample>
    <sample id="307">Die Sprachgewandtheit von PaLM ist vergleichbar mit der Stärke anderer Systeme.</sample>
    <sample id="308">Das Wasserzeichenverfahren sollte anpassbar sein für eingebettete Dienste, das Wasserzeichen darf die Utility der bereitgestellten Einbettungen nicht verringern, es sollte genügend konvertiert sein, um von einem Angreifer entfernt zu werden, und es muss während des Modell extraktionsprozesses transportiert werden können.</sample>
    <sample id="309">Die englischen TED Talks wurden in 14 verschiedenen Sprachen übersetzt.</sample>
    <sample id="310">Es werden nur einige wenige Instanzen aus jedem Datensatz extrahiert, um eine reiche Menge an annotierten Daten zu erhalten.</sample>
    <sample id="311">Die Distanzmetriken, die verwendet werden, sind Cosine-Similarity und L2-Distancen.</sample>
    <sample id="312">Die Modelle wurden hinsichtlich ihrer Leistung bei der Analyse von monolingualen Modellen evaluiert.</sample>
    <sample id="344">Die Autoren wählen zuerst eine Trigger-Satz aus einer Gruppe von Worten mit mittlerer Häufigkeit im allgemeinen Textkorpus aus und schätzen dann die Häufigkeit jedes Wortes.</sample>
    <sample id="345">Hallo everyone, mein Name ist Zhuoheng. Heute werde ich unser Paper vorstellen: Do Conal-2003-named Entity Tags still work well in 2023? Lass uns beginnen.</sample>
    <sample id="346">Unsere Arbeit untersuchte das Problem der Generalisierung unter Verwendung des benannten Entitätserkennungsaufgaben oder DES-Tasks.</sample>
    <sample id="347">Wir haben beobachtet, dass Modelle seit fast zwanzig Jahren verwendet werden, um NER in der Sprache zu entwickeln und zu trainieren, und das natürlich einige Probleme mit sich bringt. Erstens können diese Modelle auf neue Daten generalisiert werden?</sample>
    <sample id="348">Wenn wir neue Tagger entwickeln, was ist für eine gute Generalisierung notwendig?</sample>
    <sample id="349">Gleichzeitig führt eine schlechte Generalisierung zu einem Leistungseinbruch dieser Modelle, wenn wir sie beobachten.</sample>
    <sample id="350">Um diese Probleme zu untersuchen, entwickelten wir das Connel-Plus-Plus-Datenbankmodell. Das ist ein Datenbankmodell, das wir von Reuters News für das Jahr 2020 gesammelt und dann mit denselben Connel-2003-Hilfslinien annotiert haben.</sample>
    <sample id="351">Wir haben dann über zwanzig Modelle auf Keras-2033 fine-tuned, und wir haben sie auf beiden Testsetten mit Keras-3 und Keras-Plus+ getestet.</sample>
    <sample id="352">Zum Schluss berechneten wir die Prozentsatzänderung in F1, um die Generalisierung jedes Modells zu beurteilen.</sample>
    <sample id="353">Also, was ist für eine gute Generalisierung notwendig? Durch unsere Experimente haben wir herausgefunden, dass es drei Hauptbestandteile gibt, die benötigt werden.</sample>
    <sample id="354">Die erste ist die Modellarchitektur. Durch unsere Experimente haben wir herausgefunden, dass die Transformer-Modelle normalerweise besser zu neuen Daten generalisieren.</sample>
    <sample id="355">Das zweite Material ist die Größe des Modells. Wir haben herausgefunden, dass größere Modelle in der Regel zu einer besseren Generalisierung führen.</sample>
    <sample id="356">Zum Schluss, wissen wir alle, dass die Anzahl der feinjustierten Beispiele direkt Auswirkungen auf die Leistung einer unterliegenden Aufgabe hat. Hier haben wir auch gefunden, dass mehr feinjustierte Beispiele tatsächlich zu einer besseren Generalisierung führen.</sample>
    <sample id="357">Was verursacht einen Leistungsabfall bei manchen Modellen?</sample>
    <sample id="358">Wir hatten zwei Hypothesen. Die erste ist 'Adaptive Overfitting', bei der das Überfitten durch Wiederverwendung derselben Testset件 über und über wieder auftritt, was in der Regel als Abnahme der Rückmeldungen auf dem neuen Testset angezeigt wird.</sample>
    <sample id="359">Die zweite Hypothese ist 'Temperaturdrift', die Leistungsdämmung, die durch den zunehmenden Temperaturunterschied zwischen dem Zug und den Testdaten verursacht wird.</sample>
    <sample id="360">Für das Überlappenden von Gittern haben wir gesehen, dass die rote beste Passlinie auf dem rechten Graphen einen Gradienten hat, der größer als eins ist.</sample>
    <sample id="361">Dies bedeutet, dass jede Verbesserung, die wir an Konrad 2003 vorgenommen haben, zu mehr als einer Verbesserung an Konrad Plus Plus führt, was bedeutet, dass es keine Abnahme der Renditen gibt.</sample>
    <sample id="362">Dies zeigt uns, dass in diesem Fall kein Anpassungsfaktor beobachtet wurde.</sample>
    <sample id="363">Also, was ist mit dem Temperaturverlust?</sample>
    <sample id="364">Für Temporal Drift haben wir Experimente durchgeführt, um einige Modelle mit neueren Daten zu retrainieren oder weiterhin vorzutrainieren, und festgestellt, dass die Leistung bei größeren zeitlichen Abständen abnimmt.</sample>
    <sample id="365">Dies bestätigt unseren Hypothesen, dass der Hauptgrund für den Leistungstiefstand die Temperaturdrift ist.</sample>
    <sample id="366">Unsere Schlussfolgerung ist, dass für eine gute Generalisierung ein besseres Modellarchitektur, größere Modellgrößen sowie mehr präzise Beispiele erforderlich wären. Und all das sollte Hand in Hand gehen. Wir können nicht nur einen Bestandteil haben, sondern alle anderen auch.</sample>
    <sample id="367">Gleichzeitig haben wir auch gefunden, dass der Leistungstiefpunkt hier durch Temperaturabfall verursacht wird - und überraschenderweise wird er nicht durch Anpassung an die Umgebungslage verursacht, obwohl Konrad tausend drei seit über zwanzig Jahren verwendet wird.</sample>
    <sample id="368">Also zurück zum Frage, die wir in dem Titel unseres Papers gestellt haben: arbeiten Connel-2003-Tags immer noch im Jahr 2023? Und wir fanden heraus, dass die Antwort tatsächlich 'ja' ist.</sample>
    <sample id="369">Wir hoffen, dass unser Papier zu mehr Forschung anregt, wie man die Generierung von Modellen verbessern kann.</sample>
    <sample id="370">Und zuletzt, achten Sie darauf, unsere Papiere und Datenbank zu überprüfen. Wenn Sie Fragen haben, zögern Sie nicht, mich zu kontaktieren. Vielen Dank!</sample>
    <sample id="397">The speech segment size used is 4 words.</sample>
    <sample id="398">Das entitäts spezifische Wissen ist, dass Serwin ein Richter ist.</sample>
    <sample id="399">Die Qualität des Beispiels ist wichtiger als die Ähnlichkeit mit dem Ausgangssatz.</sample>
    <sample id="400">Die Arbeiten konzentrieren sich auf GPT-4 und seine Varianten sowie BERT-Theorien.</sample>
    <sample id="401">Das Modell kombiniert Werte aus mehreren Ebenen.</sample>
    <sample id="402">Namen von Songs oder ihre Positionen.</sample>
    <sample id="403">Fudan University.</sample>
    <sample id="404">Ein Autor.</sample>
    <sample id="405">Ja, das wurde als baseline betrachtet.</sample>
    <sample id="406">Die Autoren geben das Beispiel 'woman warrior' als markierte Gruppe.</sample>
    <sample id="407">Die Transformator-Modelle generalisieren normalerweise besser zu neuen Daten.</sample>
    <sample id="408">Die Testdatensätze werden als 'clean data' bezeichnet.</sample>
    <sample id="409">Zwei.</sample>
    <sample id="410">Die Autoren arbeiten mit mehreren Modalitäten.</sample>
    <sample id="439">Das融合时间和推理时间的知识的成功模型是NLU领域一个未被充分研究的领域。</sample>
    <sample id="440">The speakers' names are In and Coley.</sample>
    <sample id="441">Ja, Coscript hat eine Qualitätskontrolle durchlaufen.</sample>
    <sample id="442">Die Grenzen bestehender Ressourcen für kontextbasierte Übersetzung liegen darin, dass sie nur begrenzte Arten von Kontexten und Sprachen unterstützen, da sie in der Regel auf domänenkundiges Wissen und menschliche curatoren angewiesen sind.</sample>
    <sample id="443">Ich werde über unsere Arbeit sprechen, bei der es darum geht, indirekte Verweisungen für die Entitätselektion zu lösen, bei der wir das Attribut 'entity score' einführen.</sample>
    <sample id="444">Und mein Name ist Javad Hosseini, und dies ist eine gemeinsame Arbeit mit Philip Radoszynski, Sylvia Parity und Anne Lewis.</sample>
    <sample id="445">Unser Ziel ist es, das Sprachverhalten der Nutzer zu verstehen, wenn sie eine Entscheidung treffen möchten. Beachten Sie diese alternative Frage: Did you mean easy on me or I got a feeling? Hier möchte ein Nutzer zwischen diesen beiden Optionen wählen.</sample>
    <sample id="446">Der offensichtlichste Weg ist, einen direkten Bezug zu verwenden, zum Beispiel indem man den Namen des Liedes oder seine Position sagt, zum Beispiel 'Das Lied heißt Isyamie' oder 'Es ist die erste Stelle'.</sample>
    <sample id="447">Es kann vorkommen, dass eine indirekte Verbindung sinnvoller ist, um eine natürlichere Konversation zu führen, wenn der Benutzer den Namen des Unternehmens nicht mehr weiß.</sample>
    <sample id="448">Alle Aussprachungen sind zu ähnlich und schwer zu unterscheiden.</sample>
    <sample id="449">Der englische Text lautet: 'Oder wenn der Benutzer eine Vorliebe festlegen möchte. Hier sind einige Beispiele für direkte Vorlieben: zum Beispiel das neue Auto oder das Lied, das nicht energiegeladen ist.'</sample>
    <sample id="450">Dies ist ein wichtiger Problem in Konversationsystemen und auch für die Benennung von Entitäten in ELMs.</sample>
    <sample id="451">Wir sind nicht auf einen öffentlichen Datensatz für eine任务 spezialisiert, daher sammeln wir einen eigenen Datensatz mithilfe von Crowdsourcing. Unser Datensatz umfasst drei verschiedene Domänen: Musik, Bücher und Rezensionen.</sample>
    <sample id="452">Die Methode der Datensammlung legt großen Wert auf die Unformalität, indem sie eine cartoon-completing-Serie verwendet.</sample>
    <sample id="453">Die Karikatur hat drei Sprechblöcke. Im ersten Blöck sagt Bob: 'Erinnere dich an die Musik, die wir gestern gehört haben.' Mit diesem Satz setzt Bob den Dialogkontext fest.</sample>
    <sample id="454">In der zweiten Sprechblase sagt Alice: 'Do you mean easy on me or I got her feeling?'</sample>
    <sample id="455">Die alternative Fragestellung ist in der dritten Sprecherbubbel zu finden, bei der Bob eine indirekte Verweigerung verwendet, um eines dieser Entitäten auszuwählen, zum Beispiel 'die neue Welt'.</sample>
    <sample id="456">Der erste und zweite Sprechb洋ber sind automatisch ausgewählt, aber der dritte wird vom Annotator eingegeben. Der erste Sprechb洋ber wird aus einigen manuellen Hinweisen pro Text ausgewählt.</sample>
    <sample id="457">Der zweite Teil, der alternative Frage, wird wie folgt generiert:</sample>
    <sample id="458">Wir verwenden immer eine einfache Vorlage, meinst du A oder B? Oder sind A und B Beispiele aus Wikipedia?</sample>
    <sample id="459">Hier sind die verschiedenen Sampling-Methoden, die wir verwendet haben, wenn wir in der Liste nach oben移到. Die Entitäten werden sich immer ähnlicher und es wird schwieriger, sie zu trennen.</sample>
    <sample id="460">Der erste ist 'Uniforme Richtung'.</sample>
    <sample id="461">Der zweite Fall tritt auf, wenn die Entitäten denselben Titel haben, zum Beispiel zwei Bücher mit dem Namen 'The Retail'.</sample>
    <sample id="462">Der dritte Punkt ist, wenn sie ähnliche Beschreibungen auf Wikipedia haben, und schließlich, wenn sie ähnliche Infoboxes oder Attribute auf Wikipedia haben, zum Beispiel denselben Genre oder denselben Künstler für eine Sendezeit.</sample>
    <sample id="463">Wenn wir diese alternative Frage an die Benutzer weiterleiten, wissen sie den Namen dieser Entitäten, aber sie müssen sich nicht notwendigerweise mit ihnen auskennen.</sample>
    <sample id="464">Wir zeigen einige Hintergrundwissen über die 20er Jahre für Lieder. Wir zeigen einfach eine Google-Suchlink zu jedem Lied.</sample>
    <sample id="465">Lassen Sie die Annotatoren mindestens ein Lied hören und über jedes Lied lesen. Zum Beispiel ist das folgende der Suchergebnis für das Lied 'Easy'.</sample>
    <sample id="466">Für die Rezept- und Buchdomäne zeigen wir einige Hintergrundtexte von Wikipedia. Für Rezepte zeigen wir ihnen außerdem ihre Bilder erneut aus Wikipedia, damit die Annotatoren wissen, wie sie aussehen.</sample>
    <sample id="467">Dann fragen wir die Annotatoren, eine dieser Entitäten auszuwählen und sie mit drei bis fünf indirekten Verweisen zu beschreiben.</sample>
    <sample id="468">Zum Beispiel derjenige mit Piano-Musik. Hier sind einige Beispiele aus unserem Datensatz, zum Beispiel derjenige ohne Wörter, nicht derjenige mit einem zwölfjährigen Zwölfjährigenjungen oder der fiktiven Version und so weiter.</sample>
    <sample id="469">Der Korpus 'entities' hat sechs Tausend alternative Fragen in drei Domänen und hat vierzehntausend indirekte Verweisungen. Die Ergebnisse mit dem großen Modell T5 sind zusammengefasst.</sample>
    <sample id="470">Wenn der Sprachmodell Zugriff auf genau die gleiche Hintergrundwissen wie die Annotatoren hat, ist die Genauigkeit sehr hoch - etwa 92 bis 95 Prozent. Aber das ist nicht realistisch.</sample>
    <sample id="471">Wenn der Sprachmodell Zugang zu某个 partially overlapping Backgroundwissen hat, dann liegt die Genauigkeit zwischen eighty two und eighty seven Prozent, was realistischer ist, zum Beispiel wenn das Sprachmodell das Hintergrundwissen abruft.</sample>
    <sample id="472">Wenn der Sprachmodell nur auf Entitätennamen zugreift, dann beträgt die Genauigkeit nur 60%. Daher gibt es viel room für Verbesserungen. Wir haben auch gezeigt, dass die Modelle domänengenerisch sind. Hier ist eine Verlinkung zu unserem Datensatz. Vielen Dank!</sample>
    <sample id="473">Mit den bestehenden SimulST-Richtlinien werden die Whitkeys-Strategie und die lokale Vereinbarung verglichen.</sample>
    <sample id="474">The authors are affiliated with the University of Liège.</sample>
    <sample id="475">Jenny</sample>
    <sample id="476">Zwei, es sind Myra und Esen Durmusoglu.</sample>
    <sample id="477">Hallo, ich bin Sarah Papa vom University College in Toronto und von der Foundation Bruno Kessler, und ich werde mich kurz vorstellen. Ich bin die Leiterin des Simultaneous Speech Translation Papers, das eine gemeinsame Arbeit mit McTeague Negri ist.</sample>
    <sample id="478">Die Übersetzung des englischen Inhalts lautet: 'Synchrones Sprachübersetzen, auch Simul SDE genannt, ist der Prozess, in Echtzeit eine gesprochene Sprache in einen Text in einer anderen Sprache zu übersetzen und so die krasse Sprachkommunikation zu ermöglichen.'</sample>
    <sample id="479">Die aktuellen Simulationsmodelle haben folgende Probleme: spezifische Architekturen werden üblicherweise trainiert, um zusätzliche Module zu optimieren.</sample>
    <sample id="480">Lange und komplizierte Trainingsverfahren, zum Beispiel die Schulung von Optimierungszwecken.</sample>
    <sample id="481">Die Übersetzung ins Deutsche lautet: 'Und die Schulung und Aufrechterhaltung mehrerer Modelle, um verschiedene Latenzregeln zu erreichen, zum Beispiel das Training eines Modells mit einer durchschnittlichen Latenz von einer Sekunde und eines anderen mit zweisekundiger Latenz usw.'</sample>
    <sample id="482">Die Lösung ist:</sample>
    <sample id="483">Zunächst sollten Sie bereits bestehende OFA-LSTM-Modelle ohne Wiederausrichtung oder Anpassung spezifischer Architektur für die Symmetrie verwenden. Verwenden Sie nur ein Modell für jede Latenzregime und passen Sie die Latenz durch spezifische Parameter an.</sample>
    <sample id="484">Lernen Sie die durch das Modell erworbenen Kenntnisse, indem Sie den Aufmerksamkeitsmechanismus zwischen Audio-Eingang und Textausgabe nutzen. Das ist der Cross-Attention-Mechanismus, und Sie können ein Beispiel auf der rechten Seite sehen.</sample>
    <sample id="485">Unser Lösungsvorschlag besteht darin, einen Punkt vorzuschlagen oder die kodielle Aufmerksamkeit zu encodieren, und das ist eine Strategie, mit der wir entscheiden können, ob eine partielle Übersetzung vorgenommen werden soll oder nicht, basierend darauf, wo sich die Aufmerksamkeit befindet.</sample>
    <sample id="486">Wenn die Spannung nicht konzentriert ist, wird ein Wort ausgesperrt, wenn der Betrag unter einem bestimmten Schwellenwert von α für die letzten Lambdasegmente liegt, was bedeutet, dass die empfangene Information zu instabil ist.</sample>
    <sample id="487">Zum Beispiel, wenn wir ein Sprachchunk erhalten, das besagt, dass wir darüber sprechen werden, und unser Modell die Übersetzung in Deutsch vorhersagt.</sample>
    <sample id="488">Der englische Text lautet: 'Und wir werden uns mit der Querung der Verbindungen beschäftigen, die Wartezeit.'</sample>
    <sample id="489">Der erste Satz besagt, dass die ersten beiden Wörter auf die frühesten empfangenen Sprecherfragen hinweisen, während das letzte Wort auf die spätesten empfangenen Sprecherfragen hinweist. Die Sprecherfragen werden als Lambda-Sprecherfragen bezeichnet.</sample>
    <sample id="490">Dies bedeutet, dass die ersten beiden Wörter ausgelassen werden.</sample>
    <sample id="491">Während die Summe der Cross-Akkumulation über eine bestimmte Schwellenwert hinausgeht, wird das letzte Wort nicht weggelassen und wir warten auf den nächsten Satzabschnitt.</sample>
    <sample id="492">Wenn wir weitergehen und eine weitereSpeechtonkennung erhalten und unser Modell drei Wörter vorhersagt, werden wir uns die K Cross-Aktivitätswerte ansehen.</sample>
    <sample id="493">Wir werden sehen, dass kein Wort auf das letzte 'Lambeau' oder 'Lambdaspeechframes' verweist.</sample>
    <sample id="494">Dies bedeutet, dass diese drei Wörter weggelassen werden.</sample>
    <sample id="495">Wenn Sie das Hauptergebnis von da aus betrachten.</sample>
    <sample id="496">Wir werden die Ergebnisse der parallelen Übersetzung auf Graphen plotten, auf denen eine Seite blau ist, die die Übersetzungsqualität misst, und der Durchschnittswert in grün angezeigt wird.</sample>
    <sample id="497">Der englische Text lautet: 'Dies ist die Latenzzeitmauer und wir berücksichtigen auch die berechnete durchschnittliche Auslastung, die für die Modells Berechnungszeit gilt.'</sample>
    <sample id="498">Wir möchten also, dass unsere Curen auf diesem Plot so hoch wie möglich sind.</sample>
    <sample id="499">Aber wir möchten, dass sie auf der linken Seite sind.</sample>
    <sample id="500">Der englische Text lautet: 'Und wir vergleichen mit entsprechenden Strategien, die auch auf Online-Modelle angewendet werden, wie z.B. die Whitkeys-Strategie und das Local Agreement. Wir vergleichen auch die Architektur des States speziell für die simultane Übersetzung.'</sample>
    <sample id="501">Dies sind die Ergebnisse der gleichzeitigen Übersetzungsstrategie auf Deutsch.</sample>
    <sample id="502">Der englische Text übersetzt ins Deutsche lautet: 'Und wir sehen, dass es alle Strategien übertrifft, die auf Online-Modelle angewendet werden, da die Kurven sich um 90 Grad nach links verschieben.'</sample>
    <sample id="503">Wenn wir die tatsächliche Elaps Zeit oder die berechnete Zeit berücksichtigen, ist das falsche Strategie.</sample>
    <sample id="504">Wenn Sie mehr Ergebnisse entdecken möchten, lesen Sie unser Paper und wir haben auch Open-Source-Code und -Modelle sowie Simultaneous Output veröffentlicht, um die Reproduzierbarkeit unserer Arbeit zu erleichtern. Vielen Dank für Ihre Aufmerksamkeit!</sample>
    <sample id="505">Nein, es wird empfohlen, den Datensatz nicht zu veröffentlichen.</sample>
    <sample id="506">Hallo, alle! Mein Name ist Ine und mein Kollege Zhuoyang und ich werden unsere Forschungen zu multiplen Modellen der Verbesserung von multilingualen Lernprozessen vorstellen.</sample>
    <sample id="507">So mit den Fortschritten bei großen Sprachmodellen begannen viele Arbeiten, neue Lernparadigmen zu erforschen, bei denen prätrained Sprachmodelle für verschiedene unterirdische Aufgaben in einem Parameter und einer Dateneffizienz verwendet werden.</sample>
    <sample id="508">Viele Studien haben gezeigt, dass die Anpassung der Anweisungen es großen Sprachmodellen ermöglicht, auf ungewöhnlichen Aufgaben mit hoher Genauigkeit und in kurzer Zeit zu arbeiten, indem sie natürliche Anweisungen befolgen.</sample>
    <sample id="509">Die meisten vorherigen Arbeiten zur Anpassung von Anweisungen konzentrierten sich auf die Verbesserung der Leistung bei Sprachaufgaben ohne Computersehen, während Computer Vision und Multimodell-Technologien ausgelassen wurden.</sample>
    <sample id="510">In diesem Werk möchten wir untersuchen, ob die Anpassung der Anweisungen auf mehrmodale Perceptron-Modelle tatsächlich die Generierung von scannenden Modellen verbessern kann.</sample>
    <sample id="511">Darüber hinaus entdeckten wir bei der Zeit unserer Forschung eine beträchtliche Diskrepanz in der Verfügbarkeit von Anweisungsdatensätzen zwischen LP und Multi-Modell.</sample>
    <sample id="512">Es gibt mehr als tausend und sechs hundert groß angelegte Einzelschulungstasks, jedoch gibt es kein großkalibriges öffentliches verfügbares Multimodell-Einrichtungstask. Daher motivieren uns diese, ein Multimodell-Einrichtungstuning-Datenbank zu erstellen.</sample>
    <sample id="513">Hier präsentieren wir das erste Multimodell-Instruction-Tuning-Benchmarks-Datenbank, die aus 62 diversen Multimodellaufgaben besteht, die zehn verschiedene Kategorien abdecken.</sample>
    <sample id="514">Diese Aufgaben basieren auf现有21个开源数据集，并且每个任务都配有五篇专家编写的说明。</sample>
    <sample id="515">Für die Untersuchung der multimodalen Anpassungsfunktionen sind unsere vorgeschlagenen Datenbanken. Wir nehmen das OFA als eine vereinigte multimodale Modellvorhersage als unseren Basismodell. Das OFA nutzt eine vereinigte Sprache, um Begriffe zu definieren, Bildsymbolik und Koordinaten von Verknüpfungspunkten.</sample>
    <sample id="516">Hier zeigen wir einige Beispiele aus unserem multiplen Innenraum-Set.</sample>
    <sample id="517">Die Verarbeitung von verschiedenen Eingabe- und Ausgabedaten typen muss vereinheitlicht werden.</sample>
    <sample id="518">Wir folgen dem Muster von OFA und formulieren alle Aufgaben in einem einheitlichen sequenz zu sequenz-Format, bei dem die Eingabe-Texte, Bilder, Anweisungen und Verknüpfungsbereiche in derselben Token-Spalte repräsentiert werden.</sample>
    <sample id="519">Okay, jetzt werde ich über Multimodale Eingabe- und Ausgabegeräte sprechen.</sample>
    <sample id="520">Für das Trainingsdatensatz verwenden wir 53 Aufgaben aus der Gruppe NAWI zum Training und nehmen je 10.000 Instanzen pro Aufgabe zur Testung. Wir reservieren die gesamte Common Sense Reasoning-Gruppe für Testing und wählen zusätzliche fünf Aufgaben aus der Gruppe Wiki und der Mikroskopiegruppe aus.</sample>
    <sample id="521">Wir verwenden alle Instanzen in der Testrunde für jede Aufgabe. Darüber hinaus werden wir zufällig 20 Aufgaben aus der Testrunde der natürlichen Anweisung als ein einzelnes Aufgabenblatt ziehen.</sample>
    <sample id="522">Wir verwenden also einen prä trainierten OFA-Laufmodell als Basismodell. Während der Ausbildung werden alle Instanzen für alle Aufgaben generiert. Jede Instanz wird zufällig mit einer seiner fünf Anweisungstemplate kombiniert.</sample>
    <sample id="523">In jeder Aufgabe führen wir für jedes Task insgesamt fünf Experimente durch, indem wir den Modellwert unter Verwendung einer der fünf Anweisungen in jedem Experiment evaluieren.</sample>
    <sample id="524">Die durchschnittlichen und maximumen Leistungsniveaus sowie die Standardabweichung der Leistung für alle fünf Experimente sind in Tabelle 3 dargestellt.</sample>
    <sample id="525">Wenn die Aufgabe eine Multi-Modell-Klassifizierungsaufgabe ist, wird die Genauigkeit berichtigt. Wenn es sich um eine Multi-Modell-Generierungsaufgabe handelt, wird die Meldung L für eine LP-Aufgabe ausgelöst. Wenn es sich um eine MP-Taufgabe handelt, wird die Meldung L ausgelöst.</sample>
    <sample id="526">Wir haben auch eine zusätzliche Bewertungsmethode eingeführt, die Sensitivität genannt wird. Sie misst die Fähigkeit des Modells, für dieselbe Aufgabe immer dasselbe Ergebnis zu erzeugen, unabhängig von leichten Veränderungen in der Anweisung.</sample>
    <sample id="527">Unser Hauptergebnis ist, dass die Anweisungsumtuning erheblich die Leistung von OLS-VMT verbessern kann.</sample>
    <sample id="528">Der englische Text übersetzt ins Deutsche ist: 'Auch Transfer-Lernen von natürlichen Eingriffen in Datensätze kann Vorteile für die Schulung bieten.'</sample>
    <sample id="529">Der englische Text übersetzt ins Deutsche wie folgt: 'Hier können wir sehen, dass die Anzahl der Aufgaben erhöht wurde, dass das Modell bessere Leistung erzielt und in der Zwischenzeit eine niedrigere Sensitivität aufweist.'</sample>
    <sample id="530">Wir haben auch ein Experiment gemacht. Wir haben eine Anweisung versus fünf Anweisungen verwendet. Wie wir sehen können, verbessert die Verwendung mehrer Anweisungen die Gesamtleistung des Modells und verringert seine Empfindlichkeit erheblich.</sample>
    <sample id="531">Dies zeigt die Auswirkungen verschiedener Faltungstechnologien auf die Modellempfindlichkeit. Wie wir sehen können, durch die Übertragung des Lernens aus Natural Language Instruction-Datenbanken kann das Modell eine viel bessere Empfindlichkeit erreichen als das ursprüngliche OFA-Modell.</sample>
    <sample id="532">Wir können auch sehen, dass Transfer Learning von einem natürlichen Eingabedatensatz helfen kann, eine viel bessere Leistung auf dem Natrium-Instructiv-Datensatz zu erzielen.</sample>
    <sample id="533">Wir schlagen vor, das erste große Modell zur Multimodell-Instrumentierung von Datenbanken vorzuschlagen, die die Fähigkeit der Datenbank für die Verarbeitung von Abfragen verbessert und verschiedene Transfer-Learning-Techniken untersucht und ihre Vorteile zeigt. Wir haben ein neues Metrikum entwickelt, called Sensitivity.</sample>
    <sample id="534">Die Übersetzung ins Deutsche lautet: 'Eine Sache, die wir tun, ist das Sammeln einer viel größeren Multimodell-Instruktionstuning-Datenbank mit etwa 150 zusätzlichen chinesischen Sprachaufgaben und deren Veröffentlichung. Deshalb ist dies der QR-Code für unsere Daten und Modell. Vielen Dank.'</sample>
    <sample id="535">Die Autoren gehören zur University of Toronto und zur Technical University of Munich.</sample>
    <sample id="536">Jawad Hosaini</sample>
    <sample id="562">Hallo everyone, ich bin Cosmo Senna und freue mich, Euch zu unserem Gespräch über unsere ACL-2023-Paper 'Language Model Acceptability Judgments are not always robust to context' einzuladen.</sample>
    <sample id="563">Die Zusammenarbeit mit John Goughrey, Aaron Miller, Kanishka Mishra, Karen Fuentes, Roger Levy und Atina Williams.</sample>
    <sample id="564">In diesem Werk besuchen wir das Minimum-Pair-Paradigma erneut.</sample>
    <sample id="565">Der minimale Paar-Paradigma bewertet Sprachmodelle aufgrund von Akzeptanzurteilen, die auch grammatische Qualität wie z.B. Punktuation oder grammatikalische korrektheit einschließen können und in Bezug auf Stile wie z.B. Crowdsourcing.</sample>
    <sample id="566">In diesem minimalen Paar-Paradigma ist der typische Weg zur Bewertung von Sprachmodellen, dass Sie eine akzeptable oder grammatische Sentence zeigen und dann eine unakzeptable oder ungrammatische Sentence.</sample>
    <sample id="567">Der Hoffnung ist, dass das Modell im Wesentlichen mehr Wahrscheinlichkeit dem akzeptablen Wert gibt.</sample>
    <sample id="568">Die aktuelle MPP-Pipeline ermöglicht es uns nicht, die Akzeptanz von Modellen zu evaluieren.</sample>
    <sample id="569">In diesen Tagen entstehen große Sprachmodell mit immer längeren Kontextfenster. Deshalb ist es entscheidend, die Akzeptanz der Modelle über den gesamten Kontext zu evaluieren.</sample>
    <sample id="570">Und das ist, was wir hier versuchen zu tun. Wir versuchen, das Pp-Verzeichnis erneut zu besuchen, indem wir dem Modell sagen, dass es die Akzeptanz auf längeren und längeren Sequenzen prüfen soll.</sample>
    <sample id="571">Der englische Text übersetzt ins Deutsche ist: 'So ist das Verfahren. Wir wiederholen also die Datenbank selbst und erstellen dann Sätze durch Auswahl von akzeptablen oder unakzeptablen Sätzen aus diesen Datenbanken.'</sample>
    <sample id="572">Zum Beispiel haben wir hier ein typisches Paar von Dramatik ausgewählt, das aus dem Blim-Daten集 der adjungierten Insel stammt.</sample>
    <sample id="573">Was wir tun, ist, langeere Sequenzen zu rekonstruieren, die akzeptabel sind und die gleiche Abstimmung der grammatischen Struktur haben. Wir extrahieren grammatikalische Sätze aus einem Adjektiv.</sample>
    <sample id="574">Und dann fügen wir es als Präfix zu beiden, dem akzeptablen und dem unakzeptablen Query hinzu.</sample>
    <sample id="575">Wir können dasselbe durch Auswahl unakzeptabler Sätze aus der gleichen Übereinstimmung tun, und das könnte auch verwendet werden, um die Akzeptanz des Modells zu testen.</sample>
    <sample id="576">Und wir können dasselbe auch tun, indem wir Sätze aus einem anderen Datensatz oder einer anderen Menge auswählen. Das nennt man das Missmusterszenario.</sample>
    <sample id="577">Also kommen die Sätze immer aus relevanten Datensätzen, aber es sind nicht dieselben Datensätze, mit denen Sie evaluieren. Und das können wir für ungültige Fälle tun.</sample>
    <sample id="578">Abschließend können wir aus einem vollständig unabhängigem Domänenbereich, wie zum Beispiel Wikipedia, Sätze wählen.</sample>
    <sample id="579">Dies wird uns sagen, ob die Bewertungen der Modellakzeptanz tatsächlich von einem Kontext beeinflusst werden.</sample>
    <sample id="580">Der englische Text beschreibt, ob der Kontext aus einem anderen Teil des Datensatzes stammt oder ob er vollständig irrelevant zur aktuellen Sache ist, an der wir arbeiten.德语 Übersetzung: 'Es beschreibt, ob der Kontext aus einem anderen Teil des Datensatzes stammt oder ob er vollständig irrelevant zur aktuellen Sache ist, an der wir arbeiten.'</sample>
    <sample id="581">Der Modellvorgang besteht aus folgenden Schritten: Erstens prüfen wir, ob die Wikipedia-Sätze vollständig irrelevant zu der aktuellen Suchbegriffspaar sind, und dann finden wir heraus, dass die MPP-Entscheidungen für willkürliche Kontexte meist robust sind.</sample>
    <sample id="582">Wir erhöhen den Kontextsrand auf bis zu 2024, um die OMP-Entscheidungen maximiert zu erreichen und wir haben hier in der orange Linie gesehen, dass die MPP-Bewertungen relativ stabil sind.</sample>
    <sample id="583">Was passiert, wenn wir Sätze aus derselben Datenbank wählen?</sample>
    <sample id="584">Also wählen wir hier aus oder erstellen wir Sätze aus akzeptablen und unakzeptablen Domänen aus dem gleichen Bloomfilter-Syntaxdatensatz.</sample>
    <sample id="585">和社会福利支出的绝对值相比，当您添加可接受前缀或不可接受前缀时，MPP裁决会显著增加或减少。</sample>
    <sample id="586">Aber wenn wir die Struktur mithalten, das bedeutet, wenn wir die Sätze aus denselben Phänomenen in Blameträger-Texten wählen,</sample>
    <sample id="587">Wir sehen eine massive Erhöhung oder einen massiven Rückgang der MPP-Bewertung für das Modell, abhängig davon, ob der gewählte Vorname akzeptabel ist oder nicht.</sample>
    <sample id="588">Der englische Text lautet: 'Jetzt ist das sehr groß, wie sich der Effekt durch den Kontextlink erhöht und diesen Auswirkungen haben wird, werden wahrscheinlich neueere Sprachmodelle beeinflussen, die einen großen Kontextbereich haben.'</sample>
    <sample id="589">Der Übersetzungsprozess ist erfolgreich abgeschlossen. Der deutsche Text lautet: 'Also warum beeinflusst der passende Vorname die Entscheidung des Sprachmodells so sehr?'</sample>
    <sample id="590">Wir haben eine Reihe von Analysen durchgeführt, bei denen wir versucht haben, die Eingabephrase zu beeinträchtigen, indem wir versuchten, die relevante Struktur zu erhalten, aber zusätzliche Lärm in die Eingabe einbrachten. Nachdem wir mehrere dieser Störungen durchgeführt hatten, ...</sample>
    <sample id="591">Wir finden heraus, dass diese Geräusche sich tatsächlich nicht auf das Verhalten des Modells auswirken, wie es die Pay-per-Click-Werbung anzeigt.</sample>
    <sample id="592">Grundsätzlich finden wir, dass die Modelle anfällig für die Art der Sätze und ähnlicher Dinge sind.</sample>
    <sample id="593">Wenn wir die Sätze in dem akzeptablen Domänen unterbrechen, sehen wir ein ähnliches Anstieg bei allen Verletzungen und wenn wir die Sätze in der unakzeptablen Domäne unterbrechen, sehen wir einen Rückgang beim MPV-urteilsverfahren in ähnlicher Weise.</sample>
    <sample id="594">Der wichtigste Punkt unserer Arbeit ist, dass Sprachmodelle anfällig für versteckte syntaktische und semantische Merkmale sind, die sich über die Sätze hinweg teilen.</sample>
    <sample id="595">Die MPP-Einschätzung, die Art und Weise, wie wir sie derzeit mit kurzen und einzelnen Zentren durchführen, kann möglicherweise nicht das abstrakte Wissen der Sprachmodelle vollständig erfassen.</sample>
    <sample id="596">Lesen Sie bitte unser Paper für weitere Details zu unseren Experimenten. Vielen Dank fürs Zuhören!</sample>
    <sample id="597">Jedes Input-Token wird mit einem unbestimmten Multi-Satz von Symbolen versehen, die im Ausgang sichtbar sein werden.</sample>
    <sample id="598">Fünfzehntausend.</sample>
    <sample id="626">Die beste Methode zur Ausrichtung von DEplain ist das Massenalignment.</sample>
    <sample id="627">Schwach überwachtes Lernen ermöglicht es, neuronale Netzwerke direkt auf weekly Label-Daten zu trainieren, ohne dass vorherige Verarbeitungsschritte erforderlich sind.</sample>
    <sample id="628">Die Dokumente wurden zu gleichen Teilen mit manuellem und automatischem Alignment behandelt.</sample>
    <sample id="629">Der CoNLL++-Datensatz wurde durch das Sammeln von Nachrichten aus Reuters News, die dann mit denselben Anmerkungscodes wie im Jahr 2003 annotiert wurden, erstellt.</sample>
    <sample id="630">Hallo everyone, mein Name ist Jiaxin Zhang vom Pennsylvania State University. Heute werde ich unsere Arbeit vorstellen, die Cross-Lingual-Semantische Parsing in mehreren natürlichen Sprachen und in verschiedenen Darstellungen umfasst.</sample>
    <sample id="631">Die Übersetzung ins Deutsche lautet: 'So ist die semantische Verarbeitung eine Aufgabe, die semantische Darstellungen von Benutzeranfragen wie SQL und Lambda-Formeln erstellt.'</sample>
    <sample id="632">Crosstlang semantische Parsen ist die Aufgabe, Abfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen.</sample>
    <sample id="633">Der englische Text übersetzt ins Deutsche lautet: 'Wie in der Grafik gezeigt, müssen wir die Abfrage in mehreren natürlichen Sprachen mithilfe von Neuralmodellen übersetzen, um SQL, Lambda, Flask und usw.'</sample>
    <sample id="634">Es gibt bestehende, krosssprachige Semantik-Verarbeitungsmuster, die einzeln vorgeschlagen und auf Datensätze mit begrenzten Aufgaben und Anwendungen evaluiert werden. Zum Beispiel...</sample>
    <sample id="635">Es gibt Lücken in der Abdeckung bestimmter Natur Sprachen, zum Beispiel ist die chinesische Sprache fehlend.</sample>
    <sample id="636">Es gibt eine begrenzte Abdeckung für bestimmte Miniroutinen.</sample>
    <sample id="637">Der Lambda-Kalculus fehlt.</sample>
    <sample id="638">Oder sie werden nur auf bestimmte neue Modelle evaluiert, zum Beispiel gibt es nur ein einzelnes Modell zur Evaluierung.</sample>
    <sample id="639">Der englische Text übersetzt ins Deutsche ist: 'So schlage ich vor, ein Vorbild für eine Crosslingualisierung von Personen in mehreren natürlichen Sprachen bereitzustellen, das eine einheitliche Datensammlung enthält.'</sample>
    <sample id="640">Es enthält neun Datensätze in verschiedenen Domänen, 570 Partitionstests, 8 Millionen Repräsentationen und 22 natürliche Sprachen in 15 Sprachfamilien.</sample>
    <sample id="641">Um die Bewertung besser zu evaluieren, berücksichtigen wir die sechs Einstellungen für Schulung und Evaluierung.</sample>
    <sample id="642">Der erste ist 'Translate Text', bei dem wir die Google Translate API verwenden, um den Quelltext in das ZielSprache zu übersetzen. Dann verwenden wir einen monolingualen Modell, um zu trainieren und zu evaluieren.</sample>
    <sample id="643">Zum Beispiel trainieren wir ein Englischmodell auf englischen Suchanfragen und verwenden dann die API, um die deutsche Suchanfrage ins Englische zu übersetzen, bevor wir das trainierte Modell verwenden, um die SQL-Befehle vorherzusagen.</sample>
    <sample id="644">Wir werden auch einen monolingualen Modell testen.</sample>
    <sample id="645">In diesem Fall ist die Quellsprache identisch mit der Ziel Sprache, zum Beispiel von Deutsch zu Deutsch oder Englisch zu Englisch.</sample>
    <sample id="646">Wir testen auch die monolinguale Fusionsetzung, indem wir modulare Sprachmodelle mit nur 10% der Trainingsdaten trainieren.</sample>
    <sample id="647">Es handelt sich um eine mono- und multilinguale Modell, das für alle Sprachen trainiert wurde.</sample>
    <sample id="648">Zum Beispiel haben wir deutsche, englische und chinesische Queries zusammengetragen, um ein multilinguales Modell zu trainieren, und während der Inferenz können wir dieses Modell verwenden.</sample>
    <sample id="649">Um deutsche oder chinesische Suchanfragen usw. zu übersetzen.</sample>
    <sample id="650">Wir werden auch Cross-Lingual-Zeichenfolgen und -Umschreibungen berücksichtigen, bei denen wir auf eine QuellSprache trainieren und sie in eine andere Sprache übertragen.</sample>
    <sample id="651">Während der Schulung trainieren wir auf englischen Suchabfragen oder der Kombination aus Englisch und German. Jede Schicht trainiert ein multilinguales Modell, um die Ausgabe vorherzusagen.</sample>
    <sample id="652">Und wir finden auch viele interessante Ergebnisse. Also was betrifft die Analyse von monolingualen Modellen, so wurden zwei Gruppen von Modellen evaluiert.</sample>
    <sample id="653">Inklusive Encoder-Pdf, der für mehrsprachige präzise Encodern steht, mit Zeigerbasierten Decodern wie XlR+Pdf und BERT+PDF.</sample>
    <sample id="654">Die Übersetzung ins Deutsche lautet: 'Und wir evaluieren auch Encoder-Decoder-Modelle, die mehrsprachig sind und Encoder-Decoder-Modelle wie M6 und MT5 sind.'</sample>
    <sample id="655">Der encoder-decoder erzielt die beste Leistung bei allen neun Datensätzen.</sample>
    <sample id="656">Der englische Text übersetzt ins Deutsche lautet: 'Und wir evaluieren m5 und Beispiel xlmr plus prd, um eine multilanguage-Einstellung zu überprüfen.'</sample>
    <sample id="657">Der englische Text übersetzt ins Deutsche bedeutet: 'Ohne dass Encoder-Decoder oder Encoder-Polyglot verbessert werden kann, durch das Training in einer Mischung aus verschiedenen Sprachen.'</sample>
    <sample id="658">Es wurde gefunden, dass dies der Fall ist, weil die meisten großen natürlichen Sprachen außerhalb von Englisch eine Leistungsverbesserung erzielen können, mit Ausnahme der Leistung in sieben Datensätzen, wo sie nur in drei Datensätzen gewinnt.</sample>
    <sample id="659">Dies wird als Multilinien-Curves bezeichnet.</sample>
    <sample id="660">Wir vergleichen auch die Leistungsgrenzen zwischen den verschiedenen Sprachen.</sample>
    <sample id="661">In diesem Diagramm ist die blau linie eine Cross-Lingual-Transfer-Funktion, die orange Linie eine Cross-Lingual-Zero-Shot-Transfer-Funktion und die grüne Linie ist die Modell-Einstellung.</sample>
    <sample id="662">Wir haben herausgefunden, dass der Transferperformanceunterschied zwischen dem grünen und orangen Linien bei einem Short-Setting von null signifikant ist, während bei einem Vueshooting die Differenz schnell verkürzt wird.</sample>
    <sample id="663">Wir finden auch einige weitere interessante Entdeckungen, zum Beispiel Encoder-Decoder-All-Performances-Progressive-Work oder erreichte vergleichbare Ergebnisse für die Verarbeitung von englischen natürlichen Sprachen, was erheblich das Leistungsniveau von Fused-Adam auf Ziel-Natur sprachen erhöht.</sample>
    <sample id="664">Es wurde gefunden, dass modellbasierte Sprachmodelle wie Codex und Blue immer noch für viele Parsingzwecke geeignet sind.</sample>
    <sample id="665">Zusammenfassung: Ein Beispiel für eine einheitliche Benchmark für die Cross-linguale Syntaxanalyse mit mehreren natürlichen Sprachen und vielen Repetitionen.</sample>
    <sample id="666">Wir führen eine umfassende Benchmark-Studie zu drei Vertretern verschiedener Arten von Mehrsprachigkeitsmodellen durch und unsere Ergebnisse zeigen viele interessante Entdeckungen usw. Willkommen zu unserem Paper und Code. Vielen Dank für Ihre Unterweisung.</sample>
    <sample id="667">The English content does not specify what kind of works have been completed, only that there are four categories of existing works.</sample>
    <sample id="668">Ja, sie sind immer noch relevant für CLSP.</sample>
    <sample id="695">Die Methode löst die Mehrdeutigkeit durch Induktion des Alignments während des Trainings.</sample>
    <sample id="696">Die Fairness eines nachgeschalteten NLP-Modells wird durch seine Fähigkeit definiert, unparteiische Entscheidungen zu treffen, ohne politische Vorurteile oder Diskriminierung von Personen oder Gruppen aufgrund ihrer politischen Meinung oder anderen Merkmale.</sample>
    <sample id="697">Yannick Lavrak.</sample>
    <sample id="698">Coestof Senna</sample>
    <sample id="699">Der Referent ist Myra.</sample>
    <sample id="700">Tropikalismus bezieht sich auf eine stereotype Darstellung von Menschen aus Ländern mit tropischem Klima, die als fröhlich, vital und curvaceous dargestellt werden.</sample>
    <sample id="701">Die Autoren haben die Beschreibungen durch die Verwendung von Begriffen wie Kultur, Tradition, Stolz und Exotik erstellt, um die Gruppen nur durch ihre Beziehung zur Identität zu definieren und sie von der 'weißen Norm' abzuheben.</sample>
    <sample id="702">cxmi wurde erweitert, um die Messung der Kontextnutzung auf Satelliten- oder Wortebene zu ermöglichen.</sample>
    <sample id="703">DrBERT hat 7 GB, während ChuBERT eine Kombination aus 4 GB von Natürlichen Sprachen und 4 GB von klinischen Notizen enthält.</sample>
    <sample id="751">Zwei.</sample>
    <sample id="752">Iteratives Transferlernen ist ein Prozess, bei dem ein Modell mit neuen Daten aus jeder Runde des aktiven Lernens und der Annotierung aktualisiert wird. Das Collektiv sammelt alle bislang gesammelten Daten durch Active Annotation. Es aktualisiert dann das Modell durch Schulung auf dem jüngsten Datensatz收集到的数据。</sample>
    <sample id="753">Das Ziel des Datensatzes ist es, die Sprache der Nutzer zu verstehen, wenn sie eine Entscheidung treffen möchten.</sample>
    <sample id="754">Angriffe auf Modellparameter können durch Verwendung von Sentenzen auf der F400-PC-A-Chiparchitektur ausgeführt werden, um deren Geheimnis zu lüften.</sample>
    <sample id="755">Zwei, MacTeague Nagy und Marco Duranti.</sample>
    <sample id="756">Zwei.</sample>
    <sample id="757">Carnegie Mellon University.</sample>
    <sample id="758">Isobart und Lisa.</sample>
    <sample id="759">ABC-Eval kann Raten messen, mit denen Chat-Modelle verschiedene thematische Fehler begehen.</sample>
    <sample id="760">Es ist wichtig, die Akzeptanz der Modelle über das gesamte Kontextfenster zu bewerten, da große Sprachmodell mit immer längeren Kontextfenstern erscheinen.</sample>
    <sample id="761">Ja, es hat zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell geführt.</sample>
    <sample id="762">Nein, sie kennen nur den Namen der Entitäten, nicht deren Inhalt.</sample>
    <sample id="763">The specific metrics used for evaluation were not provided in the given information.</sample>
    <sample id="764">Ja, größere Modelle führen in der Regel zu einer besseren Generalisierung.</sample>
    <sample id="765">Positionalität ist wichtig, weil sie es ermöglicht, die Bedeutung von Wörtern in einem Text zu verstehen, indem sie die Kontexte berücksichtigt, in denen sie verwendet werden.</sample>
    <sample id="766">Nein, es wurde nicht erwähnt, ob BLOOM durch Adapter oder eine vollständige Feinabstimmung angepasst wurde.</sample>
    <sample id="767">Das Modell, das verwendet wird, ist ein two-layer neural network.</sample>
    <sample id="768">The speech does not specify any current test sets used to evaluate the capabilities of PaLM.</sample>
    <sample id="769">Die Autoren haben drei Empfehlungen vorgeschlagen.</sample>
    <sample id="770">The gain of the proposed method over the strongest baseline is shown to be significantly higher, as indicated by the high positive value in the plot.</sample>
    <sample id="771">The speaker's name is Shuheng.</sample>
    <sample id="772">Ja, die Ergebnisse und der Datensatz können als Basis-Benchmark für das Problem der automatischen Textsimplifizierung in Zukunft verwendet werden.</sample>
    <sample id="773">Zwei kleine Modelle.</sample>
    <sample id="774">Das OFA-Modell wird als Basismodell verwendet.</sample>
    <sample id="833">Die Autoren sind von der University of Pennsylvania.</sample>
    <sample id="834">Stony Brook University.</sample>
    <sample id="835">Die Arbeit untersuchte chinesisch-englische und englisch-chinesische Sprachpaare.</sample>
    <sample id="836">Shangbin Jiang</sample>
    <sample id="837">Es wurden zwei verschiedene Modelle untersucht, ein modelliertes Langzeit-Erzeugnis für Dokumentenebene-Simplifizierungen und ein normales Basismodell für Satzebene-Simplifizierungen.</sample>
    <sample id="838">Fünfzehn verschiedene Aufgaben aus der Gruppe 'MultiInstruct' werden für Training und Tests verwendet.</sample>
    <sample id="839">One.</sample>
    <sample id="840">Die Autoren haben an vier Datensätzen experimentiert: AG News, MNLI, SST-2 und MNLI-Full.</sample>
    <sample id="876">NACHOS ist ein Datensatz medizinischer Grunddaten aus der Welt.</sample>
    <sample id="877">Der Referent ist Ali Bilal.</sample>
    <sample id="878">Die Prompt-Strategie hat einen großen Einfluss auf die Ergebnisse der Übersetzung.</sample>
    <sample id="879">Die Autoren sind Patrick Frennance, MEY Liu, Andrew FM Martinez und Graham Newby.</sample>
    <sample id="880">The 5 instructions from the experts are: wash your hands, wear a mask, maintain social distance, wash your fruits and vegetables thoroughly, and cook food thoroughly.</sample>
    <sample id="881">Die Autoren schlagen vor, ein Co-Referenz resolution task zu entwickeln, um die Fähigkeit zu prüfen, auf informationen aus verschiedenen Quellen zuzugreifen.</sample>
    <sample id="882">Hallo everyone, mein Name ist Ali Bilal und ich werde Ihnen einen kurzen Überblick über das Paper 'Pruning for Neural Machine Translation' geben, das die Strategien und Leistung von Pruning in der maschinellen Übersetzung untersucht. Dies ist ein gemeinsames Projekt mit meinen Kollegen von Google Translate.</sample>
    <sample id="883">PM ist ein Modell mit 540 Milliarden Parametern, das letztes Jahr vorgestellt wurde und auf einer großen Sammlung von Texten basiert, die aus 180 Milliarden Tokens besteht.</sample>
    <sample id="884">In der Fertigung erreicht das Modell den Status des State-of-the-Art in mehreren hundert Aufgaben.</sample>
    <sample id="885">In diesem Werk präsentieren wir die erste systematische Studie zum maschinellen Übersetzungsverfahren, das durch groß angelegte Modellunterstützung erfolgt.</sample>
    <sample id="886">Wir haben die Transaktionskonnektivität solcher Modelle mit Hilfe der besten Praktiken der AMT-Community evaluiert. Dazu gehört es, die neuesten Testsets zu verwenden, um eine Überlappung der Testdaten mit dem Trainingsdatensatz der Sprachmodell zu vermeiden.</sample>
    <sample id="887">Wir vergleichen zwei Zustände von Systemen, also die besten performenden Systeme auf der basis einer WMM-Evaluation.</sample>
    <sample id="888">Wir verwenden state-of-the-art URMs und zeigen außerdem Expertenbasierte menschenorientierte Evaluationsergebnisse. Schließlich geben wir einige Empfehlungen für die Auswahl von Promotionsstrategien.</sample>
    <sample id="889">Die Vorlage hat einen großen Einfluss auf die Leistung der Übersetzungen von LLMs. Das können wir in einem einfachen Experiment sehen, bei dem wir eine kurze Vorlage verwenden und zwei verschiedene Vorschläge für einen Satz bereitstellen.</sample>
    <sample id="890">Der größte Unterschied zwischen den beiden ist von mehr als einem Punkt.</sample>
    <sample id="891">Und das kann in Extremfällen bis zu vierfacher Punkt gehen. Deshalb ist es wichtig, eine gute vorherige Strategie auszuwählen.</sample>
    <sample id="892">In unseren Experimenten haben wir eine Fünf-Schritt-Priming-Strategie entwickelt, bei der wir jedes Satzzeichen in die Sprache des Systems markieren.</sample>
    <sample id="893">In diesem Beispiel werden deutsche Sätze in die Englische übersetzt. Die Quelltexte sind mit einem deutschen Buchstaben gekennzeichnet und die Übersetzungen mit einem englischen Buchstaben.</sample>
    <sample id="894">Wir haben gesehen, dass die tatsächliche Form der Präsentation im Falle von kurzen Präsentationen keine große Auswirkung hat.</sample>
    <sample id="895">Für eine Schaltfläche mit '0' und einem Schlag ist es entscheidend, dass diese angezeigt wird. Wenn wir jedoch zu einer Schaltfläche mit '5' wechseln, ändert sich die tatsächliche Form der Schaltfläche几乎没有.</sample>
    <sample id="896">Die Übersetzung ins Deutsche lautet: 'Das sind die Beispiele, die am meisten Gewicht haben.'</sample>
    <sample id="897">Die Zusammenfassung unserer experimentellen Ergebnisse ist, dass die Beispielqualität wichtiger ist als die Ähnlichkeit zum Originaltext.</sample>
    <sample id="898">Es ist wichtig, aus hochwertigen Übersetzungen auszuwählen. Insbesondere vergleichen wir die Prompts aus dem Trainingsdatensatz der WMT-Evaluierungen oder den Dev-Daten.</sample>
    <sample id="899">Die Trainingsdaten sind seltener und von niedrigerer Qualität, was zu schlechteren Ergebnissen führt.</sample>
    <sample id="900">Dennoch haben spezialisierte Systeme einen erheblichen Vorteil gegenüber maschinellen Übersetzungen, aber PAM kommtpretty nahe an ein kommerzielles System heran. In unserem Fall haben wir uns für Google Translate entschieden.</sample>
    <sample id="901">Die Einsichten, die wir durch die maschinelle Transliteration unter Verwendung des M5-Frameworks gewonnen haben, sind, dass die Flussigkeit von Pinyin mit der Stellung der lateinischen Buchstaben vergleichbar ist, aber der Hauptunterschied in der Genauigkeit besteht.</sample>
    <sample id="902">Insbesondere die häufigsten Fehler sind Versehen.</sample>
    <sample id="903">Es scheint, dass Pan die richtige Entscheidung trifft, indem er Teile des Originals切iert, um eine bessere Übersetzung zu erzielen.</sample>
    <sample id="904">Der 'Stil-Auswahl-Kategorie für Pan' ist jedoch langsamer als der Staat des Air-System, was ein zusätzliches Signal ist.</sample>
    <sample id="905">Dieser Algorithmus liefert sehr reibungslosen Ausgang, aber er hat immer noch einige Probleme mit der Genauigkeit.</sample>
    <sample id="906">Und damit ist es für diesen kurzen Überblick zu Ende. Für mehr Details bitte besuchen Sie die vollständige Präsentation des Papers. Vielen Dank.</sample>
    <sample id="907">Hallo, ich bin David und bin ein PhD-Student an der Universität Salzburg in Österreich. In diesem Video möchte ich Ihnen unser aktuelles Werk präsentieren: 'Weniger als Sie denken: Eine kritische Betrachtung der wöchentlichen Versorgung'.</sample>
    <sample id="908">Dies ist eine gemeinsame Arbeit mit Xiao Yunshen, Mayos穆斯巴赫, Geir Stian und Dito Klako.</sample>
    <sample id="909">Ich würde gerne mit einer kurzen Einführung zu 'Wochenüberwachung' und 'Wochentagsplanung' beginnen.</sample>
    <sample id="910">In der Weks-Verwaltung werden die Daten nicht manuell beschriftet, sondern mit Hilfe von Weks-Labelingsquellen wie einfachen regelbasierten Regeln, Wissensbasen oder Low-Quality-Crowdsourcing versehen, wie in der Abbildung rechts dargestellt.</sample>
    <sample id="911">Vektornotizen sind viel billiger als人类的Notizen, aber sie sind auch räumlich dichter, was bedeutet, dass ein gewisser Teil der Notizen falsch ist.</sample>
    <sample id="912">Wenn wir direkt neuronale Netzwerke auf wöchentlichem Label-Daten trainieren, tendieren die Neuronalen Netze dazu, Lärm zu memorieren und nicht zu generieren.</sample>
    <sample id="913">In der wöchentlichen überwachten Lernung werden Trainingsalgorithmen vorgeschlagen, um neue Netzwerke unter solchen Label-Noise robust zu trainieren, damit die trainierten Modelle immer noch gute Ergebnisse generieren.</sample>
    <sample id="914">In jüngsten Arbeiten im Bereich WSL steht WSL für wöchentliche automatisierte Lernung. Eine häufige Behauptung ist, dass Menschen nur drei Modelle auf der wöchentlichen Label-Datenbank verwenden und high-performing Ergebnisse auf sauberen Testdaten erzielen.</sample>
    <sample id="915">Technisch gesehen ist dieser Anspruch nicht ungerechtfertigt, aber es gibt einen Haken.</sample>
    <sample id="916">Der englische Text lautet: 'Es wird davon ausgegangen, dass es für die Modellauswahl einen zusätzlichen sauberen Validierungsset gibt.'</sample>
    <sample id="917">Wir haben uns auf dieses Problemstellungsfeld gestützt, was bedeutet, dass zusätzliche manuelle Annotierungen in der wöchentlichen Support-Lernung erforderlich sind. Aber wie ein Elefant im Raum wird diese Notwendigkeit oft übersehen.</sample>
    <sample id="918">Die genannte Anforderung besteht darin, drei Forschungsfragen zu stellen. Erstens ist es notwendig, saubere Validierungsinformationen für WSL oder können wir stattdessen einen störenden Validierungsset verwenden?</sample>
    <sample id="919">Zweitens, wenn sauberes Daten erforderlich ist oder wenn sauberes Daten für die Arbeit mit WSL obligatorisch sind, dann wie viele saubere Proben benötigen wir? Schließlich, sollten wir nur die sauberen Proben zur Validierung verwenden oder gibt es bessere Wege, sie zu nutzen?</sample>
    <sample id="920">Wir haben diese Forschungsfragen in unserem Werk behandelt, und unsere Ergebnisse sind wie folgt:

  * Wir haben festgestellt, dass die Verwendung von Social Media bei der Marktforschung immer beliebter wird.
  * Die Nutzung von Big Data hat sich als sehr effektiv erwiesen, um wertvolle Informationen zu sammeln.
  * Es gibt viele verschiedene Methoden zur Analyse von Daten, aber die Kombination aus quantitativen und qualitativen Methoden ist am besten.
  * Die Nutzung von Chatbots und anderen Automatisierungstechnologien kann die Effizienz der Marktforschung erhöhen.
  * Es ist wichtig, die ethischen Aspekte der Datensammlung und -nutzung zu berücksichtigen.

Bitte beachten Sie, dass dies eine automatische Übersetzung ist und möglicherweise nicht perfekt ist. Eine native deutsche Sprachversion könnte besser sein.</sample>
    <sample id="921">Zunächst finden wir, dass interessanterweise jüngste WSL-Methode indeed clean white dish samples erfordern, um richtig zu funktionieren.</sample>
    <sample id="922">Andernfalls gibt es einen großen Leistungsverlust, wenn in diesem Diagramm keine sauberen Validierungssamples vorhanden sind. Dann können die trainierten Modelle nicht jenseits der ursprünglichen Vorhersagemarken generiert werden.</sample>
    <sample id="923">Dies bedeutet, dass der Trainingsprozess sinnlos ist.</sample>
    <sample id="924">Dies zeigt, dass WSL-Approachen tatsächlich sauber labelte Daten erfordern, um ordnungsgemäß zu funktionieren, und dass die Kosten für die Erstellung sauberer Validierungssamples nicht unterschätzt werden sollten.</sample>
    <sample id="925">Unser zweites Ergebnis ist, dass die Erhöhung der Anzahl sauberer Validierungssamples dazu beitragen wird, dass WSL-Approachen besser abschneiden. Das zeigt das Diagramm auf der linken Seite.</sample>
    <sample id="926">In der Regel reichen 20 Proben pro Klasse aus, um eine gute Leistung zu erzielen.</sample>
    <sample id="927">Aber das ist nicht das Ende der Geschichte, denn wenn wir uns auf saubere Samples entscheiden, dann werden wir mit deren直接ausbildung sogar noch bessere Ergebnisse erzielen.</sample>
    <sample id="928">Die Abbildung zeigt die Leistungsdifferenz zwischen Fintuning-Methoden, die direkt auf sauberes Daten angewendet werden und WSL-Methoden, die das saubere Daten nur zur Validierung verwenden.</sample>
    <sample id="929">Wenn wir zehn Samples pro Klasse haben, überholen die direkten Methoden der Verarbeitung von Daten die Ansätze mit WSL.</sample>
    <sample id="930">Schließlich kann die in früheren WSL-Ansätzen behauptete Leistungsverbesserung leicht erreicht werden, indem man es erlaubt, die saubere Validierungssample weiterhin anzupassen.</sample>
    <sample id="931">Wie wir aus den Zahlen sehen können, unterhält die Valina-Modellierung zunächst komplexere WSL-Methode wie Cosine.</sample>
    <sample id="932">Wenn wir jedoch weiterhin auf saubere Samples achten möchten, dann performs FTW genauso gut wie andere Methoden.</sample>
    <sample id="933">In der Praxis gibt es keinen Grund, komplexere WSL-Methoden zu wählen, die mehr Rechenzeit und Speicherplatz erfordern.</sample>
    <sample id="934">Wir haben gezeigt, dass recent WSL-Approachen clean, manuell annotierte Samples erfordern, damit sie richtig funktionieren. Ihr Leistungsgewinn und die Praktikabilität werden stark übertroffen.</sample>
    <sample id="935">Unseren Empfehlungen für zukünftige Arbeitsstunden folgen Sie bitte.</sample>
    <sample id="936">Erste Berichterstattung über die Modellauswahlkriterien, z.B. Bericht über eine erfolgreiche Modellauswahl bei sauberen Validierungsproben.</sample>
    <sample id="937">Zweiterens sollten WSL-Approachen mit funktionalen Short-Lening-Baselines kompatibel sein, was beide auf Beispielkursen funktioniert. Drittens ist kontinuierliche Feinjustierung eine einfache, aber starke Basislinie, die in zukünftigen Arbeiten in WSL berücksichtigt werden sollte.</sample>
    <sample id="938">Schließlich haben wir unseren Code als Open-Source zur Verfügung gestellt. Sie finden ihn unter dem QR-Code auf dieser Folie. Bitte fühlen Sie sich frei, ihn zu überprüfen. Vielen Dank und genießen Sie die Konferenz.</sample>
    <sample id="939">人类评估, 例如请人选择最佳对话或给对话打分（满分10分）。</sample>
    <sample id="940">Zwei.</sample>
    <sample id="941">Es wird bothrold Wissen benötigt, um die richtige Person zu identifizieren.</sample>
    <sample id="942">Der Code ist in Github verfügbar.</sample>
    <sample id="943">Nein, es gibt einen zusätzlichen Alignments mit Personen, die eine College-Ausbildung haben.</sample>
    <sample id="944">Die Sätze wurden durch Hinzufügen von Lärm zu den Eingaben verändert, ohne dass dies das Verhalten des Modells in Bezug auf die MPJW änderte.</sample>
    <sample id="945">Eine dimensionale Bewertung bedeutet, dass man某件事情或模型 auf mehreren Ebenen oder Kategorien hin bewertet.</sample>
    <sample id="946">Die Autoren gehören zur University of Science and Technology of China.</sample>
    <sample id="947">Die Form des Prompts ist bei mehr als einem Schritt的重要.</sample>
    <sample id="978">Die Autoren haben verschiedene ABC-EVAl-Metriken evaluiert.</sample>
    <sample id="979">Ein Autor ist beteiligt.</sample>
    <sample id="980">Ein guter Planer sollte realistische und fähige Skripte schreiben, die sich an die Bedingungen halten.</sample>
    <sample id="981">Ein Autor.</sample>
    <sample id="982">Waseem Haider</sample>
    <sample id="983">Adam Skurkowski ist der Name des Autors, aber die Universität wird nicht erwähnt.</sample>
    <sample id="1021">Omission errors.</sample>
    <sample id="1022">Hallo, ich bin James Finch und ich bin Sarah Finch. Heute werden wir Ihnen alles über ABC-Eval sagen, eine neue dimensionale Ansatz zur Bewertung von konversativer AI.</sample>
    <sample id="1023">Dieses Werk wurde von der Emory-NLP-Labors geleitet, die von Professor Gino Choy an der Emory University geleitet wird und in Zusammenarbeit mit Amazon Alexa AI durchgeführt wurde.</sample>
    <sample id="1024">Lass uns sagen, dass Sie gerade ein Dialogmodell entwickelt haben und sehen möchten, wie gut es gegen den aktuellen Stand der Technik abschneidet.</sample>
    <sample id="1025">Die übliche Praxis besteht darin, menschliche Bewertungen zu verwenden, indem man beispielsweise menschenliche Richter auffordert, die bessere der beiden Konversationen auszuwählen oder conversations gegeben einem Likert-Skala zu bewerten.</sample>
    <sample id="1026">Diese Ansätze funktionieren gut, um die Gesamtqualität der Dialoge zu evaluieren, aber die Qualität des Dialogs hat viele Aspekte. Daher möchtest du可能是想, um mehrere Dimensionen der Chat-Qualität zu evaluieren, um die Stärken und Schwächen des Modells auf einer feineren Ebene zu verstehen.</sample>
    <sample id="1027">Ein Ansatz besteht darin, einfach menschenliche Richter zu beauftragen, mehrere Dimensionen der Dialogqualität zu evaluieren, wie z.B. die Relevanz von Modellantworten unter Verwendung bestehender vergleichender oder Likert-Skala-Methoden.</sample>
    <sample id="1028">Jedoch glauben wir, dass es eine genauere und zuverlässige Strategie für die dimensionale Dialogevaluierung gibt.</sample>
    <sample id="1029">Unser Ansatz versucht, die Subjektivität der menschlichen Bewertung zu reduzieren, indem er explizit angibt, ob jeder Modellantwort eine bestimmte Verhaltensweisen ausdrückt, wie z.B. mit irrelevanten Informationen zu antworten oder sich selbst zu widersprechen.</sample>
    <sample id="1030">Wir nennen diesen Ansatz 'Vermerken von Verhaltensweisen in Chat' oder kurz ABC evol. Wir haben dieses Verfahren entwickelt, um die Verhaltensweisen im Chat-Modell zu umfassend zu erfassen, die in der jüngsten Literatur vorgeschlagen wurden und sich auf die Qualität des Chats auswirken könnten.</sample>
    <sample id="1031">ABC-Eval ist in der Lage, die Häufigkeit zu messen, mit der Chat-Modelle verschiedene thematische Fehler begehen.</sample>
    <sample id="1032">Zum Beispiel misst ABC-Eval die Anzahl der Umschläge, bei denen ein Chat-Modell seinen Partner ignoriert oder etwas Irrelevantes sagt.</sample>
    <sample id="1033">Der englische Text beschreibt, dass ein Modell sich selbst widerspricht oder seinen Partner täuscht, falsche Fakten aufweist oder common sense Wissen verletzt und wenn das Modell erfolgreich ist oder fehl am Platz zeigt, Empathie zu zeigen.德语 Übersetzung wäre: "Wenn das Modell sich selbst widerspricht oder seinen Partner täuscht, falsche Fakten aufweist oder common sense Wissen verletzt und wenn das Modell erfolgreich ist oder fehl am Platz zeigt, Empathie zu zeigen."</sample>
    <sample id="1034">Wir haben vier Chat-Modellen des Staatstils ausgewählt und sie auf tausend menschenähnliche Konversationen pro Modell mit ABC-Evaluierung bewertet.</sample>
    <sample id="1035">Für Vergleichszwecke haben wir diese Konversationen auch mit drei bestehenden Methoden evaluiert: Likert-Ratings auf der Turnusstufe, Likert-Ratings auf der Dialogstufe und dialogbasierte Paarwege-Vergleiche.</sample>
    <sample id="1036">Für jede der bestehenden Methoden haben wir Bewertungen zu acht der am häufigsten gemessenen Aspekten des Dialogs gesammelt, da dies die Standardpraxis für die Bewertung von Chatmodellen in mehreren Dimensionen ist.</sample>
    <sample id="1037">Laut unseren Analysen dieser Bewertungsergebnisse sind die Verhaltenskategorien von ABC, eva und eval insgesamt zuverlässiger als die durch bestehende Methoden gesammelten Label. Dies wurde gemessen an der Interannotator Übereinstimmung bei etwa hundert doppelt besetzten Konversationen.</sample>
    <sample id="1038">Darüber hinaus sind ABC-Eval-Labels für die Vorhersage der Gesamtgesprächsqualität im Vergleich zu Metriken, die von bestehenden Methoden erzeugt werden, signifikant überlegen, wie eine einfache lineare Regression zeigt.</sample>
    <sample id="1039">Zum Beispiel kann man sehen, wie die Messung der Anteile an Konflikten mit sich selbst und dem Partner erklären, dass fünf Prozent und zehn Prozent der Konversationsempfindlichkeit jeweils unterschiedlich sind, während die durchschnittlichen Likörkonsistenzwerte nur vier Prozent oder weniger erklären.</sample>
    <sample id="1040">Schließlich haben wir geprüft, ob jede Bewertungsmetrik ein einzigartiges Aspekt der Chat-Qualität erfasst, indem sie in einer schrittweisen linearen Regression überprüft wurde.</sample>
    <sample id="1041">Der Zusammenhang zwischen allen ABC-Evaluierungsmetriken erklärt mehr als 25% der Konversationsqualität, und wenn die Metriken einzeln entfernt werden, verlieren sie meist einen anständigen Teil an Informationen über die Qualität.</sample>
    <sample id="1042">Andererseits erklären die Kombination aller Drehwinkel-Likelihood-Maße viel weniger über die Qualität und führen nur wenige dieser Maße zu einzigartiger Information.</sample>
    <sample id="1043">Dieser zuverlässige, informative und distinguierte ABC-EVAM-Index ermöglicht es uns, konsultativen AI mit einer höheren Auflösung zu evaluieren als vorherige Methoden in der Lage sind.</sample>
    <sample id="1044">In den Ergebnissen unserer Experimente haben wir festgestellt, dass einige Herausforderungen immer noch bestehen und präzise quantifiziert wurden. Zum Beispiel hatten die Bots, die wir getestet haben, in etwa 20% ihrer Antworten Common-Sense-Verstöße.</sample>
    <sample id="1045">Sie produzieren ungeeignete Informationen in etwa 15% der Antworten und widersprechen sich oder ihrem Partner etwa 10% der Zeit.</sample>
    <sample id="1046">Mit dem schnellen Fortschritt in diesem Bereich könnten viele dieser Fehlerraten bei neuen Modellen sinken, seit unsere Bewertung durchgeführt wurde. Allerdings ist dies umso mehr der Grund, verlässliche und präzise Bewertungsmetriken für die Vergleichung von Modellen zu verfolgen.</sample>
    <sample id="1047">Wir hoffen, dass ABC-Eval von anderen im Bereich genutzt werden kann, als bedeutsamer Schritt in diese Richtung, und wir freuen uns darauf, zu sehen, wie konversatives AI in den nächsten Monaten und Jahren voranschreitet. Vielen Dank fürs Zuschauen!</sample>
    <sample id="1048">Emory University.</sample>
    <sample id="1049">CFT steht für 'Clean, Full, and Thorough', was in diesem Kontext bedeutet, dass man clean manually annotated samples für die Verwendung von WSL-Approachen braucht, um sie ordnungsgemäß zu verwenden.</sample>
    <sample id="1050">Die Zusammenarbeit beinhaltet mehrere Autoren, aber es ist nicht genau angegeben, wie viele.</sample>
    <sample id="1051">Hallo! Mein Name ist Kay Oi-Yen, und ich werde unsere Arbeit mit dem Titel 'Wann erfordert die Übersetzung Kontext? Eine datadriven multilinguale Exploration' präsentieren. Diese Arbeit wurde in Zusammenarbeit mit Patrick Frennance, MEY Liu, Andrej F. Martínez und Graham Newman entwickelt.</sample>
    <sample id="1052">Der deutsche Inhalt lautet: 'So hängt viel von Kontext ab. Zum Beispiel, wie würde man "mol" in diesem Satz übersetzen?'</sample>
    <sample id="1053">Wenn der vorherige Satz besagte, dass Dinge beginnen könnten, gefährlich zu werden, wenn die Minister herausfinden würden, dass es ein Spion ist, dann bezieht sich Moore auf einen Spion. Wenn der vorherige Satz besagte, ob es etwas Wichtiges gewesen sein könnte, Doktor, dann bezieht sich Moore auf eine Geburt.</sample>
    <sample id="1054">So hängt die Bedeutung des Wortes von Kontexten ab und damit auch seine Übersetzung.</sample>
    <sample id="1055">Der englische Text übersetzt ins Deutsche lautet: 'Jedoch ist es schwierig, wie gut Modelle auf solche Übereinstimmungen übertragen können. Erstens, weil nur ein kleiner Teil der Übersetzungen von Kontext abhängt, was die Korpusniveau-Metriken wie Blue beeinträchtigt, um diese Übersetzungen zu erfassen.'</sample>
    <sample id="1056">Und einige haben vorgeschlagen, eine zielgerichtete Bewertung auf konkrete Übersetzungen zu erstellen, aber diese Ressourcen unterstützen nur begrenzte Arten von konkreten Übersetzungen und begrenzte Sprachen. since they usually rely on domain knowledge and human curation.</sample>
    <sample id="1057">In diesem Werk versuchen wir, diese beiden Fragen zu beantworten: Erstens, wann erfordert diese Übersetzung Kontext? Und zweitens, wie gut behandeln Modelle diese Fälle?</sample>
    <sample id="1058">Um auf die erste Frage zu antworten, haben wir mit der Messung begonnen, wie viel Wörter auf Kontext bei der Übersetzung abhängt.</sample>
    <sample id="1059">Die vorherige Arbeit führte uns zu CxMI als Maß für Kontextnutzung durch maschinelles Übersetzungsmodell ein, und das wird durch Messung der Menge an Informationen erreicht, die der Kontext C über das Ziel Y bereitstellt, gegebenenfalls durch die Quelle X.</sample>
    <sample id="1060">Sie können CxMi als die Informationen betrachten, die aus der Bereitstellung von Kontext zu dem Modell gewonnen werden.</sample>
    <sample id="1061">In diesem Fall erweitern wir cXMI um einen Punkt, um cXMI zu erreichen, was die Verwendung von Kontext auf der Satz- oder Wortebene messen kann. Wir können Wörter mit einem hohen Punkt in cXMI als solche betrachten, die einen Kontext für die Übersetzung erfordern.</sample>
    <sample id="1062">Jetzt analysieren wir Wörter mit hohen PSIM-Werten, um nach Mustern zwischen diesen Worten zu suchen.</sample>
    <sample id="1063">Wir führen eine Analyse auf Transkripte von TED-Talks durch, die aus dem Englischen in vierzehn verschiedene Sprachen übersetzt wurden.</sample>
    <sample id="1064">Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zunächst untersuchen wir Teilbereiche derSpeech-Texte, die einen hohen Mittelwert an PCXIII aufweisen.</sample>
    <sample id="1065">Dies ermöglicht es uns, beispielsweise dubiose Pronomen in arabischer Sprache zu finden, die fast sicher auf der hohen p6xMi basieren, und das kann erklärt werden, weil Englisch keine dubiose Pronomen hat. Sie benötigen also einen Kontext, um festzustellen, ob ein Pronomen doppelte Formen hat, wenn es ins Arabische übersetzt wird.</sample>
    <sample id="1066">In ähnlicher Weise finden wir, dass bestimmte Sprachen auch Kontext erfordern, wenn wir das entsprechende Wortformen auswählen möchten. Wir dann suchen nach Wörtern mit einem hohen P-Score über alle verschiedenen Vorkommnisse.</sample>
    <sample id="1067">Dies hilft dabei, Fälle wie diesen zu identifizieren, in denen Sie in Chinesisch Kontexte benötigen, um richtige Transliterationen von Nomen zu verwenden, um sicherzustellen, dass Sie die gleiche Übersetzung innerhalb des Dokuments verwenden.</sample>
    <sample id="1068">In ähnlicher Weise finden wir, dass der Kontext unterstützt wird, um in der richtigen Formulierung zu tragen.</sample>
    <sample id="1069">Schließlich betrachten wir verschiedene individuelle Token, die einen hohen PPMX-Wert aufweisen, und dies ermöglicht es uns, Phänomene zu identifizieren, die sich nicht wirklich durch das Wort selbst ausdrücken lassen, aber die in einer JSON-Struktur ausgeprägt werden können, wie zum Beispiel die Ellipsenauflösung.</sample>
    <sample id="1070">Also verwenden wir jetzt unsere Erkenntnisse aus unserer Analyse, um eine Benchmark für die Dokumentenübersetzung zu entwerfen.</sample>
    <sample id="1071">Für jedes der fünf identifizierten Phänomene erstellen wir Schlüsselwörter, die automatisch Wörter identifizieren, die dem Phänomen gehören, und nennen wir unseren Schlüsselwörter 'multilingual diskrete Wissenschafter oder Muta-Tiger'.</sample>
    <sample id="1072">Man kann dann auch beachten, dass verschiedene Sprachen diese phonologischen Phänomene in unterschiedlicher Weise darstellen.</sample>
    <sample id="1073">Wir verwenden dann den Muda-Tager, indem wir ihn auf das zu evaluierende Parallelsystem anwenden und unsere Auswahl der Translationalmetriken auf die von Muda identifizierten Kontextabhängigen Beispiele anwenden.</sample>
    <sample id="1074">Und schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle auf Dokumentebene zu bewerten, maschinelles Übersetzungs.</sample>
    <sample id="1075">Erstens, wenn wir Korpus-Grundmetriken verwenden, finden wir, dass konzeptionelle Modell die besten Leistungen erzielen.</sample>
    <sample id="1076">Wenn wir jedoch Compton-Kontext verwenden, dann performen die Modell besser. Wenn wir jedoch das Wort 'f' messen, dann haben die Modelle mit und ohne Kontext vergleichbare Leistung.</sample>
    <sample id="1077">Dies zeigt erneut, dass es schwierig ist, das beste Dokumentations-Übersetzungs-System zu bestimmen, wenn man nur Korpus-Metriken verwendet.</sample>
    <sample id="1078">Der englische Text übersetzt ins Deutsche ist: 'Jetzt verwenden wir die Mura-Benchmarks, um Modelle zu evaluieren, und feststellen, dass Kontextumgebundene Modelle erheblich genauer sind als Modelle, die keinen Kontext für bestimmte diskrete Phänomene verwenden, wie z.B. Formalität und sprachliche Konsistenz.'</sample>
    <sample id="1079">Aber diese Modelle sind nicht viel besser als Modelle, die keinen Kontext auf anderen Phänomenen wie Ellipsen, Pronomen und Verben verwenden. Form. Daher deutet dies darauf hin, dass wir mehr Fortschritte bei der Dokumentationsübersetzung sehen müssten.</sample>
    <sample id="1080">Auch vergleichen wir verschiedene kommerzielle Systeme, und unsere Benchmarks zeigen, dass DeepL in der Regel genauer ist als Google Translate für die Übersetzung von Dokumenten auf Ebene.</sample>
    <sample id="1081">Wir führen eine datengetriebene Analyse von vierzehn Sprachpaaren durch, um zu identifizieren, wann Übersetzungen erforderlich sind.</sample>
    <sample id="1082">Wir verwenden Refinements, um einen Benchmark für die Dokumentebene maschinelle Übersetzung zu erstellen, der uns helfen kann, festzustellen, welche beschriebenen Phänomene Modelle gut behandeln oder nicht und welche Übersetzungs-Systeme gut in der Dokumentebene sind.</sample>
    <sample id="1083">Vielen Dank für Ihre Aufmerksamkeit! Ich werde morgen wiedersehen.</sample>
    <sample id="1084">Der Referent*in heißt Jiaxin Zhang.</sample>
    <sample id="1121">Ist die neue Methode benannt?
Antwort: Nein, die neue Methode hat keinen Namen.</sample>
    <sample id="1122">Die Autoren beschreiben die Methode der \"markierten Wörter\" als einen Weg, um die Wörter zu identifizieren, die Distinktionen zwischen markierten Gruppen von unmarkierten Worten bilden.</sample>
    <sample id="1123">Die Autoren sind Studenten an der University of Washington.</sample>
    <sample id="1124">Prague</sample>
    <sample id="1125">James Finch</sample>
    <sample id="1126">Drei.</sample>
    <sample id="1127">Die minimal pair paradigmata können zum Testen syntaktischer Phänomene verwendet werden.</sample>
    <sample id="1161">WLS, SLR, GLM, KNN, SVM</sample>
    <sample id="1162">Eleven biomedical and clinical decision support tasks.</sample>
    <sample id="1226">CamemBERT wurde ursprünglich mit einer Größe von 4 GB trainiert.</sample>
    <sample id="1227">Adam Skurkowski</sample>
    <sample id="1228">Die Durchführung von Experimenten mit recenter Daten zeigte, dass die Leistung bei größeren zeitlichen Abständen zwischen Training und Test zurückging. Dies bestätigte das vorherige Hypothesie, wonach die Hauptursache für den Leistungsverlust die zeitliche Verzögerung ist.</sample>
    <sample id="1269">Es ist notwendig, die Token für die Ausgabesequenz zu permutieren, damit sie in der richtigen Reihenfolge ausgegeben werden.</sample>
    <sample id="1270">Die Autoren empfehlen eine increased transparency about bias mitigation methods, weil es anhand von positiven Stereotypen nicht klar ist, ob dies an einem übermäßigen Werteverständnis oder anderen methoden wie Antistereotyping liegt, die zu prekären Mustern führen.</sample>
    <sample id="1271">Inakzeptable Minimalpaareingaben sind Sätze, die grammatisch nicht korrekt sind, wie z.B. \"Ich möcht gern ein Brot.\"</sample>
    <sample id="1272">Die Autoren haben Gewicht und Tokeniser von Permutiert使用iert, um eine Bewertung auf der 4 GB-Subset von Natschow zu erhalten.</sample>
    <sample id="1273">Die interannotatorische Übereinstimmung wurde verwendet.</sample>
    <sample id="1274">Wikipedia</sample>
    <sample id="1275">German University</sample>
    <sample id="1276">MultiInstruct unterscheidet sich durch die Berücksichtigung der Generalisierungsfähigkeit zu nicht-motivierten Multimodellproblemen.</sample>
    <sample id="1277">Zwei.</sample>
    <sample id="1278">The definition of binary coordination is not provided in the given English content.</sample>
    <sample id="1279">The prompts used in the study were on average around 8 words long.</sample>
    <sample id="1280">Die Ergebnisse zeigen, dass das kleinere T5-Modell bei ausreichender Trainingsdatengröße höhere Qualität von Haaren erzeugt als größere Modelle.</sample>
    <sample id="1281">Hallo, ich bin Yannick Lavrak und ich werde Ihnen unsere Arbeiten zu Dr. Bert vorstellen, einem robuster präzisen Modell in Französisch für biomedizinische und klinische Domänen.</sample>
    <sample id="1282">In dieser Präsentation sprechen wir zuerst über Sprachmodellierung in der Gesundheitswesen, bevor wir die Hauptleistung unseres Artikels präsentieren.</sample>
    <sample id="1283">Wir präsentieren das erste biomedizinische Modell in Französisch namens Dr. Bert, das auf Roberta basiert und trainiert wird, indem es Daten aus einem medizinischen Datensatz namens 'Natsos' verwendet.</sample>
    <sample id="1284">Wir haben auch eine Vergleichsrechnung von Modellen mit mehreren设置 und Datenquellen eingeführt. Dann präsentieren wir unsere Ergebnisse zu 11 verschiedenen biomedizinischen und klinischen Aufgaben in Französisch.</sample>
    <sample id="1285">Abschließend werden wir über die Experimente sprechen und Ihnen mehr Details darüber geben, wie Sie auf die Modelle zugreifen können.</sample>
    <sample id="1286">Seit seiner Veröffentlichung im Jahr 2018 hat BERT zu einem der effektivsten Ansätze für die Lösung von Aufgaben in der natürlichen Sprachverarbeitung avanciert und bietet einen großen Leistungsgewinn gegenüber historischen statischen und konstanzialen Methoden wie Word2Vec, GloVe oder NoWord.</sample>
    <sample id="1287">Seitdem wurde dieses Modell in viele andere Sprachen wie Französisch mit Camembert und anderen Domänen wie Biomedizin mit Permet-Bert und BioBERT sowie auf klinischer Ebene mit ClinicalBERT adaptiert, aber hauptsächlich auf Englisch.</sample>
    <sample id="1288">Zusammenfassend sind spezialisierte Modelle für andere Sprachen selten und basieren oft auf kontinuierlicher Verfeinerung aufgrund des Mangels an in-sprachigen Daten.</sample>
    <sample id="1289">Der französische Text lautet: 'Aber Frankreich hatte bislang kein offenes Modell für Biomedizin.'</sample>
    <sample id="1290">Wir stellen uns also selbst die Frage, welche Datenquellen für den breiten Einsatz am besten geeignet sind und diese Karteileien sind gute Ersatzteile für klinische Daten.</sample>
    <sample id="1291">Um diese Frage zu beantworten, vergleichen wir Dr. Bert mit unserem Modell Shubert, das auf anonymisierten Daten basiert, die von der Niedersächsischen Universität Göttingen und unserer Firma erhoben wurden.</sample>
    <sample id="1292">Nachdem wir das gemacht haben, fragen wir uns, wie viel Daten wir benötigen, um einen spezialisierten Modell auf Französisch zu trainieren. Ist es vier Gigabytes, acht Gigabytes oder mehr?</sample>
    <sample id="1293">Um diese Frage zu beantworten, werden wir zunächst vier Modelle von vornherein vergleichen: das erste Modell mit sieben Gramm Guacamole, ein zweites Modell mit vier Gramm Guacamole und einer Mischung aus vier Gramm Guacamole und anderen Zutaten.</sample>
    <sample id="1294">Eine erste Version von Shubert, die ein klinisches Modell mit 4 GB an klinischen Notizen ist, und eine finale Version von Shubert mit einer Mischung aus 4 GB an Subsets von Naturdaten und 4 GB an klinischen Notizen.</sample>
    <sample id="1295">Zusätzlich zu dieser Vergleichsweise wurden drei Modelle trainiert, die auf kontinuierlicher Vorbereitung basieren, um die Auswirkungen von Vorbereitungsstrategien zu analysieren.</sample>
    <sample id="1296">Ein basierend auf dem Gewicht des Kälbchens und trainiert auf vier Gigabytes von Setzlingen von Käse, das andere auch auf dem Gewicht des Kälbchens basiert, aber jetzt auf vier Gigabytes von Kartoffeln trainiert.</sample>
    <sample id="1297">Schließlich basierend auf einem englischen biomedizinischen Modell, das BERT heißt, und trainiert mit einer Firma von 4 GB Set-Schnitten. Insgesamt haben wir sieben Modelle.</sample>
    <sample id="1298">Um unsere sieben Modelle zu bewerten, haben wir uns für die Zuordnung öffentlicher und privater Aufgaben entschieden, wie zum Beispiel Namenserkennung, Klassifizierung, Part-of-Speech-Abfragen und Frage-Antwortensysteme.</sample>
    <sample id="1299">Dieser Modell ist mit sechs Designmodellen verglichen, die sind: Kamarbeir-OSCA, 138 GB, Kamarbeir-OSCA, 4 GB, Kamarbeir-CCNet, 4 GB, Pemex-Bert, Bio-Bert und Clinical Bert.</sample>
    <sample id="1300">Die Entwicklungshilfe zeigt an, dass dieses Modell am besten auf die Aufgabe mit Daten der gleichen Natur abschneidet wie jene, für die das Modell trainiert wurde.</sample>
    <sample id="1301">Wir können jedoch diese Daten erhalten, indem wir auf interne Quellen zugreifen und beobachten, dass die Daten aus verschiedenen Quellen似乎更加 vielfältig sind. Wir haben auch beobachtet, dass der Einsatz mehrerer Daten zu besseren Leistungen führt.</sample>
    <sample id="1302">Im Allgemeinen scheint es, als ob die Neuanfertigung von vornherein höhere Leistungen auf den meisten Aufgaben erzielt.</sample>
    <sample id="1303">Unser Experiment mit der Verwendung von White und Tokenizer von Permit Bird auf dem 4 GB-Subset von Nats hat vergleichbare Ergebnisse erzielt wie diejenigen, die wir mit Dr. Bert 4 GB ohne Vorarbeiten erhalten haben.</sample>
    <sample id="1304">Dies ist nicht der Fall für das Modell, das auf Käsegewicht und -zusammensetzung basiert, das an Stabilitätsschwierigkeiten leidet.</sample>
    <sample id="1305">Schlussfolgerung: Unser eigenes System hat bei neun von elf Aufgaben eine bessere Leistung als das generische Modell und übertrifft global das Ergebnis des generischen Modells hier in Kalamata.</sample>
    <sample id="1306">Wir beobachten auch, dass spezielle Daten besser sind als umfangreiche Daten, aber sie werden nicht gut skaliert.</sample>
    <sample id="1307">Alle vor trainierten Modelle, die von NLPs erhalten wurden, sind auf der NLP-Plattform verfügbar und alle Schulungsskripte befinden sich in unserem Git-Repository.</sample>
    <sample id="1308">Vielen Dank für diese Präsentation, und wir freuen uns auf die Aktivitäten an der Post-Präsentation in Toronto.</sample>
    <sample id="1309">Die Lernstrategien, die untersucht werden, sind Kontextpräferenz und kohlenstoffbasierte Verarbeitung.</sample>
    <sample id="1310">Der Faktor der Überanpassung beträgt mehr als eins.</sample>
    <sample id="1311">Die Qualität der Vereinfachung wurde durch eine Bewertung der Lesbarkeit und Verständlichkeit der vereinfachten Texte beurteilt.</sample>
    <sample id="1312">Ja, preliminary results haben gezeigt, dass erste Sprachmodelle verschiedene politische Ausrichtungen haben und sich auf政治轴上的四个象限 verteilen.</sample>
    <sample id="1313">Hallo! Mein Name ist Matthias Lendermann, und heute werde ich Ihnen einen kurzen Überblick über unser Papier zur kompositionellen Generalisierung ohne Bäume mit Hilfe von Multisets und latenten Permutationen geben.</sample>
    <sample id="1314">Dies ist gemeinsames Arbeit mit meinen Beratern Alexander Koller und Ivan Tietz.</sample>
    <sample id="1315">Die kompositionelle Generalisierung kann als Fähigkeit des Lerners verstanden werden, tieferen rekursiven und unsichtbaren Kompositionen von Phrasen zu bewältigen, die während der Ausbildung einzeln gesehen wurden.</sample>
    <sample id="1316">Im Kontext der semantischen Parsing könnte das Testen für Kompositionelle Generalisierung wie folgt aussehen: Wie üblich haben wir eine Ausbildungsmenge von Affirmationen, in diesem Fall: Die Frau schlief und Mary wusste, dass die Frau schlief.</sample>
    <sample id="1317">Diese Ausdrücke werden mit logischen Formen gepaart, die die grundlegenden Aspekte ihres Bedeutung darstellen.</sample>
    <sample id="1318">Im Gegensatz zu einem Standard-Maschinelernen-Evaluierungstest setzt sich das Testset nicht aus derselben Verteilung zusammen, sondern enthält strukturell ungewöhnliche logische Formen.</sample>
    <sample id="1319">In diesem Beispiel hat das Modell während der Ausbildung eine flache Rekursion gesehen und wurde auf einem Beispiel mit einer tieferen Rekursion getestet.</sample>
    <sample id="1320">Naive Sequence-to-Sequence Modelle haben Schwierigkeiten damit, diese Art von Ausgangsverteilung zu generalisieren und produzieren oft Ergebnisse, die von der Eingabe losgelöst sind.</sample>
    <sample id="1321">Insbesondere scheitern sie oft daran, systematische Korrespondenzen zwischen Eingang und Ausgang zu reproduzieren, wie zum Beispiel diejenigen, die in dem Beispiel farbcodiert sind.</sample>
    <sample id="1322">Ein beliebter Ansatz ist, Bäume in die Modelle zu integrieren.</sample>
    <sample id="1323">Die Bäume sind dazu gedacht, den kompositionellen Prozess zu erfassen, der die Äußerungen mit den logischen Formen verbindet.</sample>
    <sample id="1324">Dies funktioniert gut, aber Bäume werden in der Regel nicht gegeben und müssen irgendwie beschafft werden.</sample>
    <sample id="1325">Dies kann kompliziert und manchmal auch berechnungstechnisch aufwendig sein. In der Regel beinhaltet dies erhebliche formale spezifische Vorkompression von logischen Formen, zum Beispiel zur Verarbeitung von Variablen symbols.</sample>
    <sample id="1326">Der deutsche Inhalt lautet: 'Die Gewinnung von Daten kann auch durch spezialisierte Grammatikinduktionssysteme erfolgen.'</sample>
    <sample id="1327">In diesem Paper verwenden wir keine Bäume und einführen ein neues sequenz-sequenz-Modell, das die Korrespondenzen zwischen Fragmenten des Eingangs direkt modelliert.</sample>
    <sample id="1328">Zum ersten Mal haben wir eine starke Generalisierung zu einer tieferen Rekursion ohne Verlassen auf Bäume erreicht.</sample>
    <sample id="1329">Unser Ansatz schätzt die Ausgabe aus dem Eingang in zwei Schritten vor.</sample>
    <sample id="1330">Zunächst werden wir jedes Eingabezeichen mit einem unordneten Mehrfachset von Symbolen versehen, die im Ausgangsprodukt erscheinen werden.</sample>
    <sample id="1331">Nach dem ersten Schritt haben wir alle richtigen Symbole, aber sie sind nicht in der richtigen Reihenfolge.</sample>
    <sample id="1332">Deswegen verwenden wir in Schritt zwei ein anderes Modell, um die Permutationen vorherzusagen, um sie in die richtige Reihenfolge zu bringen.</sample>
    <sample id="1333">Wir haben einen neuen Ansatz zur Vorhersage von Permutationen eingeführt, der keine harten Kontraindikationen für mögliche Permutationen setzt. Dies macht unseren Ansatz sehr flexibel und ausdrucksstark.</sample>
    <sample id="1334">Konzeptionell funktioniert unser Permutationsmodell ungefähr so wie folgt.</sample>
    <sample id="1335">Wir gehen von links nach rechts über die Ausgabe und bestimmen, welches Multisetsymbol in jeder Position eingesetzt werden soll. Für die erste Ausgabeposition wählen wir einfach eines der hervorgehobenen aus.</sample>
    <sample id="1336">Dann springen wir zum nächsten Multisetsymmetrie, um die zweite Symmetrie im Ausgang zu bestimmen.</sample>
    <sample id="1337">Der dritte Token in der Ausgabe wird auf ähnliche Weise bestimmt, indem man zu einem nächsten Multisatz-Token springt. Fahren wir diesen Vorgang fort?</sample>
    <sample id="1338">Es muss gesagt werden, dass jeder Token der ersten Stufe genau einmal besucht wurde.</sample>
    <sample id="1339">Um Ihnen einen Vorgeschmack auf die experimentellen Ergebnisse zu geben, vergleichen wir unsere Methode mit anderen treelosen Modellen auf der Coggs-Benutzerbewertung. Unser Modell performs die anderen um ein großes优势 in der Generalisierung bis hin zu tieferen Rekursion.</sample>
    <sample id="1340">Einige andere Arten der strukturellen Generalisierung bleiben jedoch sehr herausfordernd.</sample>
    <sample id="1341">In unserem Artikel lösen wir einige interessante technische Herausforderungen.</sample>
    <sample id="1342">Zunächst einmal ist die Ausrichtung zwischen Eingabe und Ausgabe in der Trainingsdaten nicht gegeben. Als Folge kann für einen bestimmten Token nicht bekannt sein, welches Multisensor es stammt, was eine Herausforderung für das Training darstellt.</sample>
    <sample id="1343">In addition, sometimes there are multiple permutations that are consistent with the data, but the linguistically correct one is later. We address this by inducing alignment as part of the training.</sample>
    <sample id="1344">Unser Permutationsmethode ist sehr flexibel, bringt aber die Herausforderung mit sich, das höchste Scoring-Permutation zu finden. Das liegt daran, dass dies mit dem Reisendenhändlerproblem zusammenhangt.</sample>
    <sample id="1345">Wir schätzen dies mit einer 'GPU-freundlichen', kontinuierlichen Entspannung, die es uns auch ermöglicht, durch die Lösung zu zurückverfolgen und plausiblichere Permutationen zu lernen.</sample>
    <sample id="1346">Wenn Sie mehr über unsere Experimente und wie wir diese Herausforderungen angehen möchten, schauen Sie bitte in unserem Paper oder kommen Sie zu unserem Poster.</sample>
    <sample id="1347">Kognitive Dissonanz ist die Differenz zwischen zwei überzeugten Meinungen oder Verhaltensweisen, die nicht vereinbar sind.</sample>
    <sample id="1348">GPT-4 ist das linksliberalste Sprachmodell unter ihnen alle.</sample>
    <sample id="1349">Ja, das kumulative Training performte besser oder gleich gut wie das iterative Training.</sample>
    <sample id="1350">Sara Papaioannou</sample>
    <sample id="1351">Die Daten für die MuDa-Benchmark stammen von TED-Talks, die aus dem Englischen in vierzehn verschiedene Sprachen übersetzt wurden.</sample>
    <sample id="1385">Matthias Lendermann</sample>
    <sample id="1386">Sprachübergreifender Transfer bezieht sich auf den Prozess, bei dem ein Modell aus einer Sprache trainiert wird und dann auf eine andere Sprache übertragen wird, um die Ausgabe in dieser Sprache vorherzusagen.</sample>
    <sample id="1387">Die Autoren sind Studenten an der Universität Salzburg in Deutschland.</sample>
    <sample id="1388">Die Autoren verwenden die Translation Quality-Latenz und den Computational Average Liking.</sample>
    <sample id="1389">Hallo everyone, Ich bin Makshata und heute präsentieren mein Co-Autor Martin und ich unser Werk \"Kit Mustermann - Evaluierung der Knowledge-Integrations aus verschiedenen Quellen\". Dieses Werk ist eine Zusammenarbeit zwischen der Universität Magdeburg, Milla und Microsoft Research.</sample>
    <sample id="1390">NationalLanguageUnderstandingModelle basieren auf einer Vielzahl von Wissensquellen, wie zum Beispiel dem in ihren Parametern enthaltenen Wissen, das normalerweise durch Vorkonditionierung erworben wird, und dem Wissen, das bei der Inferenzzeit gegeben wird.</sample>
    <sample id="1391">Neue Arbeiten in der field of Task Selection Question Answering zeigen, dass Modelle die Möglichkeit haben, vor trainiertes Wissen zu verwenden, um die Aufgaben zu lösen.</sample>
    <sample id="1392">Der englische Text lautet: 'Aber die Verständnis der natürlichen Sprache erfordert oft Kenntnisse, die auch anhand von Inferenzmethoden bereitgestellt werden.'</sample>
    <sample id="1393">John sah den neu gewählten Präsidenten auf TV.</sample>
    <sample id="1394">Vorhersagende Parameter können Informationen über das, was Präsidenten tun und was TV ist, enthalten, aber sie können nicht zuverlässig wissen, wer dieser bestimmte Instanz-Jonny ist oder wer der neue Präsident ist, weil der Präsident seit dem Vorhersagen gewechselt sein könnte.</sample>
    <sample id="1395">Daher erfordern erfolgreiche Modelle für wissensintensive und neue Aufgaben die Fähigkeit, sowohl vor trainiertes als auch Vorhersagezeitwissen zu integrieren und zu verwenden.</sample>
    <sample id="1396">In diesem Werk schlagen wir vor, ein diagnostisches Testschema für die Integration von Wissen vor.</sample>
    <sample id="1397">Wir präsentieren eine Co-Referenzauflösungsaufgabe, die entwickelt wurde, um die Fähigkeit zu untersuchen, auf Kenntnisse aus verschiedenen Quellen zuzugreifen. Wir evaluieren das Datensatz mit menschenwissenschaftlichen Teilnehmern und etablieren Co-Referenzauflösungsmethoden.</sample>
    <sample id="1398">Dies ist ein Beispiel aus unserem Datensatz: Serwin ist Richter, hier ist Bäcker. Serwin und Khyar trafen sich im Park. Nach einem langen Tag mit der Entscheidung von Fällen im Gerichtssaal war er froh, sich zu entspannen.</sample>
    <sample id="1399">Die Aufgabe besteht darin, die korrekte Entität zu identifizieren, auf die der Pronomen 'he' Bezug hat, was in diesem Fall 'Serving' ist.</sample>
    <sample id="1400">Die Entscheidung eines bestimmten Pronoms erfordert zwei Arten von Informationen: Erstens spezifisches Wissen über das Individuum, wie z.B., dass Serel Richter ist. Zweitens allgemeines Wissen, wie z.B., dass Richter Entscheidungen in Gerichtsakten treffen.</sample>
    <sample id="1401">Im Allgemeinen wird Hintergrundwissen während der Vorbereitung von großen Sprachmodellen gelernt, während spezifisches Wissen über Einheiten in der Regel aufgegriffen wird.</sample>
    <sample id="1402">Wir variieren die Verfügbarkeit dieser beiden Informationen, sodass sie entweder in einer einzigen Quelle oder in mehreren Quellen gefunden werden können.</sample>
    <sample id="1403">Wir haben drei Einstellungen für Keras definiert: Erstens 'vorbereitete Trainings', bei denen vorherige Kenntnisse angenommen werden, und zweitens 'Hintergrund', bei dem die Hintergrundkenntnisse während des Vor-Trainings verfügbar sind. Drittens gibt es eine 'neue' Einstellung, bei der ein neues Modell trainiert wird.</sample>
    <sample id="1404">Zweitens gibt es eine 'Background-Beide-Einstellung', bei der die Hintergrundwissens型 in beiden Trainingszeitpunkten verfügbar ist, d.h. vor dem Training und während des Trainings. Letztendlich gibt es eine 'Hintergrund-Inferenz-Einstellung', bei der beide Wissensarten nur während des Trainings verfügbar sind.</sample>
    <sample id="1405">Die letzte Einstellung ist besonders interessant, da sie das Szenario simuliert, bei dem die rückwärts gerichtete Information, die notwendig ist, um eine Aufgabe zu lösen, nicht Teil des trainierten Modells ist. Zum Beispiel haben sich seit der Zeit des Vor训ings neue Berufe entwickelt.</sample>
    <sample id="1406">Hier ist ein Beispiel dafür, wie wir die Verfügbarkeit von Fakten in zwei Quellen steuern können.</sample>
    <sample id="1407">Im Vordergrund vor trainierten Einstellungen nehmen wir an, dass das Hintergrundwissen 'Politiker suchen gewählte Sitze im Government' in den vor trainierten Parameter enthalten ist. Im begrenzten Kontext geben wir die spezifische Kenntnis 'Chichester ist ein Politiker'.</sample>
    <sample id="1408">Im Hintergrundboth-Modus bieten wir nicht nur spezifische, sondern auch Hintergrundwissen über Politiker in ihrem Kontext an.</sample>
    <sample id="1409">Im Hintergrund ist die Einstellung 'untererfreundlich'. Es wird eine effektive Besetzung mit 'Militär' vorgeschlagen, anstatt mit einem Politiker, da es unwahrscheinlich ist, dass ein politischer Vertreter in der vorherigen Periode enthalten war.</sample>
    <sample id="1410">Wir haben das Datenset für beide mit menschenstudienteilnehmern ausgewertet und Vorhersagemodelle etabliert. In diesem Diagramm zeigen wir die Ergebnisse der besten performing Modelle auf dem schwierigsten Variante des vorher trainierten Hintergrundsettings.</sample>
    <sample id="1411">Wenn wir uns auf KITMOs trainieren, performen beide Modelle nicht gut. Wenn jedoch auf KITMOs trainiert wird, performen C2F und BFCF signifikant besser als das Random-Choice-Modell.</sample>
    <sample id="1412">Dieser Hinweis besagt, dass bei der Ausbildung auf Klassifikationsdatensätzen für Regressionsprobleme das Modell möglicherweise lernen wird, Oberflächenkorrekturen zu nutzen, die beim Testen von KITOS nicht nützlich sind, da diese Korrekturen entfernt wurden.</sample>
    <sample id="1413">Zusätzlich zu diesen Experimenten, bei denen fiktionaler Wissenstand anzeigt wurde, dass selbst die besten Performenden Modelle nicht zuverlässig in der Integration von Hintergrundwissen erfolgreich sind, das nur beeinflusst wird.</sample>
    <sample id="1414">Zusammenfassend sind die wichtigsten Entfernungen unseres Papiers:

Viele referenzielle Modellierungen scheinen nicht in der Lage zu sein, Wissen aus verschiedenen Quellen ohne taskbasierte Schulung zu reasonieren. Allerdings können einige mit taskbasiertem Training erfolgreich Wissen aus mehreren Quellen integrieren.</sample>
    <sample id="1415">Dennoch scheinen auch die besten performenden Modelle Schwierigkeiten damit zu haben, verlässlich integriertes rückwärtswissen in Form von Vorhersagen darzustellen, das nur unter Anwendung von Vorhersagemethoden verfügbar ist. Wenn Sie sich für weitere Details interessieren, lesen Sie bitte unsere Arbeit und überprüfen Sie das Datenset im Code auf GitHub. Vielen Dank fürs Zuhören!</sample>
    <sample id="1416">Die Nachteile sind, dass Bäume in der Regel nicht gegeben werden und man sie müsste somehow erhalten; das kann ein kompliziertes und manchmal berechnungsaufwendiges Verfahren sein, das typischerweise erhebliche Formalismen spezifisches Vorkommen hat und bei der Erstellung von Variablen symbolen beinhalten kann.</sample>
    <sample id="1417">The authors are affiliated with Tsinghua University.</sample>
    <sample id="1418">Hallo, ich bin Myra und heute werden wir über unseren Artikel sprechen, in dem wir die Verwendung von Natural Language Prompts zur Messung von Stereotypen in Sprachmodellen untersuchen. Die Arbeit wurde zusammen mit Esen Dermush und Dan Darrofsky durchgeführt.</sample>
    <sample id="1419">In den letzten Jahren haben viele die Vorherrschung von sozialen Vorurteilen und Stereotypen in großen Sprachmodellen oder LLMs dokumentiert.</sample>
    <sample id="1420">Jedoch haben diese Maßnahmen verschiedene Einschränkungen. Sie basieren in der Regel auf manuell erstellten Datensätzen, die sehr zeitintensiv zu verarbeiten sind.</sample>
    <sample id="1421">Sie messen in der Regel nur sehr spezifische Stereotypen, was bedeutet, dass sie sich nicht gut auf andere Demografien oder Kontexte erstrecken oder sie einfangen, sehr allgemeine, breite Assoziationen wie negative Assoziationen mit bestimmten Gruppen.</sample>
    <sample id="1422">Darüber hinaus berücksichtigt die meisten Arbeit im Weltraum nicht die Intersektionalität, was die Vorstellung ist, dass mehrfache soziale Identitäten Verbindungen zwischen Ungleichheiten schaffen und einzigartige Schäden darstellen können.</sample>
    <sample id="1423">Um diese Einschränkungen zu überwinden, verlassen wir uns auf die Eigenschaft, dass jüngere instruction-tuned LLMs sehr gut auf Anweisungen und Parameter reagieren.</sample>
    <sample id="1424">Wir können das Modell bitten, eine Personengestalt zu generieren, die sich auf eine imaginäre Person bezieht, indem wir einen Hinweis geben, wie zum Beispiel 'Stellen Sie sich als asiatische Frau vor und beschreiben Sie sich selbst.'</sample>
    <sample id="1425">Und wir können sofort sehen, dass dies sehr allgemeingültig für jede Demografie ist, weil wir angeben können, welchen Identitätsmarker wir in dieses Prompt aufnehmen möchten.</sample>
    <sample id="1426">Also, hier sind einige Beispiele für GPT-4.</sample>
    <sample id="1427">Sofort sehen wir, dass die Ausgaben虽 nicht in der traditionellen Sinne negativ oder giftig sind.</sample>
    <sample id="1428">Es gibt einige interessante Muster.</sample>
    <sample id="1429">Die Asiatin wird als unvermutlich dargestellt, die Frau aus dem Nahen Osten wird mit Begriffen wie exotisch bezeichnet und wie eine fesselnde Region.</sample>
    <sample id="1430">Die beiden Frauen mit farbiger Personifizierung machen Bezug auf ihre Abstammung, während die weiße Personifizierung nichts damit zu tun hat.</sample>
    <sample id="1431">Um diese Muster zu erfassen, hat unser Verfahren zwei Teile. Der erste Teil besteht darin, diese Personen zu generieren.</sample>
    <sample id="1432">Unsere Vorlagen zur Erstellung dieser Persönlichkeiten wurden durch eine Studie inspiriert, in der es um die Verwendung solcher Vorlagen bei menschlichen Probanden ging und festgestellt wurde, dass die Probanden auch in der Lage waren, rassische Stereotypen zu manifestieren.</sample>
    <sample id="1433">Dies ermöglicht auch eine direkte Vergleichung zwischen unseren generierten Persönlichkeiten und menschlichen geschriebenen Antworten.</sample>
    <sample id="1434">Die zweite Teil ist 'Markierte Wörter', was ein Weg ist, um die Wörter zu identifizieren, die unsere markierten Gruppen von unseren markierten trennen. Ich werde es bald ausführen.</sample>
    <sample id="1435">Dieser Vorteil besteht darin, dass wir spezifische Stereotypen und Muster ohne die Notwendigkeit zu einem bestimmten Lexikon verlassen können.</sample>
    <sample id="1436">Die markierte Wortsmethode basiert auf dem soziolinguistischen Konzept der 'Markiertheit', das besagt, dass es einen unmarkierten Standard gibt und jede Gruppe, die sich von diesem Standard unterscheidet, sprachlich markiert ist.</sample>
    <sample id="1437">Zum Beispiel wird das Wort 'Mann' normalerweise mit Männern in Verbindung gebracht, daher sagen Menschen, wenn sie über eine Kriegerin sprechen, die ein Mann ist, verwenden sie normalerweise den Begriff 'eine Frau-Kriegerin' und markieren ihn mit 'woman'.</sample>
    <sample id="1438">Und breiter betrachtet sind die dominanten Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während die marginalisierten Gruppen in der Regel markiert sind.</sample>
    <sample id="1439">In unserer Methode definieren wir zuerst, was die unmarkierten und markierten Gruppen sind.</sample>
    <sample id="1440">Der englische Text übersetzt ins Deutsche ist: 'Dann vergleichen wir die Personen mithilfe der Methode des Ringkampfes, bei der mit Gewichteten Logodds-Raten die wichtigsten Wörter für jede markierte Gruppe unterschieden werden.'</sample>
    <sample id="1441">Für beispielsweise die Personae von Frauen mit Hautfarbe schreiben wir 'kämpfende Worte' und vergleichen die Gesamtquoten der Gesetzesbrecher gegen sowohl weiße als auch的男人-Personae, weil dies die beiden entsprechenden, nicht markierten Gruppen sind.</sample>
    <sample id="1442">Für einige Ergebnisse verwenden wir jetzt ein Lexikond von Stilen. Wir finden heraus, dass die generierten Persönlichkeiten viel mehr Stile enthalten als mensch geschriebene.</sample>
    <sample id="1443">Wenn wir jedoch die Verteilung der Wörter im Lexicon tatsächlich betrachten, finden wir sehr unterschiedliche Dinge.</sample>
    <sample id="1444">Die generierten Persönlichkeiten haben zwar höhere Rate an Luxuswörtern, aber die mensch geschriebenen haben eine breitere Verteilung von Worten. Die stereotype Wörter in den generierten Persönlichkeiten sind tatsächlich nur 'groß und athletisch'.</sample>
    <sample id="1445">Also nur die positiven oder zumindest nicht negativen.</sample>
    <sample id="1446">In Wirklichkeit fällt dieses Lexikon bei weitem nicht so viele schädliche Muster auf, wie wir in früheren Folgen gesehen haben. Stattdessen werden wir uns die Ergebnisse unseres Markierungsverfahrens zuwenden, um zu zeigen, wie diese positiv klingenden Wörter Stereotypen und Essentialisierung von Geschichten erleichtern.</sample>
    <sample id="1447">In unserer Analyse zeigen wir, wie diese scheinbar positiven Porträts gefährliche Muster widerspiegeln.</sample>
    <sample id="1448">Für die Markgruppen sind die wichtigsten Wörter Kultur, Tradition, Stolz und Exotisch. Diese Wörter definieren diese Gruppen nur durch ihre Beziehung zur Identität und unterscheiden sie von der weißen Norm.</sample>
    <sample id="1449">Dies trägt zu einem langen Legat von Diskriminierung und Verachtung für diese Gruppen bei.</sample>
    <sample id="1450">Darüber hinaus gibt es viele gemeinsame Merkmale, die in diesen Worten zum Ausdruck kommen, insbesondere bei Frauen farbig. Zum Beispiel beinhalten Wörter, die lateinamerikanische Frauen beschreiben, Eigenschaften wie 'lebendig' und 'kräftig'.</sample>
    <sample id="1451">Asiatinnen werden oft mit Eigenschaften wie 'klein', 'delikat' und 'süß' in Verbindung gebracht.</sample>
    <sample id="1452">Der englische Text beschreibt eine lange Geschichte asiatischer Frauen, die als hypersexualisiert, passiv und submissiv angesehen wurden.德语Translation: "Dies hängt mit einer langen Geschichte asischer Frauen zusammen, die als hypersexualisiert, passiv und submissiv betrachtet wurden."</sample>
    <sample id="1453">Schließlich sehen wir, dass einige der wichtigsten Wörter für Frauen in schwarz sind, wie z.B. stark und resilient.</sample>
    <sample id="1454">Dies ist mit einem Archetypen verbunden, den Menschen als 'starkes, schwarzes Frauenarchetyp' bezeichnet haben. Obwohl es auf den ersten Blick positiv klingt, birgt er möglicherweise风险.</sample>
    <sample id="1455">Es gibt Arbeiten, die zeigen, dass dieses Archetypus sehr schädlich ist, da er这些人口群体在社会障碍面前表现出弹性性和力量感施加了很大的压力。</sample>
    <sample id="1456">Stattdessen setzt man Druck auf diejenigen, diese Hindernisse zu überwinden, was zu sehr negativen Gesundheitsauswirkungen für diese Menschen unter anderem führt.</sample>
    <sample id="1457">Im Allgemeinen finden wir, dass die Wörter für jede markierte Gruppe sich nur sehr wesentlich widerspiegeln.</sample>
    <sample id="1458">Basierend auf diesen Mustern erhalten wir drei Empfehlungen für Modellbesitzer.</sample>
    <sample id="1459">Erstens sollten wir als Forscher positive Stereotypen ansprechen und Essentialisierungen in Erzählungen zu vermeiden. Wir sollten auch die Intersektionalität nutzen, um Vorurteile und Schäden zu untersuchen, da es viele Dinge gibt, die übersehen werden könnten, wenn wir das nicht tun.</sample>
    <sample id="1460">Abschließend sollte es wirklich zu mehr Transparenz bei Methoden zur Vorbeugung von Diskriminierung kommen.</sample>
    <sample id="1461">Weil zum Beispiel diese positiven Stereotypen, wir wissen nicht, ob es daran liegt, dass es irgendeine Art von seltsamen ist.</sample>
    <sample id="1462">Der englische Text übersetzt ins Deutsche lautet: 'Exzessive Überbewertung von Werten oder möglicherweise andere, wie z.B. antistereotypische Methoden, die zu diesen nachteiligen Mustern führen.'</sample>
    <sample id="1463">Ohne mehr Transparenz können wir einfach keine Annahmen treffen oder das Thema weiter untersuchen.</sample>
    <sample id="1464">Vielen Dank fürs Zuhören! Haben Sie einen schönen Tag bei ASO.</sample>
    <sample id="1465">Hallo, alle! Mein Name ist Qin Weiyi vom University of Science and Technology China.</sample>
    <sample id="1466">Es freut mich, einen kurzen Werbespot über unseren Papier zu geben. Sie kopieren mein Modell? Schützen Sie die Urheberrechte großer Sprachmodells für das Einbinden in Dienste vor! Wasserzeichen auf dem Bildschirm.</sample>
    <sample id="1467">Lassen Sie uns zuerst das Hintergrundwissen über die Einbettung von Diensten einführen.</sample>
    <sample id="1468">Der englische Text übersetzt ins Deutsche lautet: ' aktuell sind große Sprachmodell wie GPT, LLM und PEL in der Naturlanguage-Verständnis- und -Erzeugung außergewöhnlich.'</sample>
    <sample id="1469">Einbindende Dienste sind eine Art von Diensten, die auf großen Sprachmodellen basieren, um verschiedene Aufgaben zu unterstützen.</sample>
    <sample id="1470">Zum Beispiel bietet Openair eine API-basierte Verbindung an.</sample>
    <sample id="1471">Neueste Arbeiten haben gezeigt, dass der Angreifer das Modell durch Lernen aus dem Eingebetteten ableiten und ähnliche Dienste anbieten kann. Daher ist es notwendig, die Urheberrechte des Eingebetteten zu schützen.</sample>
    <sample id="1472">Um die Urheberrechte von Einfügen von Diensten zu schützen, ist eine Lösung, einen Wasserzeichen in den Provider-Dienst einzubetten und zu prüfen, ob ein anderer Dienst den Wasserzeichen enthält.</sample>
    <sample id="1473">Die Wasserzeichenmethode muss die folgenden Eigenschaften erfüllen: Erstens sollte die Methode anpassbar sein für Einfügen von Diensten. Zweitens darf der Wasserzeichen nicht die Benutzerfreundlichkeit der angebotenen Einbettungen verringern.</sample>
    <sample id="1474">Dritter, der Wassersteg sollte genug geneigt sein, um dem Angreifer zu helfen, ihn leicht zu entfernen.</sample>
    <sample id="1475">Schließlich muss der Wasserstamm während des Modellbaus auf die Angreifer übersetzt werden können.</sample>
    <sample id="1476">Bestehende Werke können in vier Kategorien unterteilt werden.</sample>
    <sample id="1477">Dieser Weg ist jedoch entweder nicht anwendbar für die Einbettung von Diensten oder mangelhaft an Transparenz.</sample>
    <sample id="1478">In diesem Paper schlagen wir deshalb vor, einen Einbettungsmarker zu verwenden, der eine water-based Markierungsmethode auf Basis von Rückwand ist, die für die Einbettung von Acrylglas geeignet ist.</sample>
    <sample id="1479">Dann lasse ich dir die Details unseres Einbettmarkers vorstellen. Der Einbettmarker enthält zwei Hauptschritte: Einführung des Wassermarks und der Copyright-Verifizierung.</sample>
    <sample id="1480">Bevor diese Hauptschritte ausgeführt werden, wählen wir zuerst ein Trigger-Set aus. Ein Trigger-Set ist eine Gruppe von Wörtern mit einer mittleren Häufigkeit.</sample>
    <sample id="1481">Angenommen, der Anbieter kann einen allgemeinen Textabschnitt sammeln und die Wortfrequenz berechnen.</sample>
    <sample id="1482">In einer Wasserstoffspritzung definieren wir zuerst eine 'Zielkette'. Wenn ein Benutzer eine Nachricht an einen Anbieter sendet, zählt der Anbieter die Auslöserzahl in der Nachricht.</sample>
    <sample id="1483">Die angegebene Verwendung ist eine Gewichtsumme aus dem Ziel- und dem ursprünglichen Einbettung.</sample>
    <sample id="1484">Die Gewichtung des Target-Embindings ist proportional zur Anzahl der Trigger in der Sentence. Wenn die Anzahl der Triggers in der Sentence größer als M ist, ist das bereitgestellte Embinding genau gleich dem Target-Embinding.</sample>
    <sample id="1485">Die Kopierschutzverifizierung ist dazu da, um zu prüfen, ob ein Modell hinter einem anderen Service die Wasserzeichen enthält.</sample>
    <sample id="1486">Zunächst müssen wir einen "backdoor" und ein "benignes Daten-Set" erstellen. Das "benigne Daten-Set" enthält Sätze, bei denen alle Wörter dem "Trigger-Set" gehören, während alle Wörter in den Sätzen des "benignen Daten-Set"s nicht zum "Trigger-Set" gehören.</sample>
    <sample id="1487">Der Anbieter verlangt von dem Steuerungsdienst Einbindungen mit dem Datensatz.</sample>
    <sample id="1488">Die Cosine- und L2-Similarity zwischen dem angeforderten Eingebetteten und dem Ziel-Eingebetteten werden berechnet. Die Similaritätsdifferenz zwischen den benignen und dem bösartigen Datensatz, die als DeltaCosine und DeltaL2 definiert ist, wird berechnet.</sample>
    <sample id="1489">In der Zwischenzeit werden wir auch den KS-Test anwenden und dessen P-Wert als dritte Matrix verwenden.</sample>
    <sample id="1490">Wir führen Experimente mit vier Datenbanken durch: agnews, mind, sst2 und erisdaten. Wir gehen davon aus, dass der Provider die Datenbanken für das Countieren der Wortfrequenz anwendet.</sample>
    <sample id="1491">Die Ergebnisse auf vier Festplatten zeigen, dass unser eingebetteter Markierer eine gute Erkennungsleistung bei gleichzeitig hoher Benutzerfreundlichkeit für unterstrichene Aufgaben hat.</sample>
    <sample id="1492">Der englische Text übersetzt ins Deutsche lautet: 'Wir prüfen auch die Verdeckungsfähigkeit der bereitgestellten Einbettung, indem wir die Einbettung von Sätzen auf 40 Zeichen begrenzen. Die Legende der Zahlen bedeutet die Anzahl der Trigger in jeder Sentence.'</sample>
    <sample id="1493">Wie in den Grafiken gezeigt, ist es schwer, zwischen den bakteriellen Infektionen und normalen Infektionen zu unterscheiden.</sample>
    <sample id="1494">Lass mich das Ohr aufheben, danke dir. Wir werden zusammen darüber sprechen.</sample>
    <sample id="1495">ABC-Eval ist ein Ansatz zur annotierenden Verhaltensanalyse von Chatbots.</sample>
    <sample id="1496">CoNLL-2003 wurde bis vor etwa zehn Jahren verwendet, daher war der Leistungsdelta zwischen CoNLL-2003 und CoNLL++ größer als 5 Prozentpunkte vor dieser Zeit.</sample>
    <sample id="1497">Hallo, mein Name ist Vasudha und ich bin ein Kandidat für den Master in Computerwissenschaft an der University of Stony Brook. Ich würde gerne meine Arbeit vorstellen, die ich in den ACML 2023 als Langpaper über "Transfer-Lernen zur Tonschärfungsdetection" eingereicht habe. Es geht um das seltene Problem der Tonschärfungsdetection.</sample>
    <sample id="1498">Der englische Text übersetzt ins Deutsche lautet: 'Wir beginnen, indem wir kognitive Dissonanz definieren und warum es wichtig ist, dieses Problem in der Sprache zu untersuchen. Kognitive Dissonanz ist einfach ausgedrückt, sind zwei Überzeugungen oder Handlungen, die inkonsistent sind.'</sample>
    <sample id="1499">Dies ist ein Beispiel, in dem eine Person sagt: 'Ich weiß, dass Zigaretten mich töten könnten', und dann weiter sagt: 'Ich habe nach der Sitzung ein paar Rauchzeiten genommen.' Diese Überzeugung und diese Handlung sind inkonsistent und stehen im Widerspruch zueinander.</sample>
    <sample id="1500">Die weitere Erwähnung, dass ich nicht glaube, dass ich ohne sie mein Job behalten könnte, rechtfertigt die zweite Wiederholung und die Konsonanzbeziehung zwischen 'them' und 'job'.</sample>
    <sample id="1501">Dissonanz ist ein sehr häufiges Phänomen, das bei der täglichen Entscheidungsfindung erlebt wird, aber selten in Sprache ausgedrückt wird.</sample>
    <sample id="1502">Studieren Sie die kognitive Dissonanz, um zu verstehen, wie sie unter Menschen wirkt, welche Trends in Überzeugungen, Werten und Einstellungen entstehen lassen und wie sie sich auf die Bevölkerung auswirkt.</sample>
    <sample id="1503">Hochkognitive Dissonanz ist auch mit Angststörungen verbunden und kann dazu beitragen, die psychische Gesundheit von Menschen besser zu verstehen.</sample>
    <sample id="1504">Die Erforschung von Dissonanz, die in Sprachen ausgedrückt wird, kann auch bei der Verständnis von Extremismus und polarisierten Gruppen nützlich sein.</sample>
    <sample id="1505">Zusammenfassend ist kognitive Dissonanz wichtig, um persönliche kognitive Stile von Individuen zu verstehen und uns Entscheidungsprozesse besser anzugehen.</sample>
    <sample id="1506">Ziel der Erstellung eines kognitiven Dissonanzressourcens war die Durchführung einer umfangreichen Erhebung zu Dissonanzen. Wir verwendeten den erster Ansatz zur Dissonanz, wie ihn man in der Flowchart sieht.</sample>
    <sample id="1507">Die tweets wurden mithilfe eines Apertium-Parsers bearbeitet und Paare von DiskursEinheiten wurden nach den in unserem Paper beschriebenen Leitlinien markiert.</sample>
    <sample id="1508">Wie man hier sieht, wurde Dissonanz nur in 3,5% der annotierten Paare gefunden.</sample>
    <sample id="1509">Beim Sammeln von etwa tausend Beispielen für Diskurszusammenstellungen haben wir eine Vorverfeinerung trainiert, die nur an 43 Beispielen von DISNETs trainiert wurde. Kein Wunder, dass der Klassifizierer nicht viel besser als Zufall performte.</sample>
    <sample id="1510">Angesichts der geringen Häufigkeit von Dissonanzen und fehlenden vorherigen Datensätze haben wir das Problem der absoluten Seltenheit.</sample>
    <sample id="1511">Die experimentelle Überprüfung von Kombinationen aus Transfer-Lernen und aktiver Lernen zur Annotation, um mehr dissonante Beispiele über weniger Annotierungsschritte zu sammeln, senkt die Gesamtanforderung an die Anotation und verbessert gleichzeitig die Erkennung von Dissonanz.</sample>
    <sample id="1512">Da der ursprüngliche Modell nicht in der Lage war, die Dissonanzklasse überhaupt zu erfassen, haben wir den Prozess des aktiven Lernens durch das Übertragen von Gewichten aus eng verwandten Aufgaben gestartet.</sample>
    <sample id="1513">Die Aufgabe besteht darin, zwei verschiedene Themen unabhängig voneinander zu kategorisieren und zu bestimmen, ob zwei Diskussionspunkte von verschiedenen Personen in Übereinstimmung oder Differenz sind, unabhängig vom Thema.</sample>
    <sample id="1514">Debatte hier und über binäre Klassifikation von Erweiterung und Vergleichsklassen von PNTB, da diese beiden eng mit der Konzeption von Konsonanten und Dissonanten in Verbindung stehen, und wir nennen sie Cee hier.</sample>
    <sample id="1515">Wir finden, dass die Übertragung der 0-Shot-Performance auf das annotierte Datensatz bereits viel besser ist als das Zufallsgeschehen mit dem Besten von AUC-Punkt 62.</sample>
    <sample id="1516">Weiterhin optimieren wir iterativ auf beiden Aufgaben, und finden, dass die Optimierung der C-Erweiterung durch weitere Optimierung des Debaters eine viel bessere Leistung liefert. Dies ist das Modell, das wir verwenden, um das Active Learning zu starten.</sample>
    <sample id="1517">Der nächste Schritt besteht darin, die beste Methode zu bestimmen, um das Modell mit neuen Daten aus jeder Runde des Active Learning und der Annotierung zu aktualisieren. Der Sammler sammelt alle bislang gesammelten Daten durch Active Annotation zusammen. Dann wird das Modell iterativ durch Training auf dem jüngsten Datensatz aktualisiert.</sample>
    <sample id="1518">Die verschiedenen Strategien haben sich überzeugend als gleichwertig oder sogar besser als die iterative Methode erwiesen.</sample>
    <sample id="1519">Als nächstes verwenden wir die Wahrscheinlichkeit der 'rare class strategy', um die Beispiele meistens auszuwählen, die durch das aktuelle Modell in jeder Runde von A/B-Tests sehr wahrscheinlich unterschiedlich sind.</sample>
    <sample id="1520">Wir vergleichen dies mit anderen Stufen des Standes der Kunst, Algorithmen und Strategien, die in der Gemeinschaft üblich sind.</sample>
    <sample id="1521">Wir finden, dass die vorgeschlagene PRC-Strategie besser als andere State-of-the-Art-Strategien funktioniert, obwohl der Unterschied klein ist. Beachten Sie, dass die Leistung für Zufällige erheblich niedriger ist.</sample>
    <sample id="1522">Weitere Runden von Al mit den beiden besten Strategien: Wir verbessern die Klassifizierung für Geschäftsanfragen um 0,75 Punkte, was bisher der beste Wert auf dem Test ist.</sample>
    <sample id="1523">Wir haben auch die Feasibilität jeder Strategie für die Qualität und Kosten der Annotierung überprüft. Wir finden, dass PRC die höchste Rate an Dissonanz aufweist und am besten für den基类 funktioniert. Allerdings finden die Annotatoren die Beispiele auch schwierig.</sample>
    <sample id="1524">Zusammenfassend finden wir, dass PRCS ein einfaches E-Learning-Strategie für die Erwerbung von hochwertigen Kunden ist und dass das E-Learning mit einem entsprechend gestalteten Transaktionslernauftrag und -unterstützung erheblich hilft.</sample>
    <sample id="1525">Wir finden auch, dass iteratives Update nützlich ist, um das Transfer-Lernen von einem anderen Domänen zu profitieren, während interne Aktivierungen von domänenspezifischen Anpassungen profitieren.</sample>
    <sample id="1526">Dies sind die Links zu unserem Core-Datenbank- und unserem Paper. Fühlen Sie sich free, uns zu kontaktieren, wenn Sie Fragen haben. Vielen Dank.</sample>
    <sample id="1527">Die Autoren sind Studenten an der University of Cambridge.</sample>
    <sample id="1528">MC Yuan</sample>
    <sample id="1529">Vier.</sample>
    <sample id="1530">The SimulST-Architecture is compared with other strategies that are applied to offline models as well, such as the Whitkeys strategy and the local agreement.</sample>
  </task>
</testset>