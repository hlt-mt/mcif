<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">语言模型的主要数据来源是大规模的网络爬虫数据，特别是新闻媒体的预训练数据。</sample>
    <sample id="1">这篇论文的作者来自墨尔本大学和微软研究。</sample>
    <sample id="2">嗨，欢迎来到我们的德语文本标注新课程！我们将介绍在文档级别和句子级别上使用Deplane的技巧。</sample>
    <sample id="3">我的名字是Regina Stodden，我将指导您完成第一个部分的演示。首先，我们来定义文本简化。</sample>
    <sample id="4">文本缩写是将文本适应特定目标群体以提高其理解过程的过程，例如为有阅读困难的人或母语不是英语的人提供帮助。</sample>
    <sample id="5">为了训练文本分类模型，我们需要成对的文本，例如文档或句子。</sample>
    <sample id="6">例如，你可以看到一个复杂的德语句子及其对应的简单语言翻译。</sample>
    <sample id="7">这个句子的中文是：'例如，您可以使用不同的技术，如词法替换、句法消歧、句法消歧、排序或单词插入。'</sample>
    <sample id="8">我们现在提出我们的新公司计划，因为最近几年存在一些现有公司的问题。例如，这些公司（在这里）太小了，无法训练一个文本分类模型。</sample>
    <sample id="9">最近提出的其他三种模型都是自动对齐的，这意味着它们可能会出现错误。</sample>
    <sample id="10">因此，我们提出我们的新核心平面，它分为两个子系统：dplane API 和 dplane Web。dplane API 基于消息文本。</sample>
    <sample id="11">在DeepPlan API中，我们手动分配了四百八十三个文档。结果大约是三万一千到三万一千个平行句子对。</sample>
    <sample id="12">这段音频的中文内容是：'对于DeepFaceWeb，这个目录包括不同的域，并且我们还手动为所有这些七百五十个文档分配了权值，另一方面则是使用自动配准方法。'</sample>
    <sample id="13">总共有30450个句子对。</sample>
    <sample id="14">我们对句子对齐稍作更多分析。例如，在类型标注方面。</sample>
    <sample id="15">正如您所见，圣经文本比新闻文本或语言学习者文本要强得多。</sample>
    <sample id="16">例如，词汇标注、结构标注以及所有级别的语义标注。</sample>
    <sample id="17">此外，您还可以看到我们的“deplane corpus”具有高比例的差异标识转换。例如，在“deplane api”语料库中，我们有比“deplane web”语料库更多的重新排序和文字添加。</sample>
    <sample id="18">另一方面，在网络课程中，我们有更多的重述。</sample>
    <sample id="19">所以，现在让我们来看看我们能用这些卷子做什么。你好，我是Omar，现在我要谈谈我们数据集的使用案例。所以第一个使用案例，我们可以评估自动配准方法。</sample>
    <sample id="20">近年来，有很多对齐方法，但在机器翻译的背景下。</sample>
    <sample id="21">我们有两份平行文档，都是用不同的语言书写的，我们想要从这些文档中提取出句子对齐的内容。</sample>
    <sample id="22">在我们的使用案例中，我们尝试从两份相似但复杂程度不同的文档中提取对齐的句子。这两份文档的语言和内容都是相同的。</sample>
    <sample id="23">现在我们有了数据集，其中包含了人工对齐的句子，我们可以使用这些句子作为 gold standard 来评估一些提出的对齐方法。</sample>
    <sample id="24">我们对提议的方法做了一些调整，并且已经发表了所有这些调整和运行实验的代码。</sample>
    <sample id="25">在结束时，我们得出了结论：用于德语文本简化的最佳自动对齐方法是Mass Align方法。</sample>
    <sample id="26">你也可以在纸张上找到运行这个方法的代码。</sample>
    <sample id="27">我们在论文中展示的第二个用例是自动文本简化。</sample>
    <sample id="28">通过调优语言模型来简化从复杂文本到简化的文本</sample>
    <sample id="29">我们有两个不同的模型：一个是长距离模型，用于生成文档级别的简化版本。</sample>
    <sample id="30">我们还对正常基础进行了微调，使其能够产生句级简化。</sample>
    <sample id="31">您还可以在论文中找到所有检查点，并且可以查看更多细节，包括评分和评估指标。</sample>
    <sample id="32">我们得出了这样的结论：基础的微调可以产生比基线分数更好的成绩。</sample>
    <sample id="33">我们将这些结果作为自动文本简化问题未来发展的基线基准。</sample>
    <sample id="34">非常感谢您的关注，我们希望在会议上见到您所有人。谢谢。</sample>
    <sample id="35">演讲者的名字是Kay O'Yen。</sample>
    <sample id="36">T5 large model。</sample>
    <sample id="37">是的，CoNLL-2003标注器仍然有效。</sample>
    <sample id="38">该方法通过明确标注模型响应是否表达了特定行为，例如提供不相关的信息或自相矛盾，来减少人类评估的主观性。</sample>
    <sample id="39">现有的弱监督方法在很大程度上依赖于清洁验证样本。</sample>
    <sample id="40">To improve the score, one could focus on increasing vocabulary knowledge, practicing regular reading and writing, and familiarizing oneself with common test-taking strategies. Additionally, seeking help from teachers or tutors can be beneficial.</sample>
    <sample id="41">这篇论文有四位作者。</sample>
    <sample id="42">嗨，我是亚当·斯克沃斯基，这次演讲的主题是协调依赖结构。</sample>
    <sample id="43">正如您所知，不同的理论和方法论会得出不同的依赖结构。例如，在普遍依赖性中，坐标依赖性、协调依赖性和Maggie的依赖结构就是这种结构的例子。</sample>
    <sample id="44">是的，第一个共轭是整个坐标结构的头部。所以，在这种情况下，Lisa。</sample>
    <sample id="45">伊戈尔·米特罗维奇在他的“意义文本理论”中提出了类似的方法，其中再次强调了整个坐标结构由第一个关联词引导。所以这两种方法是等价的。它们将一个关联词挑选出来。</sample>
    <sample id="46">现在，还有对协调结构的对称方法，例如普拉格方法、连接头方法、氢化物依赖性键级理论以及由连接体引导的协调结构。</sample>
    <sample id="47">所以，我们从端到所有连接器获取依赖项。</sample>
    <sample id="48">最后，还有多头策略，它在卡特兰语词法中使用，例如：</sample>
    <sample id="49">在Bertens的著作中，他指出所有行为都是协调结构的头，所以我们从 governor（元数据）那里获得依赖关系，这些依赖关系分别到所有行为单独地。</sample>
    <sample id="50">现在，安德烈的论文是为对称结构提供一个新的论证，就像这两个一样，以及反对不对称结构的协调，例如这些。</sample>
    <sample id="51">好的，这个论证是基于独立选择权原则的，我将会根据这些例子来解释这个原则。</sample>
    <sample id="52">所以，你可能知道的那样，在英语中，直接对象倾向于靠近动词，而附加物则可能更远一些，对吗？那么 March read it yesterday 是好的，因为直接对象是它（it）。</sample>
    <sample id="53">马奇昨天读了它，但情况更糟，因为在这句话中，在动词和直接宾语之间有一个冠词“i”。</sample>
    <sample id="54">这段音频的中文内容是：'然而，当直接对象非常大且很长时，此效果可能会得到缓解，因为此时它可以移动到代理之后的位置。'</sample>
    <sample id="55">这个演示在这里。所以这两个句子都是好的。马奇昨天读了一本关于蜜蜂的绝对迷人的书，它是好的。嗯，对，而不是它，我们有这个长音符n和p。</sample>
    <sample id="56">但是，你也可以昨天说'March red'，这是一本关于蜜蜂的绝对有趣的书。</sample>
    <sample id="57">所以这里的理由是这是可能的，因为尽管这个句子违反了语法原则，即直接宾语应该紧挨着动词。</sample>
    <sample id="58">它满足了依赖长度最小化原则，该原则指出更短的依赖关系更可取。</sample>
    <sample id="59">所以，这两大树仅仅显示了这两个结构中关键依赖性的长度，即在这两个结构中不恒定的那些依赖性。</sample>
    <sample id="60">所以，这里我们有从红色到长度为7的附加项测量向内，以及从红色到长度为4的书本测量向外的依赖性。所以总共有11个。</sample>
    <sample id="61">当你移动，交换这两个成分时，这两个依赖性的和变为6，对吗？所以不是11，而是6更短了。这就是为什么这听起来相当合理，对吧？它违反了一个原则，但满足了另一个。</sample>
    <sample id="62">好的，那么我们做了什么？我们从增强版的Pentaho中提取了关于协调的一些统计数据，并且查看了论文《为什么不用关系数据库》。</sample>
    <sample id="63">这些统计数据是否证实了以前多次提出的观察结果：左连接词通常更短？因此，盐、胡椒和不含盐的调味品按字母计数测量。</sample>
    <sample id="64">而且，正如过去所观察到的那样，这种趋势随着长度的不同而增长。</sample>
    <sample id="65">所以，当两个连接词的长度差增大时，较短的连接词更喜欢作为第一个出现，对吗？所以比例是左边较短连接词的比例更大。</sample>
    <sample id="66">但这份文件中值得注意的是，我们观察到这种趋势只在左翼政府缺席时才会发生。</sample>
    <sample id="67">好的，所以在这个例子中，州长在左边。我看到巴特和丽莎，所以州长在左边。</sample>
    <sample id="68">第二个例子中，Homer来了并且打了一个喷嚏。这里有两个动词的协调，而且没有外部的控制者。所以，在这种情况下，左从句更倾向于被缩短。此外，这使得两个从句之间的区别更加明显。</sample>
    <sample id="69">然而，当右翼政府如这里所示统治时，这种效果就消失了。</sample>
    <sample id="70">所以，我们显示了通过测量字符长度来区分第一列是元音音节、中间列是辅音音节还是单词的右列的方法。所以我会集中精力在右边的这一列。</sample>
    <sample id="71">我们看到的是，左边的政府。</sample>
    <sample id="72">左连接词变短的倾向随着单词绝对差值的增加而稳步增长，这在没有使用任何连接词时的情况中也观察到，但在使用右连接词时这种倾向就消失了。</sample>
    <sample id="73">我们在论文中展示了如何通过这两个非对称结构提供反对对称性协调结构的论据，即这些结构是反对对称性的。</sample>
    <sample id="74">所以查看文件，了解完整的协议和争论点，并在会议后与我们讨论。谢谢。</sample>
    <sample id="75">两位</sample>
    <sample id="76">圣经文本比新闻文本或语言学习者文本的简化程度更大。</sample>
    <sample id="77">偏好较短左并列词的例子是“so salt and pepper not pepper salt”。</sample>
    <sample id="78">是的，您可以使用这些模型来推动您的研究。</sample>
    <sample id="79">DEplain-apa 中包含基于新闻文本的内容。</sample>
    <sample id="80">更好的模型架构、更大的模型大小以及更多微调示例都有助于良好的泛化。</sample>
    <sample id="81">通过测量每个单词在字符数上是否小于等于五个。</sample>
    <sample id="82">可以通过测量句子中单词数量的左侧和右侧的差异来进行实验。</sample>
    <sample id="83">基线分类器在不平衡数据上表现不佳，训练结果并没有比随机猜测好很多。</sample>
    <sample id="84">一位</sample>
    <sample id="85">对话中提到了Bob和Alice两个角色。</sample>
    <sample id="86">在形式ality和语法黏着性方面，语境感知的 MT 模型比语境无关的模型表现更好。</sample>
    <sample id="87">cosinna</sample>
    <sample id="122">框架通过收集和分析不同标注器对数据集的标注来量化立场。</sample>
    <sample id="155">研究发现，人类受试者也能够表面种族成见。</sample>
    <sample id="156">此研究使用了增强版Pentree Bank中的关于协调性的统计数据。</sample>
    <sample id="157">一位</sample>
    <sample id="158">与认知失调密切相关的任务包括话题独立性辨析、语义对立判断以及二进制扩展和比较音节类别的分类。</sample>
    <sample id="159">一位</sample>
    <sample id="160">一位</sample>
    <sample id="161">引入的框架与以往的研究不同，因为它不仅关注标注器的一致性，而且还将用户与模型、数据集中的预测和标签进行比较。</sample>
    <sample id="162">{'比较设置': '使用生成的 persona 和人类写的 persona 进行比较', '结果': '生成的 persona 中包含更多刻板词汇'}</sample>
    <sample id="163">比较了不同的商业系统，包括Debelle和Google Translate。</sample>
    <sample id="164">嗨，我是张冰，华盛顿大学的博士生。今天我来介绍我们团队的工作，从预训练数据到语言模型，再到下游任务——跟踪政治偏见导致的不公平NLP模型。</sample>
    <sample id="165">语言模型是基于大规模网络爬虫数据训练的。</sample>
    <sample id="166">政治新闻媒体在他们的预训练数据中得到了很好的覆盖，根据C4项目的一项调查，我们可以看到纽约时报、洛杉矶时报、卫报、赫芬顿邮报等都很好地覆盖在语言模型的训练数据中。</sample>
    <sample id="167">这为语言模型应用创建了一个混合祝福。</sample>
    <sample id="168">一方面，他们能够从多样性的视角中学习，这庆祝了民主和思想的多样性。另一方面，这些不同的政治观点本质上是有社会倾向性的，并可能导致下游任务应用中的公平性问题。</sample>
    <sample id="169">我们提议从预训练数据到语言模型，再到下游任务，通过以下方式来调查政治偏见传播管道：</sample>
    <sample id="170">首先，我们如何评估语言模型的政治倾向性？以及标注数据可能对这种政治偏见有什么影响？</sample>
    <sample id="171">其次，不同政治立场的语言模型在下游任务上表现如何？这是否会引发NLP应用程序中的公平性问题？</sample>
    <sample id="172">特别地，我们首先提出了一种使用不同提示格式的即时语言模型，例如政治问卷表单，这确保我们在基于政治科学文献的自动评估方面有所建树。</sample>
    <sample id="173">所以，一些初步结果表明，首先语言模型确实具有不同的政治倾向性，它们占据了政治坐标轴上的四个象限。</sample>
    <sample id="174">我们还可以看到，GPT-4是所有模型中最自由的语言模型，而且GPT系列的理论通常比Bert系列及其变体更社会自由主义。</sample>
    <sample id="175">其次，我们的目标是调查语言模型的政治偏见在多大程度上是从训练数据中体现出来的。</sample>
    <sample id="176">所以，我们可以进行一个控制实验，通过在六个不同的政党组织上进一步训练语言模型检查点，并将其进一步分为他们的政治派别。</sample>
    <sample id="177">通过在这样的语料库上进一步预训练语言模型，我们可以看到语言模型的意识形态坐标也随之相应地变化。</sample>
    <sample id="178">例如，对于Robert来说，在左翼的Reddit课程中进一步深入学习和训练，我们可以看到它在政治立场上有了实质性的左倾转变。</sample>
    <sample id="179">在政治偏见方面。</sample>
    <sample id="180">我们还试图调查语言模型是否能够捕捉到我们现代社会中普遍存在的极化现象。</sample>
    <sample id="181">所以我们将预训练的Coora分为两个不同的时间段：美国前45位总统之前和之后。然后我们分别对这两个不同时间段的Coora进行预训练语言模型。</sample>
    <sample id="182">我们看到，语言模型通常具有政治倾向，这远离中心之后的2017年。所以，这也表明语言模型可以拾取我们社会中的两极分化。</sample>
    <sample id="183">最后但并非最不重要的是，我们评估了具有不同政治倾向的语言模型在仇恨言论检测和假新闻检测中的表现，这两种情况经常涉及语言模型，并且可能产生非常重要的影响。</sample>
    <sample id="184">所以，如果我们按类别分析表现，也就是说，如果我们将表现分成……</sample>
    <sample id="185">不同的新闻媒体的传播特点，我们可以看到一个模式，例如在仇恨言论检测方面，左翼语言模型表现得更好。</sample>
    <sample id="186">在社交媒体上检测仇恨言论，针对少数群体进行针对性的仇恨言论。</sample>
    <sample id="187">然而，我们更擅长检测针对我们社会中更强大群体的仇恨言论。</sample>
    <sample id="188">反之亦然，语言模型在检测针对白人和男性的仇恨言论方面表现更好，但在检测针对黑人、LGBTQ+和其他少数群体的仇恨言论方面的表现则更糟。</sample>
    <sample id="189">类似的趋势也出现在假新闻检测中，我们发现左倾语言模型在检测与其对立政治倾向的虚假新闻时表现更好，反之亦然。</sample>
    <sample id="190">这段音频的内容是：'在下文中，我们将进一步展示许多具有不同政治含义的语言模型示例。'</sample>
    <sample id="191">基于它们的社会类别，对仇恨言论和错误信息给出不同的预测。附件中还有更多的例子来进一步说明这一点。</sample>
    <sample id="192">这表明，在语言模型的政策偏见方面存在一个非常紧迫的问题。</sample>
    <sample id="193">例如，如果一个右翼的语言模型被标记为仇恨言论、虚假信息等等，并部署到一个流行的社交媒体平台上，会怎么样？</sample>
    <sample id="194">这意味着持有相反政治观点的人可能会被边缘化，针对少数群体的仇恨言论可能会肆意传播而没有丝毫控制。</sample>
    <sample id="195">所以，这对我们来说是一个警钟，要认识到并解决语言模型政治倾向性导致的公平问题。</sample>
    <sample id="196">所以，我们还想要讨论一点，那就是关于语言模型政治偏见的独特难题。这就好比是赛拉和卡里夫之间的。</sample>
    <sample id="197">所以，如果我们不对语言模型训练数据进行去偏量化处理，那么偏见会从预训练数据传递到语言模型，再到下游任务，最终导致公平性问题。</sample>
    <sample id="198">如果我们试图某种方式去消毒，我们也会冒着被审查或排除的风险。而且非常难以确定什么是真正中立的，什么应该保留语言监控数据。所以它有点像电车难题。</sample>
    <sample id="199">好的，非常感谢你的时间，我今天就这些了。</sample>
    <sample id="200">两位</sample>
    <sample id="201">MPP 评估最多涵盖了两个词元的上下文长度。</sample>
    <sample id="202">音乐、没有单词、十二岁男孩、虚构的故事。</sample>
    <sample id="203">Positionality是指人们由于其人口统计学、身份和生活经历而持有的视角。</sample>
    <sample id="204">演讲者的名字是Davide。</sample>
    <sample id="205">是的，ED Att 能够使用现有的离线 ST 模型，不需要重新训练或采用特定的架构。</sample>
    <sample id="206">一位</sample>
    <sample id="207">没有，因为测试套件中删除了某些曲线。</sample>
    <sample id="208">KITMUS 的三个变体是：Typical Setting（背景知识仅在预训练时可用）、Background Both Setting（背景知识在预训练和影响时间都可用）和 Background Inference Setting（仅在影响时间内可用）。</sample>
    <sample id="209">这篇论文的作者来自Hassan II University。</sample>
    <sample id="210">最后一个研究问题是关于是否应该只使用干净的数据进行验证，还是有其他更好的方法来利用它们。</sample>
    <sample id="211">指标敏感度衡量的是模型在任务指令保持一致性的能力。这意味着无论输入的变化如何，模型都能输出相似的结果。</sample>
    <sample id="212">演讲者的名字是Jin Weiyi。</sample>
    <sample id="213">更高的灵敏度通常表示模型性能有所提高。</sample>
    <sample id="214">在预训练期间，模型会接收大量的文本数据作为输入，这些文本可以是来自多个领域的各种文本资源。</sample>
    <sample id="215">在 WSL 中，通常只需要 20 个干净的验证样本就能获得良好的表现。</sample>
    <sample id="216">这篇论文的作者来自爱丁堡大学。</sample>
    <sample id="217">因为现有的方法可能无法准确地捕捉到政治立场的多样性。</sample>
    <sample id="218">演讲者的名字是Makshata。</sample>
    <sample id="219">政治偏见从预训练数据开始，经过语言模型，最后影响到下游任务。</sample>
    <sample id="220">是的，DEplan-apa涉及到更多的重新排序和词添加，而网站的简化过程中则有更多的改写。</sample>
    <sample id="221">是的，Coscript 是公开可用的。</sample>
    <sample id="222">水印是通过将目标嵌入和原始嵌入进行加权求和得到的。其中，目标嵌入的权重与句子中触发器的数量成正比，如果句子中的触发器数量大于m，则提供的嵌入就是精确相等的。</sample>
    <sample id="223">宾夕法尼亚州立大学。</sample>
    <sample id="224">是的，像 mt5 这样的编码器-解码器模型可以通过混合语言的训练来改进。</sample>
    <sample id="225">受限语言规划的一个示例是为制作一个巧克力蛋糕而进行规划。</sample>
    <sample id="226">他们通过在句子中隐藏嵌入来验证提供的编码的隐秘性，具体来说是通过计算每个句子中的句法标记数量来实现。</sample>
    <sample id="227">The paper discusses how to leverage existing PLM platforms to build new ones.</sample>
    <sample id="228">GPT-4 在社会接受性分析中的立场与英语 speaking countries 最不一致。</sample>
    <sample id="229">演讲者在提到“你可以看到右边的一个例子”时，展示了模型如何利用注意力机制利用已经学到的知识。</sample>
    <sample id="230">随着任务数量的增加，模型的性能会提高。</sample>
    <sample id="231">作者没有具体提到用来比较的三个无树基线是什么，只是说他们的模型在一般化到更深的递归方面表现超过了这些基线。</sample>
    <sample id="232">两位合著者（Alexander Coler and Ivan Tietov）是第一作者（您）的研究顾问。</sample>
    <sample id="233">PaLM 的第一作者是 Noam Chomsky。</sample>
    <sample id="234">大家好，我是Jenny，卡内基梅隆大学的一年级PhD学生，今天我将介绍我的研究成果《Annoyance Positioning Characterizing Design by ACID Models》。</sample>
    <sample id="235">这项工作是在与华盛顿大学的一些人以及AI研究所的合作下完成的，合作的人包括：Sevastian Santi、Ronan Le Bras、Caterina Rinica和Martin Sap。</sample>
    <sample id="236">所以，让我们从想象开始，假设你为一家报纸工作，你在新闻文章下评论中筛选出有害的内容。</sample>
    <sample id="237">你可能会转向一个流行的API，比如Perspective API来检测毒性。如果你是Carl Jones，这工作得很好，因为Perspective API能够正确地检测出有毒物质的实例。</sample>
    <sample id="238">但是，在Adithya Sharma的情况下，并非真的如此，因为在印度语境中，前瞻性API并不真正敏感于更具攻击性的术语。</sample>
    <sample id="239">这是设计障碍的一个例子，我们在这里看到技术在人群之间系统性地产生表现差异。</sample>
    <sample id="240">像之前看到的那样，设计偏见可能由于NLP研究人员和模型开发者的定位而产生。定位是指人们由于其人口统计学、身份和生活经验而持有的观点。</sample>
    <sample id="241">这是一个在批判性研究中广泛使用的概念，尤其是在女权主义和queer学术空间中。</sample>
    <sample id="242">作为研究人员，位置性可以影响研究过程及其成果，因为它可以改变研究人员的决策。</sample>
    <sample id="243">所以，人们可能会问的一个问题是：数据集和模型是否有定位性？</sample>
    <sample id="244">我们并不试图说模型、细胞和数据集本身具有人口统计学身份和生活经历，但是它们汇总了真实人们的判断和意见，并且能够代表某些政治立场。</sample>
    <sample id="245">演讲者提到，前人工作提供了一些位置性的证据，比如文化差距、模型和数据集的定性定义等。</sample>
    <sample id="246">然而，这些作品并没有真正比较用户与数据集和模型本身。</sample>
    <sample id="247">随着情境测验变得更加具体和社会导向，学习模型和数据集定位的重要性不断增加。</sample>
    <sample id="248">在文档中记录下所有决策是具有挑战性的，而且许多模型都隐藏在API之后。</sample>
    <sample id="249">所以，为了研究数据集和模型定位性，我们实际上会将注释与真实用户和现有的数据集以及模型进行比较。</sample>
    <sample id="250">我们通过框架NLPositionality来完成这项工作。</sample>
    <sample id="251">我们的框架分为两个主要步骤。</sample>
    <sample id="252">第一步是使用不同的注释器重新注释数据集。</sample>
    <sample id="253">我们应当通过查看原始数据集的标记样本来做到这一点，因为通常每个实例只会被标记为几个标记器，而且由于很少有统计数据被收集和共享。</sample>
    <sample id="254">因此，我们选择重新标识数据以获取大量注释，并获得丰富的统计信息。</sample>
    <sample id="255">我们将使用皮尔逊相关系数来比较这些注释与模型和数据集的匹配情况。</sample>
    <sample id="256">因此，我们的框架实际上与注释器不一致的文献有所区别，它通过比较模型和数据集中的最终用户来预测标签，而不是只关注注释器的一致性或建模注释器的分布。</sample>
    <sample id="257">我们的框架主要是通过Lab在云中实现的，这是一个在线的众包平台，以前是HCI的合作者。</sample>
    <sample id="258">在《实验野》中，我们是一个在线实验平台，可以招募各种志愿者，与像Mturk这样的平台相比，我们的参与者来自世界各地，而且《实验野》还能获得高质量的数据。</sample>
    <sample id="259">我们在野外举办两个任务型实验室，其中一个涉及社会可接受性。这个实验的运作方式是参与者从社会化学数据集中阅读一个情境，并且写下他们认为这个情境在社会上是否可以接受。</sample>
    <sample id="260">为了保持对研究的兴趣，他们可以将自己的反应与AI和其他人进行比较。</sample>
    <sample id="261">我们将这些注释与社会化学、Delphi和GPT-4进行比较。</sample>
    <sample id="262">然后，我们为毒性仇恨言论检测任务复制了一个非常相似的设置，在那里他们会阅读Dina Hate的示例，并写下他们是否认为这是一个仇恨言论的例子。</sample>
    <sample id="263">然后，我们将这些注释与Dinahate、Perspective API、Rewire API和GPT-4进行了比较。我们的研究最终收集了来自87个国家的超过16,000个注释。</sample>
    <sample id="264">所以，现在我们已经准备好回答：谁与NLP数据集和模型最匹配？我们发现，在NLP中存在位置性。</sample>
    <sample id="265">例如，我们发现数据集和模型大多与说英语的国家相关联。因此，在针对GPT-4进行社会接受性分析时，我们发现它与孔子和说英语的国家联系最紧密。我们还发现“Dina hate”也大多与说英语的国家联系在一起。</sample>
    <sample id="266">我们还发现，大多数额外的配对与拥有大学教育的人相符。因此，在社会可接受性任务中，我们发现它最适合那些有大学教育或研究生学历的人。</sample>
    <sample id="267">同样，我们发现乔纳森·哈特的情况也是一样，它最适合拥有大学教育的人群。</sample>
    <sample id="268">然而，当模型和数据集与特定人口联系起来时，一些不可避免地会被落下。</sample>
    <sample id="269">例如，在社会可接受性任务以及代沟分析中，我们发现数据集和模型与非二元人群相比更少关联到男性和女性的对应物。</sample>
    <sample id="270">所以，既然ADLP中有空位，我们能做些什么呢？</sample>
    <sample id="271">所以，我们有几点建议：首先，在研究过程中要记录所有相关的设计选择；其次，以多学科研究的视角来进行研究。</sample>
    <sample id="272">我们的第三项建议是，在四个特定的社区内建立专门的数据集和模型。这是一个很好的例子，即“Masakani倡议”。我们想强调的是，包容性NLP不仅仅意味着让所有技术都能为每个人工作。</sample>
    <sample id="273">所以，这包括我们的介绍，但如果你想要学习更多，请随时查看我们最更新的分析结果和我们的论文。谢谢！</sample>
    <sample id="274">演讲者没有具体提到 SimulST 的几个问题。</sample>
    <sample id="275">无法确定。</sample>
    <sample id="276">嗨，我是来自复旦大学的司玉媛。我在这里介绍我们的一项工作，即“区分脚本知识与大规模语言模型对于约束语言规划的影响”。</sample>
    <sample id="277">在日常生活中，人类通常通过遵循预先设定的步骤来规划自己的行动，这些步骤以指令的形式给出。</sample>
    <sample id="278">上一个工作坊探讨了使用语言模型来规划抽象的、典型的活动，例如制作蛋糕，并且表明大型语言模型能够有效地分解动作步骤。</sample>
    <sample id="279">然而，以前的工作主要集中在为抽象的目标规划，为具有特定目标和约束条件的目标规划仍然被认为是未开发的领域。</sample>
    <sample id="280">在这篇论文中，我们定义了约束语言规划问题。</sample>
    <sample id="281">不同的规划目标会受到不同约束的影响，一个理想的规划者应该写出对约束条件合理的、可行的剧本。</sample>
    <sample id="282">在这篇论文中，我们首先评估并改进了大型语言模型的约束语言规划能力。</sample>
    <sample id="283">除了特定的鬼魂外，没有其他任何鬼魂存在来支持我们的研究。</sample>
    <sample id="284">我们必须首先获得这些数据，然后根据下表所示，我们将使用结构化CPython对人类遗传数据进行聚类分析。</sample>
    <sample id="285">从大型语言模型中生成脚本并抽取摘要。</sample>
    <sample id="286">这个表格报告了结果的总体准确性：我们发现所有线性模型在特定目标上的预测结果都达到了令人满意的结果。</sample>
    <sample id="287">然后，我们进行了详细的分析，探讨了为什么机器学习模型失败。</sample>
    <sample id="288">该图的结果表明，生成脚本的语义完整性是可以接受的，但是对约束的忠实性并不能得到保证。</sample>
    <sample id="289">我们深入研究了维基百科中各种约束的更细粒度的主题分类，图中的主图表明，不同类别下的指导性能差异显著。</sample>
    <sample id="290">先前的研究已经表明，兰银官话模型的输出质量呈现高度变异性，导致性能不佳。因此，我们采用了过生成网络的思想来提高生成质量。</sample>
    <sample id="291">我们首先展示约束类型，并给出它们的抽象目标的例子，然后根据这些抽象目标获得具体的目标。</sample>
    <sample id="292">然后，为特定的课程创建GPT-Overwriter脚本。</sample>
    <sample id="293">接下来，一个过滤器模型被开发来选择最有效的脚本。</sample>
    <sample id="294">我们将脚本和目标转换为JSON格式的绑定，并计算余弦相似度和相似性分数，以衡量语义相似性。</sample>
    <sample id="295">在搜索中，我们只保留包含目标约束关键字的脚本。如果目标鬼魂在鬼点数中得分最高，则保留该脚本。</sample>
    <sample id="296">使用我们的方法，内嵌式CBD可以生成更高品质的头发丝。我们的方法在语法完整性以及对约束的忠实度方面都能极大提高可规划性。</sample>
    <sample id="297">由于小型语言模型的部署成本高昂，因此必须能够启用小型和专用语言模型的计划能力。创建数据集是此过程中的重要步骤。</sample>
    <sample id="298">然而，先前的研究并没有为特定目标进行计划，并且手动数据集注释是昂贵的。</sample>
    <sample id="299">他们遵循象征知识抽取的理念，从大规模语言模型中抽取约束语言规划数据集中的模式。</sample>
    <sample id="300">我们将应用我们构建的基于约束语言规划的数据集，名为CoScript。</sample>
    <sample id="301">我们总共生成了五万五千个特定的脚本，为了确保验证质量和测试用例的质量，我们邀请了外包的工人来审查不正确的示例。</sample>
    <sample id="302">这个图显示了约束分布的コスクリプト。我们发现コスクリプト在生成的特定语句中表现出高度的一致性。使用コスクリプト，我们可以创建更小但专用的模型来进行约束语言规划。</sample>
    <sample id="303">我们发现，T5L在词汇量上可以生成比大多数大型语言模型更高的质量的代码片段，这表明小型模型可以在适当的数据集上训练后能够支持比大型模型更大的模型。</sample>
    <sample id="304">我们建立了约束语言规划问题，评估了大规模语言模型的约束语言规划能力，并为大规模语言模型开发了一种超生成滤波器方法。</sample>
    <sample id="305">我们使用大型语言模型来生成高质量的代码数据集CoScipt，用于约束语言规划。我们希望CoScipt数据集能够成为研究语言规划可用资源的宝贵资源。</sample>
    <sample id="306">感谢您花时间！请在我们的报纸上找到更多关于科氏集团的细节。</sample>
    <sample id="307">PaLM 的流畅度与现有的艺术系统相当。</sample>
    <sample id="308">水印方法的重要属性包括适用性、不降低服务可用性、对攻击者的可见性以及在模型提取过程中的可移植性。</sample>
    <sample id="309">英语演讲已经被翻译成了 14 种不同的语言。</sample>
    <sample id="310">通常只用少数几个注释器对每个实例进行注释，并且由于统计数据很少被收集和共享，因此我们需要重新注释数据以获取多个注释器并得到丰富的统计信息。</sample>
    <sample id="311">cosine similarity和L2 distance被用来衡量良性和后门数据集之间的差异。</sample>
    <sample id="312">在这项任务中，我们通过使用基于编码器的多语言模型来分析数据。这些模型能够处理多种语言，并且可以被用来进行多语言预测。</sample>
    <sample id="344">作者假设提供者能够收集一个一般性的文本段落，并用该段落来计算每个单词的频率。</sample>
    <sample id="345">大家好，我叫朱洪。今天我要介绍的论文是：康纳·特里门迪命名实体标签器在2023年仍然有效吗？让我们开始吧。</sample>
    <sample id="346">我们的论文调查了使用命名实体识别任务或NER任务进行泛化的问题。</sample>
    <sample id="347">我们观察到，模型们已经使用卷积神经网络发展了近二十年来开发Ner，这自然引起了一些问题。首先，这些模型能够推广到更多的数据上吗？</sample>
    <sample id="348">当我们开发新的标记时，什么对于良好的泛化是必要的？</sample>
    <sample id="349">同时，如果我们确实观察到泛化性能不佳，那么是什么导致了这些模型的性能下降呢？</sample>
    <sample id="350">为了调查这些问题，我们开发了Connel加加数据集。这是一个我们从Reuter新闻中收集的数据集，并且对它们进行了与2003年相同Connel注释指南的标注。</sample>
    <sample id="351">然后，我们在Coneo2003上对超过20个模型进行了微调。我们分别在Coneo3测试集和Coneo+测试集上评估了它们。</sample>
    <sample id="352">最后但并非最不重要的是，我们计算了f1中百分比的变化，以评估每个模型的一般化情况。</sample>
    <sample id="353">所以，进行良好泛化所需的元素是什么？通过我们的实验，我们发现数据集中有三个主要的元素是必要的。</sample>
    <sample id="354">第一个是模型架构。根据我们的实验，我们发现变换器模型通常对新数据的泛化性能更好。</sample>
    <sample id="355">第二个成分是模型大小。我们发现，通常情况下，更大的模型会导致更好的泛化。</sample>
    <sample id="356">最后但并非最不重要的是，我们都知道，微调示例的数量直接影响下游任务的性能。在这里，我们也发现，更多的微调示例实际上也会导致更好的泛化。</sample>
    <sample id="357">到下一个问题，是什么导致一些模型的性能下降？</sample>
    <sample id="358">我们有两个假设。第一个是适应性过拟合，这是由重新使用同一个测试集多次而导致的过拟合，这通常表现为新测试集上的回归下降。</sample>
    <sample id="359">第二个假设是'温度漂移'，即由于火车和测试数据之间温度差的增加而导致的性能下降。</sample>
    <sample id="360">对于适应性过拟合，我们看到从右图中的图表来看，红色的最佳拟合线的斜率大于1。</sample>
    <sample id="361">这意味着我们在二零一三年对Konnal的每一个改进都会在Konnal+上转化为超过一个单位的改进，这意味着没有减少回报。</sample>
    <sample id="362">这个例子表明，在这种情况下，适应性过度拟合并没有发生。</sample>
    <sample id="363">所以，什么是气温骤降？</sample>
    <sample id="364">对于temporal drift，我们进行了一项实验，来重新训练或继续预先训练一些模型，使用更近期的数据。我们发现，随着时间间隔的增大，性能会下降。</sample>
    <sample id="365">这证实了我们的假设，即性能下降的主要原因是温度漂移。</sample>
    <sample id="366">我们的结论是，为了获得良好的泛化能力，我们需要一个更好的模型结构、更大的模型大小以及更多样化的示例。而且这些目标相辅相成，我们不能只有一个成分，但需要在整个过程中都考虑到它们。</sample>
    <sample id="367">同时，我们还发现这里的性能下降是由温度漂移引起的，令人惊讶的是，它并不是由适应性过配造成的，尽管康拉德二千零三已经被使用了超过二十年。</sample>
    <sample id="368">所以，回到我们论文标题中提出的问题，2003年版的Connel标签还有效吗？我们发现答案其实是肯定的。</sample>
    <sample id="369">我们希望我们的论文能够为提高模型的泛化能力提供更多的研究。</sample>
    <sample id="370">最后，请确保检查我们的论文、数据集，如果您有任何问题，请随时联系我。非常感谢！</sample>
    <sample id="397">The size of the speech segment used in this method is 200 milliseconds.</sample>
    <sample id="398">需要知道 Servin 是一名法官，以及Kea是一名面包师。</sample>
    <sample id="399">示例质量比与源句子的相似度更为重要。</sample>
    <sample id="400">在扩展实验中，论文侧重于六种不同的政党阵营分离出来的新闻和社交媒体上的政治派别。</sample>
    <sample id="401">该模型是结合了多个层的注意力分数。</sample>
    <sample id="402">直接推断的示例包括：'the name of the song is young me' 或者 'its position the first'.</sample>
    <sample id="403">论文中的作者来自复旦大学。</sample>
    <sample id="404">一位</sample>
    <sample id="405">是的，使用Google Translate API将源语言翻译成目标语言作为基线。</sample>
    <sample id="406">作者举例了“man”和“warrior”这两个词，指出“warrior”这个词通常与男性相关联，当描述一个女性战士时，人们会特别指出她是女性战士。</sample>
    <sample id="407">Transformer模型架构泛化能力较差。</sample>
    <sample id="408">测试数据集的名称是clean data。</sample>
    <sample id="409">两位</sample>
    <sample id="410">仅使用了文本。</sample>
    <sample id="439">作者提到成功模型需要能够整合和使用既有训练时间知识和推断时间知识。</sample>
    <sample id="440">演讲者的名字是In和Colly。</sample>
    <sample id="441">是的，Coscript 经过了一次质量检查。</sample>
    <sample id="442">现有的资源仅支持有限类型的依赖上下文翻译和有限数量的语言。</sample>
    <sample id="443">嗨，我要谈谈我们关于实体选择中解决间接引用表达式的工作。在这项工作中，我们引入了实体分数。</sample>
    <sample id="444">我的名字是贾瓦德·侯赛尼，这是与菲利普·拉辛斯基、西尔维娅·帕里蒂和安妮·刘易斯的合作项目。</sample>
    <sample id="445">我们的目标是理解用户在做出选择时的语言。考虑这个替代问题，你是想让我简单一点吗？还是我有一种感觉？是的，用户想要在这两个选项中进行选择。</sample>
    <sample id="446">最明显的是使用直接引用，例如通过说歌曲的名字是“Eminem”或者它的位置是第一。</sample>
    <sample id="447">但是有时候，使用目录朋友更合适，进行更自然的对话。这种情况可能会发生，当用户不记得对方的名字时。</sample>
    <sample id="448">发音方式彼此太相似，难以分辨。</sample>
    <sample id="449">或者当用户想要指定一个偏好时，这里有一些直接的例子。例如，新的版本或不带能量的歌曲。</sample>
    <sample id="450">这是会话系统中一个重要的问题，也是分词的一个重要方面。</sample>
    <sample id="451">我们并不知道一个公开的数据集，一个大规模的公共数据集用于测试。所以我们使用crowd annotation来收集一个。我们的数据集包含三个不同的领域：音乐、书籍和电影。</sample>
    <sample id="452">我们的数据集收集方法强调使用流程图完成。</sample>
    <sample id="453">这个漫画有三个说话泡泡。在第一个泡泡里，鲍勃说：“记住我们昨天听的那首歌吗？”然后，鲍勃设置了对话上下文。</sample>
    <sample id="454">在第二个演讲泡泡中，爱丽丝说：'你是问我容易吗？还是我有感觉了？'</sample>
    <sample id="455">替代问题？在第三个演讲泡泡中，鲍勃使用了直接引用来选择其中一个实体。例如，新的空域。</sample>
    <sample id="456">我们自动提供前两个speech bubble，但第三个是由编辑器填充的。第一个speech bubble是通过手动提示选择的。</sample>
    <sample id="457">第二个问题，即替代性问题，是这样产生的：</sample>
    <sample id="458">我们总是使用一个简单的模板，你的意思是a或b吗？那里a和b是来自维基百科的示例吗？</sample>
    <sample id="459">当你在列表中移动时，实体变得越来越相似，而且通常更难进行拆分。</sample>
    <sample id="460">第一个是统一战线。</sample>
    <sample id="461">第二个是当实体具有相似的标题时，例如两本书名为《他们回忆》。</sample>
    <sample id="462">第三个是当他们在维基百科有类似的描述时，最后是当他们在维基百科有相同的 infobox 或属性时，例如相同的类型、艺术家等。</sample>
    <sample id="463">向实体展示这个替代问题时，他们知道这些实体的名称，但他们并不一定了解实体本身。</sample>
    <sample id="464">所以，我们做的是为歌曲展示一些背景知识，我们只是为每首歌显示一个谷歌搜索链接。</sample>
    <sample id="465">然后，请注音符号听至少每首歌，并阅读关于每首歌的内容。例如，这是“Easy”这首歌的搜索结果。</sample>
    <sample id="466">在“食谱和书籍”领域，我们显示了一些来自维基百科的背景文本。对于食谱，我们还额外展示了它们的形象，同样来自维基百科，以便注释者知道它们的样子。</sample>
    <sample id="467">然后，我们会请注释者选择其中一个实体，例如这里的第一個，並使用三到五個不直接相關的表達式來描述它。</sample>
    <sample id="468">例如，有钢琴伴奏的那一个。我们的数据集中有一些例子，例如没有单词的版本，十二岁男孩的版本，或者来自阿塞拜疆的虚构版本等等。</sample>
    <sample id="469">实体语料库包含6000个不同领域的替代问题，以及42000个直接相关表达式。结果以t5大型模型的形式进行了总结。</sample>
    <sample id="470">如果语言模型能够访问到与注释者完全相同的背景知识，那么它的准确性会非常高，大约在百分之九十二到百分之九十五之间。但这并不现实。</sample>
    <sample id="471">如果语言模型可以访问一些部分重叠的背景知识，那么精确度会在八十二到八十七之间，这更加现实，例如当语言模型检索到背景知识时。</sample>
    <sample id="472">如果语言模型只能访问实体名称，则准确性只有60％，因此有很大的改进空间。我们还展示了模型是泛化的。这是一个指向数据集的链接，谢谢。</sample>
    <sample id="473">该方法与 Whorf 策略和本地协议进行了比较。</sample>
    <sample id="474">Yannick Lavrak来自博世公司。</sample>
    <sample id="475">演讲者的名字是Jenny。</sample>
    <sample id="476">两位</sample>
    <sample id="477">我叫Sara Papa，来自罗马大学和Fondazione Bruno Kessler，我将简要介绍“simultaneous speech translation paper”，这是与Mactteau-Negri和Marco Duranti合作的一项联合工作。</sample>
    <sample id="478">实时口译是指在说话的同时将一种语言实时翻译成另一种语言的过程，这种技术能够增强跨语言沟通。</sample>
    <sample id="479">当前的模拟模型有什么问题？通常，特定的架构会被训练，以引入要优化的额外模块。</sample>
    <sample id="480">例如涉及不同优化目标的训练程序等复杂情况。</sample>
    <sample id="481">例如，训练一个平均延迟为一秒钟的模型和另一个平均延迟为两秒的模型等等。</sample>
    <sample id="482">我们的解决方案是什么？</sample>
    <sample id="483">首先，使用现有的LSTM模型，无需重新训练或为特定的架构采用CNN。只使用一个模型针对所有延迟模式，并通过特定参数传递时延。</sample>
    <sample id="484">通过模型利用注意力机制在音频输入和文本输出间进行交互，可以利用已经获得的知识。你可以看到右侧的一个示例。</sample>
    <sample id="485">我们的解决方案是提出一个点，或者编码代码中的注意力点，并且这是一个策略，根据注意力点指向哪里来决定是否进行部分翻译。</sample>
    <sample id="486">如果张力没有集中，即其总和低于某个阈值$\alpha$，则会删除最后一个语音帧，这意味着接收到的信息不够稳定。</sample>
    <sample id="487">例如，如果我们收到一个包含“我要谈谈”信息的语音片段，并且我们的模型预测出德语翻译是“Ich bin bereit zu sprechen”。</sample>
    <sample id="488">我们将研究跨接线的重量。</sample>
    <sample id="489">我们将看到，前两个单词指向最早接收到的语音帧，而最后一个单词则指向最近接收到的语音帧，即Lambda语音帧。</sample>
    <sample id="490">这意味着前两个单词将被省略。</sample>
    <sample id="491">这段音频的原始内容是：'while since the sum of the cross attention is above a certain threshold alpha we will not emit the last word and we wait for another speech segment.'</sample>
    <sample id="492">如果我们继续，并且收到另一个语音消息，而且我们的模型预测是三个单词，我们会查看交叉注意力权重。</sample>
    <sample id="493">我们将看到，没有单词指向最后一个lambda表达式帧。</sample>
    <sample id="494">这意味着这三句话会被删除。</sample>
    <sample id="495">如果看作一个整体，它的主要结果就是这个。</sample>
    <sample id="496">我们将应用图表来展示翻译结果，其中一面用蓝色表示翻译质量，并且平均长度为...</sample>
    <sample id="497">这是滞后期度量，我们还考虑了计算平均权值，它代表模型计算时间来预测输出。</sample>
    <sample id="498">所以，我们希望这些药物在这个菌株中的活性尽可能高。</sample>
    <sample id="499">但是我们还希望他们向左倾斜。</sample>
    <sample id="500">我们将与适用于离线模型的更适合策略进行比较，这些策略是：Whitkeys策略和本地协议。我们还将与专门为并行机器翻译量身定制的Artificial Intelligence体系结构进行比较。</sample>
    <sample id="501">这是德语同步翻译策略的所有结果。</sample>
    <sample id="502">而且，我们看到它比所有应用到离线模型的策略都能更好地表现，因为曲线向左倾斜。</sample>
    <sample id="503">而且，如果我们考虑实际耗时或计算时长，那就是最差策略。</sample>
    <sample id="504">如果您想发现更多结果，请阅读我们的论文，并且我们还发布了开源代码、模型和并行计算输出，以促进我们的工作的可重复性。谢谢您的关注！</sample>
    <sample id="505">是的，数据集是公开的。</sample>
    <sample id="506">大家好，我是金。我的同事智杨和我将会展示我们的研究成果：多模态学习的改进。</sample>
    <sample id="507">因此，随着大语言模型的进步，许多工作开始探索使用预训练语言模型来执行不同下游任务的新学习范式，在参数和数据效率方面都有所提高。</sample>
    <sample id="508">最近的研究表明，通过遵循自然的指示，结构化调音能够使大型语言模型以一种可解释的方式执行复杂的任务。</sample>
    <sample id="509">然而，大多数关于指令调优的先前工作都集中在提高语言任务的零错误性能上，而计算机视觉和多模态任务则被忽略了。</sample>
    <sample id="510">因此，在本工作中，我们想要探究多模态预训练模型的指令调优是否能够实际上提高对增强型多模态任务的泛化能力。</sample>
    <sample id="511">此外，在我们进行研究的时候，还发现P和多模态之间存在相当大的差异。</sample>
    <sample id="512">存在超过一万六千个仅使用语言的任务，但是没有大规模的公开多模态训练任务，因此这激励我们构建一个多模态训练数据集。</sample>
    <sample id="513">这里我们介绍多模型指示性调优基准数据集，它包含62个不同的多模型任务，涵盖了10个不同的主题类别。</sample>
    <sample id="514">这些任务是从现有的21个开源数据集中派生出来的，并且每个任务都附带了五个专家编写的说明。</sample>
    <sample id="515">在调查多模态指示调整时，我们提出的数据集包括一个统一的多模态表示模型作为我们的基础模型。OFA使用一个统一的词汇表用于语言、图像标记和绑定框的坐标。</sample>
    <sample id="516">这里有一些来自我们多层数据集的示例实例。</sample>
    <sample id="517">各种输入和输出数据类型的统一处理</sample>
    <sample id="518">我们遵循OFA的步骤，将所有任务统一为一个顺序到顺序的格式，在其中输入文本、图像、说明和约束框都表示为相同的标记空间。</sample>
    <sample id="519">好的，现在我要讲的是多模型指示调优。</sample>
    <sample id="520">所以对于训练数据集，我们使用了53个任务，每个任务从n维空间中抽取10000个样本进行测试。我们保留了整个common sense reasoning组用于测试，并且从维基百科和多模态组中选择了另外五个任务。</sample>
    <sample id="521">我们使用测试集中的所有实例针对每个任务进行测试。此外，我们还会从自然语言处理的测试集中随机选取20个任务。</sample>
    <sample id="522">在训练过程中，我们使用一个经过预训练的大型模型作为基础模型。对于所有任务，我们会为每个实例随机组合一个它的五个方向模板之一。</sample>
    <sample id="523">所以对于每个任务，我们通过使用这五个指令中的一个来执行总共五个实验来评估模型。</sample>
    <sample id="524">我们将报告所有五次实验中的平均值和最大值以及标准偏差。</sample>
    <sample id="525">如果任务是多模型分类任务，我们将报告准确率；如果是多模型生成任务，我们将报告Rouge-L；如果是LSTM任务，我们也将报告Rouge-L。</sample>
    <sample id="526">我们还引入了一个额外的评估指标，称为“敏感性”，它衡量模型在相同任务中，无论输入变化如何，都能持续产生相同输出的能力。</sample>
    <sample id="527">这是我们的主要结果。正如我们所见，指令调音可以显着提高OFA在多模态任务上的性能。</sample>
    <sample id="528">自然语言处理数据集可以从多个角度受益于迁移学习。</sample>
    <sample id="529">这段音频的中文是：'我们可以看到，随着任务量的增加，模型的性能会更好，在 meantime 下降低敏感性。'</sample>
    <sample id="530">所以，我们还做了一个实验，使用一个指令与五个指令进行对比。正如我们所见，使用更多的指令可以提高模型的总体性能并减少其敏感性。</sample>
    <sample id="531">所以，这显示了不同的调优策略对模型灵敏度的影响。正如我们所看到的，通过从自然指示数据集中进行迁移学习，模型可以比原始OFA模型实现大大提高的敏感性。</sample>
    <sample id="532">我们还可以看到，从自然结构数据集中提取的传输学习可以帮助我们在自然结构数据集上获得更好的性能。</sample>
    <sample id="533">我们提出第一个大规模多模态训练数据集，显著提高了OFA的分类能力，并探索了不同的迁移学习技术，并展示了它们的好处。我们设计了一个新的度量敏感性。</sample>
    <sample id="534">所以，我们正在收集一个更大规模的多模态训练数据集，大约有150个额外的维珍尼亚语言任务，并且我们会发布它们。所以这个是我们的数据和模型的QR代码。谢谢。</sample>
    <sample id="535">Sara Papa是罗马尼亚布加勒斯特大学的研究员。</sample>
    <sample id="536">演讲者的名字是Jabot Hossaini。</sample>
    <sample id="562">大家好，我是Coosha Sina，我很高兴地邀请您参加我们关于ACL 2023论文“语言模型接受性判断在不同语境下的鲁棒性的讨论”。</sample>
    <sample id="563">与John Gathier、Aaron Muller、 Kanishka Mishra、Karen Fuentes、Roger Levy和Adina Williams的合作项目。</sample>
    <sample id="564">所以，在这个工作中，我们重新审视了最小二乘法族。</sample>
    <sample id="565">所以，最小二乘法并行模型基本上是根据可接受性判断来评估语言模型的，这些判断可能包括语法正确性（例如，是否有正确的时态和单数复数形式）、句法结构以及符合某种类型的模板（例如，主语-谓语宾语结构）。</sample>
    <sample id="566">在这个最小二乘模型中，评估语言模型的典型方法是，首先展示一个可接受的句子或语法正确的句子，然后展示一个不可接受的句子或非语法正确的句子。</sample>
    <sample id="567">模型的希望是基本上把更多的概率分配给可接受的解决方案。</sample>
    <sample id="568">当前的MPP管道系统基本上不允许我们评估模型对长句子的接受度。</sample>
    <sample id="569">这些天来，大型语言模型正在出现，它们具有越来越长的上下文窗口。因此，在整个上下文中评估模型的可接受性至关重要。</sample>
    <sample id="570">我们正在尝试在这里做的就是重新访问PDB管道，通过让模型来评估越来越长序列的可接受性。</sample>
    <sample id="571">所以这就是我们的方法。我们所做的就是重新访问数据集本身，然后通过选择来自这些数据集中可接受或不可接受的句子来重建句子。</sample>
    <sample id="572">例如，这里我们选择了一个典型的戏剧性强度对来自附属岛屿案例的BIM数据集。</sample>
    <sample id="573">我们将从一个文本中提取出符合语法结构、长度合适的句子。</sample>
    <sample id="574">然后，我们将它作为前缀添加到可接受查询和不可接受查询中。</sample>
    <sample id="575">我们可以通过选择与匹配相同的不可接受句子来实现相同的目的，并且这也可以用来测试模型的可接受性。</sample>
    <sample id="576">我们也可以通过从不同的子集或不同的数据集中选择句子来实现这一点，这就是我们所谓的“错配”情况。</sample>
    <sample id="577">所以，这里的句子仍然来自相关数据集，但不是你们正在评估的数据集。我们可以对不可接受性情况做同样的事情。</sample>
    <sample id="578">最后，我们可以从一个与维基百科完全无关的域中选择句子。</sample>
    <sample id="579">所以，这将告诉我们模型的接受性判断是否受到任何上下文的影响。</sample>
    <sample id="580">这个上下文是来自数据集的不同子集还是与我们正在查看的句子完全无关？</sample>
    <sample id="581">所以，这个模型是如何工作的？首先，我们来看维基百科句子，它们与当前查询对完全不相关。在那里，我们发现MPP决策大多对于任意上下文来说都是强大的。</sample>
    <sample id="582">我们增加了背景链接，直到达到2024个，以最大限度地发挥OPT和GPT-2模型的作用。我们在这里看到，在橙色虚线处，MPP判断相对稳定。</sample>
    <sample id="583">从同一个数据集中选择句子时会发生什么？</sample>
    <sample id="584">所以，这里我们选择或创建的是来自同一blimp语法数据集的可接受和不可接受的域名。</sample>
    <sample id="585">添加可接受的前缀或不可接受的前缀时，MPP裁决会显著增加或减少。</sample>
    <sample id="586">但是，当我们匹配结构时，也就是说当我们从“blame”文本中选择同一现象的句子时，</sample>
    <sample id="587">根据所选前缀是否可用或不可用，我们看到模型的MPP判断出现了大规模的增长或减少。</sample>
    <sample id="588">现在，这个——嗯，这是非常大的，比如这个影响会贯穿整个上下文链接，而且这可能会影响像新的语言模型这样的大背景窗口。</sample>
    <sample id="589">所以，为什么匹配前缀会影响语言模型的判断这么多？</sample>
    <sample id="590">所以，我们做了一系列的分析，在尝试保持相关结构的同时，向输入中添加噪音。在进行了几次这种干扰后。</sample>
    <sample id="591">我们发现这些噪音实际上并没有改变模型在显示网页时的预测结果。</sample>
    <sample id="592">基本上，我们发现模型对句子结构和类似方式敏感。</sample>
    <sample id="593">在可接受域中打断句子时，我们会看到所有干扰项都有类似的增加。而在不可接受域中打断句子时，我们则会看到MPP判断值以相似的方式下降。</sample>
    <sample id="594">所以，我们工作的关键点是语言模型对潜在的句法和语义特征敏感，这些特征在整个句子中共享。</sample>
    <sample id="595">“MPP评估，我们目前使用短语和单个中心输入进行的方式，可能无法完全捕捉到语言模型在上下文窗口中提取的抽象知识。”</sample>
    <sample id="596">请阅读我们的论文，了解我们实验的更多细节。感谢您的倾听。</sample>
    <sample id="597">该方法的第一步将输入词元映射到一个无序多集的词元。</sample>
    <sample id="598">Coscript 生成了 55,000 个特定脚本。</sample>
    <sample id="626">DEplain 最佳对齐方法是使用 mass align。</sample>
    <sample id="627">弱监督学习可以在标签噪声较大的数据上训练神经网络，并且能够生成有用的模型。</sample>
    <sample id="628">手动对齐了 75%，自动对齐了 25%。</sample>
    <sample id="629">CoNLL++数据集是通过从Reuter's新闻中收集并标注数据而创建的。这些数据按照相同的2003年注释指南进行了标注。</sample>
    <sample id="630">大家好，我叫Yunpeng Zhang，来自宾夕法尼亚州立大学。今天我要介绍的是我的研究成果——多语言多模态解析器Exemplar。</sample>
    <sample id="631">所以，符号解析是一项任务，用于为用户查询构建符号表示，例如SQL和Lambda calculus。</sample>
    <sample id="632">多语言语义解析的任务是将多种自然语言的查询翻译成多种意义表示形式。</sample>
    <sample id="633">演讲者说的是：'使用神经模型在多种自然语言中翻译查询。到SQL，Lambda表达式，函数式编程等。'</sample>
    <sample id="634">现有的跨语言语义解析模型分别被提出并在有限的任务和应用中进行评估。例如，</sample>
    <sample id="635">音频中说的是：'存在某些自然语言的覆盖率缺失，例如中文。'</sample>
    <sample id="636">某些特定的医疗设备没有获得覆盖。</sample>
    <sample id="637">缺失的lambda系数。</sample>
    <sample id="638">或者只有在某些新型模型上进行评估，例如只有一个模型可以评估它们。</sample>
    <sample id="639">所以，为了解决这个问题，我们提出了一种示例器，它提供了一个通用的数据集示例器，用于跨语言的多模态解析。</sample>
    <sample id="640">它包含9个数据集在各种域中，570个解析的 Texas，8百万表示和22种自然语言，在15个语言家族中。</sample>
    <sample id="641">为了更好地评估基准，我们考虑训练和评估的六种设置。</sample>
    <sample id="642">第一个是“translate text”，我们将使用Google Translate API来将源语言文本翻译成目标语言，然后使用单语言模型来进行训练和评估。</sample>
    <sample id="643">例如，我们训练一个英语模型来处理英语查询，在这个过程中，我们会使用API将德语查询翻译成英语，然后利用训练过的模型来预测SQL查询结果。</sample>
    <sample id="644">还将测试单语言模型。</sample>
    <sample id="645">这个场景中，源语言与目标语言是相同的，例如德语到德语或英语到英语。</sample>
    <sample id="646">我们还会测试单语言模型的多语言设置，通过仅使用训练集中百分之十的数据来训练多语言模型。</sample>
    <sample id="647">我们会训练一个多语言模型，它能识别所有语言。</sample>
    <sample id="648">例如，我们将德语、英语和中文查询放在一起训练多语言模型，并通过推断来使用该模型。</sample>
    <sample id="649">德语查询或中文查询等。</sample>
    <sample id="650">我们还将考虑跨语言零 shot和零 shot迁移。我们将基于一种源语言训练模型，并将其迁移到另一种语言。</sample>
    <sample id="651">在训练过程中，我们使用英语查询或英语和德语混合的短语查询来训练多语言模型，以预测SQL输出。</sample>
    <sample id="652">关于分析单语言模型，我们评估了两个组的模型。</sample>
    <sample id="653">包括多语言编码器，例如x86_64-ppc64le、armv7l-ppc64le和bert-ppc64le。</sample>
    <sample id="654">我们还评估了多语言编码器/解码器模型，例如M6和MT5。</sample>
    <sample id="655">发现编码器/解码器在所有九个数据集中都能获得最佳性能。</sample>
    <sample id="656">我们评估m5和example xlmr+pride多语言设置。</sample>
    <sample id="657">没有发现编码器/解码器或编码器/PR可以改进通过在各种语言中混合训练。</sample>
    <sample id="658">而且我们发现，这是因为大多数主要的自然语言在所有数据集中都能获得性能提升，除了英语，在七个数据集中的表现下降，在三个数据集中有所提高。</sample>
    <sample id="659">这通常被称为多语言性障碍。</sample>
    <sample id="660">我们还将比较跨语言性能差距。</sample>
    <sample id="661">这个图中，蓝色线条表示多线性转换，橙色线条表示零阶转换，而绿色线条表示模型的设置。</sample>
    <sample id="662">通过对比绿色和橙色线条，我们发现零截短设置时，跨语言传输性能差距很大。而通过对比蓝色和橙色线条，我们发现视图截短设置时，传输差距迅速缩小。</sample>
    <sample id="663">我们还发现了一些其他有趣的发现，例如编码器-解码器、全性能进度工作或可比结果，它们在英语自然语言处理方面的性能大幅提升。</sample>
    <sample id="664">我们发现，像Coda和Blue这样的多语言模型仍然适用于跨语言解析任务。</sample>
    <sample id="665">要总结一下，使用Beautifier作为跨语言语义解析的统一基准，具有多种自然语言和多模态表现形式。</sample>
    <sample id="666">对三类多语言模型进行综合基准测试，并且我们的结果展示了许多有趣的发现等等，欢迎访问我们的论文和代码库。感谢您的倾听！</sample>
    <sample id="667">英文内容中并没有提供关于现有研究的具体信息，只是提出了一个关于现有工作的分类方法。</sample>
    <sample id="668">是的，Codex 和 Bloom 等多语言 LLM 仍然适用于跨语言句法分析。</sample>
    <sample id="695">该方法通过将排列作为训练的一部分来处理排列的不确定性。</sample>
    <sample id="696">下游 NLP 模型的公平性可以通过最小化对特定群体的偏见和歧视来定义。这包括避免在模型中使用可能加剧不平等的语言或进行有偏见的分类。</sample>
    <sample id="697">Yannick Lavrak</sample>
    <sample id="698">演讲者的名字是Coosje van der Zanen。</sample>
    <sample id="699">演讲者的名字是Mira。</sample>
    <sample id="700">在本文中，'tropicalism' 指的是与拉丁美洲女性相关的特定形容词和特质，这些词汇常常带有贬义，并暗示着这种女性的外貌和性格特征。</sample>
    <sample id="701">作者通过提及文化、传统、自豪和异国情调等词汇来定义这些群体，并指出它们与主流人群的不同。</sample>
    <sample id="702">cxmi</sample>
    <sample id="703">DrBERT的第一个版本包含7GB的nachos，而ChuBERT的第一个版本包含从clinical notes中提取的4GB句子。</sample>
    <sample id="751">两位</sample>
    <sample id="752">迭代迁移学习是一种机器学习方法，它通过在不同任务之间循环应用已有的模型来进行训练，以提高模型性能。</sample>
    <sample id="753">数据集的目标是理解用户在做出选择时使用的是什么语言。</sample>
    <sample id="754">攻击者可以通过利用句法分析工具在 EaaS 中对句子进行解析，从而提取模型参数。</sample>
    <sample id="755">两位</sample>
    <sample id="756">两个。</sample>
    <sample id="757">哥伦比亚大学梅尔学院。</sample>
    <sample id="758">在提供的例子中，左侧的支配词是isobutane和lisa。</sample>
    <sample id="759">对话系统中的最先进模型是A.P.C.Eval。</sample>
    <sample id="760">因为随着大型语言模型出现具有越来越长的上下文窗口，因此必须在所有上下文窗口中评估模型的可接受性。</sample>
    <sample id="761">是的，多语言训练在某些数据集上会导致性能下降。</sample>
    <sample id="762">是的，注释者预先知道了这些实体的名称。</sample>
    <sample id="763">该评估使用了BLEU、ROUGE和METEOR这些MT指标。</sample>
    <sample id="764">是的，泛化中的回归可以影响特定的 NER 类型。通常情况下，较大的模型会得到更好的泛化。</sample>
    <sample id="765">因为 NLP 系统会被用来处理和理解大量的文本数据，如果这些系统没有被正确地设计和训练，它们可能会反映出偏见和错误的观点。因此，在构建 NLP 系统时，确保其立场是公正和平等的是非常重要的。</sample>
    <sample id="766">是采用完整微调。</sample>
    <sample id="767">他们在任务A（主题独立的语义解析）上使用了预训练的Transformer模型，并在任务B（二元分类器的扩张和比较类聚类）上使用了与之相关的CE模型。</sample>
    <sample id="768">最近用于评估 PaLM 能力的测试集包括：BookCorpus、CommonCrawl 和 Wikipedia。</sample>
    <sample id="769">三条</sample>
    <sample id="770">提议的方法比最强的基线获得了20%以上的收益。</sample>
    <sample id="771">演讲者的名字是Shuheng Zhuo。</sample>
    <sample id="772">是的，论文中提到的结果和数据集可以被用作自动文本简化问题未来研究的基准。</sample>
    <sample id="773">他们在论文中进行了五个较小模型的实验。</sample>
    <sample id="774">OFA被用作研究多模型指令调整的基础模型。</sample>
    <sample id="833">谷歌翻译。</sample>
    <sample id="834">斯托尼布鲁克大学。</sample>
    <sample id="835">论文分析了state-of-the-art和NLP（自然语言处理）相关的语言。</sample>
    <sample id="836">演讲者的名字是张冰。</sample>
    <sample id="837">在实验过程中研究了两种不同的模型：fine-tuned longformer和fine-tuned normal base。</sample>
    <sample id="838">53 个任务用于训练，10,000 个样本每个任务用于测试。另外还有 5 个任务从维基百科和多元性群体中选择，以及额外的 20 个任务来自自然语言处理任务的数据集。</sample>
    <sample id="839">一位</sample>
    <sample id="840">作者在实验中使用了AG News、Minds、SST-2和EraserGAN这四个数据集。</sample>
    <sample id="876">NACHOS 是一个医学数据集。</sample>
    <sample id="877">演讲者的名字是Arvind。</sample>
    <sample id="878">提示策略对机器翻译的结果有很大的影响。</sample>
    <sample id="879">这篇论文的作者之一是来自Patrick Frenneaux教授所在的机构。</sample>
    <sample id="880">指令是：'so one more thing we are collecting a much larger multimodal instruction tuning dataset with around one hundred and fifty additional vision language tasks and we will release them so this is the q r code for our data and model thank you.'</sample>
    <sample id="881">作者建议通过引入一个元参考解决方案任务来评估模型在利用不同来源的知识时的能力。</sample>
    <sample id="882">大家好，我是Aydin Bilal，我将为大家简要介绍谷歌翻译的脚本编程翻译评估策略和性能。这是与我的同事们合作完成的工作。</sample>
    <sample id="883">“棕榈”是一个由540亿参数的大型语言模型，它是在2022年展示的。它的训练集中包含了大量的文本，共有一百八十亿个标记。</sample>
    <sample id="884">在DAMO制造过程中，它在数百个能量任务中达到了最先进的水平。</sample>
    <sample id="885">这项工作呈现了大规模语言模型在翻译任务中的首次系统性研究。</sample>
    <sample id="886">我们使用空格模型的最佳实践来评估它们的迁移能力，这包括使用最新的测试集来避免与训练数据中的测试数据重叠。</sample>
    <sample id="887">我们将两个操作系统状态进行比较，即最佳性能系统的双因素评估。</sample>
    <sample id="888">我们使用最先进的NLP技术，并且还展示了专家级的人工评估结果。最后，我们提供了一些关于词形选择策略的建议。</sample>
    <sample id="889">提示对机器翻译的性能有很大的影响，正如我们在一个简单的实验中看到的那样，我们使用了一个短语提示，并为每个句子提供了两种不同的提示。</sample>
    <sample id="890">在1000个句子中，大多数句子的差异观察到的是一个以上的灰点。</sample>
    <sample id="891">极端情况下，它甚至可以达到四十几分。所以选择一个好的提示策略很重要。</sample>
    <sample id="892">在我们的实验中，我们为一个五轮提示策略设计了一个系统，我们在提供的每个句子上使用它的语言标记。</sample>
    <sample id="893">这个例子演示了从德语到英语的翻译。德语句子和对应的英语翻译用德语的大写字母标记。</sample>
    <sample id="894">我们看到，实际的打印形式对几个短语的影响并不大。</sample>
    <sample id="895">对于零和一发提示而言，这一点至关重要。但是当我们进行五发提示时，实际提示的形式几乎没有区别。</sample>
    <sample id="896">这是承载大部分重量的例子。</sample>
    <sample id="897">我们的实验结果总结是，例句质量比与源句相似性更重要。</sample>
    <sample id="898">所以，从高质量翻译中选择例子很重要。尤其要指出的是，我们对比了训练数据中的WMT评估指标或Dev数据中的选择步骤。</sample>
    <sample id="899">数据集的创建和质量更高，比训练集更出色，因此使用深度学习可以获得更好的性能。</sample>
    <sample id="900">尽管如此，专门化的艺术系统在某些方面比通用翻译具有显著优势，但通义千问接近商业系统。在我们的案例中，我们选择与谷歌翻译进行融合。</sample>
    <sample id="901">我们通过使用MNM框架进行的人机交互获得的见解是，棕榈树的可读性与艺术系统的状态相当，但主要的区别在于准确性。</sample>
    <sample id="902">尤其是最常见的错误是遗漏错误。</sample>
    <sample id="903">所以，它似乎，潘选择的名字是产生更好的翻译，有时会删除源句子中包含的某些词，这些词在翻译中保留了。</sample>
    <sample id="904">然而，计划的“样式”类别对于状态来说要慢一些，这是额外的一个信号。</sample>
    <sample id="905">该模式可以提供非常流畅的输出，但也存在一些准确性问题。</sample>
    <sample id="906">这是对这份文件的简短概述。如果您需要更多详细信息，请观看完整的演示文稿。非常感谢！</sample>
    <sample id="907">这个视频中，我将介绍我们最近的研究成果：《你可能没有意识到的每周习惯》。</sample>
    <sample id="908">这是与萧予森、马约什·穆斯巴赫和加斯帕内合作的工作。</sample>
    <sample id="909">我想开始时简要介绍周报和周报制度。</sample>
    <sample id="910">在微监督中，我们不手动标记数据。相反，我们会使用微标注源对数据进行标记，例如简单的概率规则、知识基础或低质量的众包标记，如图右所示。</sample>
    <sample id="911">与人名相比，维基百科的注释要便宜得多，但它们也很吵闹，这意味着它们中一定有错误的数量。</sample>
    <sample id="912">如果我们直接用每周的标签数据来训练神经网络，那么神经网络就会记住这些标签噪音，并且不会生成新的内容。</sample>
    <sample id="913">在周报中，训练算法被提议用来在标签噪声下 robustly 训练神经网络，以便训练的模型仍然能够生成真实的内容。</sample>
    <sample id="914">在最近的WSL工作中，'WSL代表每周主管学习'已经成为一种共识。一个常见的说法是，人们使用基于周度标签的数据来训练模型，并在干净测试集上获得高性能。</sample>
    <sample id="915">从技术上讲，这一要求不正确，但是……</sample>
    <sample id="916">人们确实认为存在一个额外的清洁验证集，可用于模型选择。</sample>
    <sample id="917">我们在这一问题设置上卡住了，这意味着每周需要额外的手动注释。但是就像房间里的大象一样，这种必要性常常被忽视。</sample>
    <sample id="918">提到的适应性方法是：首先，需要进行干净数据验证吗？还是我们可以使用脏数据集代替？</sample>
    <sample id="919">第二，如果需要干净的数据或干净数据对WSL工作是强制性的，那么我们需要多少干净的样本？最后，我们应该只使用干净的样本进行验证吗？还是有其他更好的方法来利用它们？</sample>
    <sample id="920">我们在工作中解决了这些问题，并且我们的发现如下所示。</sample>
    <sample id="921">首先，我们发现有趣的是，最近的WLSL方法实际上要求干净的权重示例才能正常工作。</sample>
    <sample id="922">否则，这个图中有一个大的性能下降。如果没有干净的验证样本，则训练模型无法生成比原始弱标签更强大的模型。</sample>
    <sample id="923">这意味着训练是没有意义的。</sample>
    <sample id="924">这表明，WSSL方法实际上要求对数据进行清晰标记才能正常工作，而且获得清洁验证样本的成本不应被忽视。</sample>
    <sample id="925">我们的第二个发现是，增加清洁验证样本来帮助WSL方法获得更好的性能，如图左边所示。</sample>
    <sample id="926">我们通常每班只需要20个样本就能达到高绩效。</sample>
    <sample id="927">但是，故事还没有结束，因为我们如果无论如何都决定使用清洁样本进行训练，那么直接使用它们来获得更好的性能也是可以的。</sample>
    <sample id="928">图表显示了在使用干净数据进行验证的WSL方法与直接应用于干净数据的微调方法之间的性能差异。</sample>
    <sample id="929">如果我们有每个类十例，直接的fine-tuning开始击败WSL方法。</sample>
    <sample id="930">最后，通过允许对干净验证样本进行持续微调，可以轻松实现之前WSL方法中提出的性能改进。</sample>
    <sample id="931">从数字中可以看出，瓦林纳模型最初不支持更复杂的WSL方法，例如余弦。</sample>
    <sample id="932">然而，如果我们想要继续对干净的样本进行微调，则FTW的性能与其它方法一样好。</sample>
    <sample id="933">所以实际上，没有理由选择更复杂的WML方法，它们需要更多的时间和磁盘空间计算。</sample>
    <sample id="934">我们展示了最近的WSL应用程序需要干净的手动注释的样本才能正常工作，它们的性能提升和实用性被严重高估了。</sample>
    <sample id="935">我们对今后工作的具体建议如下：</sample>
    <sample id="936">首先，报告模型选择标准，例如在干净验证样本上完成模型选择。</sample>
    <sample id="937">第二，WLS方法应该与函数近似匹配，即使是在小样本中也能有效工作。第三，持续的微调是一个简单但强大的基础，未来在WLS工作中应该考虑使用。</sample>
    <sample id="938">最后，我们的代码是开源的。您可以通过qr码在演示文稿中找到它。请自由查看。谢谢您的参与，享受会议！</sample>
    <sample id="939">对话系统的常用评估方法包括使用人类评价，例如让人类评委选择最佳对话或给定评级量表来评估对话。</sample>
    <sample id="940">这篇论文有四位作者。</sample>
    <sample id="941">在 Servin 和 Kea 的示例中，需要知道 Servin 是一名法官以及他们是在公园里相遇的。</sample>
    <sample id="942">是的，代码是公开的。可以在GitHub上获取。</sample>
    <sample id="943">不均衡。例如，在社会可接受性任务中，NLPositionality 的注释者最常与拥有大学教育或研究生学历的人群关联。</sample>
    <sample id="944">通过尝试保持输入语句的相关结构，但向其中添加噪音来干扰句子。</sample>
    <sample id="945">进行维度评估意味着要分析多个方面来理解对话质量的优点和缺点。</sample>
    <sample id="946">作者所属机构是中国科学技术大学。</sample>
    <sample id="947">在零和一 shot prompting 的情况下，提示的形式很重要。</sample>
    <sample id="978">作者评估了几种不同的对话模型。</sample>
    <sample id="979">一位</sample>
    <sample id="980">优秀规划器的理想品质是能够遵循合理和对约束条件友好的剧本进行规划。</sample>
    <sample id="981">一位</sample>
    <sample id="982">演讲者的名字是Wasudha。</sample>
    <sample id="983">Adam Skurkowski</sample>
    <sample id="1021">最常见的错误是拼写错误。</sample>
    <sample id="1022">我是詹姆斯·芬奇，我是莎拉·芬奇。今天我们来告诉你关于ABC-Eval的一切，即评估对话式AI的一种新方法。</sample>
    <sample id="1023">这项工作是由埃默里NLP实验室完成的，该实验室由埃默里大学的吉诺·楚领导，并与亚马逊Alexa AI合作。</sample>
    <sample id="1024">假设你刚刚开发了一个对话模型，你想看看它和当前艺术水平相比怎么样。</sample>
    <sample id="1025">通常的做法是使用人类评估，例如通过让人类评委选择两场对话中哪一场更好，或者根据一个等级量表给对话打分。</sample>
    <sample id="1026">这些方法很好地提供了全面的对话质量评估，但是对话质量有许多方面。因此，你可能想要评估聊天质量的多个维度，以了解模型在更细微层面上的优势和劣势。</sample>
    <sample id="1027">一种方法是简单地要求人类法官评估对话质量的几个方面，例如模型回复的相关性，使用现有的比较或Likert量表方法。</sample>
    <sample id="1028">然而，我们认为对于维度对话评估存在一个更精确和可靠的战略。</sample>
    <sample id="1029">我们的方法试图通过明确地标记每个模型响应是否表达某些行为来减少人类评估的主观性，例如提供不相关的信息或与自身矛盾。</sample>
    <sample id="1030">我们称这种方法为在聊天中注释行为，或简称为ABC evol。我们开发了这种方法来全面地涵盖聊天模型行为，这些行为已被建议会影响聊天质量，最近的文献中有提到。</sample>
    <sample id="1031">A/B测试能够衡量聊天模型犯各种错误的概率。</sample>
    <sample id="1032">例如，APC-Eval衡量聊天模型忽略其伴侣或说一些不相关事情的次数的轮数。</sample>
    <sample id="1033">模型如果自身矛盾、或与伙伴抵触、或错误地粉饰事实、或违反常识知识，以及当模型成功或失败时不能表现出同情心的话，那么它就是不道德的。</sample>
    <sample id="1034">确定哪种评估方法最有效。我们选择了四个最先进的聊天机器人模型，并使用了每个模型在每种情况下进行的一百次人类-机器对话来评估它们。</sample>
    <sample id="1035">为了进行比较，我们还使用了三种不同的方法来评估这些对话：

1. 在转录级别上使用利克特评分；

2. 在对话级别上使用利克特评分；

3. 对话级别的配对比较。</sample>
    <sample id="1036">对于现有的每种方法，我们收集了关于对话最常见度量的八个方面的评估结果，因为这是评估聊天模型多维标准实践的标准做法。</sample>
    <sample id="1037">根据我们对这些评估结果的分析，我们发现ABC行为标签比现有方法收集到的标签更可靠，这通过一百多次被双标标注的对话来衡量。</sample>
    <sample id="1038">此外，ABC情感标签更能够预测整体对话质量，与现有方法产生的指标相比，如简单的线性回归分析所示。</sample>
    <sample id="1039">例如，你可以看到测量自我和伴侣矛盾的比例如何解释了五分之四和十分之十的对话质量分别，而平均酒精浓度分数只解释了四分之四或者更低。</sample>
    <sample id="1040">最后，我们使用逐步线性回归来检查每个评估指标是否捕捉到聊天质量的独特方面。</sample>
    <sample id="1041">您可以看到，所有ABC评估指标的组合可以解释超过百分之二十五的对话质量。每次移除一个指标时，它们大多导致关于质量的合理信息量减少。</sample>
    <sample id="1042">另一方面，所有转录水平利克特测量指标结合起来解释的质量要少得多，并且这些测量指标中很少有包含独特信息的。</sample>
    <sample id="1043">这些可靠、信息丰富且独特的ABC评估指标使我们能够以比以往方法更高的分辨率来评估对话式AI。</sample>
    <sample id="1044">在我们的实验结果中，可以看到仍然存在几个挑战，并且已经被精确量化。例如，我们测试的Bots有大约20%的响应包含常识性错误。</sample>
    <sample id="1045">大约百分之十五的回复是不相关的，并且他们或者他们的伴侣大约百分之十的时候会相互矛盾。</sample>
    <sample id="1046">随着领域中改进的迅速步伐，许多这些错误率在新模型发布以来都有所下降。然而，自从我们的评估进行以来，情况更是如此。因此，追求可靠的和精确的评估指标来比较模型的理由就更加充分了。</sample>
    <sample id="1047">我们希望ABC评估能够被其他领域的人士作为朝着这个方向迈出的有意义的一步，并且我们期待着在接下来的几个月和几年里看到对话式AI的发展。谢谢观看。</sample>
    <sample id="1048">这篇论文是由埃默里NLP实验室完成的。</sample>
    <sample id="1049">CFT 代表 'Clean Annotation'。</sample>
    <sample id="1050">七位</sample>
    <sample id="1051">大家好，我是贺晓燕，我将介绍我们题为“翻译何时需要上下文：一个基于数据的多语言探索”的工作。这项工作是在与帕特里克·范恩合作完成的。埃米尔·李、安德烈·马丁斯和格雷姆·纽贝克也参与了这项工作。</sample>
    <sample id="1052">例如，我们如何翻译这个句子中的'mol'？</sample>
    <sample id="1053">如果前面的句子是“如果部长们发现某些事情开始变得危险，那么莫雷指的是间谍”，那么莫雷指的是一种出生证明；如果前面的句子是“这可能是任何严重的事情吗，医生？”，那么莫雷指的是一种出生证明。</sample>
    <sample id="1054">所以，根据上下文，单词的意思会变化，因此它的翻译也会变化。</sample>
    <sample id="1055">然而，评估所有这些翻译的准确性相当困难。首先，只有小部分翻译依赖上下文，这使得词法级别的指标（例如蓝）无法捕捉到这些翻译。</sample>
    <sample id="1056">有些人建议对依赖于上下文的翻译进行有针对性的评估，但是这些资源只支持有限类型的依赖于上下文的翻译和有限的语言集合，因为它们通常依赖于域知识和人类创作。</sample>
    <sample id="1057">在这项工作中，我们试图回答这两个问题：首先，翻译时需要上下文吗？其次，模型能很好地处理这些情况吗？</sample>
    <sample id="1058">为了回答第一个问题，我们首先开始研究在翻译中语境的重要性。</sample>
    <sample id="1059">在先前的工作中，我们引入了CMI作为衡量机器翻译模型对上下文使用程度的指标，其方法是衡量源文本x向目标文本y提供的上下文信息量。</sample>
    <sample id="1060">你可以将cxmi理解为给模型提供上下文信息。</sample>
    <sample id="1061">这个工作扩展了cxmi到双倍的cxmi，它可以测量句子级别的上下文使用情况或单词级别上的上下文使用情况。我们可以认为那些具有高pmi的词是那些在翻译时需要上下文的词。</sample>
    <sample id="1062">现在我们分析带有高PSI值的单词，寻找这些单词之间的模式。</sample>
    <sample id="1063">我们分析了从英语翻译成14种不同语言的 TED 演讲的转录文本。</sample>
    <sample id="1064">我们分析了三个不同的层面。首先，我们着眼于具有高平均值PCXMI的语音标签。</sample>
    <sample id="1065">这允许我们找到，例如，在阿拉伯语中，有大约50个以“ح”开头的名词变位词，这是因为在英语中没有复数名词，所以需要上下文来确定翻译成阿拉伯语时名词是否为复数形式。</sample>
    <sample id="1066">同样地，我们在选择适当的动词形式时也会发现某些语言也需要上下文。然后我们查找词汇项，其在所有不同出现情况下的平均pmi值都较高。</sample>
    <sample id="1067">这个帮助我们识别像下面这样的情况，在中文中，您需要上下文来正确地翻译专有名词，以确保文档中使用的是相同的翻译。</sample>
    <sample id="1068">同样地，我们发现context支持在正确的格式下传输。</sample>
    <sample id="1069">最后，我们查看那些pmi值很高的个体标记，这允许我们识别出不能通过单词本身表达的现象，但它们在句法结构中有所体现，例如同义词的分辨率。</sample>
    <sample id="1070">所以，现在我们使用分析结果来设计文档本地化翻译的基准。</sample>
    <sample id="1071">对于这五种现象，我们识别到的每一种，我们都会创建一个“多语言讨论者”来自动识别属于这种现象的词，并且我们将这个多语言讨论者称作Muda Tiger。</sample>
    <sample id="1072">然后，我们也要注意不同语言对这些数字现象有不同的比例。</sample>
    <sample id="1073">然后，我们使用mudata标签器，通过在我们想要用于评估的平行语料库上应用标签来做到这一点，并且我们根据上下文选择应用我们的转换度量。</sample>
    <sample id="1074">最后，我们使用我们的基准以及其他的度量标准来评估文档级别的机器翻译模型。</sample>
    <sample id="1075">首先，使用体素级度量时，我们发现基于概念的模型具有最佳性能。</sample>
    <sample id="1076">但是，如果我们使用context aware模型，性能会更好吗？如果使用word f measure衡量，有上下文和没有上下文的模型会有可比性吗？</sample>
    <sample id="1077">再次证明，仅使用词汇级别的度量标准来确定最佳文档翻译系统是困难的。</sample>
    <sample id="1078">现在我们使用Mooda基准来评估模型，并发现使用上下文的模型在某些特定的语义现象上显著更准确，例如形式ality和语法一致性。</sample>
    <sample id="1079">但是，这些模型并不比不使用上下文和其他现象（例如省略号、名词和动词形式）的模型更好。这在某种程度上表明了我们在文档级翻译方面需要取得更多进展。</sample>
    <sample id="1080">我们还比较了不同的商业系统，而我们的基准测试表明DeepL通常比Google Translate更准确，尤其是在文档级翻译方面。</sample>
    <sample id="1081">我们对十四组语言的配对进行了数据驱动分析，以确定哪些情况下需要翻译。</sample>
    <sample id="1082">然后，我们使用细化来建立文档级机器翻译的基准，这可以帮助我们确定哪些描述现象模型能够很好地处理以及哪些翻译系统擅长文档级翻译。</sample>
    <sample id="1083">非常感谢您的关注，明天见！</sample>
    <sample id="1084">演讲者的名字是Yuchen Zhang。</sample>
    <sample id="1121">该段英文没有明确提到任何特定的方法名称。</sample>
    <sample id="1122">作者提到"显性词汇"是一种方法，用于识别区分标记组的词。</sample>
    <sample id="1123">作者属于华盛顿大学。</sample>
    <sample id="1124">第一个提到的对称依存关系结构的名称是普拉格依存关系结构。</sample>
    <sample id="1125">James Finch 和 Sarah Finch。</sample>
    <sample id="1126">这篇论文有三位作者。</sample>
    <sample id="1127">常用的句法数据集包括CoNLL-2003、UD树bank和LDC语料库中的句法任务数据。</sample>
    <sample id="1161">WSL代表什么方法？</sample>
    <sample id="1162">该模型在11个生物医学和临床决策任务上进行了评估。</sample>
    <sample id="1226">CamemBERT 是在 4 GB 的 nichos 数据集上训练的。</sample>
    <sample id="1227">Adam Skurkowski</sample>
    <sample id="1228">在实验中，使用更近期的数据进行训练会导致模型性能下降，这证实了时间漂移是性能下降的主要原因的假设。</sample>
    <sample id="1269">因为原始序列中的词元可能没有按照某种顺序排列，所以需要使用另一个模型来预测它们的正确排序。</sample>
    <sample id="1270">作者建议提高偏见缓解方法的透明度，因为目前对于某些积极的刻板印象，我们并不确定其原因是否是因为存在某种过度的价值观认同或其他的反刻板印象方法导致了这些有害的模式。</sample>
    <sample id="1271">最小对不可接受输入是指在模型中，当给出一个可接受的句子和一个不可接受的句子时，模型会更倾向于预测那个可接受的句子。</sample>
    <sample id="1272">作者使用了准确率（accuracy）、精确率（precision）、召回率（recall）和F1分数来评估他们的模型。</sample>
    <sample id="1273">使用了内标一致性（inter-annotator agreement）来衡量注释者之间的一致性。</sample>
    <sample id="1274">选择一个与模型可接受性判断无关的领域，例如维基百科。</sample>
    <sample id="1275">德累斯顿大学</sample>
    <sample id="1276">MultiInstruct 相较于其他基准，更专注于改善多模态任务的泛化能力。</sample>
    <sample id="1277">两位</sample>
    <sample id="1278">二进制协调是通过测量字符长度来确定多行文本中不同列的相对顺序的一种方法。它特别涉及到第一列（以音节为单位）、中间列和右列。</sample>
    <sample id="1279">The average length of the hints in this study is approximately 13 words.</sample>
    <sample id="1280">这些发现表明，较小的 T5 模型在适当训练后可以支持比大型模型更大的模型。</sample>
    <sample id="1281">我是扬妮·拉瓦拉克，我将向您介绍我们在Bert模型上的研究成果，这是一款法语预训练模型，用于生物医学和临床领域。</sample>
    <sample id="1282">在这篇演讲中，我们首先讨论了健康照护中的语言建模，然后介绍了我们文章的主要贡献。</sample>
    <sample id="1283">我们引入了第一个法语生物医学模型，名为Dr. Bert，它是基于Roberta和Natsos的数据集构建的，该数据集是从网络抓取的医疗级数据集。</sample>
    <sample id="1284">我们还引入了多设置和数据源的模型比较，然后呈现我们在法语中关于11个不同生物医学和临床流式任务的结果。</sample>
    <sample id="1285">最后，我们将介绍有关实验的更多细节，并告知您如何访问这些模型。</sample>
    <sample id="1286">自2018年发布以来，BERT 已经成为解决自然语言处理任务最有效的方法之一，并且比历史上的静态和词性标注方法（如 Word2Vec、FastText 或 GloVe）提供了巨大的性能提升。</sample>
    <sample id="1287">从那时起，这个模型已经被适应到许多其他语言，比如法语的Camembert和其他领域，比如biomedical的Permit和BioBERT，以及临床的ClinicalBERT，但主要是英语。</sample>
    <sample id="1288">其他语言的专用模型很少，而且通常基于连续训练，因为缺乏内部数据。</sample>
    <sample id="1289">直到现在，法国还没有任何生物医学方面的公开数据集。</sample>
    <sample id="1290">我们所以会问自己，最合适的数据源是什么，适用于广泛使用的那种？而这些核心数据是临床数据的良好替代品。</sample>
    <sample id="1291">为了回答这个问题，我们把Dr. Bert与我们基于从非诺华获得的匿名数据建立的Shubert模型进行了比较。</sample>
    <sample id="1292">在法语数据集上训练一个专用模型，我们需要多少数据？是4GB、8GB还是更多？</sample>
    <sample id="1293">为了回答这个问题，我们首先训练并比较了四个从头开始的模型：第一个版本是7GB的牛油果味的DoctorBeard；第二个版本是4GB的牛油果味的SetOfNatas；第三个版本是3GB的牛油果味的DoctorBeard；第四个版本是2GB的牛油果味的SetOfNatas。</sample>
    <sample id="1294">雪碧的的第一个版本，是一个临床模型，包含4GB的临床笔记；还有一个雪碧的最终版，混合了4GB的自然语言和4GB的临床笔记。</sample>
    <sample id="1295">除了这个比较，我们还引入了三个模型来分析预训练策略的影响。</sample>
    <sample id="1296">一个基于鳄梨的重量，进行四组二十个俯卧撑的训练。另一个也是基于鳄梨，但是这次是进行四组二十五个仰卧起坐的训练。</sample>
    <sample id="1297">最后一个是基于英语生物医学模型的伯明翰模型，并且使用了四套价值为GB的SNAPs。总共有七个模型。</sample>
    <sample id="1298">对这七种模型进行评估，我们根据它们在公共和私有领域的不同任务（例如姓名识别、分类、语音识别和问答）的表现来划分。</sample>
    <sample id="1299">这个模型与六个设计模型进行了比较，这六个模型是：Kamembere-Huber 1GB、Kamembere-Huber 4GB、Kamembere-CCN 4GB、Permit、BioBERT 和 ClinicalBERT。</sample>
    <sample id="1300">该模型在数据类型相同的任务上表现最好，但在这次训练中没有使用这些数据。</sample>
    <sample id="1301">然而，我们可以从多个来源获取数据，并且使用更多的数据可以实现更好的性能。</sample>
    <sample id="1302">从头开始编写程序似乎在大多数任务上都能获得更高的性能。</sample>
    <sample id="1303">然而，使用白噪声和令牌化对允许的鸟儿进行持续实验，在4GB子集上获得的结果与使用Dr Bert从头开始获得的结果相当。</sample>
    <sample id="1304">基于卡姆巴尔重量和托克纳的模型并不是这种情况。</sample>
    <sample id="1305">最后，我们的自定义系统在11项任务中的9项上表现更好，且优于通用模型的结果，这证明了我们的方法的有效性。</sample>
    <sample id="1306">我们还观察到，专用数据更好，专用性更强的数据更好，但这并不意味着它能很好地扩展应用。</sample>
    <sample id="1307">从nachos获得的预训练模型是免费的，并且在newface上使用，所有训练脚本都在我们的git仓库中。</sample>
    <sample id="1308">所以，感谢你为本次会议的准备，并且我们期待在多伦多会议上采取行动。</sample>
    <sample id="1309">研究了词嵌入和连续提示训练两种学习策略。</sample>
    <sample id="1310">测试重复使用的过拟合因素是1.2。</sample>
    <sample id="1311">通过人工评估和自动评估指标（如BLEU）来评估简化质量和准确性。</sample>
    <sample id="1312">是的，初步结果表明，不同的语言模型具有不同的政治倾向性，它们占据了政治坐标上的四个象限。</sample>
    <sample id="1313">嗨，我叫马蒂亚斯·林德曼，今天我要给大家介绍一篇关于无树的构造式泛化论文，使用多标签和潜在标记法。</sample>
    <sample id="1314">这是与我的顾问亚历山大·科勒和伊万·蒂洛夫的合作。</sample>
    <sample id="1315">组合泛化可以被理解为学习者处理更深的递归和未见过的构成短语的能力，在训练期间这些短语会被单独看到。</sample>
    <sample id="1316">在语义解析的上下文中，测试构词一般化可能看起来像这样：像往常一样，我们有一套训练过的元音发音；在这个例子中，女孩睡了，玛丽知道女孩睡觉了。</sample>
    <sample id="1317">这些语音实体与逻辑形式相匹配，代表了它们含义的核心要素。</sample>
    <sample id="1318">与标准机器学习评估不同的是，测试集并不来自相同的分布，但包含结构性未见过的逻辑形式。</sample>
    <sample id="1319">在本例中，模型在训练期间出现了浅层循环，并且在测试示例上进行了更深层次的循环。</sample>
    <sample id="1320">朴素的序列到序列模型在处理这种输出分布泛化时会遇到困难，并且常常会产生与输入分离的输出。</sample>
    <sample id="1321">特别是，它们往往无法复制输入和输出之间的系统对应关系，例如示例中的彩色编码。</sample>
    <sample id="1322">一种流行的方法是将树木整合到模型中。</sample>
    <sample id="1323">树木旨在捕捉与语法形式相关的表达过程的构图。</sample>
    <sample id="1324">这个方法可行，但是通常树是不能随便给的，需要通过其他方式获得。</sample>
    <sample id="1325">这可能是一个复杂的过程，在某些情况下甚至是计算上昂贵的。通常，这涉及到大量的形式化语言特定的预处理步骤，例如处理变量符号。</sample>
    <sample id="1326">从树中获取叶子也可能涉及到专门的语法解析程序。</sample>
    <sample id="1327">在这篇论文中，我们不使用树，并引入了一种新的序列到序列模型，它直接建模了输入片段和输出片段之间的对应关系。</sample>
    <sample id="1328">我们首次在不依赖于树的情况下实现了强泛化到更深的递归。</sample>
    <sample id="1329">我们的方法通过两步预测输入的输出。</sample>
    <sample id="1330">首先，我们为每个输入标记一个无序的多标签集，这些标签将在输出中出现。</sample>
    <sample id="1331">第一步之后，我们有了所有正确的标记，但是它们没有排序。</sample>
    <sample id="1332">这就是为什么在第二步中，我们使用另一个模型来预测转换，以便将它们按正确顺序排列。</sample>
    <sample id="1333">我们引入了一种新的预测旋转方法，它不对可能的旋转施加任何硬约束，这使得我们的方法相当灵活和表达式。</sample>
    <sample id="1334">我们的Permutation模型大致上是这样工作的：</sample>
    <sample id="1335">我们从左到右遍历输出，并确定要在每个位置放置的多字节标记。对于第一个输出位置，我们简单地选择一个突出显示为红色的标记。</sample>
    <sample id="1336">然后，我们跳到下一个多字节标记来确定输出中的第二个标记。</sample>
    <sample id="1337">我们以类似的方式通过跳转到另一个多字节标记来确定输出的第三个标记。我们将继续这个过程吗？</sample>
    <sample id="1338">直到第一阶段的每一个标记都至少被访问过一次。</sample>
    <sample id="1339">为了让你对实验结果有一个初步了解，我们在这里将我们的方法与其它无树模型进行比较，在测试集上表现良好。我们的模型在泛化到更深的循环时比其他模型性能更高。</sample>
    <sample id="1340">尽管其他类型的结构化聚合似乎很有挑战性，但它们仍然很有用。</sample>
    <sample id="1341">在我们的论文中，我们解决了一些有趣的技巧挑战。</sample>
    <sample id="1342">首先，训练数据中没有提供输入和输出之间的对齐信息。因此，对于一个给定的标记，我们不知道它来自哪个多分类器，这为训练带来了挑战。</sample>
    <sample id="1343">此外，有时会出现与数据一致的多个转换，但语法正确的那个是后期添加的。我们通过引导对齐将其作为训练的一部分来解决这个问题。</sample>
    <sample id="1344">我们的转换方法非常灵活，但也带来了挑战：找到评分最高的转换是NP hard问题。这是因为这与旅行推销员问题有关。</sample>
    <sample id="1345">这个结果可以通过一个对GPU友好的、连续的放松过程来近似，同时允许我们通过溶液传播并学习更合理的语言结构变化。</sample>
    <sample id="1346">如果您想更多地了解我们的实验以及我们如何应对这些挑战，请查看我们的论文或访问我们的海报。</sample>
    <sample id="1347">认知失调是指个体持有两种或多种不一致的观点、信念或行为时产生的心理不适。</sample>
    <sample id="1348">GPT-4是最倾向于自由派的语言模型。</sample>
    <sample id="1349">是的，在主动学习中，累积训练通常表现得更好或至少与迭代训练相当。</sample>
    <sample id="1350">演讲者的名字是Sara Papa。</sample>
    <sample id="1351">MuDa基准中的数据是来自于英语到14种不同语言的翻译。</sample>
    <sample id="1385">演讲者的名字是Matthias Lendermann。</sample>
    <sample id="1386">跨语言转移是指在一个语言中训练模型，并将其应用于另一个语言中的任务。</sample>
    <sample id="1387">沙尔茨大学（Saarland University）。</sample>
    <sample id="1388">作者提到了两种延迟测量方法：翻译质量和计算平均延迟。</sample>
    <sample id="1389">大家好，我是玛克沙塔，今天我和我的合作者马丁一起介绍我们的作品——“kit mustache”，这是一个多源知识集成的评估工具。这项工作是麦吉尔大学、密莱和微软研究的协作成果。</sample>
    <sample id="1390">自然语言理解模型建立在各种知识来源的基础上，例如它们的参数中包含的知识，通常是在预训练过程中获得的，以及在推理时给出的输入知识。</sample>
    <sample id="1391">最近在选择题回答任务方面的研究显示，模型可以使用预训练的时间知识来完成任务。</sample>
    <sample id="1392">但是，自然语言理解通常需要在推断时提供知识。</sample>
    <sample id="1393">例如，在句子中，约翰在电视上看到了新当选的总统。</sample>
    <sample id="1394">预训练参数可以包含关于什么总统住在哪里以及什么是电视的信息，但他们不能可靠地知道这个实例特定实体John是谁，或者新总统是谁，因为总统可能在预训练以来已经改变了。</sample>
    <sample id="1395">因此，知识密集型和AI任务的成功模型需要能够整合和使用既有训练时间和推理时间的知识。</sample>
    <sample id="1396">在这项工作中，我们提出了一种知识整合的诊断测试套件。</sample>
    <sample id="1397">核心参考解决方案任务设计用于测试从不同来源获取知识的能力。我们评估了人类研究参与者的数据集，并建立了核心参考解决方案模型。</sample>
    <sample id="1398">这是我们的数据集中的一个例子：瑟文是一名法官，凯尔是一名面包师。瑟文和凯尔在公园见面。劳累了一整天后，处理完法律案件后，他很高兴能放松一下。</sample>
    <sample id="1399">这里的任务是确定代词“he”所指的正确实体，而在这个例子中，它指的是Sergei。</sample>
    <sample id="1400">特定实体的知识，例如“Serel”是一位法官；以及一般知识，例如法官决定案件的法律代码。</sample>
    <sample id="1401">背景知识通常在大型语言模型的预训练过程中学习，而实体特定知识则通常在推理时进行观察。</sample>
    <sample id="1402">这样就可以分别确定这两件事情的可获得性，以便它们要么只在一个来源中出现，要么在多个来源中出现。</sample>
    <sample id="1403">我们已经定义了三个Keras设置：第一个是“背景预训练”，其中假设背景知识在预训练时间内可用；</sample>
    <sample id="1404">其次，存在背景知识双向设置，其中背景知识在预训练时间和迁移时间上都是可变的。最后是背景知识迁移设置，在此设置中可用的知识类型仅限于迁移时间。</sample>
    <sample id="1405">最后一个设置尤其有趣，因为它模拟了在解决问题时需要的后端知识并不是模型预训练数据的一部分的情况。例如，自从预训练模型以来，新职业就已经发展起来了。</sample>
    <sample id="1406">这是一个控制事实来源可用性的示例。</sample>
    <sample id="1407">在背景预训练设置中，我们假设背景知识“政治家寻求在政府中获得席位”包含在预训练参数中，在受限上下文环境中，我们提供特定的知识“奇切斯特是政治家”。</sample>
    <sample id="1408">背景知识设置：我们还提供不仅针对特定问题的背景知识，还包括政治家在影响其所在国家或地区的背景下所起的作用。</sample>
    <sample id="1409">在后台设置中，提供有效职业婚姻顾问而不是政治家，因为婚姻顾问不太可能包含在预训练模型中。</sample>
    <sample id="1410">我们评估了人类研究参与者的数据集，并建立了相关解决方案的模型。在本图中，我们展示了在最困难的背景预训练设置下表现最佳的模型的结果。</sample>
    <sample id="1411">在没有使用Kittos的情况下，这两个模型的性能都不好。然而，一旦使用了Kittos，无论是在随机选择还是在Cerebro中训练，这两个模型的表现都要明显优于随机选择。</sample>
    <sample id="1412">这表明，在使用基于卡方检验的解决方案数据集进行训练时，模型可能会学习到如何探索表面标签，而这些标签在测试基线分类器时并没有用处，因为这些标签已经被移除了。</sample>
    <sample id="1413">额外的实验表明，即使是最成功的模型也无法可靠地整合背景知识，提供的影响时间也不足。</sample>
    <sample id="1414">对某些人来说，主要的收获是他们能够在没有特定训练的情况下理解和从不同来源的知识中推理出知识。但是，在接受了特定训练之后，一些人能够成功地整合来自多个来源的知识。</sample>
    <sample id="1415">尽管如此，表现最好的模型似乎在推断时间上遇到了可靠集成后向知识的困难。如果您有兴趣了解更多信息，请参阅我们的论文，并查看GitHub上的数据集代码。谢谢收听！</sample>
    <sample id="1416">基于树的方法在处理复杂问题时可能会很耗费时间，并且涉及到大量的形式化特定的预处理步骤。</sample>
    <sample id="1417">作者所属机构是康奈尔大学。</sample>
    <sample id="1418">我叫Mira，今天我们将讨论我们的论文《使用自然语言提示来测量语言模型中的类型》。这项工作是与Essen Dermanish和Dan Yurowitz合作完成的。</sample>
    <sample id="1419">近年来，许多人都记录了大型语言模型（或称LLM）中社会偏见和刻板印象的普遍存在。</sample>
    <sample id="1420">然而，这些措施具有各种局限性。它们通常依赖于耗时构建的手工数据集。</sample>
    <sample id="1421">而且，它们通常只衡量非常具体的类型，这意味着它们不能很好地概括其他人口统计学特征或上下文，或者它们只是捕捉了非常一般的、广泛的联想，例如与特定群体的负面联系。</sample>
    <sample id="1422">此外，大多数空间工作并没有考虑到“交叠性”，即多层面的社会身份能够累积偏见，并造成独特的伤害。</sample>
    <sample id="1423">我们克服这些局限性的方法是依赖于这样一种属性：即这些较新的指令式LLMs对指令和参数的响应非常好。</sample>
    <sample id="1424">所以我们可以请模型生成一个肖像画，即想象中的一个人物的描绘，使用提示来引导，比如“想象你是一个亚裔女性，描述你自己”。</sample>
    <sample id="1425">而且我们可以立即看到，这适用于任何人口统计学特征，因为我们只需要指定我们想要的任何身份标记到这个提示中即可。</sample>
    <sample id="1426">所以，这里有一些来自GPT-4的例子生成。</sample>
    <sample id="1427">传统意义上的这些词汇，并非字面意思上的消极或有毒。</sample>
    <sample id="1428">有一些有趣的模式。</sample>
    <sample id="1429">这位亚裔女性被描绘为不那么引人注目，而中东女性则被称为“异国情调”和“令人着迷的地区”。</sample>
    <sample id="1430">女性的黑人角色都提到她的族裔，而白人男性角色则没有提到这一点。</sample>
    <sample id="1431">我们的方法有两部分。第一部分是生成这些人物。</sample>
    <sample id="1432">我们的生成人物的提示是受到一项研究的启发，在这项研究中，研究人员向人类受试者提供了这些提示，发现他们也能表面种族主义的偏见。</sample>
    <sample id="1433">而且，这还可以实现我们生成的人格与人类写下的回复之间的直接对比。</sample>
    <sample id="1434">第二部分是标记词，它是一种方法来识别区分标记组的单词，我稍后会详细解释。</sample>
    <sample id="1435">这的好处是，我们能够得到非常具体的类型和模式，而不需要依赖任何特定的词汇表。</sample>
    <sample id="1436">所以，标记词法借鉴了社会语言学中的"标记性"概念，该概念指出存在一个未标记的默认值，任何偏离这个默认值的群体在语言上都是被标记的。</sample>
    <sample id="1437">例如，单词“man”通常与男性相关联，因此当人们描述一位女性战士时，他们通常会使用“一名女战士”这一表达，并在其中加上“woman”一词来指明性别。</sample>
    <sample id="1438">更广泛地说，社会上的主导群体在语言上和社会上都是非标记性的，而边缘化的群体通常是有标记的。</sample>
    <sample id="1439">所以，在我们的方法中，我们首先指定什么是未标记的和标记的组。</sample>
    <sample id="1440">然后，我们使用“战斗词汇法”来比较人物，这种方法是使用加权词频比值来区分每个标记组的前几个单词。</sample>
    <sample id="1441">例如，对于黑人女性的肖像画，我们会使用“战斗性的言语”并对比白人和男性人物的法律保护率，因为这是两个对应的、未被标记的群体。</sample>
    <sample id="1442">现在我们来看一些结果。首先，我们使用了词典生成器，发现生成的 persona 内容包含比人类写的内容更多的类型。</sample>
    <sample id="1443">但是，当我们实际上查看字典中单词的分布时，会发现非常不同的事情。</sample>
    <sample id="1444">虽然生成的人格面具具有更高的LEx词频，但人类写就的内容则有更广的词汇分布。而生成人格面具中的“刻板印象”词汇，实际上就是那些“高大和运动型”的词汇。</sample>
    <sample id="1445">所以，只考虑积极的或至少非负面的方面。</sample>
    <sample id="1446">这个词汇表并不能完全捕捉到我们在前面的幻灯片中看到的许多有害模式。所以，相反地，我们将转向我们标记单词方法的结果，来展示这些看似积极的词语如何促进偏见和本质化叙述。</sample>
    <sample id="1447">在我们的分析中，我们揭示了这些表面上看似乎是正面的描绘如何反映出有害的模式。</sample>
    <sample id="1448">“我们”群体的前几个词包括文化、传统、自豪和奇异，这些词仅根据它们与身份的关系来定义这些群体，并将它们与白人标准区别开来。</sample>
    <sample id="1449">这为这些群体长期存在歧视和压迫做出了贡献。</sample>
    <sample id="1450">此外，这些词汇中还反映了许多共同的倾向，尤其是针对有色人种女性的。例如，形容拉丁裔美国女性时，可能会用到“充满活力”和“心地善良”等词语。</sample>
    <sample id="1451">这种热带风情的词儿，亚洲女性常用来形容她们的娇小、精致和柔滑。</sample>
    <sample id="1452">这与亚洲女性长期以来被视为被动、顺从的历史有关。</sample>
    <sample id="1453">最后，对于黑人女性来说，我们看到的最上面的词汇是“强大”和“坚韧”。</sample>
    <sample id="1454">这与人们所说的“强壮黑人女性”这一类型有关，虽然乍一看似乎很积极。</sample>
    <sample id="1455">研究表明，这种模式实际上是有害的，因为它给这些人口群体带来了很大的压力，要求他们坚韧不拔、坚强地应对社会障碍。</sample>
    <sample id="1456">与其实际致力于改变这些障碍，不如对这些人施加压力，让他们克服这些障碍，这会导致这些人出现非常负面的健康结果，以及其他危害。</sample>
    <sample id="1457">更广泛地讲，我们发现每个标记组的词都反映了非常基本的叙述。</sample>
    <sample id="1458">基于这些模式，我们得出了三个建议给模型所有者。</sample>
    <sample id="1459">首先，作为研究人员，我们应该关注正面的榜样和强调叙事。我们也应该使用交叉学科的方法来研究偏见和危害，因为我们如果不这样做的话，可能会有很多东西被忽视。</sample>
    <sample id="1460">最后，关于偏见减缓方法应该有更高的透明度。</sample>
    <sample id="1461">例如，这些正面的刻板印象，我们不知道是不是因为有些奇怪的原因。</sample>
    <sample id="1462">这段音频的内容是：'过度的过度价值认同，或者一些其他反刻板印象的方法导致这些有害的模式。'</sample>
    <sample id="1463">没有更多的透明度，我们真的无法做出任何假设或进一步研究这个问题。</sample>
    <sample id="1464">非常感谢收听，祝您在AC有美好的时光！</sample>
    <sample id="1465">大家好，我叫金维一，来自中国的科学技术大学。</sample>
    <sample id="1466">这是我的荣幸，能够在我们的报纸上做简短的广告宣传。你愿意复制我的模型吗？保护大型语言模型的版权对于嵌入式服务很重要。我们会在背后提供帮助。</sample>
    <sample id="1467">让我们首先介绍嵌入式服务的基础知识。</sample>
    <sample id="1468">目前，像TPT、Lama和Palm等大语言模型在自然语言理解与生成方面表现突出。</sample>
    <sample id="1469">基于语言模型的服务是利用大语言模型来帮助执行各种任务的一类服务。</sample>
    <sample id="1470">例如，OpenAI提供了一个基于GPT的集成API。</sample>
    <sample id="1471">然而，最近的研究表明攻击者可以通过从嵌入式设备中学习来窃取模型，并提供类似的服务。因此，保护嵌入式服务的版权是必要的。</sample>
    <sample id="1472">为了保护嵌入式服务的版权，一种解决方案是在提供者服务中嵌入水印，并检测是否有其他服务包含该水印。</sample>
    <sample id="1473">水印方法需要满足以下几点：首先，该方法应适用于嵌入式服务；其次，水印不应降低提供的嵌入式服务的可用性。</sample>
    <sample id="1474">第三，水印应该足够暗淡，以至于攻击者可以轻松地移除水印。</sample>
    <sample id="1475">最后，在模型提取过程中，水印需要能够传输到攻击者的服务器上。</sample>
    <sample id="1476">现有的作品可以大致分为四类。</sample>
    <sample id="1477">这种方法要么不适用于嵌入式服务，要么缺乏可移植性。</sample>
    <sample id="1478">因此，本文提出了一种背门式水印方法，适用于嵌入式服务。</sample>
    <sample id="1479">那么，让我介绍一下我们的嵌入式标记器。嵌入式标记器包含两个主要步骤：水印注入和版权验证。</sample>
    <sample id="1480">在这些主要步骤之前，我们首先选择一个触发集。触发集是一组在中等频率间隔内的单词。</sample>
    <sample id="1481">我们假设供应商可以收集一般文本段落并计算单词频率。</sample>
    <sample id="1482">在水印注入中，首先定义一个目标宿主。当用户向服务发送一条消息时，服务会计算触发次数。</sample>
    <sample id="1483">提供的内嵌入是目标内嵌入和原始内嵌入的权重求和。</sample>
    <sample id="1484">目标嵌入的权重与句子中触发词的数量成正比。当句子中的触发词数量大于m时，提供的嵌入与目标嵌入完全相等。</sample>
    <sample id="1485">版权验证是检测服务背后模型是否包含水印的技术。</sample>
    <sample id="1486">首先，构建一个后门和一个良性数据集。后门数据集中包含所有单词属于触发器集的句子，而良性数据集中所有句子中的每个单词都不属于触发器集。</sample>
    <sample id="1487">然后，提供商要求从Steller服务中导入映射。</sample>
    <sample id="1488">请求的编码与目标编码之间的余弦相似性被计算出来。我们计算了基尼和背景数据集之间的相似性差异，这定义为余弦角的差值。</sample>
    <sample id="1489">同时，我们将应用ks测试，并使用它的p值作为第三个矩阵。</sample>
    <sample id="1490">我们在四张数据集中进行了实验，分别是AG News、Mind、SST-2和Ernie-Span。我们假设供应商使用WordCount来计算词频。</sample>
    <sample id="1491">在四台服务器上进行的结果表明，嵌入式标记器可以有良好的检测性能同时保持很高的实用率，适用于非结构化任务。</sample>
    <sample id="1492">我们还通过在Forth虚拟机上分析句子的嵌入来验证提供的嵌入的隐秘性。' figures legend'表示每个句子中的引号数量。</sample>
    <sample id="1493">如图所示，很难区分聚合物嵌段与普通嵌段。</sample>
    <sample id="1494">没关系，谢谢你的邀请，我们将会讨论的。</sample>
    <sample id="1495">ABC-Eval 是一个用于全面覆盖聊天模型行为的方法。</sample>
    <sample id="1496">无法确定，因为音频信息中没有提供关于性能增量的具体年份。</sample>
    <sample id="1497">你好，我是瓦苏达，是斯托尼布鲁克大学计算机科学系的博士生候选人。我想介绍我接受的ACM论文，题目为《迁移学习在失真检测中的应用》，这是一项针对一类罕见挑战的研究。</sample>
    <sample id="1498">认知失调是指一个人的行为或信念与他/她的价值观或期望之间存在冲突。它是一个重要的研究领域，因为人们的行为和信仰是他们如何理解和解释世界的基础。认知失调理论认为，当一个人的行为或信念与其价值观或期望不一致时，他会感到不舒服或焦虑。这种不适感驱使人们采取行动来减少或消除这种不一致。因此，认知失调理论对理解人类行为动机和决策过程具有重要意义。</sample>
    <sample id="1499">例如，有人陈述：“我知道香烟会要我的命，然后接着说：‘会议之后我抽了几支雪茄’，这种信念和行为不一致，且彼此矛盾。”</sample>
    <sample id="1500">进一步提到'我认为没有他们我就无法保住工作'，证明了第二个词的出现，并且它们有重合的关系。</sample>
    <sample id="1501">虽然失真在日常决策制定中是一个非常常见的现象，但在其他类型的交流中却真的很难找到表达。</sample>
    <sample id="1502">所以为什么这很重要？研究认知差异可以帮助我们理解人们之间的分歧，趋势和信仰价值观以及社会影响。</sample>
    <sample id="1503">高认知功能障碍也与焦虑症有关，并且能够帮助人们更好地理解心理健康状况。</sample>
    <sample id="1504">学习语言中的音调变化也可以帮助我们理解极端主义和弱势群体的分化。</sample>
    <sample id="1505">最后，认知正误是理解个人的认知风格的重要因素，它能帮助我们更好地理解决策过程。</sample>
    <sample id="1506">为了创建一个认知失真资源，我们进行了大规模的失真关系调查。我们使用了失真度的第一个方法，如流程图中所示。</sample>
    <sample id="1507">推文使用了Apertium解析器进行分词，并根据我们在论文中描述的指导原则对话语对进行了标注。</sample>
    <sample id="1508">如图所示，在注释的对数中，只有3.5%的音程具有失真。</sample>
    <sample id="1509">在收集了大约一千个话语单元对之后，我们运行了一个初始分类器，它只根据四十三个disnet示例进行训练。不出所料，分类器的性能并没有比随机猜测好多少。</sample>
    <sample id="1510">给定的低发生率和任何先前此类数据集的缺失，我们面临着绝对罕见的问题。</sample>
    <sample id="1511">通过组合转移学习和主动学习来进行标注，可以收集到更多不同的样本来减少标注轮数，从而降低总体标注成本，同时提高识别精度。</sample>
    <sample id="1512">由于初始模型无法捕捉解耦类，我们通过从紧密相关的任务中转移权重来启动主动学习过程。</sample>
    <sample id="1513">独立话题分类任务是根据两个人的辩论声明，判断他们是否同意或不同意某一个主题。</sample>
    <sample id="1514">这里所谓的“辩论”是关于二进制分类的扩展和比较，特别是P纽特贝类别的概念。因为这两个概念与辅音和元音的概念紧密相关，我们在这里称之为C2。</sample>
    <sample id="1515">在传输带有标记的数据集的零位性能时，我们发现它已经比随机性能好得多，甚至优于AUC点六二。</sample>
    <sample id="1516">在两个任务上进行迭代微调后，我们发现跟随在“ce”任务后面的进一步微调在零截断性能方面要好得多。这是我们在启动主动学习时使用的模型。</sample>
    <sample id="1517">接下来，我们确定了最佳方法来更新模型，使用每轮主动学习和注释收集到的所有新数据。累加器会积累到目前为止通过主动注释收集的所有数据，而递归算法则通过训练最新收集的数据来更新模型。</sample>
    <sample id="1518">在不同的策略下，我们发现累加器表现等于或优于迭代器。</sample>
    <sample id="1519">接下来，为了提高异构体示例的数量，我们使用了稀有类策略PRC来选择当前模型在任何一轮迭代中都极有可能识别出的示例。</sample>
    <sample id="1520">我们将这个与其他常见的社区艺术策略进行比较。</sample>
    <sample id="1521">我们发现，提出的方法比其他最先进的策略效果更好，尽管它们之间的差异很小。注意，随机选择的性能明显较低。</sample>
    <sample id="1522">在进一步的轮次中，我们通过使用两种最佳策略来提高客户分类的精确度，将其提高到了0.75，这是我们在该任务上迄今为止的最佳表现。</sample>
    <sample id="1523">我们还检查了每个策略的注释质量及成本对注释者的影响。我们发现PRC具有最高的失真率，并且最适合稀有类别。但是，注释者也认为示例太难了。</sample>
    <sample id="1524">总而言之，我们发现使用PRC作为尾部收购策略和冷启动Erl有助于大幅提升学习任务的性能。</sample>
    <sample id="1525">我们还发现，对于从不同域中转移学习而言，累积更新是有用的，而域内主动注释则受益于累积更新。</sample>
    <sample id="1526">这些是核心数据集和论文的链接。如果您有任何问题，请随时联系我们。谢谢。</sample>
    <sample id="1527">这篇论文的作者是来自马普尔研究所的。</sample>
    <sample id="1528">演讲者的名字是MC Yuan。</sample>
    <sample id="1529">这篇论文有四位作者。</sample>
    <sample id="1530">该方法与专门为同步翻译设计的 simST 架构进行了比较。</sample>
  </task>
</testset>