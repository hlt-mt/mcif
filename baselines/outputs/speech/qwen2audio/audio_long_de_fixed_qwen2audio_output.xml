<testset name="IWSLT2025" type="output">
  <task track="long" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind große webbasierte Datensätze, darunter politische Nachrichtenmedien.</sample>
    <sample id="1">Die Autoren sind an der University of Magelhaen verbunden.</sample>
    <sample id="2">Die Präsentation beinhaltet eine Vorstellung des Papers 'Document Understanding with Visual Reasoning' von TV aus dem Team von Ad Group, das sich auf die visuelle Verständnisproblematik bei Dokumenten konzentriert. Das Paper basiert auf der täglichen Arbeit der Autoren und richtet sich an Experten in der Document Understanding Branche. Es untersucht die Probleme, die bei der automatischen Verarbeitung von Dokumenten auftreten, und bietet Lösungen durch visuelles Denken.</sample>
    <sample id="3">Hallo und willkommen zu unserer Präsentation von DeepL, einem neuen Modul für die deutsche Texterkennung auf Dokumentebene und auf Satzebene. Mein Name ist Regina Stodden und ich werde Ihnen in der ersten Teil des Vortrags führen. Lassen Sie uns zunächst definieren, was Textsimplifizierung ist. Textsimplifizierung ist ein Prozess, bei dem ein Text angepasst wird, um seine Verständlichkeit für einen bestimmten Zielgruppe zu verbessern. Wie Menschen lesen.</sample>
    <sample id="4">Der Referent*in heißt Kayo Yan.</sample>
    <sample id="5">Das Multi-Head Attentive Model (MHA) wurde verwendet.</sample>
    <sample id="6">Die Arbeit besteht aus der Vereinigung von Multilingual- und Cross-Lingual-Summarisierung zu einer allgemeineren Methode namens Many-to-One-Summarization. Die Autoren sind Jane, Fandong, Du, Yunlong, Zhichu, Jianfeng und Jie.</sample>
    <sample id="7">Die Untersuchung hat ergeben, dass es weiterhin funktioniert.</sample>
    <sample id="8">Die vorgeschlagene menschliche Bewertungsmethode ist eine neue Dimensionale Ansatz zur Evaluierung von konversationalen AI.</sample>
    <sample id="9">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von der Qualität der Daten, der gewählten Algorithmen und der Anzahl der Benutzer ab.</sample>
    <sample id="10">Die尺例 können durch eine bessere Verständlichkeit der Antworten erhöht werden, indem z.B. zusätzliche Informationen oder Beispiele gegeben werden.</sample>
    <sample id="11">Der Vortragende Jack Hessel, Forscher am AI2, präsentiert humorvolle Erkennungsmarken für New Yorker-Caption-Wettbewerbe.联合研究涉及犹他大学、康奈尔大学、华盛顿大学、雅虎和开放AI。大型语言模型 können jetzt Witze generieren und erklären.</sample>
    <sample id="12">Zwei.</sample>
    <sample id="13">Inhaltsangabe: Das Vortragende Daniel Rothe präsentiert seine Arbeit 'Finding the sweet spot: Analysis and improvement of adaptive inference in low-resource settings' im Labor von Professor Roy Schwartz an der Hebrew University in Jerusalem. Adaptive Inferencing ist ein Verfahren zur Reduzierung der Vorhersagezeit bei großen Sprachmodellen, das auf dem Prinzip der Variabilität realer Weltdaten basiert. Durch die Verwendung von Low-Capacity-Modellen kann man sich auf variierende Komplexität des Datenmaterials verlassen.</sample>
    <sample id="14">Der Vortrag handelt über die Abhängigkeitsstruktur der Koordination. Es werden verschiedene Theorien und Ansätze zur Koordinierung diskutiert, bei denen sich die Struktur der Koordinatoren unterscheidet. Zum Beispiel in der universellen Abhängigkeit ist die Koordinatensystemstruktur von Lisa Bart und Maggie so gestaltet, dass der erste Konjunkt der gesamten Koordinatensystemstruktur vorsteht (in diesem Fall Lisa). Ein ähnlicher Ansatz wird in Godwin's gezeigt, was auf 'text' hindeutet.</sample>
    <sample id="15">Die Arbeit ist ein gemeinsames Projekt mit是我的导师亚历山大·科拉和伊万·蒂多夫。</sample>
    <sample id="16">Die Domänen, die stärker vereinfacht werden, sind der Dokumentebene und der Satzebene im Deutschen Texttyp.</sample>
    <sample id="17">The speech discusses multi-model relation extraction, a widely researched task aiming to determine the semantic relationship between entities in text. However, in real-world scenarios like social media, data is often presented in various forms and modalities, making it challenging to apply traditional methods.</sample>
    <sample id="18">In der Coordinierung von LISA-Bart und Maggie ist die erste Konjunktion der Kopf der ganzen Koordinatensstruktur.</sample>
    <sample id="19">The speech is about the acceptance of a research work on efficient open-domain question answering by SCL. The speaker, a Shenzhen University master's student named Zhang Chen, will present their work in five parts, focusing on the two-stage model as the main framework.</sample>
    <sample id="20">Ja, es werden Modelle für die biomedizinische Forschung präsentiert.</sample>
    <sample id="21">DEplain-apa beinhaltet deutsche Texte für die automatische Prüfung auf korrekte Grammatik und Syntax.</sample>
    <sample id="22">Die gute Generalisierung wird durch eine ausreichende Menge an trainierten Daten, die Qualität der Trainingsdaten, das Verständnis des Modells für das Problem und die 적절ige Verwendung von Features geführt.</sample>
    <sample id="23">In this talk, Dan Garvey will discuss their work on improving the ability of text image models to represent visual text. He specifically mentions the Imagine model, which encodes input text with a T5 architecture, highlighting its strengths and limitations in text representation.</sample>
    <sample id="24">Die Tendenz zu kürzeren linken Konjunktionen wurde durch eine Analyse der Verwendung von Coordinaten in Texten ermittelt, bei der die Anzahl der vorangestellten Konjunktionen gezählt wurde.</sample>
    <sample id="25">Die Experimente wurden so gestaltet, dass die Teilchen in verschiedenen Energiezuständen beschleunigt wurden und dann entlang einer Linie bewegt wurden, während ihre Bewegung von einem Detektor überwacht wurde.</sample>
    <sample id="26">Ein Basisklassifikator performs poorly with unbalanced data.</sample>
    <sample id="27">Ein Autor.</sample>
    <sample id="28">Jabot Hossaini, Philip Radoski, Silvia Parity und Anna Lewis.</sample>
    <sample id="29">Kontextsensitive MÜ-Modelle schneiden besser ab bei der Verarbeitung von Translationen, bei denen der Kontext eine wichtige Rolle spielt.</sample>
    <sample id="30">The paper presents Biner, a simple yet effective ensemble learning framework for large language models based on paragraph ranking and generative fusion. The team from AI2 and USC developed it. Many large language models are released weekly, claiming great performance, but this leaderboard can evaluate their relative strengths.</sample>
    <sample id="31">Die Autoren sind an der University of Cambridge verbunden.</sample>
    <sample id="33">Das Framework quantifiziert die Positionalität durch die Anzahl der Verbindungen zwischen Atomen in einem Molekül.</sample>
    <sample id="34">Crest ist eine gemeinsam entwickelte Framework für die Rationalisierung und Generierung von konträren Texten. Das Framework wurde durch eine enge Zusammenarbeit mit Alexander Ross, Fernando Guerrero und Daniel Martinez entstanden. Es dient dazu, Entscheidungen aufgrund des Eingabewerts zu interpretieren und diese Erläuterungen durch das Hervorheben relevanter Informationen zu erleichtern.</sample>
    <sample id="36">In this video, the speaker discusses multilingual machine translation and its advantages, such as scalability and speed, by collaborating with Robin Schmid, Isabelle Yao, and Stefan Bites.</sample>
    <sample id="37">Die menschenlichen Teilnehmenden haben dieselben Persona-Prompts verwendet.</sample>
    <sample id="38">Die genauen Datenquellen wurden nicht im vorliegenden Abschnitt erwähnt.</sample>
    <sample id="39">Zwei, Adam Skurawski und Maggi.</sample>
    <sample id="40">Die eng verwandten Aufgaben für cognitive Dissonanz sind die Identifizierung von Widersprüchen in Überzeugungen oder Verhaltensweisen und deren Bewältigung.</sample>
    <sample id="41">The speech discusses 'peacock', a personal common sense knowledge system for consistent and engaging narratives, developed with Sony Group Cooperation. It requires natural language processing systems to understand the relationships between speakers, listeners, or characters in a narrative.</sample>
    <sample id="42">Ein Autor.</sample>
    <sample id="43">Eine.</sample>
    <sample id="44">Das vorgestellte Framework ist durch eine 'characterizing design by means of' Vorgehensweise gekennzeichnet, was bedeutet, dass es ein neues oder verbessertes Verständnis der Designprozesse ermöglicht.</sample>
    <sample id="45">Das Setup mit den meisten Überschneidungen ist das, in dem Natural Language Prompts verwendet werden.</sample>
    <sample id="46">N/A</sample>
    <sample id="47">Hallo, ich bin Changbing, Diplom-Historiker an der University of Washington. Heute präsentiere ich unsere Arbeit von Vorbereitungsdaten bis hin zu Sprachmodellen und Downstream-Tätigkeiten wie dem Verfolgen von politischen Vorurteilen, die zu unfairen NLB-Modellen führen können. Sprachmodelle werden auf großen Online-Datenbanken trainiert, darunter auch politische Nachrichtenmedien. Laut einer Umfrage des C4-Publikums sind New York Times, Los Angeles Times, The Guardian, Huffington Post usw. gut abgedeckt in ihren Vorbereitungsdaten.</sample>
    <sample id="48">Zusammen mit seinen Kollegen von Google Translate.</sample>
    <sample id="49">Die genaue Anzahl der Token-Kontextlängen wurde nicht angegeben, es wird nur erwähnt, dass die Auswertungen für bis zu 50 Token durchgeführt wurden.</sample>
    <sample id="50">In der Präsentation wird über 'de plane', eine neue Quelle für die Germanisierung von Dokumenten auf Ebene des Dokuments und der Satzebene, gesprochen. Der Name des Speakers ist Regina Stodden. Die Zielgruppe sind Leser, die Texte für einen bestimmten Zweck anpassen möchten.</sample>
    <sample id="51">Die Domains, die in ihren Datensatz aufgenommen wurden, sind 'entity' und 'user'.</sample>
    <sample id="52">Positionalität bezieht sich auf die Art und Weise, wie Objekte oder Personen in einem bestimmten Raum oder einer Gesellschaft positioniert sind.</sample>
    <sample id="53">Der Referent*in heißt Daewi.</sample>
    <sample id="54">In this abstract, the speaker presents their research paper titled 'Transfer Learning for Dissonance Detection Addressing the Rare Class Challenge in ASL'. They define cognitive dissonance and its significance in language studies. The paper presents a solution using transfer learning for detecting dissonance in American Sign Language, addressing a rare class challenge.</sample>
    <sample id="55">Nein, EDAtt passt nicht zu einem bestehenden Offline-ST-Modell.</sample>
    <sample id="56">Ein Autor ist an der Arbeit beteiligt.</sample>
    <sample id="57">Ja, das Modell funktioniert in der Testsuite.</sample>
    <sample id="58">Die drei Varianten von KITMUS sind KITMUS-E, KITMUS-M und KITMUS-X.</sample>
    <sample id="59">In this presentation, the speaker will discuss language modeling in healthcare and present 'Dr. Bert', a robust pre-trained French model for biomedical and clinical domains. The main contribution of the article is the introduction of the first French biomedical model named Dr. Bert, which is based on Roberta and trained on a medical crowdsourced dataset.</sample>
    <sample id="60">Die Autoren sind an der Stanford University angemeldet.</sample>
    <sample id="61">Die abschließende Forschungsfrage betrifft die Wirksamkeit von wöchentlichen Überwachungen bei der Verbesserung der Leistung in der Schule.</sample>
    <sample id="62">Inhaltsübersicht: Der Autor spricht über sein纸上的系统研究，自然语言处理（NLP）生成的气体。 Er arbeitet an einer Zusammenarbeit mit Amir von Microsoft und MPG顾问Roi. NLP-Systeme basieren auf großen Sprachmodellen, die größer, komplexer und langsamer werden, was finanziell teuer sein kann.</sample>
    <sample id="63">Die Sensitivitätmetrik misst die Anzahl der correctly classified instances divided by the total number of instances in the test set.</sample>
    <sample id="64">Der Referent ist Jin Weiyi von der Universität für Wissenschaft und Technologie Chinas.</sample>
    <sample id="65">Eine höhere Sensitivität bedeutet in diesem Kontext normalerweise eine bessere Leistung des Modells.</sample>
    <sample id="66">The abstract states that mathematical reasoning is a fundamental aspect of human intelligence, enabling understanding and decision-making based on numerical data and language. The development of machines capable of solving mathematical problems has been a long-standing focus of AI and LP research. Recently, there has been increased interest in this area.</sample>
    <sample id="67">In diesem Artikel wird über die Interferenz in multilingualen Übersetzungsmodellen diskutiert. Solche Modelle können von der Synergi zwischen verschiedenen Sprachbärern profitieren oder leiden unter Interferenz. Zum Beispiel kann das Training auf Englisch zu Finnisch die Qualität von Englisch-Hessischen verbessern, während Englisch-Chinesisch negative Auswirkungen haben könnte. Es wurden viele Methoden vorgeschlagen, um die Interferenz zu reduzieren, aber sie werden oft mit kleinen Modellen demonstriert und nicht auf größeren Daten sets getestet.</sample>
    <sample id="68">Die Modelle werden vor der Trainingsphase mit minimaler Paarungstheorie evaluiert, um ihre Fähigkeit zur Verarbeitung von Sprachmustern in Bezug auf ihre Akzeptanz zu beurteilen.</sample>
    <sample id="69">Die Anzahl der sauberen Validierungsbeispiele hängt von verschiedenen Faktoren ab, wie zum Beispiel der Art des Modells, der Größe der Datenbank und der spezifischen Anforderungen des Anwendungsproblems. Eine typische Empfehlung ist, mindestens 100 Beispiele zu haben, um eine ausreichende Stabilität und Genauigkeit des Modells zu gewährleisten.</sample>
    <sample id="70">Die Autoren sind an der University of Pennsylvania tätig.</sample>
    <sample id="71">In this presentation, the authors discuss their work on resolving indirect disambiguation expressions for entity selection. They introduce the concept of 'entity scores' and mention that they are part of a joint project with Phil Radinski, Sylvia Parity, and Anna Lewis. The goal is to understand users' language when making choices and present an alternative question to avoid ambiguity.</sample>
    <sample id="72">Es ist notwendig, neue Methoden zur Messung von Medienverzerrungen zu entwickeln, da politische Nachrichtenmedien in ihren Vor-Trainingsdaten überwiegend eine bestimmte politische Sichtweise vermitteln, was zu unfairen NLB-Modellen führen kann.</sample>
    <sample id="73">Der Referent ist Axel.</sample>
    <sample id="74">The paper presents a dance-theoretic approach to dance connectedness with high logic coverage and massive multi-hop paths. The authors introduce themselves as Xiang Changshen and list two co-authors. They describe common technology as describing facts and related judgments in the everyday world, essential for machines interacting with humans, and atomic as a large-scale common technology base covering event-centered social aspects of impression knowledge.</sample>
    <sample id="75">The presentation focuses on the 'Joint Prop' project, a collaborative effort with friends and a supervisor. It emphasizes the motivation behind the work, highlighting the importance of named entity recognition and relation extraction in information extraction. The project has made significant progress using supervised learning techniques.</sample>
    <sample id="76">Die Pipeline beginnt mit der Sammlung von Daten, einschließlich politischer Nachrichtenmedien, um große Datensätze zu trainieren. Die darauf basierenden Sprachmodelle werden dann eingesetzt, um unfaire NLB-Modelle zu erstellen.</sample>
    <sample id="77">Die Arbeit befasst sich mit der Verbesserung der summerationale Funktionalität aus natürlichen Spracherfassung. Es ist ein gemeinsames Projekt von Yale University und Microsoft Research, an dem大部分的工作 when the first author war ein Praktikant bei Microsoft Research durchgeführt wurde. Im Projekt wird ein neues Datenmodell eingeführt.</sample>
    <sample id="78">Nein, der Vereinfachungsprozess ist bei DEplane-apa und Web gleich.</sample>
    <sample id="79">Nein, der NameCoscript wurde nicht erwähnt, daher ist davon auszugehen, dass es möglicherweise ein privater oder spezieller Begriff ist, der nicht für die Allgemeinheit zugänglich ist.</sample>
    <sample id="80">Das Wasserzeichen 'viu bagdo' wird als Wasserzeichen in den Text eingebettet.</sample>
    <sample id="81">Die Autoren gehören zur Pinnock University.</sample>
    <sample id="82">This video discusses 'aggregating multiple hypothesis signals for supervision of unsupervised automated essay scoring.' It explains how automated essay scoring, or AES, uses natural language processing to assess writing quality without human intervention. State-of-the-art AES models are trained using various techniques.</sample>
    <sample id="83">Ja, durch das Training mit einer Mischung von Sprachen können Encoder-Decoder-Modelle wie mt5 verbessert werden.</sample>
    <sample id="84">The speech discusses a paper on a dynamic network framework for the current year, highlighting background knowledge and traditional static networks that only process input data.</sample>
    <sample id="85">Ein Beispiel für eingeschränkte Sprachplanung ist das Führen von vorgegebneten Schritten in der日常 Routine, wie z.B. das Planen einer Reise oder der Zubereitung eines Menüs.</sample>
    <sample id="86">Die Opazität wird durch das Verwenden von Wasserstoffperoxid und einem pH-Wert von 4 erreicht.</sample>
    <sample id="87">Die Arbeit nutzt bestehende PLMs, um ein neues PLM aufzubauen, indem sie das Modell mit einem robusten Trainingsdatensatz anreift.</sample>
    <sample id="88">GPT-4 ist am wenigsten ausgerichtet auf kein Land.</sample>
    <sample id="89">The model uses the attention mechanism to learn knowledge from the data.</sample>
    <sample id="90">The audio discusses the importance of language model advancement and data annotation, particularly in LPs where recruiting native speakers is challenging. It suggests that language learners can contribute to this process, as there is a high number of non-native speakers who can help with data annotation tasks.</sample>
    <sample id="91">Die Anzahl der Aufgaben beeinflusst die Leistung des Modells positiv, je mehr Aufgaben das Modell absolvieren kann, desto besser wird seine Leistung.</sample>
    <sample id="92">The authors do not specify any baseline methods without trees in their paper.</sample>
    <sample id="93">Die beiden Co-Autoren sind Alexander Colah und Ivan Titev.</sample>
    <sample id="94">The video is a brief advertisement for paper, a large language model used for embedding and services. It mentions the importance of copyright protection for such models.</sample>
    <sample id="95">Omar is the first author of PaLM.</sample>
    <sample id="96">Hallo everyone, ich bin Jennie, ein erster Jahr P.H.D.-Student an der Columbia University und heute werde ich Ihre Arbeit 'Annual Positionality' präsentieren, die durch Design-basierte Analyse von C.C.P. Sets von Modellen charakterisiert ist. Dieses Werk wurde in Zusammenarbeit mit einigen Leuten an der University of Washington gemacht. Die Leitung für AI trägt Sebastian Santi, Ronan LaBosse, Katarina Rainerica und Martin SAP. Lassen Sie uns also beginnen, indem wir vorstellen, dass Sie für eine Zeitung arbeiten und Sie durch Ihre Nachrichten unter Ihrem Artikel durchsifteten, um Unterhaltungen zu entfernen.</sample>
    <sample id="97">Die Referentin geht auf vier Probleme von SimulST ein.</sample>
    <sample id="98">Durch die Überprüfung und Reduzierung von politisch beeinflussten Daten in der Vorbereitungsdatenbank und das Verwendung von unabhängigen Kontrollen während des Modelltrainings.</sample>
    <sample id="99">Hallo, ich bin Si Yu Yuan von der Fernuniversität. Ich bin hier, um unsere Arbeit zu präsentieren, die skriptbasierte Wissensunterscheidung von großen Sprachmodellen für konkrete Sprachplanung untersucht. Im Alltag planen Menschen ihre Handlungen oft durch die Verfolgung von Schritten in Form von festgelegten Skripten. Vorherige Arbeiten haben Sprachmodelle verwendet, um abstrakte Ziele stereotypischer Aktivitäten wie das Kochen zu planen.</sample>
    <sample id="100">Multi-hop QA beantwortet Fragen, die mehrere Schritte erfordern. Jeder Schritt bezieht sich auf ein Dokument im Corpus. Beispielsweise muss man zuerst alle Filme finden, an denen Brian Doyle-Murphy mitgewirkt hat, und dann den Film ausfinden, der 1988 veröffentlicht wurde.</sample>
    <sample id="101">PaLM erreicht einen State-of-the-Art-Status in hunderten von NLP-Tasks.</sample>
    <sample id="102">Wasserzeichenverfahren sind effiziente Methoden zur Identifizierung von Verpackungen oder Produkten aufgrund ihrer eindeutigen Wasserzeichen. Sie sind unverwechselbar, robust gegen Abnutzung und können automatisiert werden, um eine höhere Produktivität und Genauigkeit zu erreichen.</sample>
    <sample id="103">Die Übersetzungen der englischen TED Talks in 14 Sprachen sind verfügbar.</sample>
    <sample id="104">Eine Instanz wird aus einem Datensatz für die erneute Annotierung extrahiert.</sample>
    <sample id="105">Die Distanzmetriken, die verwendet werden, um den Unterschied zwischen harmlosen und Backdoor-Datensätzen zu messen, sind nicht spezifiziert in dem gegebenen Abschnitt.</sample>
    <sample id="106">The abstract summarizes the paper 'Quest': a collaborative work with Pete, Mungo, Kenton, and Crisina from Google DeepMind. It discusses an example of Jane, a zoologist on a field trip in Costa Rica, observing a previously unknown species of reptile. The second example is not provided in the given text.</sample>
    <sample id="107">Die Modelle wurden verwendet, um mehrere自然语言 in eine gemeinsame Metadatenstruktur zu übersetzen.</sample>
    <sample id="108">Die Arbeit untersucht, dass Sprachmodellakzeptanzurteile nicht immer robust zu Kontexten sind und präsentiert einen gemeinsamen Arbeitsentwurf mit John Gathman, Aaron Muller, Kanishka Mishra, Karen Fuentes, Roger Levy und Adina Williams. Sie besprechen dabei das Minimal-Paar-Paradigma, das Sprachmodelle auf ihre Akzeptanzurteile evaluiert.</sample>
    <sample id="109">Die vorliegende Präsentation beschäftigt sich mit der Entwicklung von Natural Instructionssystemen für die generelle Verarbeitung von Texten ohne menschliches Eingreifen. Die Methode basiert auf der Umformulierung bestehender LP-Datenbanken und ermöglicht es, beispielsweise neue akademische Benchmarks zu erstellen. Allerdings sind die Ergebnisse auf vorhandene akademische Benchmarks beschränkt und können nicht für alle Arten von Texten verwendet werden.</sample>
    <sample id="111">Die Autoren definieren Wörter mit mittlerer Häufigkeit als jene, die in einer bestimmten Textmenge vorkommen, aber nicht so häufig wie häufige Wörter und auch nicht so selten wie seltene Wörter.</sample>
    <sample id="112">Hallo everyone, mein Name ist Shu Han. Heute werde ich unser Paper vorstellen, das die Frage untersucht, ob der von uns genannte Entitätstagger \"Connel\" in 2023 noch funktioniert. Los geht's.
Unser Paper hat die Problematik der Generalisierung untersucht, indem es die benannte Entitätserkennungsaufgabe oder die NEAR-Aufgabe verwendet hat. Wir haben beobachtet, dass Modelle bisher Connel verwendet haben, um NEAR zu entwickeln.</sample>
    <sample id="114">Die Forscher der National University of Singapore arbeiten an der Entwicklung von Modellen zur Verarbeitung von Natural Language, die alle Aufgaben in einem Modell lernen können. Sie beziehen sich dabei auf das Konzept der 'Pillars of Strength for Multi-Head Attention'.</sample>
    <sample id="115">Die Größe der Sprachsegmente variiert je nachdem, welche Technologie verwendet wird.</sample>
    <sample id="116">National Language Understanding Models</sample>
    <sample id="117">Die Übereinstimmung mit dem Ausgangssatz ist der wichtigste Faktor für die Qualität des Beispiels.</sample>
    <sample id="118">The abstract summarizes theACL2023 submission which presents improvements to pre-training techniques for code switched NLPS. It defines code switching as the use of words from two or more languages in a sentence and provides an example of a code-mixed sentence. The paper aims to build computational models for this common linguistic phenomenon in diverse communities like India.</sample>
    <sample id="119">Die Arbeiten konzentrieren sich auf large-scale web crawling Daten mit politischem Schwerpunkt, insbesondere auf news media wie New York Times, Los Angeles Times, The Guardian, Huffington Post usw.</sample>
    <sample id="120">Das Modell nutzt Werte aus mehreren Ebenen.</sample>
    <sample id="121">Beispiele für direkte Inferenz sind 'x ist größer als y' oder 'y ist eine Funktion von x'.</sample>
    <sample id="122">The authors are from Fudan University.</sample>
    <sample id="123">The abstract presents research on multi-instruct, improving M6 airshow learning via instruction tuning. It discusses the use of large language models for various tasks and the benefits of instruction tuning.</sample>
    <sample id="124">The speaker discusses the importance of time reasoning and its three levels: time-to-time, such as calculating the year after 2020; time-based reasoning, involving understanding the passage of time; and temporal reasoning, which involves making judgments about when events will happen. The focus is on improving the latter capability through benchmarking.</sample>
    <sample id="125">Es ist ein einziger Autor, der die Arbeit präsentiert.</sample>
    <sample id="126">Nein, das wurde nicht erwähnt; die sprache beschränkt sich auf die Vorstellung des eigenen Arbeitsbereichs.</sample>
    <sample id="127">The paper presents a joint work between the speaker, Laura Schmidt, and their professor, Seongyun, on large language models as reasoning teachers. It summarizes how chain-of-thought reasoning has been introduced to enable large language models to solve complex tasks but faces limitations with smaller models like GPT-3 or POM.</sample>
    <sample id="128">Die Arbeit 'Kit Master' untersucht die Integration von Wissen aus verschiedenen Quellen bei der National Language Understanding Modellierung. Die Zusammenarbeit zwischen McGill University, Microsoft Research und der Mila ist beteiligt. Die Modelle beruhen auf den Parametern, die während des Vorkommens erworben werden, einschließlich dem durch Vor-Training gewonnenen Wissens.</sample>
    <sample id="129">Die Autoren haben 'paper marked personas' als Beispiel für eine markierte Gruppe genannt.</sample>
    <sample id="130">Die Modellarchitektur, die Conal 2003 genannt ist, generalisiert nicht gut.</sample>
    <sample id="131">Die Testdatensätze sind Widerstand, Kondensator und Spule.</sample>
    <sample id="132">Zwei, das Autorenduo bestehend aus Akshata und Martin.</sample>
    <sample id="133">Die Autoren arbeiten mit mehreren Modulen.</sample>
    <sample id="135">The abstract summarizes that the Emory NLP lab, led by Gino Choi, has developed ABC-Eval, a new approach to evaluating conversational AI systems. It compares the performance of a dialogue model against current state-of-the-art methods using human evaluation.</sample>
    <sample id="136">Die Arbeit untersucht 'format an alternative to accuracy for numerical reasoning', motiviert durch Anwendungen in der Realität und die Notwendigkeit von fehlerfreiem numerischem Verständnis. Die Arbeitsgrundlage ist eine QR-Code-Verbindung zu dem Paper, GitHub-Repository, Twitter- und LinkedIn-Profil des Autors.</sample>
    <sample id="137">The talk is about 'Tela Design', a data set published in ACML for language-guided floor plan generation. The speaker discusses recent advancements in test conditional generative AI models that create high-fidelity images by understanding visual concepts from sentence-level descriptions. These models generate realistic images but are not yet widely used.</sample>
    <sample id="138">Das Lernmodell muss in der Lage sein, Wissen aus verschiedenen Quellen zu integrieren.</sample>
    <sample id="139">In this presentation, the speakers' names are Yin and Zhiyang.</sample>
    <sample id="140">Ja, das hat Coscript durchlaufen.</sample>
    <sample id="141">Die Grenzen bestehender Ressourcen für kontextbasierte Übersetzung liegen in derlimitierten Verfügbarkeit von qualitativ hochwertigen Daten, künstlicher Intelligenz-Technologien und ausreichenden Testdatensätzen zur Validierung der Ergebnisse.</sample>
    <sample id="142">Der englische Text übersetzt ins Deutsche lautet: 'Hallo, und ich werde über unsere Arbeit an der Lösung von indirekten Abfragen für die Entitätselektion sprechen, bei der wir das Attributskorpus einführen. Mein Name ist Javot Hosaini, und dies ist eine gemeinsame Arbeit mit Philip Bradbury, Sylvia Parity und Anna Lewis. Unser Ziel ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Entscheidung treffen möchten. Und berücksichtigen Sie diese alternative Frage: Did you mean easy on me or I got a feeling? Hier hat ein Benutzer gesagt...'</sample>
    <sample id="143">The approach is compared with the existing SimulST guidelines.</sample>
    <sample id="144">Die Autoren sind an der Universität von Paris-Saclay angemeldet.</sample>
    <sample id="145">Jenny</sample>
    <sample id="146">The talk is about a paper on the analysis of omissions in dialogue summarization. The speaker will introduce the background of dialogue summarization, which is a subtask of text summarization. It involves creating a concise summary that captures the most important information in a dialogue. There are various scenarios in dialogue summarization.</sample>
    <sample id="147">Zwei, Myra und Esmond D'Arcy.</sample>
    <sample id="148">Hallo, ich bin Sara Papafrom der Universität von Toronto und Förderndes Mitglied von Bruno Kassler, und ich werde die Aufmerksamkeit als Leitfaden für eine gleichzeitige Übersetzungsdokumentation vorstellen. Es ist ein gemeinsames Projekt mit Matteo Negrini und Marco Turco. Was ist gleichzeitige Sprachübersetzung? Gleichzeitige Sprachübersetzung oder SimulST ist der Prozess, bei dem gesprochene Sprache in Echtzeit in einem anderen Text übersetzt wird. Dies ermöglicht es, cross-language-Kommunikation zu ermöglichen.</sample>
    <sample id="149">Nein, es ist nicht bekannt, ob der Datensatz öffentlich zugänglich ist.</sample>
    <sample id="150">The presentation focuses on the extraction of questions from meeting transcripts for Q&amp;A systems. It highlights the potential of meeting transcripts as a new domain for NLP research and mentions the collaboration with Adobe Research and UNC Chapel Hill.</sample>
    <sample id="151">Hallo everyone, mein Name ist Yin und meine Kollegin Zhixiang, und wir werden unsere Forschung über Multi-Instruktions-Verbesserung von Multi-Modell-Sicherheitslernung durch Instruction Tuning präsentieren. Mit den Fortschritten in großen Sprachmodellen haben viele Arbeiten begonnen, neue Lernparadigmen zu erforschen, bei denen per Trainings-Sprachmodell für verschiedene unterer Schichten in einem Parameter- und Dateneffizienten Weg verwendet werden. Kürzlich haben viele Studien gezeigt, dass Instruction Tuning große Sprachmodelle ermöglicht.</sample>
    <sample id="152">In der Präsentation 'Exploring Large-Scale Language Models for Classical Philology' wird über die Verwendung großer Sprachmodell für die Klassische Philologie gesprochen. Die Vorstellung beinhaltet auch die Einführung von wertvollen Ressourcen für Ancient Greek und Latin sowie die Untersuchung von Auswirkungen und Herausforderungen der Multilingualität in diesen Modellen.</sample>
    <sample id="153">In this presentation, the speaker will discuss their work on resolving ambiguities in text-to-image generative models. They examined existing prompt ambiguity and provided examples of prompts that can have various interpretations.</sample>
    <sample id="154">Die Autoren gehören zur University of Toronto.</sample>
    <sample id="155">Jabot Hossaini</sample>
    <sample id="157">The abstract describes a joint work on dialoguesummarization with dynamic structure fusion graph, aiming to extract silent information from a dialogue context into a concise summary.</sample>
    <sample id="158">The abstract describes a presentation on 'dual cash for long document neural coreference resolution'. It explains the task of coreference resolution and its importance in documents with multiple mentions of entities across text.</sample>
    <sample id="159">Hallo everyone, ich bin Kostas Sina und freue mich, Sie zu unserem Talk über unsere ACER-23-Paper Language Model Acceptability Judgments are not always robust to context zu begrüßen. Es ist ein gemeinsames Werk mit John Gehrke, Aaron Muller, Kanishka Mishra, Karen Fuentes, Roger Levy und Atina Williams. In diesem Werk besuchen wir das Minimal-Pair-Paradigma erneut. Das Minimal-Pair-Paradigma beurteilt Sprachmodelle auf der Grundlage von Akzeptabilitätsurteilen.</sample>
    <sample id="160">Die Input-Tokens werden in einem ersten Schritt mit Hilfe von Multisets annotiert.</sample>
    <sample id="161">Coscript enthält ein Skript.</sample>
    <sample id="163">Die beste Methode zur Ausrichtung von DEplane hängt von der spezifischen Zielgruppe ab, da es verschiedene Ansätze gibt, wie man Texte für eine bessere Verständlichkeit optimiert.</sample>
    <sample id="164">Der Vorteil von schwach überwachtem Lernen ist, dass es den Schülern mehr Freiheit gibt, ihre eigenen Entscheidungen zu treffen und sich auf ihre individuellen Stärken und Interessen zu konzentrieren.</sample>
    <sample id="165">The abstract summarizes the paper's title, which presents an approach to adaptive reasoning using mutually exclusive explanations. The author, Wen Teng Zhao, is a PhD student at Cornell University and will provide a concrete example followed by a formal definition.</sample>
    <sample id="166">Ein neues Arbeitspapier zur Verarbeitung von komplexen Bildern wurde vorgestellt, das auf einer neuralen Netzwerkarchitektur basiert und für die Erkennung von Bildern aus wissenschaftlich komplexen Texten entwickelt wurde. Die Methode soll bei der Verarbeitung ähnlicher Bilder helfen, die beschreibungsschwer sind.</sample>
    <sample id="167">Die Dokumente wurden zu gleichen Teilen mit manuellem und automatischem Alignment ausgerichtet.</sample>
    <sample id="168">Der CoNLL++-Datensatz wurde erstellt, indem die Entitätserkennungsaufgaben für das Jahr 2003 durchgeführt wurden.</sample>
    <sample id="169">The paper presents 'PAM', a 540 billion parameter language model created by Google Translate, which achieved state-of-the-art results on hundreds of NLP tasks.</sample>
    <sample id="170">Hallo everyone, mein Name ist Jiaxuan Zheng vom Peking-Universität. Heute werde ich meine Arbeit vorstellen: Exemplarische Cross-Lingual-Semantisches Parsing in mehreren natürlichen Sprachen und Metadaten. Also, semantisches Parsing ist die Aufgabe, semantische Darstellungen von Benutzeranfragen zu erstellen, wie z.B. SQL und Lambda-Vergleich. Und Cross-Lingual-Semantisches Parsing ist es, die Aufgabe zu sein, Anfragen in mehreren natürlichen Sprachen in mehrere Bedeutungsrepräsentationen zu übersetzen.</sample>
    <sample id="171">The background on embedding services was introduced, mentioning large language models like GPT-3 and LaMa.</sample>
    <sample id="172">Ja, mehrsprachige LLMs wie Codex oder Bloom können für Cross-Lingual Semantic Parsing verwendet werden.</sample>
    <sample id="174">The paper 'Organ Analysis 35K: A Large-Scale Dataset for Argument Quality Analysis' presents a unique dataset specifically designed for argument quality analysis. It differs from other datasets by its extensive size and the thorough annotation process, making it ideal for research in natural language processing. The authors encourage interested parties to check out their paper and conference post for more information on the dataset's features and collection process.</sample>
    <sample id="175">Die Methode nutzt Multisets und Latente Permutations zu kompositioneller Generalisierung ohne Bäume.</sample>
    <sample id="176">Die Fairness eines nachgeschalteten NLP-Modells wird durch das Verfolgen der Spuren politischer Biase in den vorherigen Trainingsdaten definiert, um unfaire Modellresultate zu vermeiden.</sample>
    <sample id="177">Jannicke Lavrak</sample>
    <sample id="178">Coast of Sina</sample>
    <sample id="179">The speech discusses 'mind-mapping' language models, such as the Theory of Mind, a game and belief tracker used to measure reasoning ability in humans and models. It also mentions false belief questions as a tool to test understanding in these models.</sample>
    <sample id="180">Der Referent*in heißt Mirah.</sample>
    <sample id="181">The speech is about a research paper that presents a method to distinguish script knowledge from large language models for constrained language planning. The approach involves using human-labeled scripts to train a model, which can then be used to plan actions by following step-by-step instructions. The paper is from Fudan University and was presented by Si Yuan.</sample>
    <sample id="182">Tropikalismus bezieht sich auf die Vorliebe von Sprachmodellen für bestimmte Formen von Text, was zu einer ungenauen Abstraktion von Informationen führen kann.</sample>
    <sample id="183">Die Autoren haben die von Menschen verfassten Beschreibungen der Zielgruppen als 'paper marked personas' verwendet.</sample>
    <sample id="184">Es wurde eine datadriven multilinguale Exploration eingesetzt.</sample>
    <sample id="185">DrBERT ist ein französisches Modell, während ChuBERT ein chinesisches Modell ist.</sample>
    <sample id="187">Zwei.</sample>
    <sample id="188">Iteratives Transferlernen ist ein Lernverfahren, bei dem Wissen und Fähigkeiten aus einer Domäne in eine andere übertragen werden.</sample>
    <sample id="189">Das Ziel des Datensatzes ist es, die Verwendung von indirekten Abfragen für Entitätselektion zu lösen und dabei die Identitätskorrekturen einzuführen.</sample>
    <sample id="190">Ein Angreifer könnte Modellparameter über den Einsatz von Wasserzeichen in den Modellen entnehmen, um ihre Integrität zu verletzen oder den Code des Modells zu kopieren.</sample>
    <sample id="191">Zwei, Sara Papa und Bruno Kassler.</sample>
    <sample id="192">Die Präsentation beinhaltet eine Einführung in das Thema 'Adaptive Gradient Based Optimization for Large-Scale Language Models', die Auswirkungen von Adam auf die Trainingsprozesse und die Anforderungen an die Optimierungsmethode.</sample>
    <sample id="193">Zwei.</sample>
    <sample id="194">Die Autoren sind Studenten an der Carnegie Mellon University.</sample>
    <sample id="195">In this presentation, the speaker will introduce their work on hierarchical question decomposition for explainable question answering (XQA). They aim to provide an explanation of why a specific answer is selected and discuss recent developments in XQA, categorizing them into two main directions: neurosymbolic methods and formal representations like Sparkle.</sample>
    <sample id="196">Lisabarb</sample>
    <sample id="197">Die Common Practice ist, menschenbasierte Bewertung zu verwenden.</sample>
    <sample id="198">Die Akzeptanz der Modelle muss über das gesamte Kontextfenster bewertet werden, da dies notwendig ist, um sicherzustellen, dass sie robust gegenüber verschiedenen Szenarien sind und nicht nur in einer begrenzten Umgebung effektiv sind.</sample>
    <sample id="199">Nein, das mehrsprachige Training hat nicht zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell geführt.</sample>
    <sample id="200">Nein, die Annotatoren kennen die Entität nicht im Voraus.</sample>
    <sample id="201">Die Bewertung erfolgte anhand von Werten wie Word Error Rate, Character Error Rate und Perplexity.</sample>
    <sample id="202">Nein, das Paper untersuchte nicht spezifisch, ob die Regression bei der Generalisierung auf bestimmte NER-Typen auswirkt.</sample>
    <sample id="203">Positionalität ist wichtig, weil sie es ermöglicht, die Bedeutung von Worten in einem Satz zu verstehen und somit die Kontexte zu analysieren, die sie bilden.</sample>
    <sample id="204">Nein, es wurde lediglich erwähnt, dass sie nicht angepasst wurden.</sample>
    <sample id="205">This presentation focuses on the issue of biased news models resulting from political bias in pretraining data used by language models. The research shows that major news media like New York Times, Los Angeles Times, and Guardian are heavily covered in their pretraining data, leading to potential unfairness in the generated news models.</sample>
    <sample id="206">Das Modell, das verwendet wird, ist ein Deep Neural Network.</sample>
    <sample id="207">Es wurden hunderte von NLP-Testsets verwendet.</sample>
    <sample id="208">Die Autoren haben vier Empfehlungen vorgeschlagen.</sample>
    <sample id="209">The proposed method outperforms the strongest baseline by a large margin.</sample>
    <sample id="210">Der Referent*in heißt Stu Heng.</sample>
    <sample id="211">Ja, die Ergebnisse und der Datensatz der Studie können als Benchmark verwendet werden.</sample>
    <sample id="212">Mit mehreren kleineren Modellen.</sample>
    <sample id="213">Das multi-instruktive Modell.</sample>
    <sample id="215">Der Vortrag handelt über die Abhängigkeitsstruktur der Koordination und untersucht, wie sie von verschiedenen Theorien und Ansätzen behandelt wird. Es wird auf die Struktur der Koordinatensysteme von Lisa Bart und Maggie verwiesen, bei denen der erste Konjunktus der Kopf des gesamten Koordinatensystems ist. Ebenso gibt es ähnliche Ansätze in der Theorie der meaningfullness.</sample>
    <sample id="217">The presentation focuses on 'Scene to Unseen: Exploring Compositional Generation of Mutual Triplet Control Dialogue' and is delivered by Lu Lu Zhao from Beijing University of Posts and Telecommunications. The speaker will elaborate on their work in seven aspects, starting with motivation.</sample>
    <sample id="218">Die Autoren sind von Google Translate.</sample>
    <sample id="219">The presentation focuses on a comparative contrast multi-stage pipeline for uncovering financial signals in financial reports. The work was conducted by Jia Huichu, a research assistant at the Academy of Economic Studies, with contributions from Yu Xianghuan and Chen Weiliang. It builds upon the background of financial report analysis, which is the foundation of this research project.</sample>
    <sample id="220">Die Autoren sind an der University of Stony Brook University.</sample>
    <sample id="221">Die Arbeit untersuchte die Übersetzung von chinesischen zu japanischen Sprachpaaren.</sample>
    <sample id="222">The speech discusses the process of answering open-domain questions using Wikipedia articles and a reader model. It involves retrieving relevant passages, integrating them with the question, and presenting the results.</sample>
    <sample id="223">Changbin</sample>
    <sample id="224">Die genauen Modelle, die während der Experimente untersucht wurden, werden in der vorliegenden Information nicht erwähnt.</sample>
    <sample id="225">Sechs Aufgaben werden für Training und Tests verwendet.</sample>
    <sample id="226">Es ist ein einziger Autor, der Regina Stodden genannt wird.</sample>
    <sample id="227">The speech addresses the success of language models and their potential for solving various NLP tasks, yet it also raises the question of what is missing in current research. The speaker suggests that grounding language understanding, which involves converting natural language expressions into actionable plans or programs, is key to advancing language models.</sample>
    <sample id="228">The authors have experimented on three datasets.</sample>
    <sample id="229">Gabriela Skarzynska und Henning van der Velden haben eine gemeinsame Arbeit über die Erkennung von ungenauen Behauptungen in der argumentativen Schreibweise vorgestellt. Textrevisionsprozesse sind ein wesentlicher Bestandteil des professionellen Schreibens und werden normalerweise iterativ durchgeführt, bis der Autor seinen Standpunkt erreicht hat.</sample>
    <sample id="231">NACHOS ist ein Datensatz medizinischer Krawlerdaten.</sample>
    <sample id="232">Der Referent ist Avi Bilad.</sample>
    <sample id="233">The abstract summarizes the presentation on simultaneous speech translation (SIMULST) as a real-time translation method enabling cross-language communication. It mentions the collaboration with Matteo Negrini and Marco Turco for the SIMULST paper.</sample>
    <sample id="234">Die Prompt-Strategie beeinflusst die Ergebnisse positiv.</sample>
    <sample id="235">Die Autoren sind Patrick Farnsworth, MEYU, Andrae F. Martinez und Graham Newbigging.</sample>
    <sample id="236">1. Set up your environment. 
2. Initialize the model. 
3. Train the model with the provided code. 
4. Evaluate the performance of the model. 
5. (Optional) Fine-tune the model for better results if needed.</sample>
    <sample id="237">Die Autoren schlagen vor, National Language Understanding-Modelle zu entwickeln, die auf einer Vielzahl von Wissensquellen basieren, einschließlich den Parametern, die während der Vorbereitung erworben wurden, sowie anderen Knowledge Sources.</sample>
    <sample id="238">In diesem Video präsentiert Abhu von der University of Central Florida einen neuen Benchmark-Datenbanken-Metadaten-Satz, der für die Entwicklung von Zusammenfassungstechnologien für verschiedene Meetingdomänen entwickelt wurde. Die Datenbank soll es ermöglichen, schnell und effektiv wichtige Informationen aus Meetings zu sammeln.</sample>
    <sample id="239">Hallo everyone, mein Name ist Avi Bilal und ich werde Ihnen einen kurzen Überblick über das Paper 'Grundlegende Konzepte der maschinellen Übersetzung mit PAMT' geben. Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate. PAMT ist ein 540 Milliarden Parameter großer Sprachmodell, das letztes Jahr auf der ICLR präsentiert wurde. Es basiert auf einer großen Sammlung von Texten mit 180 Milliarden Tokenn. Beim letzten Test hat es die State-of-the-Art erreicht.</sample>
    <sample id="240">Hallo, ich bin Daewi, ein PhD-Student an der Universität Hamburg in Deutschland. In diesem Video möchte ich Ihnen unser jüngstes Werk präsentieren: "Weiter als Sie denken - Eine kritische Betrachtung der wöchentlichen Überwachung". Dies ist gemeinsame Arbeit mit Xiao Yunshen, Majos Musba, Gias Stephen und Ditmar Klackow. Ich würde gerne mit einer kurzen Einführung zu wöchentlicher Überwachung beginnen und wöchentlicher Überwachung. In der wöchentlichen Überwachung werden wir nicht managen.</sample>
    <sample id="241">Der Abstract beschreibt ein Paper, das die menschenorientierte Bewertung von frühen Misinformationserkennungssystemen im Kontext der COVID-19-Behandlung untersucht. Das Projekt wurde gemeinsam mit Yang Chen, Wei Xu und Alvin Ritter an der Georgia Tech durchgeführt. Es wurden viele vorgeschlagenen Ansätze zur automatischen Erkennung von Falschnachrichten auf sozialen Medienplattformen untersucht, aber alle scheitern an zwei Schlüsselmerkmalen: Oft werden diese Systeme unrealistisch bewertet und es gibt mangelhafte Datengrundlage.</sample>
    <sample id="242">Gängige Bewertungsmethoden sind menschenbasierte Evaluierung.</sample>
    <sample id="243">Sechs Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="244">National Language Understanding Models</sample>
    <sample id="245">The presentation focuses on the ' needle in a haystack' problem in high agreement Amazon Mechanical Turk workers, analyzing their authors and the two-step pipeline for finding them. The motivation behind the pipeline is the problematic nature of automatic matrixes.</sample>
    <sample id="246">Ja, der Code ist verfügbar unter https://github.com/microsoft/knowledge-integration.</sample>
    <sample id="247">Die vorliegende Arbeit beschreibt die Entwicklung eines neuen Verfahrens zur Faktenverifizierung aufgrund von Wikipedia-Texten unter dem Titel 'Fact Verification via Reasoning on Wikipedia Text'. Es gibt bestehende Datensätze wie 'Fever' und 'Vitamin C', die verwendet werden, um Fakten zu verifizieren, aber es gibt keinen Datensatz, der speziell für die Verifizierung von Wikipedia-Inhalten entwickelt wurde.</sample>
    <sample id="248">Nein, es gibt keine Information darüber, ob die Annotatoren für NLPositionality in Bezug auf jede demografische Gruppe ausgewogen sind.</sample>
    <sample id="249">Die Sätze wurden durch das Hinzufügen von 'but' durcheinandergebracht.</sample>
    <sample id="250">Eine dimensionale Bewertung bedeutet, dass man某件事情 mehrere Dimensionen oder Aspekte unter Berücksichtigung prüft, anstatt nur eine einzige Perspektive zu haben.</sample>
    <sample id="251">Die Autoren gehören zur University of Science and Technology of China.</sample>
    <sample id="252">In this presentation, the speaker will outline their work on an unsupervised case retrieval using event extraction. The project is a collaborative effort with Abdullah Joshi, Akshar Sharma, and Ashmitosh Mody, involving legal professionals such as lawyers and judges who traditionally rely on precedent to cite relevant cases.</sample>
    <sample id="253">The presentation is about 'Disorder', a double domain adaptation model for detecting signs of mental disorders in social media, developed by researchers from Mexico and Spain. It defines a mental disorder as a psychological syndrome associated with distress and disability affecting cognition, feelings, mood, and behavior. Different types of mental disorders are recognized.</sample>
    <sample id="254">The presentation focuses on 'uncertainty-guided level denoising for document-level distant relation extraction'. It describes the method as a tool to extract relationships between entities within documents, represented by a figure. Previous methods relied heavily on manually annotated datasets.</sample>
    <sample id="255">In Fällen, in denen es darauf ankommt, dass der Prompt möglichst präzise und unmissverständlich ist, ist seine Form wichtig.</sample>
    <sample id="257">Die Autoren haben verschiedene Dialogmodelle evaluiert.</sample>
    <sample id="258">Die Arbeit untersucht, ob große Sprachmodellien die Qualität von Texten in der natürlichen Spracherkennung evaluieren können. Dazu werden大型语言模型受指示，以评估示例文本的质量。</sample>
    <sample id="259">The talk is about cross-language semantic parsing, which involves building semantic representations of user queries in multiple natural languages and converting them into multiple meaning representations.</sample>
    <sample id="260">Es ist nicht klar, wie viele Autoren an der Arbeit beteiligt sind.</sample>
    <sample id="261">Gute Planer sollten in der Lage sein, komplexe Aufgaben zu planen und zu organisieren, flexibel zu sein, Fähigkeiten im Zeitmanagement zu haben, Risiken zu berücksichtigen, in der Lage sein, Ziele zu definieren und zu erreichen, sowie eine gute Kommunikations- und Koordinationsfähigkeit besitzen.</sample>
    <sample id="262">Ein Autor ist beteiligt.</sample>
    <sample id="263">The paper presents work on mitigating label biases in in-context learning, a popular approach for utilizing large language models. It explains that in-context learning is unstable due to design choices like the order and examples used, and prior research has shown instability increases from these factors.</sample>
    <sample id="264">The presentation is about a paper titled 'T-ABT: Transformer-based Audio Visual Text Generation Task Generation'. It discusses the current state of large-scale language processing and model capacity, with examples such as machine translation and image captioning. The focus is on the development of a transformer-based approach for generating audio visual text tasks.</sample>
    <sample id="265">Der Name des Referenten ist Vasudha.</sample>
    <sample id="266">Die Autoren gehören ans University College London.</sample>
    <sample id="268">Die häufigsten Fehler von PaLM sind Übertaktung, falsche Einstellungen und mangelhafte Datensammlung.</sample>
    <sample id="269">Hallo, ich bin James Finch und ich bin Sarah Finch. Und heute werden wir Ihnen alles über ABC-Eval berichten, eine neue dimensionale Methode zur Evaluierung von konversationalen AI. Dieses Werk wurde vom Emery NLP-Lab unter der Leitung von Professor Gino Choi an der Emory University durchgeführt und in Zusammenarbeit mit Amazon Alexa AI. Lassen Sie uns sagen, dass Sie gerade ein Dialogmodell entwickelt haben und sehen möchten, wie es sich gegen den aktuellen Stand der Technik verhält. Die übliche Praxis besteht darin, menschliche Bewertungen zu verwenden.</sample>
    <sample id="270">Die Autoren sind James Finch und Sarah Finch, beide von der Emory University.</sample>
    <sample id="271">CFT steht für 'Critical Failure Threshold', ein Begriff aus der Informatik, der beschreibt, bis zu welchem Grad eine Fehlerquote in einem System akzeptabel ist.</sample>
    <sample id="272">Zehn Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="273">Der englische Text übersetzt ins Deutsche lautet: 'Hallo, mein Name ist Kaiyang und ich werde unsere Arbeit präsentieren, die titled When Does Translation Require Context? A Data-Driven Multilingual Exploration. Dieses Werk wurde in Zusammenarbeit mit Patrick Farnance, MEYU, Andrae FT Martinez und Graham Newbigging durchgeführt. So viele Übersetzungen hängen von Kontext ab. Zum Beispiel, wie würde man 'mol' in diesem Satz übersetzen? Well, if the previous sentence was 'Things could start to get dangerous if the ministers find out,' then mol refers to a spy.</sample>
    <sample id="274">Der Referent*in heißt Lucas John.</sample>
    <sample id="276">The abstract presents a work on evaluating machine translation metrics for Indian languages using the IndicMT dataset. Several evaluation metrics for English-to-English translations are proposed, and there are many studies that perform meta-evaluation by analyzing their correlation with human scores or discussing their advantages and shortcomings.</sample>
    <sample id="277">If the new method has a name, state it; otherwise, respond with 'No Name'.</sample>
    <sample id="278">Die Autoren beschreiben die Methode der 'markierten Wörter' als eine Möglichkeit, Stereotypen in großen Sprachmodellen oder LMs zu messen, indem sie natürliche Sprachprompts verwenden.</sample>
    <sample id="279">Die Autoren sind Studenten der University of Washington.</sample>
    <sample id="280">The speech is about multimodal fusion frameworks for emotion recognition in conversations, explaining the task and goal of emotion regulation in dialogues.</sample>
    <sample id="281">The abstract states that translation requires context, referencing a collaborative project titled 'When Does Translation Require Context? A Data-Driven Multilingual Exploration.' It explains how translations can vary based on the surrounding text and previous sentences.</sample>
    <sample id="282">The talk is about a new work in SL '23 titled 'Story Trans, Non-Parallel Story Author Style Transfer with Discourse Representations and Content Enhancing'. It addresses the challenge of non-parallel text style transfer in natural language generation. Most previous studies have focused on the token or sentence level, but this work goes beyond by considering discourse representations to improve content enhancement.</sample>
    <sample id="283">Lisa</sample>
    <sample id="284">The paper presents a novel fuzzy set-based information extraction method, called SSUIE, which enhances the accuracy of extracting universal information from text by identifying and labeling the span boundaries of the targeted entities. This method relaxes the strict binary classification of existing models by allowing for intermediate values, improving the model's robustness and adaptability to different texts.</sample>
    <sample id="285">The video discusses the importance of feature error correction for data integration using FAN grante evaluation framework. It highlights that summary generated by models may contain factual errors and presents two solutions: introducing a human in the process or utilizing advanced machine learning techniques to automate the task.</sample>
    <sample id="286">Sarah Finch</sample>
    <sample id="287">Vier Autoren sind an der Arbeit beteiligt: Javot, Hussein, Radinsky, Silvia und Anna.</sample>
    <sample id="288">Es wurden verschiedene Datensätze verwendet, einschließlich Korpusen aus der englischen Sprache mit verschiedenen Kontexten und einer Vielzahl von grammatischen Strukturen.</sample>
    <sample id="290">The five methods for the first research question are: QM, RM, SM, IM and CM.</sample>
    <sample id="291">Das Modell wird anhand von klinischen Daten aus der medizinischen Welt evaluiert.</sample>
    <sample id="294">CamemBERT wurde mit einem Datensatz namens 'NATOS' trainiert, der aus medizinischer Crowdsourced-Daten besteht.</sample>
    <sample id="295">Der Referent*in heißt Adam Skurkowski.</sample>
    <sample id="296">This video presents a collaborative work between the University of Turin and Amazon Alexa focused on language understanding and natural language processing, predominantly based on supervised machine learning and data-driven approaches. The development of these methods requires extensive data collection and preprocessing.</sample>
    <sample id="297">In der vorliegenden Aussage wird die Verwendung von Codierter Rhetorik in politischen Reden untersucht. Der Bezug zu 'Dachhorns' und 'Hundehalsbändern' symbolisiert die Kontrolle über die Kommunikation. Die Rede beinhaltet eine Beispiel-Rede des Senators Josh Holly, die als Angriff auf die jüdische Elite interpretiert werden kann. Die Aussage betont die Bedeutung von Sprache und码 bei der Verbreitung von politischer Meinung.</sample>
    <sample id="298">Die Untersuchung ergab, dass die Zeitverschiebung die Hauptursache für den Leistungsverlust bei der Generalisierung mit Hilfe des benannten Entitätserkennungsaufgaben (NER) war.</sample>
    <sample id="299">In this presentation, the authors discuss enhancing the robustness of neural network models using minimal supervision training. They highlight that despite remarkable progress, recent studies have shown that the success of these models largely depends on effective learning and user guidance. This work is a collaborative effort with Andres La霍斯, University of Cambridge.</sample>
    <sample id="300">Die vorliegende Arbeit stellt die 'interaktive Diktat' vor, ein von der Semantic Machines Group entwickeltes Werkzeug zur intuitiven und natürlichen Texterstellung durch Sprache. Das Projekt wurde in Zusammenarbeit mit Jason Isner, Adam Pauls und Sam Thompson durchgeführt.</sample>
    <sample id="302">Es ist notwendig, die Token für die Ausgabesequenz zu permutieren, um eine kompositionelle Generalisierung zu erreichen, die die Fähigkeit des Lerners zur Verarbeitung von tieferen Rekursionen und unsichtbaren Kompositionen berücksichtigt.</sample>
    <sample id="303">Die Autoren empfehlen, ihre Methoden zum Abbau von Vorurteilen transparenter zu machen, weil dies dazu beitragen kann, das Verständnis der Algorithmen und ihrer Entscheidungsgrundlagen zu erhöhen, was wiederum zur Verbesserung der Modelle führen kann.</sample>
    <sample id="304">Inakzeptable Minimalpaareingaben sind Eingaben, die von einem Sprachmodell nicht erwartet werden und daher als fehlerhaft oder ungrammatisch angesehen werden.</sample>
    <sample id="305">In 'Wider than you think. A critical look at weekly surprise learning' untersuchen die Autoren das Konzept der wöchentlichen Überraschungsforschung und präsentieren ihre Ergebnisse aus einer gemeinsamen Arbeit mit Xiao Yunshen, Maios Musba, Gias Stephen und Dieter Klackow.</sample>
    <sample id="306">Sebastian Schuster und Naj Kim geben in ihrem Vortrag einen kurzen Überblick über ihre Arbeit an der Verfolgung von Entitäten in Sprachmodellen. Sie betonen, dass ein Agent, um eine Diskurs zu verstehen, die erwähnten Entitäten tracken muss und wie sich ihr Status ändert, während der Diskurs entfaltet. Anhand eines Rezepts Beispiel werden die Veränderungen an den genannten Entitäten erläutert.</sample>
    <sample id="307">Die Bewertungsmetriken wurden nicht im vorgeschlagenen Text erwähnt.</sample>
    <sample id="308">In dem Abstract wird eine Arbeit präsentiert, die in Zusammenarbeit mit der University of Washington entstanden ist und sich auf das Design von Modellen für AI konzentriert. Die Autoren sind Sebastian Santi, Ronan Le Bras, Katarina Rainera und Martin SAP. Das Projekt beinhaltet die Erstellung von annual positionality, einer Charakterisierung von Design durch CTA-Set-Modellen.</sample>
    <sample id="309">Die Metrik, die verwendet wurde, war die Coherence Score.</sample>
    <sample id="310">Die Domäne für unzusammenhängende Sätze wurden ausgewählt, um die Performanz der Sprachmodelle zu testen.</sample>
    <sample id="311">Die Autoren gehören zur University of Manchester.</sample>
    <sample id="312">MultiInstruct verbessert Multimodell-Sicherheitslernen durch Instruction Tuning.</sample>
    <sample id="313">Zwei Autoren, James Finch und Sarah Finch.</sample>
    <sample id="314">Die binäre Koordination ist eine Form der Koordination, bei der zwei Substanzen miteinander verknüpft sind, um gemeinsame Eigenschaften zu erfüllen.</sample>
    <sample id="315">Die genauen Durchschnittswerte für die Verwendung von Prompts in dieser Studie wurden nicht angegeben.</sample>
    <sample id="316">Die Ergebnisse haben sich als besonders nützlich erwiesen, um das kleine T5-Modell zu verbessern, indem es es bei der Planung von konkreten Aktionen unterstützt.</sample>
    <sample id="317">The presentation focuses on 'Code IE Large Code Generation Models as Better Future Information Extractors'. It discusses information extraction, a fundamental task in natural language processing, which involves extracting structured information from unstructured text. Common tasks include entity recognition, named entity relation extraction, and relation extraction. The presentation highlights the potential of large code generation models as future information extractors.</sample>
    <sample id="318">Hallo, ich bin Jannicke Lavalette und werde Ihnen meine Arbeiten zu Dr. Bert präsentieren, einem robusten trainierten Modell auf Französisch für die medizinische und klinische Domäne. In dieser Präsentation werden wir zunächst über Sprachmodellierung in der Gesundheitsversorgung sprechen, dann werden wir das Hauptbeitrag unseres Artikels vorstellen. Wir präsentieren das erste biomedizinische Modell auf Französisch namens Dr. Bert, das auf Roberta basiert und anhand von NACHOS trainiert wurde, einer Datenmenge aus medizinischen aggregierten Daten.</sample>
    <sample id="319">The work studies language modeling in healthcare using a pre-trained model named Dr. Bert, which is based on Roberta and trained on a medical corpus called Natsos.</sample>
    <sample id="320">Die Größe des Faktors der Überanpassung, der speziell auf die Wiederverwendung von Tests zurückzuführen ist, beträgt 203.</sample>
    <sample id="321">Die Qualität wurde durch eine Befragung von Lesern beurteilt, die den Text vor und nach der Vereinfachung gelesen hatten.</sample>
    <sample id="322">Der Text beschreibt, was Moralphilosophie ist und wie sie uns hilft, zwischen right und wrong zu unterscheiden. Sie ist die Grundlage für unsere moralische Überzeugung.</sample>
    <sample id="323">The paper presents a dynamic knowledge representation learning approach for QA tasks using language models and knowledge repair. The method involves updating knowledge based on new information, enhancing its ability to answer questions accurately.</sample>
    <sample id="324">Ja, die vorliegenden Informationen legen nahe, dass Sprachmodelle politische Vorurteile haben können, da sie auf großen Web-Crawl-Daten trainiert werden, die überwiegend aus politischen Nachrichtenmedien wie New York Times, Los Angeles Times und The Guardian bestehen.</sample>
    <sample id="325">Hallo, mein Name ist Matthias Lendermann und heute werde ich Ihnen einen kurzen Überblick über unsere Arbeit zu kompositioneller Generalisierung ohne Bäume mit Multi-Set-Tagging und latenten Permutationen geben. Dies ist gemeinsame Arbeit mit meinen Mentoren Alexander Kolah und Ivan Titev. Kompositionelle Generalisierung kann als Fähigkeit eines Lerners verstanden werden, tieferen Rekursionen und unsichtbare Kompositionen zu behandeln.</sample>
    <sample id="326">Kognitive Dissonanz ist der Zustand, in dem zwei oder mehr Überzeugungen oder Verhaltensweisen unvereinbar sind, was zu einem Mangel an innerer Ruhe und einer Anstrengung zur Änderung führt.</sample>
    <sample id="327">The presentation focuses on 'Magic Tower', a model for universal experts in language repetition learning. It was developed during the author's internship at MSRA-LC and is thanked to Intel Cognitive Computing Group.</sample>
    <sample id="328">Das New York Times Language Model ist das am meisten links stehende Modell.</sample>
    <sample id="329">The speech is about a research project that generated structured data for location tagging of short videos. The team, consisting of Jie Minghao, Shao Gang, Haining Yu Xing, and Yang, collaborated on the project. They focused on zero-shot video localization, aiming to find relevant segments using natural language queries for non-video content.</sample>
    <sample id="330">The audio does not provide information on whether cumulative training is better than iterative training for active learning.</sample>
    <sample id="331">Der Referent*in heißt Sarah Papi.</sample>
    <sample id="332">Die Daten für die MuDa-Benchmark stammen aus einer Zusammenarbeit mit Patrick Farnsworth, EMILY, Andrae FT Martin und Graham Newbigging.</sample>
    <sample id="333">The abstract summarizes the presentation on 'Injecting Knowledge into Neural Machine Translation'. The speaker, Wenhao from Nanjing University, acknowledges the collaboration with Jinqin Xu from Shanghai AILab, Shu Jianhua and Jiayun Chen from Nanjing University, and Lin Pengkong from the University of Hong Kong. They focus on neural machine translation and aim to integrate knowledge into the model for better performance.</sample>
    <sample id="335">Matthias Lendermann</sample>
    <sample id="336">Sprachübergreifender Transfer ist der Prozess, bei dem Daten in verschiedenen Sprachen übertragen werden.</sample>
    <sample id="337">The speech provides an overview of research on vocabulary knowledge and its impact on language learning, highlighting the difficulty of representing vocabulary words and their importance for downstream models.</sample>
    <sample id="338">In his presentation, Pinxian will outline their research group's work titled 'Are Human Explanations Always Helpful towards Objective Evaluation of Human Natural Language Understanding?' This collaborative project involves researchers from Rensselaer Polytechnic Institute, Northeastern University, and IBM Research. They aim to present their motivation, discuss related works, and focus on the contributions of human explanations to the objective evaluation of natural language understanding.</sample>
    <sample id="339">Die Autoren sind Studenten an der Universität Salzburg in Deutschland.</sample>
    <sample id="340">The abstract describes a large-scale, syntactically diverse protein dataset generated by MRB translation and its collaboration with other researchers. It emphasizes the importance of this project for NLP research and its potential benefits to the field.</sample>
    <sample id="341">Die Autoren verwenden eine Latenz von bis zu 200 Millisekunden.</sample>
    <sample id="342">The presentation covered the topic of 'large-scale personalized dialogue data set' and was conducted by Gao Jinshen from Shanghai Jiaotong University and Alibaba DAMO Academy. It featured an outline of the presentation, including an introduction with an open dialog format.</sample>
    <sample id="343">Hallo everyone, ich bin Akshata und heute präsentieren mein Co-Autor Martin und ich unsere Arbeit 'The Knowledge Mustache - Evaluating knowledge integration from multiple sources'. Dieses Werk ist eine Zusammenarbeit zwischen der Universität McGill, Mila und Microsoft Research. National Language Understanding Modelle basieren auf einer Vielzahl von Wissensquellen, wie beispielsweise dem in ihren Parametern enthaltenen Wissen, das normalerweise während des Vorkommens erworben wird und dem durch die Integration erworbenen Wissens.</sample>
    <sample id="344">Baumbasierte Methoden haben normalerweise einen höheren Aufwand in Bezug auf Rechenzeit und Ressourcenverbrauch.</sample>
    <sample id="345">The paper presents a study on compositional generalization without trees using multisets and latent permutations. It is a collaborative work with Alexander Coler and Ivan Tovstolyak. Compositional generalization refers to a learner's ability to handle deeper recursion and unseen compositions.</sample>
    <sample id="346">Die Autoren sind复仇之魂 (Strengthen) und der Name ihrer Universität wird nicht genannt.</sample>
    <sample id="347">Hallo, ich bin Myra und heute werden wir über unsere Arbeit sprechen, bei der wir mit Hilfe von natürlichen Sprachprompten die Stereotypen in großen Sprachmodellen oder LMs messen. Dieses Werk wird in Zusammenarbeit mit Esmond Durmusch und Dan Jarauski durchgeführt. In den letzten Jahren haben viele die Vorhandensein von sozialer Vorurteils- und Stereotypen in großen Sprachmodellen oder LMs dokumentiert. Allerdings haben diese Messungen verschiedene Einschränkungen. Sie basieren in der Regel auf manuell erstellten Datensätzen, die sehr zeitintensiv zu sammeln sind, und sie verwenden auch.</sample>
    <sample id="348">In this paper, the authors discuss their research on using natural language prompts to measure stereotypes in large language models (LLMs). They合作研究了在大型语言模型中社会偏见和刻板印象的普遍存在，但是这些方法存在局限性，它们通常依赖耗时的手工构建数据集。</sample>
    <sample id="349">Hallo everyone, mein Name ist Jingwei Yi vom University of Science and Technology of China. Es freut mich, ein kurzes Werbevideo über Papier zu geben. kopieren Sie mein Modell? Schützen Sie die Urheberrechte großer Sprachmodells für das Einfügen von Diensten durch Wasserzeichen im Hintergrund. Lassen Sie uns zunächst das Hintergrundwissen zu eingebetteten Diensten einführen. Derzeit sind große Sprachmodelle wie TPT-Lama-Powder</sample>
    <sample id="350">Das Paper untersucht, was 'superhuman performance' im heutigen Kontext bedeutet und welche Auswirkungen es auf die Bewertung von Systemen hat. Es ist ein gemeinsames Werk mehrerer renommierter Forscher aus verschiedenen Institutionen weltweit. In den letzten fünf Jahren wurde die leaderboard-basierte Bewertung zur Standardmethode in der LP-Praxis. Das Hauptziel wurde somit, die Topposition in populären Benchmarks zu erreichen.偶尔, es kommt vor, dass Systeme die human-level-Ebene oder sogar Superhuman-Performance erreichen.</sample>
    <sample id="351">The paper investigates the effectiveness of 'Connel 2003' for named entity recognition in 2023, observing that models have been relying on it for developing NER systems.</sample>
    <sample id="352">ABC-Eval ist ein neues-dimensionalales Ansatz zur Evaluierung von konversationalen AI.</sample>
    <sample id="353">The paper presents 'Python Code Generation by Asking Clarification Questions', a program that utilizes natural language processing to automatically generate code from user specifications. The method addresses the challenge of input under specification, an issue prevalent in code generation programs.</sample>
    <sample id="354">CoNLL-2003</sample>
    <sample id="355">Hallo, mein Name ist Vasudha und ich bin ein CSE-Habilitandatskandidat an der Stony Brook University. Ich würde gerne meine Arbeit vorstellen, die ich in den ACL 2023 als einen langen Artikel über maschinelles Lernen für das Erkennen von Dissonanz eingereicht habe. Es geht darum, das seltene Problem der Dissonanzerkennung zu lösen. Wir beginnen damit, kognitive Dissonanz zu definieren und warum es wichtig ist, sie in Sprache zu studieren. Einfach ausgedrückt, kognitive Dissonanz sind zwei gegensätzliche Überzeugungen oder Handlungen.</sample>
    <sample id="356">Die Autoren sind Studenten der University of Cambridge.</sample>
    <sample id="357">Der Referent ist Si Yu Yuan von der Fernuniversität.</sample>
    <sample id="358">Die Arbeit wurde in Zusammenarbeit mit Patrick Farnance, MEYU, Andrae FT Martinez und Graham Newbigging durchgeführt.</sample>
    <sample id="359">The approach is compared with the SimulST architecture.</sample>
    <sample id="361">The speech discusses 'countercomp', a method using counterfactual scenarios to improve compositional generalization for multi-step quantitative reasoning, particularly in question answering tasks involving financial tables.</sample>
  </task>
</testset>