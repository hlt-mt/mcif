<testset name="MCIF Baselines" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">hi i'm john green phd student in university of washington today i'm presenting our work from pre-training data to language models to downstream tasks tracking the trails of political biases leading to unfair nlp models the language models are trained on large scale web crawl data political news media are well covered in their pre-training data according to a survey of the c4 corpus we can see that new york times los angeles times the guardian huffington post etc are well covered in language model training data this has created a mixed blessing for language model applications so on one hand they were able to learn from diverse perspectives which celebrates democracy and the plurality of ideas on the other hand these different political opinions are inherently socially biased and might lead to potential fairness issues in downstream task applications</sample>
    <sample id="1">hello everyone i'm mark shatta and today my co-author martin and i are presenting our work the kit must have evaluating knowledge integration from multiple sources this work is a collaboration between mcgill university niela and microsoft research</sample>
    <sample id="2">hi welcome to our presentation of deep plane a new corpus for german text amplification on the document level and on the sentence level</sample>
    <sample id="3">my name is regina stodden and i will guide you through the first part of the presentation let's first define text simplification</sample>
    <sample id="4">text amplification is a process of adapting a text to improve the text comprehension of it for a specific target group as people with reading problems or non-native speakers receive english content and use chinese to describe its meaning</sample>
    <sample id="5">to train a text simplification model we require parallel pairs of text for example of documents or sentences</sample>
    <sample id="6">in the example here you can see a parallel aligned sentence pair of a complex german sentence and its translation into plain language</sample>
    <sample id="7">to simplify the sentence different techniques are possible as you can see in the example such as lexical substitution clause deletion cross deletion reordering or insertion of words</sample>
    <sample id="8">we now propose our new corpus dplane because in the recent years there were some problems with existing corpus so for example these corpus here are too small to train a text simplification model on</sample>
    <sample id="9">the other three models which are proposed in recent years are all automatically aligned which means they can be error-prone in their alignments</sample>
    <sample id="10">therefore we propose our new corpus dplane which is split into two subcorpora dplane-apa and dplane-web dplane-apa is based on news texts</sample>
    <sample id="11">in deep lane apa we aligned 483 documents all manually it results in roughly 30000 13000 parallel sentence pairs</sample>
    <sample id="12">for deep lane web this corpus includes different domains and we also align all of these 750 documents on the one hand manually and on the other hand with automatic alignment methods</sample>
    <sample id="13">总计将产生三十四百五十个句子对。</sample>
    <sample id="14">我们分析了我们的句子对，稍微多说一下，例如在简化的类型上。</sample>
    <sample id="15">as you can see here the bible texts are much stronger simplified than for example the news text or the language learner text</sample>
    <sample id="16">on all levels regarding for example lexical simplification structural simplification also overall level of simplification</sample>
    <sample id="17">furthermore you can see that our deplaining corpus has a high variety of different simplification transformations so for example in the deplaining api corpus we have much more reorderings and word additions than we have in the deplaining web corpus</sample>
    <sample id="18">on the other hand in the web corpus we have much more rephrasings</sample>
    <sample id="19">so let's now see what we can do with this corpus hello i am omar and now i will talk about the use cases for our dataset dplay so for the first use case we can evaluate automatic alignment methods</sample>
    <sample id="20">近年来，有许多对齐方法出现，但在机器翻译的背景下。</sample>
    <sample id="21">where we have two parallel documents written in different languages and we want to extract alignments of sentences in post documents</sample>
    <sample id="22">but in our use case we are trying to extract alignments between sentences of two parallel documents having the same language having the same content but they are on a different complexity level</sample>
    <sample id="23">and now as we have our dataset d plane which have manually aligned sentences we can use these sentences as gold standard alignments to evaluate some of the proposed alignment methods</sample>
    <sample id="24">and we did some adaptations to the proposed methods and we have published all these adaptations and the codes to run our experiments in the paper</sample>
    <sample id="25">at the end we concluded that the best automatic alignment method to use for german text simplification is the method of mass alignment</sample>
    <sample id="26">you can also find the code to run this method on your own documents in the paper</sample>
    <sample id="27">the second use case that we showed in our paper is the case of automatic text simplification</sample>
    <sample id="28">by fine-tuning language models to produce simplified text from the complex input text</sample>
    <sample id="29">we have fine-tuned two different models we have fine-tuned a model of long in part to produce document-level simplifications</sample>
    <sample id="30">我们还微调了正常基础模型，以产生句子级别的简化。</sample>
    <sample id="31">you can also find all the checkpoints and you can look into more details at the scores and the evaluation metrics of our experiments in the paper</sample>
    <sample id="32">我们得出结论，这个基本的微调可以产生或可以获得比基线得分更好的得分。</sample>
    <sample id="33">我们提议将这些结果作为未来自动文本简化问题的基准。</sample>
    <sample id="34">thank you so much for your attention and we hope to meet all of you during the conference thank you</sample>
    <sample id="35">hello my name is kyo yen and i will be presenting our work titled when does translation require context a data-driven multilingual exploration this work was done in collaboration with patrick frenoux emilie yu andrew ft martins and graham newbigg</sample>
    <sample id="36">the ltd corpus has 6000 alternative questions across three domains and it has 42000 indirect referring expressions results with t5x large model are summarized below</sample>
    <sample id="37">so going back to the question that we raised in the title of our paper do conll 2003 taggers still work in 2023 and we found that the answer is actually a resounding yes</sample>
    <sample id="38">our approach attempts to reduce the subjectivity of human evaluation by explicitly annotating whether or not each model response expresses certain behaviors such as responding with irrelevant information or contradicting itself</sample>
    <sample id="39">we addressed these research questions in our work and our findings are as follows first we find that interestingly recent wsl methods indeed require clean validation samples to work properly otherwise there is a large performance drop as shown in this figure if there are no clean validation samples then the trained models cannot generalize beyond the original weak labels meaning that the training is pointless</sample>
    <sample id="40">when we show this alternative question to the armstaters they know the name of these entities but they don't necessarily know about the entity</sample>
    <sample id="41">hello i am dawei a phd student at salant university in germany in this video i would like to present our recent work weaker than you think a critical look at weakly supervised learning this is joint work with xiaoyu shen marios mouzakis and geoffrey stephens</sample>
    <sample id="42">hello my name is adam sperkowski and this talk is about the dependency structure of coordination</sample>
    <sample id="43">as you may know there are different dependency structures assumed by different theories and corpus approaches so for example in universal dependencies the structure of the coordinate coordination lisa bart and maggie</sample>
    <sample id="44">是这样的，第一个连词是整个坐标结构的头，所以在这个例子中，lisa。</sample>
    <sample id="45">a similar approach is assumed in igor milchuk's meaning text theory where again the whole coordinate structure is headed by the first conjunct so these two approaches are asymmetric right they single out one of the conjuncts</sample>
    <sample id="46">还有一些对称的方法来协调结构，例如拖拽法和结合头法，假设在拖拽树中，协调结构由结合词头。</sample>
    <sample id="47">so we get dependencies from end to all the conjuncts</sample>
    <sample id="48">最后，还有一种多头式的方法，例如在德卡森的词法语法中。</sample>
    <sample id="49">where so to say all conducts are heads of the coordinate structure so we get dependencies from the governor here labs to all conducts separately these are buttons</sample>
    <sample id="50">now the aim of this paper is to produce a novel argument for the symmetric structures of coordination like these two and against the asymmetric structures of coordination like these two</sample>
    <sample id="51">okay the argument is based on the principle of dependency length minimization that i will explain on the basis of these examples</sample>
    <sample id="52">so in english as you might know our direct objects prefer to be close to the verb while adjuncts may be further away right so march read it yesterday is fine because the direct object it is close to the verb</sample>
    <sample id="53">while march read yesterday it is much worse right because here between the verb and the direct object there is an adjective yesterday</sample>
    <sample id="54">然而，当直接宾语非常重且非常长时，这个效果可能会被缓解，因为那时它可以被移动到介词之后的位置。</sample>
    <sample id="55">this is illustrated here so both these sentences are fine marge read this absolutely fascinating book about the bcs today is okay now instead of it we have this long and p</sample>
    <sample id="56">但也可以说，马奇昨天读了一本绝对令人着迷的书。</sample>
    <sample id="57">so the reasoning here is that this is possible because even though this sentence violates the general grammatical principle that direct objects should be next to the verb</sample>
    <sample id="58">这满足依赖长度最小化原则，该原则指出更短的依赖关系更受欢迎。</sample>
    <sample id="59">so these two trees only show the length of the crucial dependencies so the ones that are not constant among these two structures</sample>
    <sample id="60">so here we have a dependency from red to the adjective of length 7 measured in words and from red to book of length 4 so to get 11</sample>
    <sample id="61">when you move when you swap these two constituents the sum of these two dependencies becomes 6 right so instead of 11 6 much shorter that's why this sounds quite okay right it violates one principle but it satisfies another one</sample>
    <sample id="62">okay uh so what we did we extracted various statistics from uh about coordination from the enhanced version of pen of the pen tree bank and see the paper why wouldn't use uh universal dependencies</sample>
    <sample id="63">and these statistics confirm the observation made many times before that left conjuncts tend to be shorter so salt and pepper and not pepper and salts measured in syllables</sample>
    <sample id="64">此外，还观察到随着长度差异的增加，这种趋势也在增长。</sample>
    <sample id="65">so when the difference between the lengths of the two conjuncts grows the shorter conjunct prefers to be the first one stronger right so the proportion is bigger of the left short conjunct</sample>
    <sample id="66">but what's novel in this paper is that we observed that this tendency only occurs when the governor is on the left or absent</sample>
    <sample id="67">right so the governor is on the left in this example i saw bob and lisa so the governor is on the left</sample>
    <sample id="68">it's absent in the second example homer came and sneezed here we have coordination of two verbs and there's no outside external governor right so in such cases the left conjunct prefers to be shorter the more so the bigger the difference between the two conjuncts</sample>
    <sample id="69">然而当右翼执政者拉夫特执政时协调团结网的效果消失了</sample>
    <sample id="70">so we showed that by measuring length in characters that's the first column in syllables the middle column and in words the right column so i'll concentrate on the right one</sample>
    <sample id="71">我们看到的是当州长在左边的时候</sample>
    <sample id="72">the tendency for the left conjunct to be shorter grows steadily with the absolute difference in words and the same is observed when there is no governor as in coordination of sentences but when the governor is on the right this tendency disappears</sample>
    <sample id="73">and we show in the paper how this provides an argument against asymmetric structures of coordination as these two and for the symmetric structures as these two</sample>
    <sample id="74">so see the paper for the full agreement and arguments sorry and talk to us about the poster session thank you</sample>
    <sample id="75">this is joint work with my advisors alexander koller and ivan titov</sample>
    <sample id="76">as you can see here the bible texts are much stronger simplified than for example the news text or the language learner text</sample>
    <sample id="77">okay so what we did we extracted various statistics from about coordination from the enhanced version of the pen tree bank and see the paper why wouldn't use universal dependencies and these statistics confirmed the observation made many times before that left conjuncts tend to be shorter so salt and pepper and not pepper and salt measured in syllables</sample>
    <sample id="78">we also observe that specialized data is better more specialized data is better but it doesn't scale well all the pre-trained models obtained from nachos are freely available on eugen face and all the training scripts are on our github repository</sample>
    <sample id="79">therefore we propose our new corpus-d-plane which is split into two sub-corpora d-plane-apa and d-plane-web d-plane-apa is based on news texts</sample>
    <sample id="80">our conclusion is that for good generalization we would need a better model architecture larger model size as well as more fine-tuning examples and these goes hand in hand we can't just have one ingredient but throw out the others at the same time we also found that the performance drop here is caused by temporal drift and kind of surprisingly it is not caused by adaptive overfitting even though connor 2003 has been used for over 20 years so going back to the question that we raised in the title of our paper do connor 2003 taggers still work in 2023 and we found that the answer is actually a resounding yes we hope our paper calls for more research on how to improve generalizations of the models</sample>
    <sample id="81">however when the governance on the right as here left governs the coordination then that this effect disappears so we show that by measuring length in characters that's the first column in syllables the middle column and in words the right column so i'll concentrate on the right one</sample>
    <sample id="82">so we showed that by measuring length in characters that's the first column in syllables the middle column and in words the right column so i'll concentrate on the right one what we see here is that when the governor is on the left the tendency for the left conjunct to be shorter grows steadily with the absolute difference in words and the same is observed when there is no governor as in coordination of sentences but when the governor is on the right this tendency disappears</sample>
    <sample id="83">on collecting around 1000 examples of discourse unit pairs we ran training for an initial classifier trained only on 43 examples of dissonance to no surprise the classifier performed not much better than chance given the low occurrence of dissonance and absence of any prior such data set we are facing the problem of absolute rarity</sample>
    <sample id="84">hi i'm john green phd student at the university of washington today i'm presenting our work from pre-training data to language models to downstream tasks tracking the trails of political biases leading to unfair nlp models</sample>
    <sample id="85">the cartoon has three speech bubbles in the first bubble bob says remember that song we were listening to yesterday and with that bob sets the dialogue context in the second speech bubble alice says do you mean easy on me or i got a feeling</sample>
    <sample id="86">now we use the muda benchmark to evaluate models and we find that context-aware models are significantly more accurate than models that do not use context for certain discourse phenomena such as formality and lexical cohesion but these models are not much better than models that do not use context on other phenomena like ellipsis pronouns and verb form so this sort of suggests where we would need to see more progress for document-level translation</sample>
    <sample id="87">hi everyone i'm cost of senna and i'm pleased to welcome you to our talk of our acl 2023 paper language model acceptability judgments are not always robust to context this is a joint work with john gauthier aaron muller kanishka misra karen fuentes roger levy and etina williams</sample>
    <sample id="122">our framework works in two main steps the first step is to re-annotate datasets with diverse annotators and we ought to do this over looking at the demographics of original datasets annotators because usually only a few annotators annotate each instance and because demographics are rarely collected and shared and so we ought to re-annotate data to get many annotates per instance and to get a rich set of demographic data we then take the annotations by demographic and compare them to the models and data sets using a pearson's r correlation score and thus our framework actually differs from annotator disagreement literature by comparing end users with models and data sets predictions and labels as opposed to looking at just annotator agreement or modeling annotator distributions</sample>
    <sample id="155">our prompts to generate these personas were inspired by a study where they gave these prompts to human subjects finding that by giving it to human subjects they also were able to surface racial stereotypes</sample>
    <sample id="156">okay uh so what we did we extracted various statistics from uh about coordination from the enhanced version of pen of the pen tree bank and see the paper why wouldn't use uh universal dependencies</sample>
    <sample id="157">hi my name is adam sperkowski and this talk is about the dependency structure of coordination</sample>
    <sample id="158">we transfer from two different tasks topic independent dissonance stance classification a task that determines if two debate statements from different people are in agreement or in disagreement irrespective of topic called debate here and on binary classification of expansion and comparison classes of pity be since these two are closely related to the conception of consonance and dissonance and we call them cee here we find that on transferring the zero-shot performance on the annotated dataset is already much better than chance with the best with auc 062 further on iteratively fine-tuning on both tasks we find that fine-tuning of cee tasks followed by further fine-tuning on debate yields a much better zero-shot performance thus this is the model that we use to cold start the active learning</sample>
    <sample id="159">hello everyone my name is xuhong today i'm going to present our paper do convolution 2003 named entity taggers still work well in 2023 let's get started</sample>
    <sample id="160">hello my name is vasudha and i'm a computer science phd candidate at stony brook university i would like to present our work accepted into acl 2023 as a long paper transfer learning for dissonance detection addressing the rare class challenge</sample>
    <sample id="161">and thus our framework actually differs from annotator disagreement literature by comparing end users with models and data sets predictions and labels as opposed to looking at just annotator agreement or modeling annotator distributions</sample>
    <sample id="162">and now for some results so first we use alexicon of stereotypes and we find that the generated personas contain a lot more stereotypes than the human written ones</sample>
    <sample id="163">but these models are not much better than models that do not use context on other phenomena like ellipsis pronouns and verb form so this sort of suggests where we would need to see more progress for document level translation we also compare different commercial systems and our benchmark shows that debel is usually more accurate than google translate for document level translation to summarize we perform a data-driven analysis across 14 language pairs to identify when translations require context</sample>
    <sample id="164">hi i'm jean bean phd student at the university of washington today i'm presenting our work from pre-training data to language models to downstream tasks tracking the trails of political biases leading to unfair nlp models</sample>
    <sample id="165">so language models are trained on large-scale web crawl data</sample>
    <sample id="166">political news media are well covered in their pre-training data according to a survey of the c4 corpus we can see that new york times los angeles times the guardian huffington post etc are well covered in language model training data</sample>
    <sample id="167">这为语言模型应用带来了混合的好处。</sample>
    <sample id="168">so on one hand they were able to learn from diverse perspectives which celebrates democracy and the plurality of ideas on the other hand these different political opinions are inherently socially biased and might lead to potential fairness issues in downstream task applications</sample>
    <sample id="169">to this end we propose to investigate the political bias propagation pipeline from pre-training data to language models to downstream tasks specifically by asking the following questions</sample>
    <sample id="170">first how do we evaluate the political leaning of language models and what role does pre-training data might have on such political biases</sample>
    <sample id="171">secondly how do language models with different political leanings actually perform on downstream tasks and whether that might result in fairness issues in nlp applications</sample>
    <sample id="172">so specifically we first propose to prompt language models with different prompt formats using the political questionnaires such as the political compass test this ensures us to do automatic evaluation well grounded in political science literature</sample>
    <sample id="173">so some preliminary results demonstrate that first language models do have varying political leanings they occupy all four quadrants on the political compass</sample>
    <sample id="174">we can also see that gpt-4 is the most liberal language model of them all and gpt theories are generally more socially liberal than bert theories and its variants</sample>
    <sample id="175">secondly we aim to investigate to which extent the political biases of language models are actually picked up from training data</sample>
    <sample id="176">so we conduct a controlled experiment by further pre-training language model checkpoints on six different parties and corpora separated into news and social media further divided into their political leaning</sample>
    <sample id="177">通过在这些党派和语料库上进一步预训练语言模型，我们可以看到语言模型的意识坐标也相应地发生了变化。</sample>
    <sample id="178">for example for robert further fine-tuned further trained on the left-leaning reddit corpus we can see a substantial liberal shift in terms of its</sample>
    <sample id="179">in terms of these political biases</sample>
    <sample id="180">and we also try to investigate whether language models can pick up the polarization that's prevalent in our modern society</sample>
    <sample id="181">so we divide pre-training corpus into pre-45th president of the united states and after 45th president of the united states we separately pre-train language models on the two different temporal corpora</sample>
    <sample id="182">we can see that language models generally had a political leaning that is further away from the center after 2017 so this indicates that language models can also pick up the like polarization in our society</sample>
    <sample id="183">so last but not least we evaluate language models with different political leanings on hate speech detection and fake news detection two nlp applications that often involve language models and could have very significant implications</sample>
    <sample id="184">so we see that if we investigate the per category performance that is to say if we separate the performance into</sample>
    <sample id="185">different demographics or political leaning of news media we can see a pattern that for example for hate speech detection left-leaning language models are better</sample>
    <sample id="186">at detecting hate speech targeting socially minority groups</sample>
    <sample id="187">however our work is detecting hate speech targeting more powerful groups in our society</sample>
    <sample id="188">and vice versa right-leaning language models are better at detecting hate speech targeting white and men however worse at detecting hate speech targeting at black lgbtq plus and other minority communities</sample>
    <sample id="189">similar trends also happen for fake news detection where we see that left-leaning language models are better at detecting misinformation from their opposite political leaning and vice versa</sample>
    <sample id="190">this will further show many qualitative examples to see that language models with different political leanings</sample>
    <sample id="191">do give different predictions to hate speech and misinformation examples based on their social categories there are a bunch of more examples in the appendix to further highlight that</sample>
    <sample id="192">这表明存在一个非常紧迫的公平性问题，涉及语言模型的政治偏见。</sample>
    <sample id="193">for example if a right-leaning language models were to be fine-tuned on hate speech or misinformation or whatever and deployed to a popular social media platform</sample>
    <sample id="194">this would mean that people with opposite political opinions might be marginalized and the hate speech targeting minority groups might just run rampant without any control</sample>
    <sample id="195">so this has sounded the alarm for us to acknowledge and tackle the fairness issues resulted by language model political leanings</sample>
    <sample id="196">so a little bit of discussion we would also like to highlight that we exposed the unique dilemma regarding language model political biases it's like between sila and carib this</sample>
    <sample id="197">so if we do not sanitize political opinions in language model training data the bias would propagate from pre-training data to language models to downstream tasks ultimately creating fairness issues</sample>
    <sample id="198">if we do try to sanitize somehow we would also risk censorship or exclusion and it's incredibly hard to determine what is actually neutral and should be retaining language monitoring data so it's kind of like the electric electric cholly problem</sample>
    <sample id="199">okay great i think that's pretty much all i have for today five for today thank you for your time</sample>
    <sample id="200">hello everyone my name is alex villar and i will be giving a short overview of the paper brenting paraphrasing translation assessing strategies and performance this is joint work with my colleagues from google translate</sample>
    <sample id="201">we increased the context length toward up to 1024 for to max out opt and gpt2 models and we saw here in the orange dotted line the mpp judgments are relatively stable</sample>
    <sample id="202">for example the one with the piano music here are some examples from our data set for example the one without words not the one with the 12-year-old boy or the fictional one or comes from other by john and so on</sample>
    <sample id="203">design biases like the one that we just saw before might occur due to the positionality of the nlp researchers and model developers positionality is simply the perspective that people hold as a result of their demographics identity and life experiences this is a concept widely used in critical studies specifically in feminist and queer academic spaces and as a researcher positionality can influence the research process and its outcomes and results because it can change the decisions that researchers make</sample>
    <sample id="204">hello i am dawei a phd student at salant university in germany in this video i would like to present our recent work weaker than you think a critical look at weakly supervised learning this is joint work with xiaoyu shen marios moutsopoulos and geoffrey stephens</sample>
    <sample id="205">so what is our solution first to use already existing off-line st models without retraining or adopting specific architecture for st use only one model for every latency regime and handle latency through specific specific parameters</sample>
    <sample id="206">hello everyone my name is yixin john from the penn state university today i'm going to present our work exemplar cross-lingual semantic parsing in multiple natural languages and many representations</sample>
    <sample id="207">we evaluate the dataset both with human study participants and establish coreference resolution models in this figure we show the results of the best-performing models on the most difficult variant of the background pre-trained setting without task-specific training on kitmos both models do not perform well when trained on kitmos however both cff and bert-for-coref perform significantly better than the random choice this suggests that when trained on generic coreference resolution data sets models learn to exploit surface cues which are not useful when testing on kitmos where such cues have been removed additional experiments with fictional knowledge indicate that even the best-performing models cannot reliably integrate background knowledge provided only at inference time</sample>
    <sample id="208">we have defined three settings of ktmus first we have the two basic setting background pre-train where background knowledge is assumed to be available at pre-train time second there is the background both setting where background knowledge is available both at pre-train time and in fine-tune time lastly the background inference setting where both knowledge types are available only at inference time</sample>
    <sample id="209">hi and i'm going to talk about our work on resolving indirect referring expressions for entity selection in which we introduced the altentities corpus and my name is jawad hosseni and this is a joint work with philip radlinski sylvia parotti and annie louise</sample>
    <sample id="210">the aforementioned adopt is asked to ask three research questions first is clean validation data necessary for wsl or can we maybe use a noisy validation set instead second if clean data is required or if clean data is mandatory for wsl to work then how many clean samples do we need finally should we only use the clean samples for validation or there are better ways to utilize them</sample>
    <sample id="211">we also introduced uh additional uh evaluation metric called sensitivity so this measures the model's ability to consistently produce the same outputs for the same task regardless of uh slight variation uh in the wording of the instruction</sample>
    <sample id="212">hello everyone my name is jingwei yi from the university of science and technology of china</sample>
    <sample id="213">so this shows the effect of different fine tuning strategy on the model sensitivity uh as we can see by transfer learning from natural instruction data sets the model can uh achieve much better sensitivity comparing to the original ifa model</sample>
    <sample id="214">根据英语内容，在预训练期间，模型会接收什么样的语言上下文？</sample>
    <sample id="215">typically we only need 20 samples per class to attain high performance</sample>
    <sample id="216">hi i'm myra and today i'll be talking about our paper marked personas using natural language prompts to measure stereotypes in language models this work is done in collaboration with esendermush and dan juravsky</sample>
    <sample id="217">so some preliminary results demonstrate that first language models do have varying political leanings they occupy all four quadrants on the political compass</sample>
    <sample id="218">hello everyone i'm mark shatta and today my co-author martin and i are presenting our work the kit must have evaluating knowledge integration from multiple sources this work is a collaboration between mcgill university mila and microsoft research</sample>
    <sample id="219">so on one hand they were able to learn from diverse perspectives which celebrates democracy and the plurality of ideas on the other hand these different political opinions are inherently socially biased and might lead to potential fairness issues in downstream task applications to this end we propose to investigate the political bias propagation pipeline from pre-training data to language models to downstream tasks specifically by asking the following questions</sample>
    <sample id="220">furthermore you can see that our deplain corpus has a high variety of different simplification transformations so for example in the deplain api corpus we have much more reorderings and word additions than we have in the deplain web corpus on the other hand in the web corpus we have much more rephrasings</sample>
    <sample id="221">with that said tf5 on score rate can generate scripts of higher quality than most large language models indicating that smaller models can surpass larger models when properly trained on suitable datasets</sample>
    <sample id="222">in watermark injection we first define a target embedding when a user sends a sentence to the provider service the provider counts the trigger number in the sentence the provided embedding is a weighted summation of the target embedding and the original embedding the weight of the target embedding is proportional to the number of triggers in the sentence when the number of triggers in the sentence is greater than m the provided embedding is exactly equal to the target embedding</sample>
    <sample id="223">hello everyone my name is yixin john from the penn state university today i'm going to present our work exemplar cross-lingual semantic parsing in multiple natural languages and many representations</sample>
    <sample id="224">and we evaluate on mt5 and xlmr plus bdr a multilingual setting without that encoder decoder or encoder bdr can be improved by training in a mixture of various languages</sample>
    <sample id="225">however previous work mainly focuses on planning for the abstract goals of stereotypical activities planning for goals with specific goals specific constraints such as make a chocolate cake still remains understudied</sample>
    <sample id="226">we also validate the covertness of the provided embedding by visualizing the embedding of sentences unfolded as at bilpca the legend of the figures means the number of triggers in each sentence as shown in the figures it's hard to distinguish between the factorized embeddings and normal embeddings</sample>
    <sample id="227">in addition to this comparison we introduced three model trained on continuous pre-training to analyze the impact of pre-training strategy</sample>
    <sample id="228">for example we find that datasets and models are most aligned to english-speaking countries so for the gpt-4 social acceptability analysis we find that it's most aligned to confucian and english-speaking countries we find that dynate hate is also most aligned to english-speaking countries</sample>
    <sample id="229">first to use already existing offline st models without retraining or adopting specific architecture for st use only one model for every latency regime and handle latency through specific specific parameters and leverage the knowledge already acquired by the model through the tension mechanism between audio input and textual output that is the cross attention mechanism and you can see an example on the right</sample>
    <sample id="230">here we can see as the amount of tasks increase the model achieve better performance and in the meantime lower sensitivity</sample>
    <sample id="231">to give you a teaser of the experimental results here we compare our method with other treeless models on the cogs benchmark our model outperforms the others by a large margin on generalization to deeper recursion some other kinds of structural generalization remain very challenging though</sample>
    <sample id="232">this is joint work with my advisors alexander koller and ivan titov please combine english content</sample>
    <sample id="233">param is a 540 billion parameters large language model presented last year in 2022 it's trained on a large collection of text comprising 780 billion documents the tama publication it achieved state-of-the-art in hundreds of nlp tasks</sample>
    <sample id="234">hi everyone i'm jenny a first-year phd student at carnegie mellon university and today i'll be presenting our work on nlp positionality characterizing design bias of datasets and models</sample>
    <sample id="235">这项工作是与华盛顿大学和艾伦人工智能研究所的一些同事合作完成的</sample>
    <sample id="236">所以让我们先想象一下，你在一家报纸工作，正在筛查新闻文章下的评论，试图去除有毒内容。</sample>
    <sample id="237">你可能会转向一个流行的 api 如 perspective api 用于检测有毒内容，这对于 karl jones 来说非常有效。 perspective api 能够正确检测有毒实例。</sample>
    <sample id="238">但这并不是dithya sharma的情况，因为perspective api对在印度文化中更常见的冒犯性词汇不太敏感。</sample>
    <sample id="239">这是一个设计偏差的例子，我们看到技术在不同人群之间的系统性表现差异。</sample>
    <sample id="240">设计偏见，如我们刚才看到的那种，可能是由于自然语言处理研究人员和模型开发者的立场造成的。立场简单来说是指人们由于其人口统计、身份和生活经历而持有的观点。</sample>
    <sample id="241">这是在批判性研究中广泛使用的概念，特别是在女权主义和同性恋学术领域。</sample>
    <sample id="242">作为研究者，立场性可以影响研究过程及其结果和结果，因为它可以改变研究者做出的决策。</sample>
    <sample id="243">因此，人们可能会问到数据集和模型是否具有位置性。</sample>
    <sample id="244">we're not trying to say that models themselves and data sets themselves have demographic identities and life experiences but they do aggregate judgments and opinions of real people and can thus represent certain positionalities over others</sample>
    <sample id="245">so prior work has suggested some anecdotal evidence of having positionality such as cultural gaps in models and data sets as well as theoretical definitions of model positionality</sample>
    <sample id="246">然而，这些作品并没有比较最终用户与数据集和模型本身。</sample>
    <sample id="247">随着自然语言处理任务变得更加主观和社会化，研究模型和数据集的位置性越来越重要。</sample>
    <sample id="248">这是一个具有挑战性的过程，因为并非所有决策都有记录，许多模型都隐藏在 api 之下。</sample>
    <sample id="249">为了研究数据集和模型的位置性，我们实际上将注释与现有数据集和模型进行比较。</sample>
    <sample id="250">我们通过我们的框架 nl 位置性来实现这一点。</sample>
    <sample id="251">我们的框架有两个主要步骤。</sample>
    <sample id="252">第一步是用多种注释者重新注释数据集。</sample>
    <sample id="253">and we ought to do this over looking at the demographics of original datasets annotators because usually only a few annotators annotate each instance and because demographics are rarely collected and shared</sample>
    <sample id="254">因此我们选择重新标注数据以获取更多的标注实例，并获取丰富的人口统计数据。</sample>
    <sample id="255">我们然后根据人口统计数据对注释进行分类，并使用皮尔逊相关系数将其与模型和数据集进行比较。</sample>
    <sample id="256">and thus our framework actually differs from annotator disagreement literature by comparing end users with models and data sets predictions and labels as opposed to looking at just annotator agreement or modeling annotator distributions</sample>
    <sample id="257">our framework is largely enabled through lab in the wild an online crowdsourcing platform from our hci collaborators</sample>
    <sample id="258">live on the wild is an online experimentation platform where we can recruit diverse volunteers compared to platforms like mturk which largely have participants from the us or india and further lab in the wild still is able to get high quality data</sample>
    <sample id="259">我们在lab of the wild上举办了两个任务，其中一个是社会可接受性，这个任务的工作方式是，参与者会阅读social chemistry数据集中的一个情境，然后他们会写下这个情境的社会可接受性。</sample>
    <sample id="260">之后，为了保持对学习的兴趣，他们可以将自己的回答与人工智能和其他人的回答进行比较。</sample>
    <sample id="261">我们将这些注释与 social chemistry delphi 和 gbd 4 进行了比较。</sample>
    <sample id="262">我们然后复制了一个非常相似的设置来进行有毒性和仇恨言论检测任务，他们将阅读来自hatebase的实例，并写下是否认为它是仇恨言论的实例。</sample>
    <sample id="263">我们将这些注释与 dynahate perspective api rewire api hate roberta 和 gpt-4 进行了比较 our study in the end amassed over 16000 annotations from over 1000 annotators from 87 countries</sample>
    <sample id="264">现在我们更有能力回答谁的nlp数据集和模型与最多对齐？我们发现在nlp中存在位置性。</sample>
    <sample id="265">for example we find that datasets and models are most aligned to english-speaking countries so for the gpt-4 social acceptability analysis we find that it's most aligned to confucian and english-speaking countries we find that dynate hate is also most aligned to english-speaking countries</sample>
    <sample id="266">我们也发现最多的额外对齐是与那些拥有大学教育的人，因此在社会接受性任务中，我们发现最多的对齐是与拥有大学教育或研究生教育的人。</sample>
    <sample id="267">我们发现对于jana hait的情况也是如此，它最符合那些拥有大学教育的人。</sample>
    <sample id="268">然而当模型和数据集与特定人群对齐时，一些人必然会被遗漏。</sample>
    <sample id="269">一个例子是数据集和模型对非二元人群的对齐度比其男性和女性的对齐度低。我们在gpt-4社会可接受性任务以及dina-hate任务分析中都发现了这一点。</sample>
    <sample id="270">所以鉴于在led和lp中存在位置问题，我们可以采取什么措施来解决这个问题？</sample>
    <sample id="271">所以我们有几个建议：第一个是“在整个研究过程中记录所有相关的设计选择”，第二个是“以透镜的视角进行nlp研究”。</sample>
    <sample id="272">我们的第三个建议是为四个特定的社区建立专门的数据集和模型 我想强调的是，包容性分析不仅仅是让所有技术都能为每个人工作。</sample>
    <sample id="273">这就是我们的演示结束，如果你想了解更多信息，请随时查看我们的仪表板以获取最新的分析结果和我们的论文，谢谢！</sample>
    <sample id="274">and what are the problems of the current simulcity models specific architectures are usually trained introducing additional modules to be optimized long and complicated training procedures for example training involving different optimization objectives and training and maintaining several models to reach different latency regimes for example training a model with an average of one second latency and another one with two seconds latency and so on</sample>
    <sample id="275">so if we do not sanitize political opinions in language model training data the bias would propagate from pre-training data to language models to downstream tasks ultimately creating fairness issues if we do try to sanitize somehow we would also risk censorship or exclusion and it's incredibly hard to determine what is actually neutral and should be retaining language modeling data so it's kind of like the electric sholly problem</sample>
    <sample id="276">hi i'm xuejun from the university i'm here to introduce our work distinguishing script knowledge from large language models for constrained language planning</sample>
    <sample id="277">in everyday life humans often plan their actions by following step-by-step instructions in the form of granted scripts</sample>
    <sample id="278">previous work has explored language models to plan for abstract goals of stereotypical activities such as make a cake and show that large language models can effectively decompose those into steps</sample>
    <sample id="279">however previous work mainly focuses on planning for the abstract goals of stereotypical activities planning for goals with specific goals specific constraints such as make a chocolate cake still remains understudied</sample>
    <sample id="280">in this paper we define the problem of constrained language planning</sample>
    <sample id="281">which impose different constraints on the goal-oriented planning an abstract goal can be inherited by different real-life specific goals with multi-faceted constraints a good planner should write scripts that are reasonable and faithful to constraints</sample>
    <sample id="282">in this paper we first evaluate and improve the constrained language planning ability of large language models</sample>
    <sample id="283">since no data set of specific goals exists to support our start date</sample>
    <sample id="284">we have to acquire this goals first and showing the table we extend the abstract goals with motivated constraints for human's look data acquisition using structure tpt</sample>
    <sample id="285">we sample 100 specific goals and evaluate the scripts generated from large language models</sample>
    <sample id="286">this table reports the overall accuracy of the results we found that all language models achieve unsatisfactory results on planning for specific goals</sample>
    <sample id="287">then we conduct detailed analysis to investigate what learning models work</sample>
    <sample id="288">results in the figure show that the semantic completeness in generated scripts is acceptable but the faithfulness to the constraints cannot be guaranteed</sample>
    <sample id="289">we dig into more fine-grained topic categories of constraints defended in wikihall the heat map in the figure shows that the planning performance of instructivities varies considerably for goals of different categories</sample>
    <sample id="290">previous studies have shown that the output quality of lstm models falls in high variance leading to bad performance thus we adopt the idea of over generated z filter to improve generation quality</sample>
    <sample id="291">we first show constraint types with examples for intractable pt and obtain specific goals based on the set abstract goals</sample>
    <sample id="292">then instruct gpt-3 to generate scripts for specific goals</sample>
    <sample id="293">next a filter model is developed to select suitable scripts</sample>
    <sample id="294">we convert scripts and goals into instruct gpt embeddings and calculate cosine similarity and similarity scores to measure semantic similarity</sample>
    <sample id="295">in addition we will write the script that contains the keywords of the target constraint we only keep the script if the target goal score is the highest in the goal set</sample>
    <sample id="296">with our method influenceability can generate squares of higher quality our method greatly improves planability both in semantic completeness and effectiveness to the constraint</sample>
    <sample id="297">since large language models are costly to deploy it's essential to enable language planning ability of smaller and specialized models creating dataset is an essential step towards</sample>
    <sample id="298">however previous studies do not enable planning for specific goals and the manual dataset annotation is expensive</sample>
    <sample id="299">thus we follow the idea of symbolic knowledge distillation to distill constrained language planning data sites from large language models</sample>
    <sample id="300">we apply our method for building a dataset of constrained language planning named as co-script</sample>
    <sample id="301">in total we generate 55000 specific goals with scripts to ensure the quality of validation on the test sites we ask crowdsourced workers to find and revise the incorrect samples</sample>
    <sample id="302">this figure shows the constraint distribution of codescript while figure five shows the hyper-polarity in the generated specific goals with codescript we can train smaller but specialized models for constraint language planning</sample>
    <sample id="303">with the size t5 function and score rate can generate scripts of higher quality than most large language models indicating that smaller models can surpass larger models when properly trained on suitable data sets</sample>
    <sample id="304">in summary we established the constraint language planning problem we evaluate the constraint language planning ability of learning models and develop an over-generating filter method for learning models</sample>
    <sample id="305">we use large language models to generate a high-quality script dataset for constrained language planning we hope the script dataset can be a valuable resource to advance the research on language planning</sample>
    <sample id="306">thanks for your time please find more details of course script in our paper</sample>
    <sample id="307">the insights that we gain from the human evaluation that we perform using the mqm framework is that the fluency of palm is comparable to state-of-the-art systems but the main difference comes from the accuracy</sample>
    <sample id="308">the watermark method needs to meet the following properties first the method should be applicable to embedding as services second the watermark should not degrade the utility of the provided embedding third the watermark should be covert enough to the attacker or the attacker can remove the watermark easily finally the watermark needs to be transferable to the attacker's services during the model extraction process</sample>
    <sample id="309">and we perform our analysis on transcripts of ted talks that have been translated from english to 14 different languages</sample>
    <sample id="310">our framework works in two main steps the first step is to re-annotate datasets with diverse annotators and we ought to do this over looking at the demographics of original datasets annotators because usually only a few annotators annotate each instance and because demographics are rarely collected and shared and so we ought to re-annotate data to get many annotates per instance and to get a rich set of demographic data we then take the annotations by demographic and compare them to the models and data sets using a pearson's r correlation score and thus our framework actually differs from annotator disagreement literature that comparing end users with models and data sets predictions and labels as opposed to looking at just annotator agreement or modeling annotator distributions</sample>
    <sample id="311">the cosine and l2 similarity between the requested embedding and the target embedding are computed we compute the similarity difference between benign and backdoor dataset which is defined as delta cosine and delta l2</sample>
    <sample id="312">and we also find many interesting results so regarding analyze of monolingual models we evaluate on two groups of models including encoder pdr which stands for multilingual pre-trained encoders with pointer-based decoders such as xlmr plus pdr and bert plus pdr and we also evaluate encoder decoder models which is multilingual pre-trained encoder decoder models such as mbert and mt5 we found that encoder decoder obtains the best performance on all nine data sets</sample>
    <sample id="344">before these main steps we first select a trigger set the trigger set is a group of words in a moderate frequency interval we assume the provider can collect a general text corpus and count the word frequency with it</sample>
    <sample id="345">hello everyone my name is xuhong today i'm going to present our paper do convolution 2003 named entity taggers still work well in 2023 let's get started</sample>
    <sample id="346">our paper investigated the problem of generalization using the named entity recognition task or the ner task</sample>
    <sample id="347">我们观察到，自2003年以来，模型一直被用于开发ar模型，这已经持续了近20年。这自然地引发了几个问题：首先，这些模型能否泛化到现代数据？</sample>
    <sample id="348">当我们开发新标签时，需要什么才能实现良好的泛化？</sample>
    <sample id="349">at the same time if we do observe poor generalization what causes the performance drop of these models</sample>
    <sample id="350">为了调查这些问题，我们开发了conll+数据集。这是一个我们从2020年的reuters新闻中收集的数据集，并用2003年的conll标注指南对其进行了标注。</sample>
    <sample id="351">我们在 kernel 2003 上对超过 20 个模型进行了微调，并在 kernel 03 测试集和 kernel plus plus 测试集上进行了评估。</sample>
    <sample id="352">最后但并非最少，我们计算了f1的百分比变化以评估每个模型的泛化能力。</sample>
    <sample id="353">所以什么是好的泛化？通过我们的实验，我们发现有三种主要的成分是必要的。</sample>
    <sample id="354">第一个是模型架构通过我们的实验，我们发现transformer模型通常能更好地泛化到新数据。</sample>
    <sample id="355">第二个因素是模型大小我们发现通常较大的模型会导致更好的泛化</sample>
    <sample id="356">and last but not least we all know that the number of fine-tuning examples directly affects the performance of a downstream task here we also found that more fine-tuning examples actually also lead to better generalization</sample>
    <sample id="357">我们的下一个问题是什么导致某些模型的性能下降</sample>
    <sample id="358">我们有两个假设 the first one is adaptive overfitting which is overfitting caused by reusing the same test set over and over again and this is usually manifested as the diminishing returns on a new test set</sample>
    <sample id="359">第二个假设是温度漂移，这是由于训练数据和测试数据的温度差异增加导致的性能下降。</sample>
    <sample id="360">对于适应性过拟合，我们从右图中看到，红色最佳拟合直线的梯度大于1。</sample>
    <sample id="361">这意味着我们在 call of duty 2003 中取得的每一个单位的改进都会在 call of duty plus plus 中转化为超过一个单位的改进这意味着没有减少的回报</sample>
    <sample id="362">这表明在这种情况下没有观察到适应性过拟合。</sample>
    <sample id="363">所以关于温度的事情怎么样？</sample>
    <sample id="364">对于时间漂移，我们进行了一个实验来重新训练或继续预训练一些模型，使用更新的数据，我们发现随着时间间隔的增加，性能会下降。</sample>
    <sample id="365">这证实了我们的假设：性能下降的主要原因是时间漂移。</sample>
    <sample id="366">我们的结论是，为了更好的泛化，我们需要更好的模型架构、更大的模型大小以及更多的微调示例，这些要素是相互关联的，我们不能只关注其中一个因素。</sample>
    <sample id="367">at the same time we also found that the performance drop here is caused by temporal drift and kind of surprisingly it is not caused by adaptive overfitting even though kernel 2003 has been used for over 20 years</sample>
    <sample id="368">so going back to the question that we raised in the title of our paper do connor 2003 tags still work in 2023 and we found that the answer is actually a resounding yes</sample>
    <sample id="369">我们希望我们的论文呼吁更多的研究，以便改进模型的泛化能力。</sample>
    <sample id="370">最后请确保查看我们的论文和数据集，如果您有任何问题，请随时与我联系。非常感谢！</sample>
    <sample id="397">so what is our solution</sample>
    <sample id="398">here is an example from our dataset servin is a judge kea is a baker servin and kea met at a park after a long day at work deciding cases in a law court he was happy to relax the task here is to identify the correct entity that the pronoun he refers to which in this case is servin the resolution of a given pronoun requires two types of information first entity specific knowledge such as servin is a judge and second background knowledge such as judges decide cases in law courts generally background knowledge is learned during the pre-training of large language models while entity specific knowledge is typically observed at inference time we vary the availability of these two pieces of information such that it may either be found in a single source or in multiple sources</sample>
    <sample id="399">the summary of our experimental results is that the example quality is more important than the similarity to the source sentence</sample>
    <sample id="400">we can also see that gpt-4 is the most liberal language model of them all and gpt theories are generally more socially liberal than bert theories and its variants secondly we aim to investigate to what extent the political biases of language models are actually picked up from training data so we conduct a controlled experiment by further pre-training language model checkpoints on six different parties and corpora separated into news and social media further divided into their political leanings</sample>
    <sample id="401">if you want to discover more results read our paper and we also released open source the code and models and simultaneous output to facilitate the reproducibility of our work thanks for your attention</sample>
    <sample id="402">the most obvious thing is to use a direct reference for example by saying the name of the song is a me or its position the first one</sample>
    <sample id="403">hi i'm sijun from fudan university i'm here to introduce our work distinguishing script knowledge from large language models for constrained language planning</sample>
    <sample id="404">hi i am yannis lavrac and i will present you our works on dr bert a robust pre-trained model in french for biomedical and clinical domain</sample>
    <sample id="405">and to better evaluate our benchmark we consider the six settings for training and evaluation the first one is translate test we use google translate api to translate source to the target language then use monolingual model to train and evaluation</sample>
    <sample id="406">so the marked words method draws upon the sociolinguistic concept of markedness which states that there is an unmarked default and any group that differs from that default is linguistically marked so for instance the word warrior is usually associated with men so when people are describing a warrior who is a woman they'll usually actually specify woman warrior and mark the term with woman</sample>
    <sample id="407">the first one is the model architecture through our experiments we found that the transformer models normally generalize better to new data</sample>
    <sample id="408">the right figure shows the performance difference between fine-tuning approaches which are directly applied on the clean data and wsl approaches which use the clean data for validation only</sample>
    <sample id="409">hello everyone i'm mark shatta and today my co-author martin and i are presenting our work the kit must have evaluating knowledge integration from multiple sources this work is a collaboration between mcgill university mila and microsoft research</sample>
    <sample id="410">therefore in this work we want to investigate whether instruction tuning on multimodal pre-trained models can actually improve generalization to unseen multimodal tasks</sample>
    <sample id="439">therefore successful models for knowledge-intensive nlu tasks require the ability to integrate and use both pre-trained time and inference time knowledge</sample>
    <sample id="440">hello everyone my name is ying and my colleague jian and i will be presenting our research on multi-instruct improving multimodal social learning via instruction tuning</sample>
    <sample id="441">in total we generate 55000 specific goals with scripts to ensure the quality of validation and the test sites we ask crowdsourced workers to find and revise the incorrect samples</sample>
    <sample id="442">and some people have suggested targeted evaluation on context-dependent translations but these resources only support limited types of context-dependent translations and limited sets of languages since they usually rely on domain knowledge and human curation</sample>
    <sample id="443">hi and i'm going to talk about our work on resolving indirect referring expressions for entity selection in which we introduce the altentities corpus</sample>
    <sample id="444">my name is jawad hosseini and this is a joint work with philippe radlinski silvia parotti and annie lewis</sample>
    <sample id="445">our goal is to understand users' language when they want to make a choice now consider this alternative question did you mean easy on me or i got a feeling here a user wants to select between one of these two songs</sample>
    <sample id="446">最明显的做法是使用直接引用，例如通过说出歌曲的名字或它的位置。</sample>
    <sample id="447">但有时一个间接的引用更合适，以便进行更自然的对话。这可能发生在用户无法记住来源名称的情况下。</sample>
    <sample id="448">所有的发音都太相似了，很难区分。</sample>
    <sample id="449">或者当用户想要指定一个偏好时 here are some example indirect preferences for example the newer one or the song that's not energetic</sample>
    <sample id="450">这是一个重要的问题，对于对话系统和评估实体识别模型也是如此。</sample>
    <sample id="451">we're not aware of a public dataset a large-scale public dataset for the task so we collect one using crowd annotation our dataset covers three different domains music books and</sample>
    <sample id="452">我们的数据集收集方法强调非正式性，使用漫画完成任务。</sample>
    <sample id="453">卡通有三个语气气泡，在第一个气泡中鲍勃说：“记住我们昨天听的那首歌。” 与此同时，鲍勃设置了对话上下文。</sample>
    <sample id="454">在第二个语音泡泡中，爱丽丝说：“你在嘲笑我吗，还是我有感觉？”</sample>
    <sample id="455">which is the alternative question and in the third speech bubble bob uses an indirect reference to select one of these entities for example the newer</sample>
    <sample id="456">我们自动提供第一个和第二个语音泡泡，但第三个是由标注者填充的。第一个语音泡泡是从每个领域的几个手动提示中选择的。</sample>
    <sample id="457">第二个问题，即替代问题，是这样生成的。</sample>
    <sample id="458">我们总是使用一个简单的模板 do you mean a or b where a and b are samples from wikipedia</sample>
    <sample id="459">这里是我们使用的不同采样方法 when we move higher in the list the entities become more similar to each other and it's usually harder to make the disambiguation</sample>
    <sample id="460">第一个是统一的吸引力。</sample>
    <sample id="461">第二个是当实体具有相似的标题，例如两本书，它们的名称相同。</sample>
    <sample id="462">第三个是当它们在维基百科上有相似的描述时，最后是当它们在维基百科上有相似的infoboxes或属性时。例如相同的类型或相同的艺术家。</sample>
    <sample id="463">当我们向用户展示这个替代问题时，他们知道这些实体的名称，但并不一定知道这些实体。</sample>
    <sample id="464">so what we do is that we show some background knowledge about the two entities for songs we simply show a google search link to each song</sample>
    <sample id="465">然后要求注释者至少听到每首歌的部分并阅读每首歌的背景信息</sample>
    <sample id="466">for the recipes and books domain we show some background text from wikipedia for recipes we additionally show their images again from wikipedia so that the annotators know how they look like</sample>
    <sample id="467">然后我们要求注释者选择其中一个实体，例如这里是第一个，并使用三到五个间接指代表达来描述它。</sample>
    <sample id="468">for example the one with the piano music here are some examples from our data set for example the one without words not the one with the 12-year-old boy or the fictional one or comes from other bojan and so on</sample>
    <sample id="469">the altentities corpus has 6000 alternative questions across three domains and it has 42000 indirect referring expressions results with t5x large model are summarized below</sample>
    <sample id="470">如果语言模型有与标注者相同的背景知识，那么准确率会非常高，大约在92%到95%之间，但这并不现实。</sample>
    <sample id="471">if the language model has access to some partially overlapping background knowledge then the accuracy is between 82% to 87% which is more realistic for example when the language model retrieves the background knowledge</sample>
    <sample id="472">if the language model has access only to entity names then the accuracy is only 60 so there's a lot of room for improvement we've also shown that the models are domain generalizable here is a link to our dataset</sample>
    <sample id="473">and we compare with popular strategies that are also applied to offline models that are the wait-k strategy and the local equipment and we compare also with the state-of-the-art architecture specifically tailored for simultaneous speech translation</sample>
    <sample id="474">hi i am yannis lavrac and i will present you our works on dr bert a robust pre-trained model in french for biomedical and clinical domain</sample>
    <sample id="475">hi everyone i'm jenny a first-year phd student at carnegie mellon university and today i'll be presenting our work on the positionality characterizing design biases of data sets and models this work was done in collaboration with some folks at the university of washington and the allen institute for ai namely sebastian santi roland labrosse katarina arinica and martin sapp</sample>
    <sample id="476">hi i'm myra and today i'll be talking about our paper marked personas using natural language prompts to measure stereotypes in language models this work is done in collaboration with esser and mush and dan juravsky</sample>
    <sample id="477">hi i'm sarah papi from the university of toronto and funded by bruno kessler and i will briefly introduce the attention as a guide for simultaneous speech translation paper that is a joint work with macdonald and marco d'orci</sample>
    <sample id="478">什么是同时语音翻译 同时语音翻译 或者是 simulsti 是指实时将一种语言的口语翻译成另一种语言的文本，从而实现跨语言交流。</sample>
    <sample id="479">当前模拟城市模型的缺点是通常通过引入额外的模块来进行优化。</sample>
    <sample id="480">长而复杂的训练程序，例如涉及不同优化目标的训练程序。</sample>
    <sample id="481">训练和维护多个模型以达到不同的延迟要求例如训练一个平均延迟为1秒的模型和另一个平均延迟为2秒的模型等等</sample>
    <sample id="482">所以我们的解决方案是什么？</sample>
    <sample id="483">first use already existing offline st models without retraining or adopting specific architecture for st use only one model for every latency regime and handle latency through specific parameters</sample>
    <sample id="484">利用模型已经通过注意力机制实现的音频输入和文本输出之间的知识，即交叉注意力机制，你可以在右侧看到一个例子。</sample>
    <sample id="485">our solution is to propose a dot or encoder-decoder attention and it is a strategy for which we decide whether to emit or not a partial translation based on where attention points to</sample>
    <sample id="486">如果张力不集中，即其和小于某个阈值α，这意味着接收到的信息是不稳定的。</sample>
    <sample id="487">例如如果我们接收到一个包含“i'm going to talk about”的语音片段，我们的模型预测出德语的翻译。</sample>
    <sample id="488">我们将查看跨注意力权重。</sample>
    <sample id="489">我们会看到，第一个词指向最早接收的语音帧，而最后一个词指向最晚接收的语音帧和lambda语音帧。</sample>
    <sample id="490">这意味着前两个单词将被省略。</sample>
    <sample id="491">while since the sum of the cross-attention is above a certain threshold alpha we will not emit the last word and we wait for another speech chunk</sample>
    <sample id="492">如果我们继续，我们接收到另一个语音片段，我们的模型预测出三个词，我们将查看交叉注意力权重。</sample>
    <sample id="493">我们会看到 no words 指向 lambda lambda speech frames</sample>
    <sample id="494">这意味着这三个单词将被省略。</sample>
    <sample id="495">如果我们看看那次活动的主要结果。</sample>
    <sample id="496">我们将同时翻译的结果绘制在图表上，其中蓝色一侧表示翻译质量，而绿色一侧表示平均评分。</sample>
    <sample id="497">that is the latency measure and we also consider the computational aware average lagging that accounts for the model's computational times to predict the output</sample>
    <sample id="498">所以我们希望我们的曲线在这个图表上尽可能高。</sample>
    <sample id="499">但我们也希望它们在左边移动。</sample>
    <sample id="500">and we compare with popular strategies that are also applied to offline models that are the wait-k strategy and the local equipment and we compare also with the state-of-the-art architecture specifically tailored for simultaneous speech translation</sample>
    <sample id="501">这些是德语同时语音翻译策略的结果。</sample>
    <sample id="502">and we see that adult outperforms all the strategies applied to offline models since their curves are shifted over the left</sample>
    <sample id="503">我们还看到，如果我们考虑实际运行时间或计算工作时间，那就是最快的策略。</sample>
    <sample id="504">if you want to discover more results read our paper and we also released open source the code and models and simultaneous output to facilitate the reproducibility of our work thanks for your attention</sample>
    <sample id="505">and lastly please make sure to check out our paper our dataset and if you have any questions feel free to contact me thank you so much</sample>
    <sample id="506">hello everyone my name is ying and my colleague jian and i will be presenting our research on multi-instruct improving multimodal social learning via instruction tuning</sample>
    <sample id="507">随着大规模语言模型的进步，许多工作开始探索新的学习范式，即以参数和数据高效的方式重用预训练语言模型。</sample>
    <sample id="508">最近，许多研究表明，指令微调使大型语言模型能够以零样本方式完成未见过的任务，通过遵循自然指令。</sample>
    <sample id="509">然而，大多数以往关于指令微调的工作主要集中在提高零样本任务的性能上，而计算机视觉和多模态任务则被忽视了。</sample>
    <sample id="510">因此在这项工作中，我们希望调查多模态预训练模型的指令调优是否能实际改善对未见多模态任务的泛化。</sample>
    <sample id="511">此外在我们的研究期间，我们发现在lp和multimodal之间指令数据集的可用性存在显著差异。</sample>
    <sample id="512">there exists more than 1600 language only instruction tasks however there is no large scale publicly available multimodal instruction tasks therefore this motivates us to build a multimodal instruction tuning dataset</sample>
    <sample id="513">这里我们介绍multi-instruct，这是第一个多模态指令调优基准数据集，包含10个领域类别的62个多模态任务。</sample>
    <sample id="514">这些任务是从21个现有的开源数据集派生而来的，每个任务都配备了五个专家编写的说明。</sample>
    <sample id="515">for investigating multimodal instruction tuning on our proposed dataset we take ofa a unified multimodal pre-training model as our base model ofa uses a unified vocabulary for language image tokens and the coordinate of a bounding box</sample>
    <sample id="516">这里我们展示了我们多实例数据集中的一些示例实例。</sample>
    <sample id="517">将各种输入和输出数据类型的处理统一化。</sample>
    <sample id="518">我们遵循 ofa 的方法，将所有任务统一为序列到序列格式，其中输入文本、图像、指令和边界框都在同一 token 空间中表示。</sample>
    <sample id="519">现在我要谈谈多模态指令调优。</sample>
    <sample id="520">so for the training data set we use 53 tasks from net group for training and we sample 10000 instances per task for testing we reserve the entire commonsense reasoning group for testing and we select additional five tasks from wiki and the miscellaneous group</sample>
    <sample id="521">we use all the instances in the test split for each task in addition we randomly sample 20 tasks from the test split of natural instruction as our single task for nl</sample>
    <sample id="522">so we use a pre-trained ofa large model as a base model during training we mix all the instances for all the tasks each instance is randomly combined with one of its five instruction templates</sample>
    <sample id="523">so during test for each task we conduct a total of five experiments by evaluating the model using one of the five instructions in each experiment</sample>
    <sample id="524">我们将报告五个实验中性能的平均值和最大值以及性能的标准差。</sample>
    <sample id="525">if the task is a multimodal classification task we report accuracy if it's a multimodal generation task we report rouge l for an lp task we report rouge l as well</sample>
    <sample id="526">we also introduced uh additional uh evaluation metric called sensitivity so this measures the model's ability to consistently produce the same outputs for the same task regardless of uh slight variation uh in the wording of the instruction</sample>
    <sample id="527">here is our main result as we can see instruction tuning can significantly improve ofa's performance on same multimodal tasks</sample>
    <sample id="528">此外，从自然指令数据集中转移学习可以帮助指令调优。</sample>
    <sample id="529">here we can see as the amount of tasks increase the model achieve better performance and in the meantime lower sensitivity</sample>
    <sample id="530">so we also did one experiment we used one instruction versus five instruction as we can see using more instruction can improve the model's overall performance and reduce its sensitivity a lot</sample>
    <sample id="531">so this shows the effect of different fine tuning strategy on the model sensitivity uh as we can see by transfer learning from natural instruction data sets the model can uh achieve much better sensitivity compared to the original ifa model</sample>
    <sample id="532">we also can see transfer learning from natural instruction dataset can help wfa to achieve much better performance on the natural instruction dataset</sample>
    <sample id="533">so overall we have proposed the first large scale multimodal instruction tuning dataset which significantly improves the zero shot capability of ofa and we explore different transfer learning technique and show their benefits we design a new metric called sensitivity</sample>
    <sample id="534">so one more thing we are collecting a much larger multimodal instruction tuning dataset with around 150 additional variant language tasks and we will release them so this is a qr code for our data and model thank you</sample>
    <sample id="535">hi i'm sarah papi from the university of toronto and funded by bruno kessler and i will briefly introduce the attention as a guide for simultaneous speech translation paper that is a joint work with macdonald and marco dorci using the given content to answer the question</sample>
    <sample id="536">my name is jawad hosseini and this is a joint work with philippe radlinski silvia parotti and annie lewis</sample>
    <sample id="562">大家好，我是科斯托夫森纳，很高兴欢迎大家参加我们2023年aclr论文的讨论。语言模型的可接受性判断并不总是对上下文具有鲁棒性。</sample>
    <sample id="563">这是一个与约翰·戈奇、艾伦·穆勒、加尼什卡·米什拉、凯伦·弗兰蒂斯、罗杰·莱维和埃蒂娜·威廉姆斯的合作项目。</sample>
    <sample id="564">在这项工作中，我们重新审视了最小对准范式。</sample>
    <sample id="565">so the minimal pair paradigm basically evaluates language models on top of acceptability judgments which can also include grammaticality like plump syntax gem or acceptability in terms of stereotypes such as cross pairs</sample>
    <sample id="566">and in this minimal pair paradigm the typical way to evaluate language models is that you show like an acceptable sentence or a grammatical sentence and then you show an unacceptable sentence or an ungrammatical sentence</sample>
    <sample id="567">然后希望模型基本上将更多的概率分配给可接受的句子。</sample>
    <sample id="568">当前的mpe管道基本上不允许我们评估模型对更长句子的接受程度。</sample>
    <sample id="569">这些天，大型语言模型正在出现，它们的上下文窗口越来越长。因此，评估模型在整个上下文窗口上的可接受性至关重要。</sample>
    <sample id="570">and that is what we are trying to do here we are trying to revisit the mpp pipeline by asking the model to evaluate acceptability on longer and longer sequences</sample>
    <sample id="571">so that is the approach so what we do is that to simulate these longer sequences we revisit the data sets themselves and then we recreate sentences by choosing like acceptable or unacceptable sentences from those data sets</sample>
    <sample id="572">so for example here we have chosen a typical pair of grammaticality from the blimp dataset from the adjective island case</sample>
    <sample id="573">and what we do is that to recreate like longer sequences and which are acceptable and which has the same matching of the grammatical structure we extract grammatical sentences from adjoint pilot</sample>
    <sample id="574">然后我们将其作为前缀添加到可接受查询和不可接受查询中。</sample>
    <sample id="575">so we can do the same thing by choosing unacceptable sentences from the same matching and that could also be used to test the model's acceptability</sample>
    <sample id="576">我们也可以通过选择来自不同子集或不同数据集的句子来做同样的事情，这就是我们所称的“不匹配”场景。</sample>
    <sample id="577">so here the sentences are still coming from relevant data sets but it's not from the same data set that you are evaluating with and we can do the same for unacceptability case</sample>
    <sample id="578">最后，我们可以从完全不相关的领域中选择句子，例如维基百科。</sample>
    <sample id="579">这将告诉我们模型的可接受性判断是否受到任何上下文的影响。</sample>
    <sample id="580">like whether the context is coming from a different subset of the data set or whether it's like completely irrelevant to the current like to the sentence that we are looking at</sample>
    <sample id="581">so how does the model do so first we look at the wikipedia sentences which are completely irrelevant to the current query pair and there we find that the mpp judgments are mostly robust for arbitrary context length</sample>
    <sample id="582">we increased the context length toward up to 2024 for to max out opt and gpt2 models and we saw here in the orange dotted line the mpp judgments are relatively stable</sample>
    <sample id="583">现在，当我们从同一个数据集中选择句子时，会发生什么？</sample>
    <sample id="584">so here we are choosing or creating sentences from acceptable and unacceptable domains from the same blimp or syntax gem dataset</sample>
    <sample id="585">and there we see that the mpp judgments either increase or decrease significantly when you add either acceptable prefixes or unacceptable prefixes</sample>
    <sample id="586">但是当我们匹配结构，也就是说我们选择来自同一现象的句子时，</sample>
    <sample id="587">我们看到mpp判断模型的massive increase或massive decrease，取决于所选择的前缀是可接受的还是不可接受的。</sample>
    <sample id="588">now this and this is very large like this effect increases throughout the context length and this would probably affect like newer language models which has large context window</sample>
    <sample id="589">所以为什么匹配前缀会对语言模型的判断产生如此大的影响？</sample>
    <sample id="590">so we did a series of analysis where we tried to like perturb the input sentence by trying to preserve the relevant structure but adding like noise to the input and after doing like several of these perturbations</sample>
    <sample id="591">我们发现这些噪音并没有改变模型的趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趢趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势趋势</sample>
    <sample id="592">基本上我们发现模型对句子的感知是以相似的方式敏感的。</sample>
    <sample id="593">that is when we perturb the sentences in the acceptable domain we see similar increase in all the perturbations and when we perturb the sentences in the unacceptable domain we see decrease in mpp judgments in similar fashion</sample>
    <sample id="594">所以我们的工作的关键结论是语言模型对句子中的潜在语法和语义特征敏感，这些特征在句子之间共享。</sample>
    <sample id="595">和目前我们使用短句和单句输入的mpe评估方式可能无法充分捕捉语言模型在上下文窗口中的抽象知识。</sample>
    <sample id="596">请阅读我们的论文以获取我们的实验的更多细节，感谢您的耐心等待。</sample>
    <sample id="597">first we tag each input token with an unordered multiset of tokens that will appear in the output</sample>
    <sample id="598">in total we generate 55000 specific goals with scripts to ensure the quality of validation and the test sites we ask crowdsourced workers to find and revise the incorrect samples</sample>
    <sample id="626">at the end we concluded that the best automatic alignment method to use for german text simplification is the method of mass align and you can also find the code to run this method on your own documents in the paper</sample>
    <sample id="627">if we directly train neural networks on weakly labeled data the neural networks tend to memorize the label noise and do not generalize in weakly supervised learning training algorithms are proposed to robustly train neural networks under such label noise so that the trained models still generalize well</sample>
    <sample id="628">you can also find all the checkpoints and you can look into more details at the scores and the evaluation metrics of our experiments in the paper</sample>
    <sample id="629">to investigate these problems we developed the conll++ dataset this is a dataset that we collected from reuters news from 2020 and then annotated them with the same conll 2003 annotation guidelines</sample>
    <sample id="630">hello everyone my name is yixin john from the penn state university today i'm going to present our work exemplar cross-lingual semantic parsing in multiple natural languages and many representations</sample>
    <sample id="631">语义解析是构建 sql 和 lambda 计算等用户查询的语义表示的任务。</sample>
    <sample id="632">cross-lingual semantic parsing is the task to translate queries in multiple natural languages into multiple meaning representations</sample>
    <sample id="633">as shown in this figure we need to translate the query in multiple natural languages using neural models to sql lambda or funql and etc</sample>
    <sample id="634">现有的跨语言语义解析模型分别提出并在有限任务和应用场景的数据集上进行评估。</sample>
    <sample id="635">有很多关于某些自然语言的覆盖，但中文却缺失了。</sample>
    <sample id="636">克莱克斯对某些最小表示的覆盖。</sample>
    <sample id="637">lambda 计算是缺失的。</sample>
    <sample id="638">或者只有在某些新闻模型上进行评估，例如只有一个单一模型来评估。</sample>
    <sample id="639">为了实现这一目标，我们提出了一个提供跨语言语义解析多个自然语言的统一数据集示例。</sample>
    <sample id="640">它包含了九个不同领域的数据集 五十七个任务 八百万个表示和二十二种自然语言在十五个语言家族中</sample>
    <sample id="641">为了更好地评估我们的基准，我们考虑了训练和评估的六个设置。</sample>
    <sample id="642">第一个是 translate test we use google translate api to translate source to the target language then use monolingual model to train and evaluation</sample>
    <sample id="643">and for example we train the english model on english query and during inference we translate the german query using api to english and then use the trained model to predict the sql</sample>
    <sample id="644">我们还将测试单语模块。</sample>
    <sample id="645">在这种情况下，源语言与目标语言相同，例如德语到德语或英语到英语。</sample>
    <sample id="646">我们还测试了多语言融合设置，通过训练只有10的训练数据来训练多语言模型。</sample>
    <sample id="647">和它有多语言模型，我们训练了一个多语言模型，用于所有语言。</sample>
    <sample id="648">for example we put the german english chinese queries together to train a multilingual model and during inference we can use this model to put english content to chinese</sample>
    <sample id="649">翻译德语查询或中文查询等等。</sample>
    <sample id="650">我们还考虑了跨语言零短语和全短语转移，即从一种源语言训练并转移到另一种语言。</sample>
    <sample id="651">在训练过程中，我们训练的是英文查询或英文和德文查询的组合，以训练一个多语言模型来预测 sql 输出。</sample>
    <sample id="652">and we also find many interesting results so regarding analyze of monolingual models we evaluate on two groups of models</sample>
    <sample id="653">包括encoder pdr，它代表多语言预训练的编码器，带有基于指针的解码器，如xlmr-pdr和bert-pdr。</sample>
    <sample id="654">我们还评估了多语言预训练的编码器解码器模型，例如m-bert和mt5。</sample>
    <sample id="655">我们发现编码器解码器在所有九个数据集上都取得了最佳性能。</sample>
    <sample id="656">我们在mt5和xlmr+bdr的多语言设置中进行评估。</sample>
    <sample id="657">如果没有这个编码器解码器或编码器pdr，可以通过在各种语言的混合中进行训练来改进。</sample>
    <sample id="658">我们发现这是因为大多数主要的自然语言可以获得性能提升，但英文在七个数据集中性能下降，只有在三个数据集中性能提升。</sample>
    <sample id="659">我认为这被称为多语言的曲线。</sample>
    <sample id="660">我们还比较了跨语言性能差距。</sample>
    <sample id="661">in this figure the blue line is cross lingual fusion transfer the orange line is cross lingual zero shot transfer while the green line is the monolingual setting</sample>
    <sample id="662">我们发现通过比较绿色和橙色线，我们发现在零秒设置下跨语言转录性能差距显著；通过比较蓝色和橙色线，我们发现在几秒设置下，转录差距迅速缩小。</sample>
    <sample id="663">我们还发现了一些其他有趣的发现，例如编码器解码器比以前的工作表现更好或取得了可比的结果，训练英语自然语言可以显著提高对其他目标自然语言的性能。</sample>
    <sample id="664">我们发现多语言语言模型，如codex和bloom，仍然在跨语言语义分类任务中表现不佳。</sample>
    <sample id="665">总结：我们构建了一个统一的跨语言语义解析基准，涵盖多种自然语言和多种表示形式。</sample>
    <sample id="666">we conduct a comprehensive benchmark study on three representative of types of multilingual language models and our results shows many interesting findings and etc and welcome to visit our paper and code thanks for listening</sample>
    <sample id="667">existing works can be broadly classified into four categories</sample>
    <sample id="668">we also find some other interesting findings for example encoder decoder outperforms previous work or achieved comparable results pre-training on english natural language can significantly boost the performance of future on-target natural languages and without modeling goal language models such as coders and bloom are still inadequate for cross-lingual semantic tasks</sample>
    <sample id="695">in addition sometimes there are multiple permutations that are consistent with the data but the linguistically correct one is latent we address this by inducing the alignment as part of the training our permutation method is very flexible but it brings the challenge that finding the highest scoring permutation is np-hard that's because this is related to the traveling salesman problem we approximate this with a gpu friendly continuous relaxation that also allows us to back propagate through the solution and learn the linguistically more plausible permutations</sample>
    <sample id="696">for example if a right leaning language models were to be fine-tuned on hate speech or misinformation or whatever and deployed to a popular social media platform this would mean that people with opposite political opinions might be marginalized and the hate speech targeting minority groups might just run rampant without any control so this sounds the alarm for us to acknowledge and tackle the fairness issues resulted by language model political leanings</sample>
    <sample id="697">hi i am yannis lavrac and i will present you our works on dr bert a robust pre-trained model in french for biomedical and clinical domain</sample>
    <sample id="698">hi everyone i'm kostas of senna and i'm pleased to welcome you to our talk of our acl 2023 paper language model acceptability judgments are not always robust to context</sample>
    <sample id="699">hi i'm myra and today i'll be talking about our paper marked personas using natural language prompts to measure stereotypes in language models this work is done in collaboration with esendermush and dan juravsky</sample>
    <sample id="700">furthermore there's a lot of common tropes that are reflected in these words especially for women of color so for example the words describing latina women include things like vibrant and curvaceous which connect to a trope of tropicalism for asian women the words are things like petite and delicate and silky</sample>
    <sample id="701">first from mark groups the top words include things like culture tradition proud and exotic and these words define these groups only by their relationship to their identity and distinguish them as different from the white norm</sample>
    <sample id="702">in this work we extend cxi to pointwise cxi which can measure context usage at the sentence level or at the word level we can think of words that have high p6mi as ones that require context for translation</sample>
    <sample id="703">to answer this question we first train and compare four from scratch model a first version of dr bert with 7 gigabytes of natchez a second version of 4 gigabytes of set of natchez a first version of schubert which is a clinical model with 4 gigabytes of sentences taken from clinical notes and a final version of schubert with a mix of 4 gigabytes of set of natchez and 4 gigabytes of clinical notes</sample>
    <sample id="751">hello everyone my name is ying and my colleague jian and i will be presenting our research on multi-instruct improving multimodal social learning via instruction tuning</sample>
    <sample id="752">next we determine the best method to update a model with new data from each round of active learning and annotations cumulative accumulates all the data collected from active annotations so far whereas iterative updates the model by training on the latest set of data collected</sample>
    <sample id="753">our goal is to understand users' language when they want to make a choice now consider this alternative question did you mean easy on me or i got a feeling here a user wants to select between one of these two songs</sample>
    <sample id="754">we also validate the covertness of the provided embedding by visualizing the embedding of sentences unfolded as a bipca the legend of the figures means the number of triggers in each sentence</sample>
    <sample id="755">hi i'm sarah papi from the university of toronto and funded by the bruno kessler and i will briefly introduce the attention as a guide for simultaneous speech translation paper that is a joint work with macdonald and marco d'orci please based on the given information answer the question</sample>
    <sample id="756">we transfer from two different tasks topic independent dissonance stance classification a task that determines if two debate statements from different people are in agreement or in disagreement irrespective of topic</sample>
    <sample id="757">hi everyone i'm jenny a first-year phd student at carnegie mellon university and today i'll be presenting our work on the positionality characterizing design biases of data sets and models this work was done in collaboration with some folks at the university of washington and the allen institute for ai namely sebastian santi roland labrosse katarina rynika and martin sapp</sample>
    <sample id="758">so when the difference between the lengths of the two conjuncts grows the shorter conjunct prefers to be the first one stronger right so the proportion is bigger of the left short conjuncts but what's novel in this paper is that we observed that this tendency only occurs when the governor is on the left or absent right so the governor is on the left in this example isabel and lisa so if the governor is on the left</sample>
    <sample id="759">abc eval is capable of measuring the rates at which chat models will commit various thematic errors</sample>
    <sample id="760">these days large language models are coming up with longer and longer context windows so it's crucial that we evaluate the model's acceptability throughout the context window</sample>
    <sample id="761">and we found it is because most of the major natural languages can obtain performance gain except that english performance drops in seven data sets and only gains in three data sets i think this is known as curse of multilinguality</sample>
    <sample id="762">when we show this alternative question to the annotators they know the name of these entities but they don't necessarily know about the entity</sample>
    <sample id="763">it's the examples that carry most of the weight</sample>
    <sample id="764">the second ingredient is the model size we found that usually larger models lead to better generalization</sample>
    <sample id="765">so let's start off by imagining that you're working for a newspaper and you're sifting through comments under your news article trying to remove toxic content you might turn towards a popular api like perspective api for toxicity detection and this works really well if you're carl jones where perspective api is able to detect correctly toxic instances but that's not really the case for adithya sharma where perspective api is really not as sensitive to offensive terms that are more common in indian contexts this is an example of a design bias where we see systematic performance differences of technology between populations</sample>
    <sample id="766">as shown in this figure we need to translate the query in multiple natural languages using neural models to sql lambda or funql and etc</sample>
    <sample id="767">we transfer from two different tasks topic independent dissonance stance classification a task that determines if two debate statements from different people are in agreement or in disagreement irrespective of topic called debate here and on binary classification of expansion and comparison classes of pity be since these two are closely related to the conception of consonance and dissonance and we call them cee here we find that on transferring the zero-shot performance on the annotated dataset is already much better than chance with the best with auc 062 further on iteratively fine-tuning on both tasks we find that fine-tuning of cee tasks followed by further fine-tuning on debate yields a much better zero-shot performance thus this is the model that we use to cold start the active learning</sample>
    <sample id="768">we saw that the actual form of the prompting doesn't have a big influence in the case of several shared prompting</sample>
    <sample id="769">so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude with three recommendations for model owners so based on these patterns we conclude</sample>
    <sample id="770">this figure shows the constraint distribution of codescript while the next one shows the hyper-polarity in the generated specific goals with codescript we can train smaller but specialized models for constraint language planning</sample>
    <sample id="771">hello everyone my name is xuhong today i'm going to present our paper do convolution 2003 named entity taggers still work well in 2023 let's get started</sample>
    <sample id="772">and we propose those results as a benchmark a base benchmark for the problem of automatic text simplification in the future</sample>
    <sample id="773">with that said tf-funchun and score rate can generate scripts of higher quality than most large language models indicating that smaller models can surpass larger models when properly trained on suitable data sets</sample>
    <sample id="774">for investigating multimodal instruction tuning on our proposed dataset we take ofa a unified multimodal pre-training model as our base model ofa uses a unified vocabulary for language image tokens and the coordinate of a bounding box</sample>
    <sample id="833">hello everyone my name is alex villar and i will be giving a short overview of the paper brenting paraphrase translation assessing strategies and performance this is joint work with my colleagues from google translate</sample>
    <sample id="834">hello my name is vasudha and i'm a computer science phd candidate at stony brook university i would like to present our work accepted into acl 2023 as a long paper transfer learning for dissonance detection addressing the rare class challenge</sample>
    <sample id="835">we use state-of-the-art neural metrics and additionally also show expert-based human evaluation results finally we provide some recommendations for prompt selection strategies</sample>
    <sample id="836">hi i'm john green phd student at the university of washington today i'm presenting our work from pre-training data to language models to downstream tasks tracking the trails of political biases leading to unfair nlp models</sample>
    <sample id="837">we have fine-tuned two different models we have fine-tuned the model of long impart to produce document-level simplifications and we also fine-tuned the normal base long the normal base impart to produce sentence-level simplifications</sample>
    <sample id="838">so for the training data set we use 53 tasks from nat group for training and we sample 10000 instances per task uh for testing we reserve the entire commonsense reasoning group for testing and we select additional five tasks from wqa and the miscellaneous group we use all the instance in the test split for each task uh in addition we randomly sample 20 tasks from the test split of natural instruction as on sintask for lmp</sample>
    <sample id="839">hi welcome to our presentation of deplain a new corpus for german text simplification on the document level and on the sentence level my name is regina stodden and i will guide you through the first part of the presentation let's first define text simplification</sample>
    <sample id="840">we conduct experiments on four datasets agnews mind sst2 and erasmus we assume the provider applied wikitext dataset to count word frequencies</sample>
    <sample id="876">we introduced the first biomedical model uh in french named dr bert which is based on roberta and trained on nachos which is a dataset of medical ground data from the web</sample>
    <sample id="877">hello everyone my name is alex villar and i will be giving a short overview of the paper brenting paraphrase translation assessing strategies and performance this is joint work with my colleagues from google translate</sample>
    <sample id="878">the prompting has a big influence on the performance of the of lms for translation as we can see in a simple experiment where we use one shot prompting and provided two different prompts for generating sentences</sample>
    <sample id="879">hello my name is kyo yen and i will be presenting our work titled when does translation require context a data-driven multilingual exploration this work was done in collaboration with patrick frenoux emily yu andrew ft martins and graham newbigg</sample>
    <sample id="880">so one more thing we are collecting a much larger multimodal instruction tuning dataset with around 150 additional variant language tasks and we will release them so this is a qr code for our data and the model thank you</sample>
    <sample id="881">we introduce a co-reference resolution task designed to probe for the ability to draw on knowledge available in different sources we evaluate the dataset with human study participants and establish co-reference resolution models</sample>
    <sample id="882">hello everyone my name is alex villar and i will be giving a short overview of the paper brenting paraphrase translation assessing strategies and performance this is joint work with my colleagues from google translate</sample>
    <sample id="883">param is a 540 billion parameters large language model presented last year in 2022 it's trained on a large collection of text comprising 780 billion tokens</sample>
    <sample id="884">在大规模公开数据集上，它在数百个nlp任务中达到了最先进的水平。</sample>
    <sample id="885">在这项工作中，我们首次系统地研究了大语言模型提示法在机器翻译中的应用。</sample>
    <sample id="886">我们使用amt社区的最佳实践来评估这些模型的翻译能力，这包括使用最新的测试集以避免测试数据与训练数据的重叠。</sample>
    <sample id="887">我们比较了两个最先进的系统，即wmt评估中的最佳性能系统。</sample>
    <sample id="888">我们使用最先进的神经网络指标，并此外还展示专家基于的人工评估结果。最后，我们提供了一些提示选择策略的建议。</sample>
    <sample id="889">the prompting has a big influence on the performance of lms for translation as we can see in a simple experiment where we use one shot prompting and provided two different prompts for the same sentence</sample>
    <sample id="890">the majority of sentences 516 out of 1000 the difference observed is of more than one blur point</sample>
    <sample id="891">这可以在极端情况下达到40亿点数，因此选择一个好的提醒策略非常重要。</sample>
    <sample id="892">在我们的实验中，我们选择了五次提示策略，即我们为系统提供的每个句子都标记为英文。</sample>
    <sample id="893">so in this example here where we perform translation from german into english the german sentences the source sentences are marked with german column and the english translations with english column</sample>
    <sample id="894">我们看到3d打印的实际形式对3d打印的情况并没有很大影响。</sample>
    <sample id="895">it's crucial for zero and one shot prompting but when we go as in our case to five shot prompting there is nearly no difference to the actual form of the of the prompting</sample>
    <sample id="896">最重要的是例子，它们承担了大部分的重量。</sample>
    <sample id="897">我们的实验结果总结是，示例质量比源句的相似性更重要。</sample>
    <sample id="898">so it's important to select the examples from high quality translations in particular we compare the selecting prompts from the training data of the wmt evaluations or the dev data</sample>
    <sample id="899">dev data is much more curated and with higher quality than the training data and the results so better performance when using the dev data</sample>
    <sample id="900">尽管专业化的最先进系统有着显著的优势，但机器翻译也相当接近商业系统。在我们的案例中，我们选择与谷歌翻译进行评估。</sample>
    <sample id="901">我们使用mqm框架进行的语音识别的见解是，palm的流畅性与最先进的系统相当，但主要的区别来自于准确性。</sample>
    <sample id="902">特别是最常见的错误是遗漏错误。</sample>
    <sample id="903">so it seems that palm chooses to produce a better-sounding translation sometimes by dropping parts of the source sentence that are irrelevant in translation</sample>
    <sample id="904">然而，pantone的风格不协调类别比最先进的系统低，这是一个额外的信号。</sample>
    <sample id="905">parn 提供了非常流畅的输出，但仍然存在一些准确性问题。</sample>
    <sample id="906">and that's it for this really short overview for more details please come to the full presentation of the paper thank you very much</sample>
    <sample id="907">hello i am dawei a phd student at salant university in germany in this video i would like to present our recent work weaker than you think a critical look at weakly supervised learning</sample>
    <sample id="908">这是与shao-yushen mario smootbach和georg steffen合作的英文内容。</sample>
    <sample id="909">i'd like to begin with a brief introduction to weak supervision and weakly supervised learning</sample>
    <sample id="910">在弱监督中，我们不手动标注数据；相反，我们使用弱标注源来标注数据，例如简单的启发式规则、知识库或低质量的众包。如右图所示。</sample>
    <sample id="911">与人工标注相比，弱标注是更便宜的，但它们也很嘈杂，这意味着其中一部分标注是不准确的。</sample>
    <sample id="912">如果直接在弱标签数据上训练神经网络，神经网络倾向于记忆标签噪声而不泛化。</sample>
    <sample id="913">在弱监督学习中，训练算法被提出用于在存在标签噪声的情况下鲁棒地训练神经网络，以便训练出的模型仍然能够很好地泛化。</sample>
    <sample id="914">在最近的工作中使用wsl so wsl stands for weakly supervised learning a common claim is that people say that they only train models on the weakly labeled data and achieve high performance on clean test sets</sample>
    <sample id="915">从技术上讲，这个说法是正确的，但有一点需要注意。</sample>
    <sample id="916">这意味着人们会假设有一个额外的清洁验证集可供模型选择。</sample>
    <sample id="917">我们可以适应这个问题设置，但这意味着需要额外的手动注释，这在弱监督学习中是必需的，但就像一个大象在房间里一样，这常常被忽视。</sample>
    <sample id="918">在上文中提到的任务是要问三个研究问题：第一，清洗验证数据是否必要，还是我们可以用噪声验证集代替？</sample>
    <sample id="919">第二，如果清洗数据是必需的，或者清洗数据是wssl工作的必要条件，那么我们需要多少清洗样本？最后，我们应该只用清洗样本进行验证，还是有更好的方法来利用它们？</sample>
    <sample id="920">在我们的工作中，我们解决了这些研究问题，我们的发现如下。</sample>
    <sample id="921">首先我们发现，有趣的是，最近的wsl方法确实需要干净的验证样本才能正常工作。</sample>
    <sample id="922">否则会出现大幅性能下降，如图中所示，如果没有清洗验证样本，则训练模型无法泛化到原始数据集之外。</sample>
    <sample id="923">这意味着训练是毫无意义的。</sample>
    <sample id="924">这表明 wsl 项目实际上需要清洁标注的数据才能正常工作，因此获取清洁验证样本的标注成本不应被忽视</sample>
    <sample id="925">我们的第二个发现是增加清洗验证样本的数量可以帮助wsl方法实现更好的性能，如左图所示。</sample>
    <sample id="926">通常，我们只需要20个样本即可达到高性能。</sample>
    <sample id="927">但这并不是故事的结局，因为无论我们选择哪种方式，都可以访问清洁的样本，然后直接在它们上进行训练，甚至可以取得更好的性能。</sample>
    <sample id="928">红色图表显示了直接应用于干净数据和仅用于验证的干净数据的wsl方法之间的性能差异。</sample>
    <sample id="929">从我们可以看到，如果我们有10个样本，直接微调开始比wsl方法更好。</sample>
    <sample id="930">最后，在之前的wsl方法中声称的性能提升可以通过允许在干净的验证样本上继续微调来轻松实现。</sample>
    <sample id="931">从图表可以看出，我们称为 ftw 的模型最初表现不如更复杂的 wsl 方法如 cosine。</sample>
    <sample id="932">然而如果我们允许在清洁样本上继续微调，那么ftw表现与其他方法一样好。</sample>
    <sample id="933">在实践中，没有理由选择更复杂的 wsl 方法，这些方法需要更多的计算时间和磁盘空间。</sample>
    <sample id="934">总结来说，我们展示了最近的wsl方法需要清洁的手动标注样本才能正常工作，他们的性能提升和实用性被大大过高估了。</sample>
    <sample id="935">我们对未来工作的具体建议如下：</sample>
    <sample id="936">首先报告模型选择标准，例如报告模型选择是否使用清洗验证样本。</sample>
    <sample id="937">第二 wsar approaches should be compared with few-shot learning baselines as both work on clean samples 第三 continuous fine-tuning is a simple yet strong baseline that should be considered in future work in wsa</sample>
    <sample id="938">最后我们开源了我们的代码， 你可以通过这张幻灯片上的二维码找到它。 请随时查看。</sample>
    <sample id="939">the common practice is to use human evaluation such as by asking human judges to select which of two conversations is better or to rate conversations given a likert scale</sample>
    <sample id="940">hi everyone i'm jenny a first year phd student at carnegie mellon university and today i'll be presenting our work on the positionality characterizing design biases of data sets and models this work was done in collaboration with some folks at the university of washington and the allen institute for ai namely sebastian santi roland labrosse katerina rineka and martin sapp</sample>
    <sample id="941">here is an example from our dataset servin is a judge kea is a baker servin and kea met at a park after a long day at work deciding cases in a law court he was happy to relax the task here is to identify the correct entity that the pronoun he refers to which in this case is servin the resolution of a given pronoun requires two types of information first entity specific knowledge such as servin is a judge and second background knowledge such as judges decide cases in law courts generally background knowledge is learned during the pre-training of large language models while entity specific knowledge is typically observed at inference time we vary the availability of these two pieces of information such that it may either be found in a single source or in multiple sources</sample>
    <sample id="942">still even the best performing models seem to have difficulties with reliably integrated background knowledge presented only at inference time if you're interested in more details please see our paper and check out the dataset and code on github thanks for listening</sample>
    <sample id="943">we also find most additional alignment with people who have a college education so for gpt-4 in the social acceptability task we find that it's most aligned to people with a college education or graduate school education</sample>
    <sample id="944">so why does the match prefix affect the language model judgment so much so we did a series of analysis where we tried to like perturb the input sentence by trying to preserve the relevant structure by adding like noise to the input and after doing like several of these perturbations we find that none of these noises are actually making the model like change its course in terms of how it shows us the mpp judgments basically we find that the models are sensitive to the perturbs and sentences in similar ways that is when we perturb the sentences in the acceptable domain we see similar increase in all the perturbations and when we perturb the sentences in the unacceptable domain we see decrease in mpp judgments in similar fashion</sample>
    <sample id="945">these approaches work well to provide holistic evaluations of overall dialogue quality but dialogue quality has many aspects therefore you might want to evaluate multiple dimensions of chat quality to understand the strengths and weaknesses of the model on a finer grained level</sample>
    <sample id="946">hello everyone my name is jingwei yi from the university of science and technology of china it's my pleasure to give a short advertisement video of our paper i will copy my model protecting the copyright of large language models for embedding and services we will back the watermark</sample>
    <sample id="947">we saw that the actual form of the prompting doesn't have a big influence in in the case of several shot prompting it's crucial for zero and one shot prompting and when we go as in our case to five shot prompting there is nearly no difference to the actual form of the of the prompting</sample>
    <sample id="978">these reliable informative and distinct abc eval metrics enable us to evaluate conversational ai with a higher resolution than previous methods are able to achieve you can see that in the results of our experiment that several challenges still remain and have been precisely quantified for example the bots we tested have common sense violations in around 20 of their responses they produce irrelevant information in around 15 of the responses and they contradict themselves or their partner around 10 of the time with the rapid pace of improvement in the field many of these error rates could see a decrease in new models released since our evaluation was conducted however this is all the more reason to pursue reliable and precise evaluation metrics for comparing models we hope abc eval can be leveraged by others in the field as a meaningful step in this direction and we look forward to seeing how conversational ai will advance in the coming months and years thank you for watching</sample>
    <sample id="979">hello everyone my name is jingwei yi from the university of science and technology of china it's my pleasure to give a short advertisement video of our paper i will copy my model protecting the copyright of large language models for embedding and services we will back the watermark</sample>
    <sample id="980">which impose different constraints on the goal-oriented planning an abstract goal can be inherited by different real-life specific goals with multi-faceted constraints a good planner should write scripts that are reasonable and faithful to constraints</sample>
    <sample id="981">hi i'm sijun from the university i'm here to introduce our work distinguishing script knowledge from large language models for constrained language planning</sample>
    <sample id="982">hello my name is vasudha and i'm a computer science phd candidate at stony brook university i would like to present our work accepted into acl 2023 as a long paper transfer learning for dissonance detection addressing the rare class challenge</sample>
    <sample id="983">hi my name is adam sperkowski and this talk is about the dependency structure of coordination</sample>
    <sample id="1021">in particular the most common error are omission errors</sample>
    <sample id="1022">hello i'm james finch and i'm sarah finch and today we'll tell you all about abc eval a new dimensional approach to evaluating conversational ai</sample>
    <sample id="1023">这项工作由埃默里大学的埃默里nlp实验室主持，由吉诺·乔伊教授领导，并与亚马逊alexa ai合作完成。</sample>
    <sample id="1024">假设你刚刚开发了一个对话模型，你想看看它与当前最先进的模型相比的表现如何。</sample>
    <sample id="1025">the common practice is to use human evaluation such as by asking human judges to select which of two conversations is better or to rate conversations given a likert scale</sample>
    <sample id="1026">这些方法可以很好地提供对整体对话质量的全面评估，但对话质量有许多方面，因此您可能希望评估对话质量的多个维度，以便更深入地了解模型的优势和劣势。</sample>
    <sample id="1027">一种方法是简单地让人类法官评估对话质量的几个方面，例如模型响应的相关性，使用现有的比较或likert尺度方法。</sample>
    <sample id="1028">然而我们相信有更精确和可靠的策略来评估多维对话评估</sample>
    <sample id="1029">our approach attempts to reduce the subjectivity of human evaluation by explicitly annotating whether or not each model response expresses certain behaviors such as responding with irrelevant information or contradicting itself</sample>
    <sample id="1030">我们称这种方法为“在聊天中注释行为”或简称为abc-eval。我们开发了这种方法，以全面覆盖近期文献中建议影响聊天质量的聊天模型行为。</sample>
    <sample id="1031">abc eval 能够测量聊天模型在提交各种主题错误的速率。</sample>
    <sample id="1032">例如， apc-eval 测量了聊天模型忽略其对方或说出无关话题的次数。</sample>
    <sample id="1033">contradicts itself or its partner hallucinates incorrect facts or violates common sense knowledge and when the model succeeds or fails to show empathy</sample>
    <sample id="1034">to determine what kind of evaluation is most effective we selected four state-of-the-art chat models and evaluated them on 100 human-bot conversations per model using abc eval</sample>
    <sample id="1035">为了比较，我们还使用了三种现有的方法来评估这些对话：对话级别的likert评分、对话级别的likert评分以及对话级别的对比分析。</sample>
    <sample id="1036">对于现有的方法，我们收集了八个最常被测量的对话方面的评估，因为这是评估聊天模型的标准做法。</sample>
    <sample id="1037">from our analyses of these evaluation results we found that abc behavior labels are overall more reliable than labels collected by existing methods as measured by inner annotator agreement on 100 doubly labeled conversations</sample>
    <sample id="1038">此外 abc eval 标签更能预测整体对话质量，与现有方法产生的指标相比，如此简单线性回归分析所示。</sample>
    <sample id="1039">for example you can see how measuring the proportion of turns with self and partner contradictions explains 5 and 10 of conversation quality respectively while the average liquor consistency scores explain only 4 or less</sample>
    <sample id="1040">最后我们检查每个评估指标是否捕捉了聊天质量的独特方面，使用逐步线性回归。</sample>
    <sample id="1041">you can see how the combination of all abceval metrics explains over 25 of conversation quality and as you remove the metrics one at a time most of them result in losing a decent amount of information about the quality</sample>
    <sample id="1042">另一方面，所有层次的likert指标的组合解释了质量的很少，而且这些指标中很少有独特的信息。</sample>
    <sample id="1043">这些可靠、信息丰富且独特的abc-eval指标使我们能够以比以往方法更高的分辨率来评估对话式ai</sample>
    <sample id="1044">you can see that in the results of our experiment that several challenges still remain and have been precisely quantified for example the bots we tested have common sense violations in around 20 of their responses</sample>
    <sample id="1045">他们在大约十五％的回答中提供无关信息，并且在十％的情况下与他们的伙伴相互矛盾。</sample>
    <sample id="1046">随着该领域改进的快速步伐，许多这些错误率可能会随着新型号的发布而减少。然而，这正是追求可靠且精确的评估指标进行比较的原因。</sample>
    <sample id="1047">we hope abc eval can be leveraged by others in the field as a meaningful step in this direction and we look forward to seeing how conversational ai will advance in the coming months and years thank you for watching</sample>
    <sample id="1048">this work was done by the emory nlp lab led by professor gino choy at emory university and in collaboration with amazon alexa ai</sample>
    <sample id="1049">to summarize we showed that recent wsl approaches require clean manually annotated samples for them to work properly their performance gain and practicality are heavily overestimated our concrete recommendations for future work are as follows first report the model selection criteria for example report if the model selection is done with clean validation samples second wsl approaches should be compared with free short learning baselines as both work on clean samples third continuous fine-tuning is a simple yet strong baseline that should be considered in future work in ws finally we have open source our code you can find it via the qr code on this slide please feel free to check it out thank you and enjoy the conference</sample>
    <sample id="1050">这篇论文有多少位作者</sample>
    <sample id="1051">hello my name is kyo yen and i will be presenting our work titled when does translation require context a data-driven multilingual exploration this work was done in collaboration with patrick frenoux emily yu andrew ft martins and graham newbigg</sample>
    <sample id="1052">所以许多翻译依赖于上下文。例如，我们如何翻译这句话中的“molly”？</sample>
    <sample id="1053">well if the previous sentence was things could start to get dangerous if the ministers find out then mole refers to a spy but if the previous sentence was could it be anything serious doctor then mole refers to a birthmark</sample>
    <sample id="1054">根据上下文，单词的含义会改变，因此它的翻译也会改变。</sample>
    <sample id="1055">然而评估模型在处理这种情况的能力是非常困难的，首先因为只有少数翻译依赖于上下文，这使得基于语料库的指标无法捕捉这些翻译。</sample>
    <sample id="1056">some people have suggested targeted evaluation on context-dependent translations but these resources only support limited types of context-dependent translations and limited sets of languages since they usually rely on domain knowledge and human curation</sample>
    <sample id="1057">在这项工作中我们试图回答这两个问题：首先翻译需要上下文吗？其次模型如何处理这些情况？</sample>
    <sample id="1058">回答第一个问题，我们首先测量了词语在翻译中依赖于上下文的程度。</sample>
    <sample id="1059">in the previous work we introduced cxi as a measure for context usage by machine translation models and this is done by measuring how much information the context c provides about the target y given the source x</sample>
    <sample id="1060">你可以把cxmi想象成是在给模型提供上下文后获得的信息。</sample>
    <sample id="1061">in this work we extend cxi to pointwise cxi which can measure context usage at the sentence level or at the word level we can think of words that have high p6mi as ones that require context for translation</sample>
    <sample id="1062">现在我们使用高精度的xmi来分析这些单词，以寻找这些单词之间的模式。</sample>
    <sample id="1063">我们在分析了从英文翻译成14种语言的TED演讲的转录上进行了分析。</sample>
    <sample id="1064">我们在三个不同的层次上进行分析 first we look at part-of-speech tags that have high means pxmi</sample>
    <sample id="1065">and this allows us to find for example dual pronouns in arabic that have relatively high xmi and this can be explained because english doesn't have dual pronouns so you need context to determine if a pronoun is dual when translating into arabic</sample>
    <sample id="1066">同样，我们发现某些语言也需要上下文来选择适当的动词形式 我们再看看一些词汇项在其所有出现的平均 p-s-e-m 值中</sample>
    <sample id="1067">and this helps us identify cases like the one here where in chinese you need context to translate proper nouns to make sure that you're using the same translation within the document</sample>
    <sample id="1068">同样地，我们发现context是支持在正确的正式性中翻译的。</sample>
    <sample id="1069">and finally we look at different individual tokens that have high p6mi and this allows us to identify phenomena that cannot really be captured by the word itself but that's rather expressed in a sentence structure such as ellipsis resolution</sample>
    <sample id="1070">现在我们使用我们分析的结果来设计文档级别翻译的基准。</sample>
    <sample id="1071">对于我们识别的五种讨论现象，我们创建了自动识别与该现象相关的词汇的标记器，我们称之为多语言讨论意识标记器。</sample>
    <sample id="1072">我们还可以注意到不同的语言有不同的这些语气现象的比例。</sample>
    <sample id="1073">我们首先使用 muda 标注器，将标注器应用于我们想要用于评估的并行语料库，然后将我们选择的翻译指标应用于 muda 标注器识别出的上下文依赖示例上。</sample>
    <sample id="1074">最后我们使用我们的基准以及其他指标来评估不同模型在文档级别机器翻译中的表现。</sample>
    <sample id="1075">首先，当我们使用语料库级别的指标时，我们发现上下文无关模型具有最佳性能。</sample>
    <sample id="1076">但是如果我们使用comment，context-aware模型表现最佳；而如果我们使用wordf，无论是有context还是没有context，模型的性能都比较相当。</sample>
    <sample id="1077">这再次表明，如果仅使用语料库级别的指标，很难确定最佳的文档级别翻译系统。</sample>
    <sample id="1078">now we use the muda benchmark to evaluate models and we find that context-aware models are significantly more accurate than models that do not use context for certain discourse phenomena such as formality and lexical cohesion</sample>
    <sample id="1079">but these models are not much better than models that do not use context on other phenomena like ellipsis pronouns and verb form so this sort of suggests where we would need to see more progress for document level translation</sample>
    <sample id="1080">我们还比较了不同的商业系统，我们的基准测试显示，deepbelt通常比google translate在文档级别翻译中更准确。</sample>
    <sample id="1081">总结：我们对14种语言对进行数据驱动分析，以确定何时需要翻译的上下文。</sample>
    <sample id="1082">然后我们利用我们的发现来构建文档级别机器翻译的基准，这可以帮助我们识别哪些语境现象模型可以很好地处理，哪些翻译系统在文档级别翻译方面表现良好。</sample>
    <sample id="1083">非常感谢您的关注，期待在多伦多见到您。</sample>
    <sample id="1084">hello everyone my name is yixin john from the penn state university today i'm going to present our work exemplar cross-lingual semantic parsing in multiple natural languages and many representations</sample>
    <sample id="1121">until every token from the first stage has been visited exactly once</sample>
    <sample id="1122">the second part is marked words which is a method to identify the words that distinguish marked groups are marked ones which i'll elaborate on shortly</sample>
    <sample id="1123">hi i'm john green phd student in university of washington today i'm presenting our work from pre-training data to language models to downstream tasks tracking the trails of political biases leading to unfair nlp models</sample>
    <sample id="1124">now there are also symmetric approaches to coordinate structures such as the plug approach the conjunction-headed approach assumed in plug-dependency tree banks where coordinate structures are headed by the conjunction</sample>
    <sample id="1125">hello i'm james finch and i'm sarah finch and today we'll tell you all about abc eval a new dimensional approach to evaluating conversational ai</sample>
    <sample id="1126">my name is jawad hosseini and this is a joint work with philippe radlinski silvia parotti and annie lewis please based on the given information</sample>
    <sample id="1127">so in this work we revisit the minimal pair paradigm so the minimal pair paradigm basically evaluates language models on top of acceptability judgments which can also include grammaticality like plump syntax gem or acceptability in terms of stereotypes such as cross pairs</sample>
    <sample id="1161">we addressed these research questions in our work and our findings are as follows first we find that interestingly recent wsl methods indeed require clean validation samples to work properly otherwise there is a large performance drop as shown in this figure if there are no clean validation samples then the trained models cannot generalize beyond the original weak labels meaning that the training is pointless this indicates that wsl approaches actually require cleanly labeled data to work properly and the annotation cost for obtaining clean validation samples should not be overlooked over second finding is that increasing the number of clean validation samples will help wsl approaches to achieve better performance as shown in the figure on the left typically we only need 20 samples per class to attain high performance</sample>
    <sample id="1162">we also introduce a comparison of model with multiple pretraining settings and data sources then we present our results on 11 biomedical and clinical downstream tasks in french</sample>
    <sample id="1226">however our experiment on continual pretraining using the weight and tokenizer of permutebert trained on the 4 gb subset of natural showed comparable results to those obtained with dr bert 4 gb from scratch</sample>
    <sample id="1227">hi my name is adam sperkowski and this talk is about the dependency structure of coordination</sample>
    <sample id="1228">for temporal drift we did an experiment to retrain or continue to pre-train some models with more recent data and we found that the performance degrades with larger temporal gap and this confirms our hypothesis that the main cause of the performance drop is temporal drift</sample>
    <sample id="1269">after the first step we have all the right tokens but they're not ordered that's why in the second step we use another model to predict a permutation to put them into the right order</sample>
    <sample id="1270">and finally there should really be increased transparency about bias mitigation methods because for instance like these positive stereotypes we don't know if it's because there is some sort of like weird overly excessive value alignment going on or maybe some other like anti-stereotyping methods that are resulting in these pernicious patterns</sample>
    <sample id="1271">and in this minimal pair paradigm the typical way to evaluate language models is that you show like an acceptable sentence or a grammatical sentence and then you show an unacceptable sentence or an ungrammatical sentence and then the hope is that the model basically puts more probability to the acceptable sentence</sample>
    <sample id="1272">however our experiment on continuous pretraining using the weight and tokenizer of permute-bert trained on the 4 gb subset of natural showed comparable results to those obtained with dr bert 4 gb from scratch</sample>
    <sample id="1273">from our analyses of these evaluation results we found that abc behavior labels are overall more reliable than labels collected by existing methods as measured by inner annotator agreement on 100 doubly labeled conversations in addition abc eval labels are more predictive of the overall conversation quality compared to metrics produced by existing methods as shown by this simple linear regression analysis</sample>
    <sample id="1274">finally we can choose sentences from a completely unrelated domain such as wikipedia so this will tell us like whether the model's acceptability judgments are actually impacted by any context</sample>
    <sample id="1275">hi welcome to our presentation of deep plain a new corpus for german text simplification on the document level and on the sentence level my name is regina stodden and i will guide you through the first part of the presentation let's first define text simplification</sample>
    <sample id="1276">however most previous works on instruction tuning focus on improving the zero shot performance on language only tasks while computer vision and multimodal tasks have been left out therefore in this work we want to investigate whether instruction tuning on multimodal pre-trained models can actually improve generalization to unseen multimodal tasks additionally at the time of our research we discovered a considerable discrepancy in availability of instruction data set between lp and multimodal there exists more than 1600 language only instruction tasks however there is no large scale publicly available multimodal instruction tasks therefore this motivates us to build a multimodal instruction tuning data set</sample>
    <sample id="1277">hello i'm james finch and i'm sarah finch and today we'll tell you all about abc eval a new dimensional approach to evaluating conversational ai this work was done by the emory nlp lab led by professor gino choi at emory university and in collaboration with amazon alexa ai</sample>
    <sample id="1278">so we showed that by measuring length in characters that's the first column in syllables the middle column and in words the right column so i'll concentrate on the right one</sample>
    <sample id="1279">so really just only the positive or at least non-negative ones</sample>
    <sample id="1280">with that said t5 outperformed unsupervised read can generate scripts of higher quality than most large language models indicating that smaller models can surpass larger models when properly trained on suitable data sets</sample>
    <sample id="1281">hi i am yannis lavrac and i will present you our works on dr bert a robust pre-trained model in french for biomedical and clinical domain</sample>
    <sample id="1282">在这次演示中，我们首先将讨论医疗保健中的语言建模，然后将介绍我们文章的主要贡献。</sample>
    <sample id="1283">we introduced the first biomedical model uh in french named dr bert which is based on roberta and trained on natasha which is a dataset of medical ground data from the web</sample>
    <sample id="1284">we also introduce a comparison of model with multiple pretraining settings and data sources then we present our results on 11 biomedical and clinical downstream tasks in french</sample>
    <sample id="1285">最后我们总结了实验结果并提供更多关于如何访问模型的细节。</sample>
    <sample id="1286">since its release in 2018 bert has become one of the most effective approach to solve natural language processing tasks and offer huge performance gain compared to historical static and contextualized methods such as word2vec fasttext or elmo</sample>
    <sample id="1287">since then this model has been adapted to many other languages like in french with camembert and also in a domain like biomedical with permabirth and biobirth and on clinical with clinical birth but mostly in english</sample>
    <sample id="1288">针对其他语言的专用模型稀缺且通常基于连续预训练，由于缺乏领域数据。</sample>
    <sample id="1289">然而，法语没有任何开源模型，而美国和中国则有。</sample>
    <sample id="1290">we so we ask ourselves question about what is the most appropriate data source for a wide range of usage and those raw data are a good substitution for clinical data</sample>
    <sample id="1291">to answer this question we compare dr bert with our schubert model which is based on anonymized data obtained from the non-university hospital that we have</sample>
    <sample id="1292">afterward we ask ourselves how much data do we need to train a specialized model on french data is it four gigabytes eight gigabytes or more</sample>
    <sample id="1293">为了回答这个问题，我们首先训练并比较了四个从头开始的模型：第一个版本是用七gb的nachos训练的，第二个版本是用四gb的nachos训练的。</sample>
    <sample id="1294">a first version of schubert which is a clinical uh model with 4 gigabytes of sentences taken from clinical notes and a final version of schubert with a mix of 4 gigabytes of natural sentences and 4 gigabytes of clinical notes</sample>
    <sample id="1295">此外在此比较之外我们引入了三种模型训练和连续预训练以分析预训练策略的影响</sample>
    <sample id="1296">one based on the weight of camomile and trained on four gigabytes of netflix another also based on camomile but trained this time on the four gigabytes of clinical notes</sample>
    <sample id="1297">and finally one based on english biomedical model bert and trained on 4 gigabytes of set of snapshots in total we have seven models</sample>
    <sample id="1298">to evaluate our seven models we gathered which port public and private don't use tasks such as name entity recognition classification part of speech tagging and question answering</sample>
    <sample id="1299">this model are compared to six baseline model which are camber oscar 138 gigabytes camber oscar 4 gigabytes camber cisnet 4 gigabytes petabyte myobert and clinicalbert</sample>
    <sample id="1300">the evolution of highlights that model perform best on the task with data of the same nature as those on which the model has been trained</sample>
    <sample id="1301">however we have we can obtain that data from uh we can observe that data from heterogeneous sources appear to be more versatile we also observe that using more data translate into better performance</sample>
    <sample id="1302">总体而言，从头开始训练的模型在大多数任务上表现更好。</sample>
    <sample id="1303">however our experiment on continuous pretraining using the weight and tokenizer of permutebert trained on the 4 gigabyte subset of natural showed comparable results to those obtained with dr bert 4 gigabytes from scratch</sample>
    <sample id="1304">这与基于卡门贝尔权重和分词器的模型不同，后者存在稳定性问题。</sample>
    <sample id="1305">finally as a conclusion uh uh our proprietary system offer better performance on nine of the 11 downstreams tasks and surpass globally the result of the generic model here camomile</sample>
    <sample id="1306">we also observe that specialized data is better more specialized data is better but it doesn't scale well</sample>
    <sample id="1307">all the pre-trained models obtained from nachos are freely available on yugenface and all the training scripts are on our github repository</sample>
    <sample id="1308">so thank you for for for this presentation and we are looking forward to actions at the poster session in 2022</sample>
    <sample id="1309">to answer this question we first train and compare four from scratch model a first version of dr bert with 7 gigabytes of natchez a second version of 4 gigabytes of set of natchez a first version of schubert which is a clinical uh model with 4 gigabytes of sentences taken from clinical notes and a final version of schubert with a mix of 4 gigabytes of set of natchez and 4 gigabytes of clinical notes in addition to this comparison we introduced three model trained on continuous pre-training to analyze the impact of pre-training strategy</sample>
    <sample id="1310">for adaptive overfitting we saw that from the graph on the right the red best fit line has a gradient that is greater than one this means that every unit of improvement that we made on colonel 2003 translates to more than one unit improvement on colonel which means that there is no diminishing returns and this shows us that adaptive overfitting in this case is not observed</sample>
    <sample id="1311">the second use case that we showed in our paper is the case of automatic text simplification by fine-tuning language models to produce simplified text from the complex input text we have fine-tuned two different models we have fine-tuned the model of long impart to produce document-level simplifications and we also fine-tuned the normal base long the normal base impart to produce sentence-level simplifications you can also find all the checkpoints and you can look into more details at the scores and the evaluation metrics of our experiments in the paper we concluded that this basic fine-tuning could produce or could get scores better than the baseline scores and we propose those results as a benchmark a baseline benchmark for the problem of automatic text simplification in the future</sample>
    <sample id="1312">so some preliminary results demonstrate that first language models do have varying political leanings they occupy all four quadrants on the political compass we can also see that gpt-4 is the most liberal language model of them all and gpt-3 is generally more socially liberal than bird theory and its variants</sample>
    <sample id="1313">hi my name is mathias lendeman and today i'm going to give you a brief introduction to our paper on compositional generalization without trees using multiset tagging and latent permutations</sample>
    <sample id="1314">this is joint work with my advisors alexander koller and ivan titov</sample>
    <sample id="1315">compositional generalization can be understood as the ability of a learner to handle deeper recursion and unseen compositions of phrases that have been seen individually during training</sample>
    <sample id="1316">in the context of semantic parsing testing for compositional generalization might look like this as usual we have a training set of utterances in this case the girl slept and mary knew that the girl slept</sample>
    <sample id="1317">these utterances are paired with logical forms that represent core aspects of their meaning</sample>
    <sample id="1318">in contrast to standard machine learning evaluation the test set does not come from the same distribution but contains structurally unseen logical forms</sample>
    <sample id="1319">in this example the model has seen shallow recursion during training and is tested on an example with deeper recursion</sample>
    <sample id="1320">naive sequence-to-sequence models struggle with this kind of out-of-distribution generalization and often produce outputs that are detached from the input</sample>
    <sample id="1321">in particular they often fail to reproduce the systematic correspondences between input and output such as those that are color-coded in the example</sample>
    <sample id="1322">一种流行的方法是将树整合到模型中。</sample>
    <sample id="1323">the trees are intended to capture the compositional process that relates utterances with their logical forms.</sample>
    <sample id="1324">this works well, but trees are usually not given and need to be obtained somehow.</sample>
    <sample id="1325">this can be a complicated and sometimes a computationally expensive process typically this involves considerable formalism-specific pre-processing of the logical forms for example to handle variable symbols</sample>
    <sample id="1326">获得树可能还涉及专门的语法归纳程序。</sample>
    <sample id="1327">in this paper we don't use trees and introduce a neural sequence-to-sequence model that directly models the correspondences between fragments of the input and fragments of the output</sample>
    <sample id="1328">for the first time we show strong generalization to deeper recursion without relying on trees.</sample>
    <sample id="1329">our approach predicts the output from the input in two steps</sample>
    <sample id="1330">first we tag each input token with an unordered multiset of tokens that will appear in the output</sample>
    <sample id="1331">after the first step we have all the right tokens but they are not ordered</sample>
    <sample id="1332">that's why in the second step we use another model to predict a permutation to put them into the right order</sample>
    <sample id="1333">we introduce a new method to predict a permutation that does not put any hard constraints on the possible permutations this makes our approach quite flexible and expressive</sample>
    <sample id="1334">概念上，我们的排列模型的工作原理大致是这样的。</sample>
    <sample id="1335">we go from left to right over the output and determine which multi-set token to put in every position for the first output position we simply select one as highlighted in red</sample>
    <sample id="1336">然后我们跳到下一个多集标记来确定输出中的第二个标记。</sample>
    <sample id="1337">we determine the third token in the output in a similar way by jumping to another multiset token we continue this process</sample>
    <sample id="1338">直到第一阶段的每个标记都被访问过一次。</sample>
    <sample id="1339">to give you a teaser of the experimental results here we compare our method with other treeless models on the cogs benchmark our model outperforms the others by a large margin on generalization to deeper recursion</sample>
    <sample id="1340">some other kinds of structural generalization remain very challenging though</sample>
    <sample id="1341">在我们的论文中，我们解决了几个有趣的技术挑战。</sample>
    <sample id="1342">first of all the alignment between input and output is not given in the training data as a consequence for a given token we don't know which multi-setter it came from which poses a challenge for training</sample>
    <sample id="1343">in addition sometimes there are multiple permutations that are consistent with the data but the linguistically correct one is latent we address this by inducing the alignment as part of the training</sample>
    <sample id="1344">our permutation method is very flexible but it brings the challenge that finding the highest scoring permutation is np-hard that's because this is related to the traveling salesman problem</sample>
    <sample id="1345">we approximate this with a gpu-friendly continuous relaxation that also allows us to backpropagate through the solution and learn the linguistically more plausible permutations</sample>
    <sample id="1346">if you want to learn more about our experiments and how we address these challenges please have a look at our paper or come to our poster</sample>
    <sample id="1347">we begin by defining cognitive dissonance and why it is an important problem to study in language simply put cognitive dissonance is two beliefs or actions that are inconsistent</sample>
    <sample id="1348">we can also see that gpt-4 is the most liberal language model of them all and gpt theories are generally more socially liberal than bert theories and its variants</sample>
    <sample id="1349">over the different strategies we found that cumulative performed equal or better than iterative across the board</sample>
    <sample id="1350">hi i'm sarah papi from the university of toronto and funded by bruno kessler and i will briefly introduce the attention as a guide for simultaneous speech translation paper that is a joint work with macdonald and marco d'orci receiving english content after</sample>
    <sample id="1351">and we perform our analysis on transcripts of ted talks that have been translated from english to 14 different languages</sample>
    <sample id="1385">hi my name is mathias lendeman and today i'm going to give you a brief introduction to our paper on compositional generalization without trees using multiset tagging and latent permutations</sample>
    <sample id="1386">and we also consider cross-lingual zero-shot and few-shot transfer we train on one source language and transfer to another language so during training we'll train it on english query or the combination of english and german few-shot queries to train a multilingual model to and predict the sql output</sample>
    <sample id="1387">hello i am dawei a phd student at salant university in germany in this video i would like to present our recent work weaker than you think a critical look at weakly supervised learning this is joint work with xiaoyu shen marios mouzakis and geoffrey stephen and david schlanger</sample>
    <sample id="1388">we plot the simultaneous space translation results on graphs in which we have blue on one side that measures the translation quality and average lagging that is the latency measure and we also consider the computational aware average lagging that accounts for the model's computational time to predict the output</sample>
    <sample id="1389">hello everyone i'm mark shatta and today my co-author martin and i are presenting our work the kit must have evaluating knowledge integration from multiple sources this work is a collaboration between mcgill university niela and microsoft research</sample>
    <sample id="1390">national language understanding models draw on a variety of knowledge sources such as knowledge contained in their parameters usually acquired via pre-training and knowledge given in inputs at inference time</sample>
    <sample id="1391">最近的工作在任务如问答中表明，模型可以利用预训练的时间知识来解决任务。</sample>
    <sample id="1392">but natural language understanding often requires knowledge that is also supplied at inference time</sample>
    <sample id="1393">for example in the sentence john saw the newly elected president on tv</sample>
    <sample id="1394">pre-trained parameters can contain information about what presidents do and what a tv is but they cannot reliably know who this instance-specific entity john is or who the new president is because the president might have changed since pre-training</sample>
    <sample id="1395">therefore successful models for knowledge-intensive nlu tasks require the ability to integrate and use both pre-trained time and inference time knowledge</sample>
    <sample id="1396">in this work, we propose a diagnostic test suite for knowledge integration.</sample>
    <sample id="1397">we introduce a co-reference resolution task designed to probe for the ability to draw on knowledge available in different sources we evaluate the dataset with human study participants and establish co-reference resolution models</sample>
    <sample id="1398">here is an example from our dataset servin is a judge kia is a baker servin and kia met at a park after a long day at work deciding cases in a law court he was happy to relax</sample>
    <sample id="1399">the task here is to identify the correct entity that the pronoun he refers to which in this case is seven</sample>
    <sample id="1400">the resolution of a given pronoun requires two types of information first entity-specific knowledge such as servin is a judge and second background knowledge such as judges decide cases in law courts</sample>
    <sample id="1401">generally background knowledge is learned during the pre-training of large language models while entity-specific knowledge is typically observed at inference time</sample>
    <sample id="1402">we vary the availability of these two pieces of information such that it may either be found in a single source or in multiple sources</sample>
    <sample id="1403">we have defined three settings of kitmos first we have the topic setting background pre-train where background knowledge is assumed to be available at pre-train time</sample>
    <sample id="1404">second there's a background both setting where background knowledge is available both at pre-train time and inference time lastly the background inference setting with both knowledge types available only at inference time</sample>
    <sample id="1405">this last setting is especially interesting since it simulates the case where the background knowledge necessary to solve a task is not part of the pre-trained data of models for example because new occupations have developed since the time of pre-training</sample>
    <sample id="1406">here's an example of how we control the availability of facts and true sources</sample>
    <sample id="1407">in the background pre-trained setting we assume that the background knowledge politicians seek elected seats in government is contained in the pre-trained parameters in the three-sentence context we provide the anti-specific knowledge chichester is a politician</sample>
    <sample id="1408">in the background both setting we additionally provide not only entity-specific but also background knowledge about politicians in the inferential context</sample>
    <sample id="1409">in the background and fictional setting we provide the fictional occupation meritour instead of politician because meritour is unlikely to be contained in the pre-training period</sample>
    <sample id="1410">we evaluate the dataset both with human study participants and establish coreference resolution models in this figure we show the results of the best performing models on the most difficult variant of the background pre-trained setting</sample>
    <sample id="1411">without task-specific training on kitmos both models do not perform well when trained on kitmos however both c2f and bird4cof perform significantly better than the random choice</sample>
    <sample id="1412">this suggests that when trained on cat genetic reference resolution data sets models learn to exploit surface cues which are not useful when testing on kitmos where such cues have been removed</sample>
    <sample id="1413">额外的虚构知识实验表明，即使是表现最佳的模型，也无法可靠地整合在推理时提供的背景知识。</sample>
    <sample id="1414">to summarize the main takeaways of our paper many co-reference resolution models appear unable to reason over knowledge from different sources without task-specific training however with task-specific training some models successfully integrate knowledge from multiple sources</sample>
    <sample id="1415">still even the best-performing models seem to have difficulties with reliably integrated background knowledge presented only at inference time if you're interested in more details please see our paper and check out the dataset and code on github thanks for listening</sample>
    <sample id="1416">this works well but trees are usually not given and need to be obtained somehow this can be complicated and sometimes a computationally expensive process typically this involves considerable formalism-specific pre-processing of the logical forms for example to handle variable symbols obtaining trees may also involve specialized grammar induction procedures</sample>
    <sample id="1417">hello everyone my name is xuhong today i'm going to present our paper do convolution 2003 named entity taggers still work well in 2023 let's get started</sample>
    <sample id="1418">hi i'm myra and today i'll be talking about our paper marked personas using natural language prompts to measure stereotypes in language models this work is done in collaboration with esendermush and danjurovski</sample>
    <sample id="1419">近年来，许多人已经记录了大型语言模型中社会偏见和刻板印象的普遍性。</sample>
    <sample id="1420">然而，这些措施有各种限制。它们通常依赖于人工构建的数据集，这些数据集需要花费大量时间来整理。</sample>
    <sample id="1421">and they also usually only measure very specific stereotypes meaning that they don't generalize well to other demographics or contexts or they simply capture very general broad associations like negative associations with particular groups</sample>
    <sample id="1422">此外，大多数在这个领域的工作都没有考虑到交叉性，即多重社会身份可以加剧偏见并成为独特的伤害点。</sample>
    <sample id="1423">为了克服这些限制，我们依靠这些较新的指令微调的语言模型非常擅长响应指令和提示。</sample>
    <sample id="1424">so we can ask the model to generate a persona which is a depiction of an imagined individual using a prompt like imagine you are an asian woman describe yourself</sample>
    <sample id="1425">and we can immediately see that this is very generalizable to any demographic because we can just specify whatever identity marker that we want into this prompt</sample>
    <sample id="1426">so here are some example generations from gpt-4 将这段英语内容用中文重新表达</sample>
    <sample id="1427">immediately we see that while the outputs aren't overtly negative or toxic in the traditional sense of these words</sample>
    <sample id="1428">有一些有趣的模式。</sample>
    <sample id="1429">asian woman is depicted as unassuming the middle eastern woman is referred to using words like exotic and like referring to a mesmerizing region</sample>
    <sample id="1430">这段英语内容的翻译是：both of the women of color personas make references to ancestry while the white man persona has nothing of the sort。</sample>
    <sample id="1431">为了捕捉这些模式，我们的方法有两个部分。第一个是生成这些角色。</sample>
    <sample id="1432">our prompts to generate these personas were inspired by a study where they gave these prompts to human subjects finding that by giving it to human subjects they also were able to surface racial stereotypes</sample>
    <sample id="1433">此外，这也使得我们生成的角色与人类撰写的响应进行直接比较。</sample>
    <sample id="1434">the second part is marked words which is a method to identify the words that distinguish marked groups or marked ones which i'll elaborate on shortly</sample>
    <sample id="1435">这个好处是我们可以获得非常具体的刻板印象和模式，而无需依赖任何特定的词汇表。</sample>
    <sample id="1436">so the marked words method draws upon the sociolinguistic concept of markedness which states that there is an unmarked default and any group that differs from that default is linguistically marked</sample>
    <sample id="1437">so for instance the word man or sorry the word warrior is usually associated with men so when people are describing a warrior who is a woman they'll usually actually specify woman warrior and mark the term with woman</sample>
    <sample id="1438">and more broadly dominant groups in society are both linguistically and socially unmarked while the marginalized groups are usually marked</sample>
    <sample id="1439">所以在我们的方法中，我们首先指定未标记和标记组。</sample>
    <sample id="1440">and then we compare the personas using the fighting words method which is basically using weighted log odds ratios to distinguish the top words for each marked group</sample>
    <sample id="1441">so for instance for the personas of black women we would do fighting words and compare the law god's ratios against both white personas and man personas because those are the two corresponding unmarked groups</sample>
    <sample id="1442">now for some results so first we use alexicon of stereotypes and we find that the generated personas contain a lot more stereotypes than the human-written ones</sample>
    <sample id="1443">然而当我们实际上查看词汇表中词的分布时，我们发现情况完全不同。</sample>
    <sample id="1444">so while the generated personas have much higher rates of the luxon words the human written ones have a much wider distribution of words while the stereotype words that are in the generated personas are really just the words tall and athletic</sample>
    <sample id="1445">所以只保留正面的或至少非负面的。</sample>
    <sample id="1446">and in fact this lexicon doesn't really capture many of the harmful patterns that we saw in the earlier slides well at all so instead to do that we'll turn to the results from our marked words method to show how these positive seeming words facilitate stereotypes and essentializing narratives</sample>
    <sample id="1447">在我们的分析中，我们揭示了这些看似积极的描绘反映了可怕的模式。</sample>
    <sample id="1448">first from mark groups the top words include things like culture tradition proud and exotic and these words define these groups only by their relationship to their identity and distinguish them as different from the white norm</sample>
    <sample id="1449">这为这些群体的长期歧视和边缘化做出了贡献。</sample>
    <sample id="1450">furthermore there's a lot of common tropes that are reflected in these words especially for women of color so for example the words describing latina women include things like vibrant and curvaceous</sample>
    <sample id="1451">这与热带主义的刻板印象有关，对于亚洲女性，这些词语是“小巧”、“精致”和“丝绸”等词。</sample>
    <sample id="1452">which connects to a long history of asian women being hypersexualized seen as very docile and submissive and so on</sample>
    <sample id="1453">最后，对于黑人女性，我们看到一些最常见的词语是“强大”和“坚韧”。</sample>
    <sample id="1454">this connects to an archetype that people have called the strong black woman archetype and while it sounds like positive at first glance</sample>
    <sample id="1455">there's been work showing that this kind of archetype actually is very harmful because it puts a lot of pressure on these demographics to be resilient and strong against societal obstacles</sample>
    <sample id="1456">so rather than actually working towards changing those obstacles it puts pressure on those people to overcome them which leads to very negative health outcomes for these people among other harms</sample>
    <sample id="1457">更广泛地说，我们发现每个标记群体的词汇基本上都反映了非常简化的叙述。</sample>
    <sample id="1458">基于这些模式，我们得出三个建议，供模型所有者参考。</sample>
    <sample id="1459">first we should as researchers be addressing positive stereotypes and essentializing narratives we should also be using intersectional lens to study biases and harms because there's a lot of things that might be overlooked if we don't do that</sample>
    <sample id="1460">最后，应该增加关于偏见缓解方法的透明度。</sample>
    <sample id="1461">because for instance like these positive stereotypes we don't know if it's because there's some sort of like weird</sample>
    <sample id="1462">过度的价值对齐或可能是其他一些反刻板思维的方法导致了这些有害的模式。</sample>
    <sample id="1463">我们确实无法做出任何假设或进一步研究，除非有更多透明度。</sample>
    <sample id="1464">谢谢你们的耐心听我讲的谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢谢</sample>
    <sample id="1465">hello everyone my name is jingwei yi from the university of science and technology of china</sample>
    <sample id="1466">这是我的荣幸，给大家展示我们的报纸，我是你的模特，保护大型语言模型的版权，我们会保护我们的水印。</sample>
    <sample id="1467">让我们首先介绍有关嵌入式服务的背景。</sample>
    <sample id="1468">目前，大型语言模型如gpt、llama和palm在自然语言理解和生成方面表现出色。</sample>
    <sample id="1469">embedding as services is one of the services built upon large language models to assist various nlp tasks</sample>
    <sample id="1470">例如，openai 提供了一个基于 gpt 的嵌入式 api。</sample>
    <sample id="1471">然而，最近的研究表明，攻击者可能通过学习嵌入式服务来窃取模型，因此保护嵌入式服务的版权是必要的。</sample>
    <sample id="1472">为了保护嵌入式服务的版权，一种解决方案是将水印嵌入服务中，并检测另一个服务是否包含水印。</sample>
    <sample id="1473">watermark method needs to meet the following properties first the method should be applicable to embedding services second the watermark should not degrade the utility of the embedded services</sample>
    <sample id="1474">第三，水印应该足够隐蔽，以便攻击者无法轻易移除。</sample>
    <sample id="1475">最后，水印需要在模型提取过程中能够转移到攻击者的服务中。</sample>
    <sample id="1476">现有的作品可以大致分为四个类别。</sample>
    <sample id="1477">然而，这些方法要么不适用于嵌入式服务，要么缺乏可转移性。</sample>
    <sample id="1478">因此，在这篇论文中，我们提出了嵌入标记器，这是一种基于后门的水印方法，适用于嵌入服务。</sample>
    <sample id="1479">然后让我介绍我们的嵌入标记器嵌入标记器包含两个主要步骤：水印注入和版权验证。</sample>
    <sample id="1480">在这些主要步骤之前，我们首先选择一个触发词集。触发词集是一组在中等频率间隔内出现的词。</sample>
    <sample id="1481">我们假设提供者可以收集一个通用文本语料库，并计算其中的单词频率。</sample>
    <sample id="1482">在watermark注入中，我们首先定义一个触发词。当用户向提供者服务发送一个句子时，提供者会计算句子中触发词的数量。</sample>
    <sample id="1483">提供的嵌入是目标嵌入和原始嵌入的加权和。</sample>
    <sample id="1484">目标嵌入体的权重与句子中触发器的数量成正比。当句子中触发器的数量大于 m 时，提供的嵌入体与目标嵌入体完全相同。</sample>
    <sample id="1485">版权验证是检测一个模型是否在另一个服务中包含水印。</sample>
    <sample id="1486">我们首先构建一个backdoor和benign数据集 backdoor数据集包含所有单词都属于trigger集的句子，而benign数据集的句子中的所有单词都不属于trigger集。</sample>
    <sample id="1487">然后，提供商从 steelers 服务请求数据集的嵌入。</sample>
    <sample id="1488">请求的嵌入和目标嵌入之间的余弦相似性和l2相似性被计算。 我们计算了bnine和backdoor数据集之间的相似性差异，这被定义为delta_cosine和delta_l2。</sample>
    <sample id="1489">同时，我们还将ks检验应用于它，并使用其p值作为第三个指标。</sample>
    <sample id="1490">我们在四个数据集上进行了实验：age news mind sst2 和 erasmus 我们假设提供者应用了 wikitext 数据集来计算词频。</sample>
    <sample id="1491">在四个数据集上的结果表明，我们的嵌入标记可以实现更好的检测性能，同时保持良好的下游任务效用。</sample>
    <sample id="1492">我们还通过将句子的嵌入可视化来验证提供的嵌入的隐蔽性： 图表的图例表示每个句子中的触发器数量。</sample>
    <sample id="1493">如图所示，很难区分因子嵌入和普通嵌入。</sample>
    <sample id="1494">that's all thank you welcome to discuss with us</sample>
    <sample id="1495">we call this approach annotating behaviors in chat or abc-eval in short we developed this method to comprehensively cover chat model behaviors that have been suggested to affect chat quality in recent literature</sample>
    <sample id="1496">our conclusion is that for good generalization we would need a better model architecture larger model size as well as more fine-tuning examples and these goes hand in hand we can't just have one ingredient but throw out the others at the same time we also found that the performance drop here is caused by temporal drift and kind of surprisingly it is not caused by adaptive overfitting even though conll 2003 has been used for over 20 years so going back to the question that we raised in the title of our paper do conll 2003 taggers still work in 2023 and we found that the answer is actually a resounding yes we hope our paper calls for more research on how to improve generalization of the models</sample>
    <sample id="1497">hello my name is vasudha and i'm a computer science phd candidate at stony brook university i would like to present our work accepted into acl 2023 as a long paper transfer learning for dissonance detection addressing the rare class challenge</sample>
    <sample id="1498">we begin by defining cognitive dissonance and why it is an important problem to study in language simply put cognitive dissonance is two beliefs or actions that are inconsistent</sample>
    <sample id="1499">such as this example where a person states i know that cigarettes could kill me and then goes on to say i grabbed a couple of smokes after the meeting this belief and action are inconsistent and they are in resonance</sample>
    <sample id="1500">further mentioning that i don't think i could keep my job without them justifies the second occurrence and they have a consonance relationship</sample>
    <sample id="1501">while dissonance is a very common phenomenon we experience in daily decision-making they are really rare to find expressed in language among other kinds of discourse relations</sample>
    <sample id="1502">so why does this matter studying cognitive dissonance can help us understand the effects of disagreement among people track trends in belief values and attitude changes in population</sample>
    <sample id="1503">high cognitive dissonance is also related to anxiety disorders and can help understand people's mental health better</sample>
    <sample id="1504">studying dissonance expressed in language can also be beneficial in understanding extremism and polarization of vulnerable groups</sample>
    <sample id="1505">finally cognitive dissonance is important to understand personal cognitive styles of individuals and helps us understand decision-making processes better</sample>
    <sample id="1506">to the goal of creating a cognitive dissonance resource we conducted a large scale annotation of dissonance relations we used a dissonance first approach as seen in the flow chart here</sample>
    <sample id="1507">tweets were passed using a pdtb parser and pairs of discourse units were annotated according to the guidelines that are described in our paper</sample>
    <sample id="1508">as can be seen here resonance was only found in 35 of the annotated pairs</sample>
    <sample id="1509">on collecting around 1000 examples of discourse unit pairs we ran training for an initial classifier trained only on 43 examples of dissonance to no surprise the classifier performed not much better than chance</sample>
    <sample id="1510">given the low occurrence of dissonance and absence of any prior such data set we are facing the problem of absolute rarity</sample>
    <sample id="1511">to alleviate this we experiment over combinations of transfer learning and active learning to annotate such that more dissonant samples can be collected over lesser annotation runs lowering the overall annotation cost while improving dissonance detection</sample>
    <sample id="1512">since the initial model was not able to capture the dissonance class at all we start the active learning process by transferring weights from closely related tasks</sample>
    <sample id="1513">we transfer from two different tasks topic independent dissonance stance classification a task that determines if two debate statements from different people are in agreement or in disagreement irrespective of topic</sample>
    <sample id="1514">called debate here and on binary classification of expansion and comparison classes of purity b since these two are closely related to the conception of consonance and dissonance and we call them ce here</sample>
    <sample id="1515">we find that on transferring the zero-shot performance on the annotated data set is already much better than chance with the best with auc 062</sample>
    <sample id="1516">further on iteratively fine-tuning on both tasks we find that fine-tuning of ce tasks followed by further fine-tuning on debate yields a much better zero-shot performance thus this is the model that we use to co-start the active learning</sample>
    <sample id="1517">next we determine the best method to update a model with new data from each round of active learning and annotations cumulative accumulates all the data collected from active annotations so far whereas iterative updates the model by training on the latest set of data collected</sample>
    <sample id="1518">over the different strategies we found that cumulative performed equal or better than iterative across the board</sample>
    <sample id="1519">next to improve the number of dissonance examples we use a probability of rare class strategy prc to select mostly the examples that are highly likely to be dissonant by the current model at any round of air</sample>
    <sample id="1520">we compare this to the other state-of-the-art strategies that are commonly used in the community</sample>
    <sample id="1521">we find that the proposed prc strategy works better than other state-of-the-art strategies although the difference is small note that the performance is significantly lower for random</sample>
    <sample id="1522">on further rounds of ale with two best strategies we improved dissonance classification auc to 075 which is the best performance that we have on the task so far</sample>
    <sample id="1523">we also checked the feasibility of each strategy for annotation quality and costs to annotators we find that prc has the highest percentage of dissonance and works best for rare class however the annotators also find the examples difficult</sample>
    <sample id="1524">in summary we find that prc is a simple al strategy for rare class acquisition and cold starting al with appropriately designed transfer learning tasks can help significantly</sample>
    <sample id="1525">we also find that iterative update is useful for transfer learning from a different domain whereas in-domain active annotations benefit from cumulative update</sample>
    <sample id="1526">these are the links to our code data set and our paper feel free to get in touch with us if you have any questions thank you</sample>
    <sample id="1527">hi my name is mathias lendeman and today i'm going to give you a brief introduction to our paper on compositional generalization without trees using multi-set tagging and latent permutations this is joint work with my advisors alexander koller and ivan titov</sample>
    <sample id="1528">hi i'm sijun from the university i'm here to introduce our work distinguish script knowledge from large language models for constraint language planning</sample>
    <sample id="1529">hello my name is kayo yen and i will be presenting our work titled when does translation require context a data-driven multilingual exploration this work was done in collaboration with patrick frenoux emily yu andrew ft martins and graham newbigg</sample>
    <sample id="1530">and we compare with popular strategies that are also applied to offline models that are the wait-k strategy and the local equipment and we compare also with the state-of-the-art architecture specifically tailored for simultaneous speech translation</sample>
  </task>
</testset>