<testset name="IWSLT2025" type="output">
  <task track="long" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind politische Nachrichtenmedien wie New York Times, Los Angeles Times, The Guardian, Huffington Post, und andere, die in den Trainingsdaten weit verbreitet sind.</sample>
    <sample id="1">Die Autoren gehören der McGill University an.</sample>
    <sample id="2">Die vorliegende Arbeit von Tiwei und seinem Team aus Edgroup konzentriert sich auf das Problem der visuell reichen Dokumentverständnis. Sie schlagen vor, Layout-Mask, ein neues Multi-Pre-Training-Modell, um die Herausforderungen der globalen Lesereihenfolge zu überwinden. Im Gegensatz zu bestehenden Modellen, die auf globaler 1D-Position basieren, verwendet Layout-Mask lokale 1D-Positionen, um Text-Layout-Interaktionen zu fördern. Durch die Einführung von whole-word-masking und layout-aware-masking, die auf Wort- und Layout-Ebene maskieren, wird der Kontext zwischen Wörtern und Layouts verbessert. Die Ergebnisse zeigen, dass Layout-Mask bei SROIE besser abschneidet als bei WSD, was auf die Anpassungsfähigkeit der globalen 1D-Positionen hinweist.</sample>
    <sample id="3">Hallo. Ich bin Omar und werde über die Verwendung von Dplain sprechen. Als erstes Beispiel können wir die Methoden zur automatischen Ausrichtung bewerten. In den letzten Jahren gab es viele Ausrichtungsmethoden. Im Kontext von maschinellen Übersetzungen wollen wir Ausrichtungen von Sätzen in zwei parallelen Dokumenten in verschiedenen Sprachen extrahieren. In unserem Fall haben wir jedoch zwei parallele Dokumente mit demselben Inhalt, aber unterschiedlicher Komplexität. Mit unserem Datensatz Dplain, der Sätze mit manueller Ausrichtung enthält, können wir diese Sätze als Standardausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten. Wir haben einige Anpassungen an die vorgeschlagenen Methoden vorgenommen und die Codes, um Experimente zu führen, in der Arbeit veröffentlicht. Am Ende haben wir festgestellt, dass die beste Ausrichtungsmethode für die deutsche Textausrichtung die Methode von Mass Align ist. Sie können auch den Code finden, um diese Methode auf Ihre eigenen Dokumente auszuführen. Das zweite Beispiel, das wir in unserer Arbeit gezeigt haben, ist die automatische Textausrichtung durch Feinabstimmung von Sprachmodellen, um komplexe Eingabedateien in vereinfachte Textversionen zu produzieren. Wir haben zwei verschiedene Modelle feinabgestimmt. Wir haben das Modell von Long impar zur Produktion von Dokumentenlevel-Ausrichtungen und das Modell von Long impar zur Produktion von Satzlevel-Ausrichtungen feinabgestimmt. Sie können auch die Checkpoints und die Ergebnisse unserer Experimente in der Arbeit finden. Wir haben festgestellt, dass diese grundlegende Feinabstimmung die Basismessungen übertreffen kann. Wir schlagen diese Ergebnisse als Basis für die zukünftige automatische Textausrichtung vor. Vielen Dank für Ihre Aufmerksamkeit. Und ich hoffe, Sie alle während der Konferenz zu treffen. Vielen Dank.</sample>
    <sample id="4">Der Referent ist Ms. Kayo Yin.</sample>
    <sample id="5">T5-XL</sample>
    <sample id="6">Zhang und Kollegen präsentieren eine neue Methode zur Zusammenfassung, die als many-to-many summarization bekannt ist. Diese Methode kombiniert die Aufgaben der multilingualen und crosslingual summarization in eine einheitliche Umgebung, die es einem Modell ermöglicht, Dokumente in jeder Sprache zu zusammenfassen und in jeder Sprache zu summarisieren. Sie haben ein Modell namens Pisces entwickelt, das durch eine dreistufige prähabilistische Schulung trainiert wird, die die Sprachmodellierung, die Fähigkeit, in verschiedenen Sprachen zu arbeiten, und die Zusammenfassungsfähigkeit umfasst. Die Ergebnisse ihrer Experimente zeigen, dass Pisces die vorherigen Modelle wie mBert50 und MT5 übertrifft. Sie haben auch Ablationsstudien und menschliche Studien durchgeführt, um die Wirksamkeit ihrer Methode zu bestätigen.</sample>
    <sample id="7">Ja, CoNLL-2003-Tagger funktionieren nach der Analyse noch, aber Verbesserungen sind erforderlich, um bessere Generalisierung zu erreichen.</sample>
    <sample id="8">Die neue Methode, ABC Evaluation, reduziert die Subjektivität menschlicher Bewertungen, indem sie spezifische Verhaltensweisen in Chat-Modellen annotiert, wie z.B. Irrelevanz, Selbstkontrahierung oder emotionale Missachtung.</sample>
    <sample id="9">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von der Verfügbarkeit von sauberen Validierungsdaten ab.</sample>
    <sample id="10">Um die Genauigkeit zu verbessern, sollten Modelle Zugang zu teilweise überlappenden Hintergrundinformationen erhalten.</sample>
    <sample id="11">Jack Hessels Vortrag über Humor-Understanding Benchmarks diskutiert die Fähigkeiten von großen Sprachmodellen bei der Generierung und Erklärung von Witzen. Er verwendet Daten aus der New Yorker Caption Contest, um Modelle wie ChatGPT und GPT-4 zu testen. Die Ergebnisse zeigen, dass diese Modelle zwar in der Generierung von Witzen und Erklärungen versiert sind, aber im Verständnis von Humor hinter menschlichen Fähigkeiten zurückbleiben. ChatGPT und GPT-4 zeigen Schwierigkeiten, die Komplexität von Humor zu erfassen, was durch menschliche Bewertungen bestätigt wird. Hessels Arbeit bietet einen umfassenden Überblick über die aktuellen Grenzen der Sprachmodelle in diesem Bereich und lädt zur weiteren Forschung und Verbesserung ein.</sample>
    <sample id="12">Die Arbeit wurde von fünf Autoren durchgeführt: Dawei, Xiaoxuan, Mario Musbach, Giasdeth, und Dittlich.</sample>
    <sample id="13">Daniel Rotem präsentiert seine Arbeit über die Analyse und Verbesserung der adaptiven Inferenz in ressourcenschränken. Er untersucht die Methoden Multi-Model und Early Exit, die beide zur Verringerung der Inferenzzeit in großen Sprachmodellen eingesetzt werden. Die Studie zeigt, dass Multi-Model zwar vielseitig ist, aber Speicher und Overhead erfordert, während Early Exit schneller und speicherfreundlicher ist, aber durch Konfliktingrade beeinträchtigt wird. Rotem entwickelt die Suite-Methode, die die negativen Auswirkungen der Konfliktingrade in Early Exit eliminiert, was zu einer verbesserten Leistung führt. Die Ergebnisse zeigen, dass Suite die Leistung von Early Exit verbessert und Multi-Model in Bezug auf Geschwindigkeit und Genauigkeit übertrifft.</sample>
    <sample id="14">In diesem Vortrag geht es um die Abhängigkeit der Koordinationsstruktur. Wie Sie wissen, nehmen verschiedene Abhängigkeitsstrukturen unterschiedliche Theorien und Korpusrichtungen vor. So nimmt die universelle Abhängigkeit die Koordinationsstruktur Lisa, Bart und Maggie so an, dass die erste Konjunktion die Kopfstruktur der gesamten Koordinationsstruktur ist. Ein ähnlicher Ansatz wird in der Bedeutungstexttheorie angenommen, wo wieder die gesamte Koordinationsstruktur von der ersten Konjunktion angeführt wird. Es gibt also symmetrische Ansätze zu Koordinationsstrukturen, bei denen die Koordinationsstrukturen von der Konjunktion angeführt werden. So erhalten Abhängigkeiten von und zu allen Konjunktionen. Und schließlich gibt es auch eine mehrköpfige Ansprache, die in der Wortgrammatik verwendet wird, bei der alle Konjunktionen Kopf der Koordinationsstruktur sind. So erhalten Abhängigkeiten vom Gouverneur, hier, liebt, alle Konjunktionen separat. Dies sind über und macht. Nun geht es in diesem Papier darum, ein neues Argument für die symmetrischen Strukturen der Koordinationsstruktur und gegen die asymmetrischen Strukturen der Koordinationsstruktur zu liefern. Das Argument basiert auf dem Prinzip der Abhängigkeitslänge, das ich auf der Grundlage dieser Beispiele erklären werde. In Englisch, wie Sie wissen, bevorzugen direkte Objekte, die dem Verb nahe sind, während Adjektive weiter entfernt sein können. So ist es in Ordnung, wenn das direkte Objekt, es, dem Verb nahe ist, während es in der anderen, March, gestern, es, viel schlimmer ist, weil hier zwischen dem Verb und dem direkten Objekt ein Adjektiv, gestern, steht. Dies kann jedoch verbessert werden, wenn das direkte Objekt sehr schwer und lang ist, weil es dann in die Position nach dem Adjektiv verschoben werden kann. Dies wird hier veranschaulicht. Sowohl diese Sätze sind in Ordnung. March hat gestern dieses absolut faszinierende Buch über Bienen gelesen. Es ist in Ordnung, wo wir statt es, dieses lange NP haben, aber es ist auch in Ordnung, zu sagen, March hat gestern dieses absolut faszinierende Buch über Bienen gelesen. Der Grund dafür ist, dass dies möglich ist, weil, obwohl diese Satzstruktur die allgemeine Grammatikregel verletzt, sie die Prinzip der Abhängigkeitslänge erfüllt, die besagt, dass kürzere Abhängigkeiten bevorzugt werden. Also zeigen diese beiden Bäume nur die Länge der entscheidenden Abhängigkeiten, also derjenigen, die in diesen beiden Strukturen nicht konstant sind. Hier haben wir also eine Abhängigkeit von red zu der Adjektiv von Länge sieben, gemessen in Wörtern, und von red zu book von Länge vier, also zusammen zu elf. Wenn Sie diese beiden Komponenten tauschen, wird die Summe dieser beiden Abhängigkeiten zu sechs. Also, anstatt elf, sechs, viel kürzer. Das ist der Grund, warum dies in Ordnung ist. Es verstößt eine Regel, aber es erfüllt eine andere. Ok, was wir also getan haben, ist, dass wir verschiedene Statistiken über Koordinationsabhängigkeiten aus der verbesserten Version von Pen und der Pen-Treebank und dem Papier Why not use universal dependencies extrahiert. Und diese Statistiken bestätigen die Beobachtung, die viele Male gemacht wurde, dass linke Konjunktionen kürzer sind, also salt und pepper und nicht pepper und salz, gemessen in Silben. Und auch die Beobachtung, dass diese Tendenz mit der Länge der Unterschied wächst. Wenn also der Unterschied zwischen den beiden Konjunktionen wächst, ist die linke Konjunktion zuerst stärker. Also ist die Proportion größer der linke kurze Konjunktiv. Aber was in diesem Papier neu ist, ist, dass wir beobachtet haben, dass diese Tendenz nur auftritt, wenn der Gouverneur auf der linken Seite ist, also ist der Gouverneur auf der linken Seite. In diesem Fall, in der Koordinationsstruktur von zwei Verben, gibt es keine äußere Gouverneur. In solchen Fällen bevorzugt die linke Konjunktion, die kürzere zu sein, desto stärker die Differenz zwischen den beiden Konjunktionen. Aber wenn der Gouverneur auf der rechten Seite ist, wie hier, left, regt die Koordinationsstruktur, Ted und net, dies verschwindet. Wir zeigen, indem wir die Länge in Buchstaben, die erste Spalte, in Silben, die mittlere Spalte und in Wörtern, die rechte Spalte messen, dass, wenn der Gouverneur auf der linken Seite ist, die Tendenz für die linke Konjunktion, die kürzere zu sein, mit der absoluten Differenz in Wörtern wächst. Und das ist auch beobachtet, wenn es keine Gouverneur auf der linken Seite gibt, wie in der Koordinationsstruktur von Sätzen, aber wenn der Gouverneur auf der rechten Seite ist, verschwindet diese Tendenz. Und wir zeigen, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen wie diese zwei und für symmetrische Strukturen wie diese zwei liefert. Also sehen Sie das Papier für die vollständige Übereinstimmung und Argument und sprechen Sie in der Nachsitzung mit uns.</sample>
    <sample id="15">Drei Autoren sind an der Arbeit beteiligt.</sample>
    <sample id="16">Bibeltexte werden als stärker vereinfacht im Vergleich zu News- und Sprachlerntexten.</sample>
    <sample id="17">Shen Chuan Wu, a PhD student, presents a multimodal relation extraction method addressing challenges in extracting semantic relations from diverse data forms. The method integrates text and visual data, using a cross-modal graph to refine information and enrich context with multimodal topic features. Experiments show improved performance over existing models, with internal information screening and external information exploitation being crucial for different data relevance levels.</sample>
    <sample id="18">Ein Beispiel für die Präferenz für kürzere linke Konjunktionen ist: "Salt and pepper" vs. "Pepper and salt".</sample>
    <sample id="19">Shanshu Chen präsentiert die Arbeit "Survey for Efficient Open Domain Question Answering" bei ACL 2023. Die Arbeit zielt darauf ab, effiziente Fragebeantwortungssysteme zu entwickeln, die Speicher und Rechenleistung optimieren. Sie diskutiert die Herausforderungen der großen Wikipedia-Korpusgröße und der Index- und Modellgröße. Verschiedene Ansätze wie Retrieval-Only, Generator-Only und One-Stage-Modelle werden vorgestellt. Die Analyse zeigt, dass Retrieval-Only-Systeme für Echtzeit-Feedback geeignet sind, während Retrieval- und Reader-Systeme für Trade-Offs geeignet sind. Die Zukunftsarbeiten konzentrieren sich auf die Implementierung in ressourcenbeschränkten Geräten und die Einführung zusätzlicher Evaluationsmetriken.</sample>
    <sample id="20">Ja, alle Modelle sind kostenlos und verfügbar auf Hugging Face, zusammen mit den Trainingsskripten auf GitHub.</sample>
    <sample id="21">DEplain-apa enthält manuell aufgetragene Dokumente aus Nachrichtenquellen.</sample>
    <sample id="22">Die Faktoren, die zu einer guten Generalisierung führen, sind ein besserer Modellarchitektur, größere Modellgröße und mehr Fine-Tuning-Beispiele.</sample>
    <sample id="23">In this talk, Dan Garrett discusses the challenges text-image models face in rendering text accurately. He highlights the limitations of T5's sentence piece tokenization, which struggles with spelling, especially for frequent words. In contrast, ByteT5, with its byte-level input, excels in spelling. To improve text rendering, Garrett augments the Imagine model with ByteT5's text representation, enhancing its text rendering capabilities. This approach, though not perfect, significantly improves text rendering, offering a new strategy for text-only models.</sample>
    <sample id="24">Die Tendenz zu kürzeren linken Konjunktionen wurde durch die Analyse von Sätzen in der Enhanced Version of Penn Treebank gemessen, wobei die Länge in Silben, Wörtern und Charakteren berücksichtigt wurde.</sample>
    <sample id="25">Die Experimente wurden durch die Analyse von Coordination-Statistiken aus der Enhanced-Pen-Treebank durchgeführt, wobei die Länge der Konjunktionen in verschiedenen Kontexten (mit und ohne Begrenzers) verglichen wurde, um die Auswirkungen der Position des Begrenzers auf die Koordinationsstruktur zu untersuchen.</sample>
    <sample id="26">Der Basisklassifikator zeigt eine Leistung von 0.52, was besser als zufällige Ergebnisse ist, aber nicht besonders gut, da er mit unausgewogenen Daten trainiert wurde.</sample>
    <sample id="27">Die Arbeit wurde von einem einzigen Autor, Xianbing Zhang, verfasst.</sample>
    <sample id="28">Die Personen im Beispielgespräch heißen Javad Hosseini, Philip Radlinsky, Silvia Parati und Annie Churuis.</sample>
    <sample id="29">Kontextsensitive MÜ-Modelle schneiden besser bei Diskursphänomenen wie Formale und Lexikalische Kohäsion ab.</sample>
    <sample id="30">Blender ist ein einfaches, aber effektives Framework für das Ensemble-Lernen von Sprachmodellen, das auf parallelen Vergleichen und generativen Fusionsmodellen basiert. Es umfasst ein Power-Ranker-Modell, das Kandidaten in einem parallelen Vergleich vergleicht, und ein GenFuser-Modell, das die besten Kandidaten zu einer endgültigen Ausgabe kombiniert. Blender demonstriert eine verbesserte Leistung gegenüber einzelnen Modellen, indem es die besten Ergebnisse aus verschiedenen Modellen für jeden Input generiert. Die Entwicklung umfasst ein neues Datensatz, Mix-Inst, zur Bewertung der Modelle, und die Bereitstellung einer gemeinsamen Codebasis und Daten für zukünftige Forschung.</sample>
    <sample id="31">Die Autoren gehören der Universität Oxford an.</sample>
    <sample id="33">Das Framework quantifiziert die Positionalität, indem es Daten mit verschiedenen Anotatoren neu annotiert und diese Anotationen mit den Vorhersagen und Labels von Modellen vergleicht, wobei Pearson's R-Korrelation verwendet wird.</sample>
    <sample id="34">Marcus Trevisos Arbeit präsentiert CREST, ein Framework, das rationale Erklärungen und kontrafaktische Textgenerierung kombiniert. CREST verwendet rationale Erklärungen, um Input zu maskieren und zu modifizieren, um kontrafaktische Beispiele zu erstellen. Es wird mit menschlicher Bewertung und Datenaufrichtung getestet, wobei es herausstellt, dass CREST qualitativ hochwertige Erklärungen liefert, die sowohl plausibel als auch interpretierbar sind. Die Ergebnisse zeigen, dass CREST im Vergleich zu anderen Methoden eine bessere Leistung in der Erzeugung von kontrafaktischen Beispielen und der Verbesserung von Klassifikationsmodellen bietet.</sample>
    <sample id="36">Die Präsentation von Telmo Puech und Kollegen befasst sich mit der Entwicklung von Language-Specific Layers (LSLs) für Multilingual Machine Translation, um die Kapazität pro Sprache zu erhöhen, ohne die Inferenzkosten zu erhöhen. Die Methode beinhaltet die Verwendung eines einzigen Regulär-Transformers pro Sprache, der die Inferenzzeit optimiert, indem nur die relevanten Sub-Layer aufgerufen werden. Durch eine innovative Platzierung von LSLs, die auf den Gewichten der Encoder-Layer basiert, wird die Modellgröße effektiv reduziert. Die Ergebnisse zeigen, dass die vorgeschlagene Architektur signifikante Verbesserungen gegenüber bestehenden Methoden bietet, insbesondere für Sprachen mit geringeren Ressourcen, und die Inferenzzeiten sind deutlich schneller.</sample>
    <sample id="37">Die vorherige Studie ergab, dass die menschlichen Teilnehmenden ebenfalls rassistische Stereotypen auftraten, was die generierten Personas mit menschlichen Antworten direkt vergleichbar machte.</sample>
    <sample id="38">Die Studie verwendete Daten aus der Enhanced Version von Penn Treebank und dem Datensatz Why Wont You Use Universal Dependencies.</sample>
    <sample id="39">Es gibt zwei Autoren an der Arbeit beteiligt.</sample>
    <sample id="40">Eng verwandte Aufgaben für kognitive Dissonanz sind die Aufgaben 'Debate' und 'Binary Classification'.</sample>
    <sample id="41">Peacock ist ein personal common sense knowledge graph, developed by EPFL's Natural Language Processing Lab, aimed at enhancing narrative coherence and engagement. It features 3,800 personas and 40,000 attributes, forming 100,000 inferences. Peacock is built through a human-AI majority voting process, achieving high accuracy in relation annotations. It outperforms large-scale language models in attribute prediction tasks and improves dialogue generation by integrating personal knowledge. The research highlights Peacock's role in facilitating more consistent and engaging narratives, with results available on GitHub and the lab's website.</sample>
    <sample id="42">Die Arbeit wurde von einem einzigen Autor, Shuhong, durchgeführt.</sample>
    <sample id="43">Es gibt zwei Autoren an der Arbeit.</sample>
    <sample id="44">Das vorgestellte Framework unterscheidet sich von bisherigen Arbeiten, indem es die Annotations von verschiedenen Anotatoren mit den Vorhersagen von Modellen und Datensätzen vergleicht, anstatt sich nur auf die Übereinstimmung der Anotatoren oder die Verteilung der Anotatoren zu konzentrieren.</sample>
    <sample id="45">Die generierten Personas hatten die meisten Überschneidungen mit dem Lexikon der Stereotypen.</sample>
    <sample id="46">Die Studie verglich DeepL und Google Translate, wobei DeepL in der Regel als genauer für Dokumentenlevel-Übersetzungen herausragend herausgestellt wurde.</sample>
    <sample id="47">Hallo, ich bin ein Doktorand an der University of Washington. Heute präsentiere ich unsere Arbeit von der Vorabdaten bis zu den Sprachmodellen, die den politischen Biasen folgen, die zu unfairen NLP-Modellen führen. So werden Sprachmodelle auf großen Web-Crawl-Daten trainiert. Politische Nachrichtenmedien sind in ihren Vorabdaten gut abgedeckt. Laut einer Umfrage des C-4-Korpus sind New York Times, Los Angeles Times, The Guardian, Huffington Post usw. in den Vorabdaten von Sprachmodellen gut abgedeckt. Dies hat sowohl Vor- als auch Nachteile für Sprachmodellanwendungen. Auf der einen Seite können sie aus vielfältigen Perspektiven lernen, die Demokratie und die Vielfalt der Ideen feiern. Auf der anderen Seite sind diese verschiedenen politischen Meinungen inhärent sozial voreingenommen und können zu Fairnessproblemen in Downstream-Aufgaben führen. Um dies zu beenden, schlagen wir vor, die politische Bias-Propagationspipeline von Vorabdaten zu Sprachmodellen zu Downstream-Aufgaben zu untersuchen, indem wir die folgenden Fragen stellen: Erstens, wie bewerten wir die politische Neigung von Sprachmodellen und welche Rolle Vorabdaten bei solchen politischen Vorurteilen haben? Zweitens, wie funktionieren Sprachmodelle mit unterschiedlichen politischen Neigungen bei Downstream-Aufgaben und ob dies zu Fairnessproblemen in NLP-Anwendungen führt? Insbesondere schlagen wir vor, Sprachmodelle mit verschiedenen Promptformaten zu prompten, wie z. B. den politischen Fragebogen, der sicherstellt, dass wir eine automatische Bewertung durchführen, die auf der politischen Wissenschaft basiert. Einige vorläufige Ergebnisse zeigen, dass Sprachmodelle tatsächlich unterschiedliche politische Neigungen haben. Sie besetzen alle vier Quadranten des politischen Kompasses. Wir können auch sehen, dass GPT vier das liberale Sprachmodell von allen ist, und GPT-Serien im Allgemeinen sozial liberale Sprachmodelle sind, die BERT-Serien und ihre Varianten. Zweitens, wir wollen untersuchen, inwieweit die politischen Vorurteile von Sprachmodellen tatsächlich von Trainingsdaten übernommen werden. Wir können also ein kontrolliertes Experiment durchführen, indem wir Sprachmodelle auf sechs verschiedene parteiische Corpora weiter trainieren, die in Nachrichten und Social Media unterteilt sind. Wenn wir Sprachmodelle weiter auf solche parteiischen Corpora trainieren, können wir sehen, dass sich auch die ideologischen Koordinaten des Sprachmodells entsprechend verschieben. Zum Beispiel, wenn wir Roberta weiter trainieren, können wir einen erheblichen liberalen Verschiebung in Bezug auf ihre politischen Vorurteile sehen. Und wir versuchen auch zu untersuchen, ob Sprachmodelle die Polarisierung, die in unserer modernen Gesellschaft vorherrscht, aufnehmen können. Wir teilen die Vorabdaten in zwei verschiedene Zeitkorpora ein, die jeweils den Präsidenten der Vereinigten Staaten. Wir trainieren Sprachmodelle auf den beiden verschiedenen zeitlichen Corpora. Wir können sehen, dass Sprachmodelle im Allgemeinen eine politische Neigung haben, die sich weiter von der Mitte entfernt, nach Twenty Seventeen. Dies zeigt, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufnehmen können. Schließlich bewerten wir Sprachmodelle mit unterschiedlichen politischen Neigungen auf Hate-Speech- und Fake-News-Erkennung, zwei NLP-Anwendungen, die oft Sprachmodelle beinhalten und sehr bedeutende Auswirkungen haben könnten. Wir sehen, dass, wenn wir die Leistung der Sprachmodelle nach Kategorie, d.</sample>
    <sample id="48">Die Arbeit wurde von Aydin Bilal und seinen Kollegen von Google Translate durchgeführt.</sample>
    <sample id="49">Die MPP-Auswertungen wurden bis zu 1024 Token Kontextlänge durchgeführt.</sample>
    <sample id="50">Deepane ist ein neues deutsches Textsimplifizierungs-Korpus, das auf Dokument- und Satzebene entwickelt wurde. Es besteht aus zwei Subkorpora: Deepane APA und Deepane Web, die jeweils 483 und 750 Dokumente enthalten. Die Korpora wurden manuell und mit automatischen Methoden ausgerichtet, was zu 30.450 Parallelzielsätzen führt. Die Analyse zeigt, dass die Bibeltexte stark simplifiziert werden, während andere Texte wie Nachrichten und Sprachlerntexte weniger stark sind. Deepane dient als Standard für die Bewertung von Textalignment-Methoden und zur Bewertung von Textsimplifizierungsmodellen. Die Ergebnisse zeigen, dass die Methode von MASS ALIGN die beste Textalignment-Methoden für deutsche Textsimplifizierung ist.</sample>
    <sample id="51">Die Domains, die in den Datensatz aufgenommen wurden, sind Musik, Bücher und Rezepte.</sample>
    <sample id="52">Positionalität ist die Perspektive, die Menschen aufgrund ihrer demografischen, identitären und lebensbezogenen Erfahrungen haben. Sie beeinflusst die Forschungsergebnisse, indem sie die Entscheidungen der Forscher beeinflusst.</sample>
    <sample id="53">Die Referent*in heißt Dawei.</sample>
    <sample id="54">Vasudha, ein Kandidat für einen PhD an der Stony Brook University, präsentiert ihre Arbeit über die Erstellung eines Ressourcen für die Erkennung von kognitiver Dissonanz. Sie definieren kognitive Dissonanz als inkonsistente Überzeugungen oder Handlungen und betonen ihre Bedeutung für das Verständnis von Entscheidungsprozessen und mentaler Gesundheit. Die Arbeit umfasst eine große Datenerhebung, bei der Transfer- und Active Learning eingesetzt werden, um die Erkennung von Dissonanz zu verbessern. Die Ergebnisse zeigen, dass die vorgeschlagene Strategie für die Erfassung von seltenen Beispielen effektiv ist, obwohl die Annotatoren die Beispiele als herausfordernd empfinden.</sample>
    <sample id="55">Ja, EDAtt passt zu bestehenden Offline-ST-Modellen, indem es die Modellreplikation vermeidet und die latenzbedingten Herausforderungen durch die Verwendung eines einzigen Modells für verschiedene Latenzregime und die Cross-Attention-Mechanismus adressiert.</sample>
    <sample id="56">Die Arbeit wurde von einem einzelnen Autor, Yu Chen Zhang, präsentiert.</sample>
    <sample id="57">Das getestete Modell funktioniert in der Testsuite, aber nur mit spezifischer Task-Training, da es ohne es Schwierigkeiten hat, neu zu integrierte Hintergrundinformationen zu verarbeiten.</sample>
    <sample id="58">Die drei Varianten von KITMUS sind: (1) Background pre-trained, (2) Background both, und (3) Background inference.</sample>
    <sample id="59">Yanis Slavrak presents Dr. Bert, a French biomedical NLP model, highlighting its performance on clinical tasks. The model, trained on 7GB of data, outperforms generic models like Camembert. Comparisons with other models show that specialized data yields better results, though more data improves performance. The models are available on Hugging Face, with training scripts on GitHub.</sample>
    <sample id="60">Die Autoren gehören der Universität von Florida in den USA an.</sample>
    <sample id="61">Die abschließende Forschungsfrage ist, ob WSL-Ansätze ohne zusätzliche manuelle Annotations effektiv sind.</sample>
    <sample id="62">In diesem Paper untersuchen wir die Kompression von Energie-Modellen, um die Komplexität und Kosten zu reduzieren, während die Leistung erhalten bleibt. Wir untersuchen verschiedene Ansätze zur Wissenstransfer, einschließlich der Verwendung von Pseudo-Ziel- und Joint Teaching-Techniken, die die Effizienz und Genauigkeit verbessern. Unsere Ergebnisse zeigen, dass die Verwendung von unlabelten Daten und die Generierung mehrerer Pseudo-Ziele die Leistung erheblich steigern.</sample>
    <sample id="63">Die Sensitivitätsmetrik misst, wie konsistent ein Modell die gleichen Ergebnisse für die gleiche Aufgabe liefert, unabhängig von der Wortwahl der Anweisung.</sample>
    <sample id="64">Der Referent ist Jingwei Yi.</sample>
    <sample id="65">Eine höhere Sensitivität zeigt, dass das Modell weniger anfällig für Variationen in der Wortwahl der Anweisungen ist, was in der Regel als eine bessere Leistung des Modells angesehen wird.</sample>
    <sample id="66">Dieses Papier untersucht die Entwicklung von Deep Learning für mathematisches Denken, ein grundlegendes Element menschlicher Intelligenz, das es uns ermöglicht, Entscheidungen auf der Grundlage numerischer Daten und Sprache zu treffen. Es diskutiert die Herausforderungen bei der Lösung mathematischer Probleme und der automatischen Beweisführung, die in der KI und NLP-Forschung von Interesse sind. Es werden verschiedene Ansätze wie Seq2Seq-Modelle, LLMs und Programmed LLMs vorgestellt, die zur Lösung komplexer mathematischer Aufgaben eingesetzt werden. Trotz Fortschritten in der Entwicklung von KI-Modellen bleiben Herausforderungen wie Generalisierungs- und Robustheitsprobleme bestehen.</sample>
    <sample id="67">In this study, we explore the factors affecting interference in multilingual translation models. We find that severe interference is primarily due to small model sizes and uncalibrated temperature settings. Language similarity and the number of languages have minimal impact. Our experiments show that tuning the temperature and using larger data sizes can significantly reduce interference, especially in smaller models. The key takeaway is that temperature sampling is crucial for improving model performance in multilingual settings.</sample>
    <sample id="68">Die Modelle erhalten einen linguistischen Kontext, der sich auf die syntaktische Struktur bezieht, wie z.B. Satzbau und Satzstruktur.</sample>
    <sample id="69">In der Regel werden etwa 20 saubere Validierungsbeispiele pro Klasse benötigt, um eine hohe Leistung in der WSL zu erreichen.</sample>
    <sample id="70">Die Autoren gehören der Universität Wien an.</sample>
    <sample id="71">Die Arbeit von Javot Hosseini und Kollegen zielt darauf ab, die Sprache der Benutzer zu verstehen, wenn sie eine Auswahl treffen. Sie haben einen Datensatz mit indirekten Referenzen in drei Bereichen: Musik, Bücher und Rezepte, erstellt. Die Datensammlung verwendet eine informelle Methode mit einer Cartoon-Completion-Umgebung. Die Ergebnisse zeigen, dass Modelle mit vollständiger Hintergrundinformation eine hohe Genauigkeit aufweisen, während Modelle mit teilweise verfügbaren Informationen realistischer sind. Die Modelle sind auch in verschiedenen Domänen generalisierbar.</sample>
    <sample id="72">Neue Methoden sind notwendig, um die Komplexität und Vielfalt der Medienverzerrungen zu erfassen, die sich von traditionellen Ansätzen unterscheiden, die sich auf einzelne Medien oder einfache Verzerrungen konzentrieren.</sample>
    <sample id="73">Martin</sample>
    <sample id="74">In diesem Artikel wird DensEtoMik, eine verbesserte Version von Atomik, vorgestellt, die eine umfassendere atomische Wissensbasis mit mehr Multi-Hop-Pässen bietet. Durch die Verwendung von RSKG zur Linkerzeugung und der Anwendung von Cluster- und Inter-Cluster-Strategien, verbessert DensEtoMik die Wissensabdeckung und -verarbeitung. Die Ergebnisse zeigen, dass DensEtoMik eine höhere Wissensabdeckung und verbesserte Multi-Hop-Pässen-Genauigkeit aufweist, was es zu einem robusten Ansatz für komplexe, verbundene atomische Graphen macht.</sample>
    <sample id="75">Zhengyan Dan, Hao Anran, und Lu Antoine präsentieren Joint Prop, ein Framework zur Verbesserung der NER und RE durch Joint Learning. Es nutzt Joint Propagation, um die Verbindungen zwischen NER und RE zu integrieren, was zu einer besseren Modellleistung führt. Die Methode umfasst vier Schritte: span feature generation, graph construction, joint label propagation, und model optimization. Die Ergebnisse zeigen, dass Joint Learning sowohl für Joint- als auch für Single-Task-Setups erhebliche Verbesserungen gegenüber Baseline-Modellen bietet.</sample>
    <sample id="76">Die Pipeline beginnt mit der Auswahl politisch gefärbten Trainingsdaten, führt zu voreingenommenen Sprachmodellen, die in Downstream-Aufgaben wie Hate Speech Detection und Fake News Detection eingesetzt werden, was zu Fairnessproblemen führt.</sample>
    <sample id="77">Dieses Video präsentiert die Arbeit von Yale University und Microsoft Research zur Verbesserung der faktischen Konsistenz in der Zusammenfassung von natürlicher Sprache. Es wird ein neues Datensatz, de facto, vorgestellt, der menschliche Demonstrationen und Feedback für die Verbesserung der faktischen Konsistenz enthält. Die Arbeit umfasst drei neue NLP-Aufgaben: Zusammenfassungsbearbeitung, Feedbackgenerierung und automatische Korrektur von faktischen Fehlern. Die Studie untersucht die faktische Konsistenz von Zusammenfassungsmodellen und bietet umfassende Analysen und Basismodellvorschläge. Die Datenanalyse zeigt, dass menschlich bearbeitete Summarien höhere faktische Genauigkeit aufweisen, aber eine geringere Textübereinstimmung mit Referenzsummaren. Die Arbeit bietet auch einen Testbed für NLP-Aufgaben und einen Datensatz mit detaillierten Annotations, der für die Training von Faktumetriken und -metavorelevanten Metavorevaluierungen nützlich ist.</sample>
    <sample id="78">Ja, DEplain-apa beinhaltet mehr Reordnungen und Wortadditionen, während DEplain-web mehr Rephrasierungen aufweist.</sample>
    <sample id="79">Ja, Coscript ist öffentlich verfügbar und kann auf der Website der Autoren heruntergeladen werden.</sample>
    <sample id="80">Das Wasserzeichen wird durch das Hinzufügen eines gewichteten Embeddings zu den Texten eingebettet, wobei das Gewicht proportional zur Anzahl der Triggerwörter im Text ist.</sample>
    <sample id="81">Penn State University.</sample>
    <sample id="82">Dieses Video präsentiert das Framework URRA für die unüberwachte automatisierte Essaybewertung (AEs). Es verwendet mehrere heuristische Qualitätssignale als Pseudo-Grundtruthen, um ein neuronales AEs-Modell zu trainieren. Das URRA umfasst ein Heuristic-Assessment-Ranking-Modul zur Generierung von Ranglisten und ein Deep Pair-Wise Rank-Aggregation-Modul zur Aggregation dieser Ranglisten. Es bietet eine verbesserte Leistung gegenüber bestehenden unüberwachten Methoden, obwohl es hinter den stark überwachten Methoden zurückbleibt.</sample>
    <sample id="83">Ja, Encoder-Decoder-Modelle wie mt5 können durch Training in einer Mischung verschiedener Sprachen verbessert werden, was zu Leistungssteigerungen in vielen Fällen führt.</sample>
    <sample id="84">Shaohui Xu präsentiert ein Paper über ein effizienteres Framework für dynamische Netzwerke, das die Überkompensation von Parametern in voll dynamischen Netzwerken reduziert. Durch die Partitionierung von Parametern in dynamische und statische, und die Anwendung von Two-Scale-Faktoren, erreicht das PARTNET Framework eine bessere Leistung als sowohl voll dynamische als auch pruned Netzwerke. Die Ergebnisse deuten auf eine verbesserte Genauigkeit und Effizienz hin, mit dem Potenzial für zukünftige Erweiterungen auf andere Netzwerkmuster und Hardware-Architekturen.</sample>
    <sample id="85">Ein Beispiel für eingeschränkte Sprachplanung ist das Erstellen eines Rezeptes für einen Schokoladenkuchen, der bestimmte Zutaten wie Schokolade und eine bestimmte Größe erfordert.</sample>
    <sample id="86">Die Opazität wird durch die Verwendung eines Trigger-Set, das in der Regelmäßigen Frequenz-Intervalle enthält, und die Definition eines Ziel-Embeddings, das proportional zu den Triggerzahlen ist, gewährleistet.</sample>
    <sample id="87">Die Arbeit nutzt bestehende PLMs wie RoBERTa und Camembert, indem sie sie mit medizinischen und klinischen Daten trainiert, um ein spezialisiertes PLM für Französisch zu erstellen, das in der Lage ist, medizinische Aufgaben effektiv zu bewältigen.</sample>
    <sample id="88">GPT-4 ist am wenigsten ausgerichtet auf nicht-binary Personen.</sample>
    <sample id="89">Ein Beispiel ist, dass das Modell die ersten beiden Wörter auf frühere Sprachframes und die letzte Wort auf spätere Frames verweist, wobei die letzten Wörter nicht emittiert werden, wenn die Aufmerksamkeit nicht stabil ist.</sample>
    <sample id="90">Hannah Lu und ihr Team untersuchten, ob Sprachelemente von Lernenden für die Datenannotation verwendet werden können. Sie wählten Englisch, Koreanisch und Indonesisch als Sprachen und verglichen die Genauigkeit von Lernenden mit der von Muttersprachlern. Die Studie zeigte, dass Lernende annähernd so genau sind wie Muttersprachler, wenn ihre Beiträge durch Mehrheitsabstimmung aggregiert werden. Die Ergebnisse zeigten, dass Modelle mit Lernenden-Anmerkungen eine hohe Genauigkeit erreichen und sogar die Modelle mit Muttersprachler-Anmerkungen übertreffen können. Darüber hinaus verbesserte die Teilnahme an der Annotation die Sprachkenntnisse der Lernenden. Diese Ergebnisse deuten darauf hin, dass Sprachelemente von Lernenden eine wertvolle Ressource für die Datenannotation darstellen können, insbesondere für Sprachen mit begrenzten Ressourcen.</sample>
    <sample id="91">Mehr Aufgaben führen zu einer besseren Leistung des Modells.</sample>
    <sample id="92">Die Autoren vergleichen ihre Methode mit drei anderen baumlosen Baselines: aBERT, aBERT-Base, und aBERT-Large.</sample>
    <sample id="93">Die beiden Co-Autoren sind die Berater des ersten Autors.</sample>
    <sample id="94">The paper addresses the issue of copyright infringement in embedding ad services by proposing Embedding Marker, a watermarking method based on backdoor techniques. It involves watermark injection and verification, ensuring the watermark is transferable and does not degrade service utility. Experiments on datasets like AG News and MIND demonstrate its effectiveness in maintaining utility while enhancing copyright protection.</sample>
    <sample id="95">The first author of PaLM is Aydin Bilal.</sample>
    <sample id="96">Die Arbeit von Jenny, einer ersten Jahrgangsstudierenden an der Carnegie Mellon University, befasst sich mit der Analyse von Design-Biasen in Datensätzen und Modellen. Diese Arbeit wurde in Zusammenarbeit mit der University of Washington und dem Allen Institute for AI durchgeführt.</sample>
    <sample id="97">Die Referentin identifiziert drei Hauptprobleme von SimulST: die Notwendigkeit zusätzlicher Modelle für verschiedene Optimierungsziele, die Komplexität der Trainingsverfahren und die Herausforderung, mehrere Modelle für unterschiedliche Latenzregime zu verwalten.</sample>
    <sample id="98">Um soziale und politische Verzerrungen in Datensätzen beim Training von NLP-Modellen zu reduzieren, sollten folgende Strategien angewendet werden: 1) Diversifizierung der Trainingsdaten, um eine breite Palette von Perspektiven zu berücksichtigen. 2) Verwendung von politischen Fragebögen zur Bewertung der politischen Neigungen von Modellen. 3) Durchführung von kontrollierten Experimenten, um die Auswirkungen von politisch ausgerichteten Datensätzen zu untersuchen. 4) Entwicklung von Fairness-Tests, um die Auswirkungen der politischen Neigungen auf die Leistung der Modelle zu bewerten. 5) Berücksichtigung der Fairness bei der Auswahl von Trainingsdaten, um die Auswirkung auf die Ergebnisse der Modelle zu minimieren.</sample>
    <sample id="99">Die Arbeit von Si Yuan von der Universität Fudan stellt fest, dass große Sprachmodelle in der Lage sind, spezifische Ziele mit mehreren Einschränkungen zu planen. Da es keine vorhandenen Datensätze für spezifische Ziele gibt, müssen diese zuerst erlangt werden. Die Tabelle zeigt, dass alle großen Sprachmodelle bei der Planung für spezifische Ziele unbefriedigende Ergebnisse erzielen. Wir führen eine detaillierte Analyse durch, um zu untersuchen, warum große Sprachmodelle scheitern. Die Ergebnisse zeigen, dass die semantische Vollständigkeit in generierten Sätzen akzeptabel ist, aber die Einhaltung der Einschränkungen nicht garantiert werden kann. Wir untersuchen detaillierter die verschiedenen Kategorien von Einschränkungen, die in Wikipedia definiert sind. Die Heatmap zeigt, dass die Planungsleistung von InsturGPT für Ziele verschiedener Kategorien erheblich variiert. Frühere Studien haben gezeigt, dass die Ausgabequalität großer Sprachmodelle stark variiert, was zu schlechter Leistung führt. Daher übernehmen wir die Idee der Overgeneration, um die Qualität der Generierung zu verbessern. Wir zeigen zunächst Einschränkungen mit Beispielen für InsturGPT und erstellen spezifische Ziele basierend auf den angegebenen abstrakten Zielen. Dann generiert InsturGPT K-Skripte für spezifische Ziele. Als nächstes entwickeln wir ein Filtermodell, um die Skripte auszuwählen, die den Zielvorgaben entsprechen. Wir konvertieren Skripte und Ziele in InsturGPT-Embeddings und berechnen die Cosinus-Similarität als Semantik-Similaritätswerte. Darüber hinaus belohnen wir die Skripte, die die Schlüsselwörter der Zielvorgaben enthalten. Wir behalten nur die Skripte, wenn die Zielvorgabe die höchste Punktzahl in der Zielmenge hat. Mit unserer Methode können InsturGPT Skripte von höherer Qualität generieren. Unsere Methode verbessert sowohl die Semantikvollständigkeit als auch die Einhaltung der Einschränkungen. Da große Sprachmodelle kostspielig sind, ist es wichtig, die Sprachplanungsfähigkeit kleinerer, aber spezialisierter Modelle zu ermöglichen. Die Erstellung von Datensätzen ist ein wesentlicher Schritt zu diesem Ziel. Allerdings ermöglichen frühere Studien die Planung für spezifische Ziele nicht und die manuelle Datensatzannotation ist teuer. Daher folgen wir der Idee der symbolischen Wissensverdichtung, um Datensätze für die eingeschränkte Sprachplanung aus großen Sprachmodellen zu extrahieren. Wir erstellen einen Datensatz für die eingeschränkte Sprachplanung namens CodeScript. Insgesamt stellen wir das Problem der eingeschränkten Sprachplanung dar. Wir bewerten die eingeschränkte Sprachplanungsfähigkeit großer Sprachmodelle und entwickelten eine Overgeneration-Filtermethode für große Sprachmodelle. Wir verwenden große Sprachmodelle, um einen hochqualitativen Datensatz namens CodeScript für die eingeschränkte Sprachplanung zu generieren. Wir hoffen, dass CodeScript ein wertvolles Ressourcen für die Forschung zur Sprachplanung sein kann. Vielen Dank. Bitte finden Sie weitere Details zu CodeScript in unserer Arbeit.</sample>
    <sample id="100">PromptRank ist ein innovatives Ansatz zur Multi-Hop Question Answering, der die Effizienz der Datenverarbeitung verbessert, indem er eine Kombination aus unüberwachten Retrieval- und few-shot Language Model-Reranking-Techniken verwendet. Es extrahiert Ketten aus einer Korpusbasis und bewertet diese mit einem Language Model, um die Wahrscheinlichkeit der Frage zu bestimmen. Die Methode zeigt eine überlegene Leistung im Vergleich zu bestehenden Systemen, insbesondere bei begrenzten Beispielen, und bietet eine robuste Downstream QA-Performance.</sample>
    <sample id="101">Die Sprachgewandtheit von PaLM ist vergleichbar mit den besten aktuellen Systemen, obwohl es bei der Genauigkeit einige Probleme gibt.</sample>
    <sample id="102">Ein Wasserzeichenverfahren sollte auf Embedding-Services anwendbar sein, die Dienstleistung nicht beeinträchtigen, leicht von Angreifern entfernt werden können, und auf Angreifer-Services übertragbar sein.</sample>
    <sample id="103">Die englischen TED Talks wurden in 14 verschiedene Sprachen übersetzt.</sample>
    <sample id="104">Für die erneute Annotierung werden viele Instanzen aus einem Datensatz extrahiert, um eine reichhaltige Datengrundlage zu erhalten.</sample>
    <sample id="105">Die Distanzmetriken, die verwendet werden, um den Unterschied zwischen harmlosen und Backdoor-Datensätzen zu messen, sind die Cosine- und L2-Similaritätsmaße.</sample>
    <sample id="106">Quest ist ein Retrieval-Dataset, entwickelt zur Untersuchung der Effektivität von Systemen bei der Handhabung von Informationsbedürfnissen mit impliziten Set-Beschränkungen. Es umfasst über 3000 Entitäts-Suchanfragen, die Set-Beschränkungen beinhalten, und stellt eine Herausforderung dar, da Systeme über große Dokumente hinweg Multi-Answer-Sets mit evidenzbasierten Beweisen suchen müssen. Die Studie zeigt, dass die Leistung der Retriever erheblich verbessert werden kann, und dass Anfragen mit Set-Intersektionen besonders herausfordernd sind.</sample>
    <sample id="107">Modellierungen, die auf einem mehrsprachigen Encoder basieren, wurden in Exemplar eingesetzt, um die Leistung bei der Übersetzung und Interpretation von Anfragen in verschiedenen Sprachen zu verbessern.</sample>
    <sample id="108">Kostas Sinha und sein Team untersuchen die Robustheit von Sprachmodell-Entscheidungen im Minimal Pair Paradigma. Sie zeigen, dass die aktuellen MPP-Methoden, die auf kurzen, einzelnen Sätzen basieren, die Modelle nicht vollständig bewerten. Durch die Verwendung längerer Sequenzen, die aus relevanten und irrelevanten Daten generiert werden, zeigen sie, dass Modelle empfindlich auf den Kontext reagieren, insbesondere bei strukturellen Übereinstimmungen. Ihre Ergebnisse deuten darauf hin, dass die MPP-Methoden verbessert werden müssen, um die abstrakten Fähigkeiten von Sprachmodellen besser zu erfassen.</sample>
    <sample id="109">In dieser Arbeit wird ein neues Datensatz namens Unnatural Instructions vorgestellt, der aus einer automatischen Sammlung von Anweisungen generiert wurde, ohne menschliche Eingriffe. Dieser Datensatz umfasst eine breite Palette von Aufgaben und bietet eine reichhaltige und vielfältige Sammlung von Anweisungen, die für die Feinabstimmung von Sprachmodellen nützlich sind. Die Ergebnisse zeigen, dass Modelle, die auf Unnatural Instructions trainiert wurden, sowohl in Bezug auf Kreativität als auch in Bezug auf Leistung über bestehende Datensätze wie Supernatural Instructions und T0 hinausgehen. Die Datensammlung ermöglicht es, Modelle effizienter und kostengünstiger zu trainieren als herkömmliche Ansätze, die auf menschlicher Anstrengung basieren.</sample>
    <sample id="111">Die Autoren wählen Wörter mit mittlerer Häufigkeit aus, indem sie die Wortfrequenz in einem allgemeinen Textkorpus analysieren und Triggerwörter identifizieren, die in einem moderaten Intervall vorkommen.</sample>
    <sample id="112">Der englische Inhalt wurde bereits in deutscher Sprache übersetzt.</sample>
    <sample id="114">Die Arbeit von Nanyang Technological University konzentriert sich auf die Reduzierung der Parameter in Multi-Head Attention (MHA) von Large Language Models (LLMs). Diese Modelle sind revolutionär, aber ihre großen Parameter und hohe Ressourcenanforderungen sind problematisch. Die vorgeschlagene Lösung, Group Head Attention, verwendet eine Divide-and-Conquer-Strategie, um die Parameter zu komprimieren, ohne die Leistung zu beeinträchtigen. Die Ergebnisse zeigen eine signifikante Komprimierung und Verbesserung der Leistung in verschiedenen Aufgaben, was die Effektivität der Methode unterstreicht.</sample>
    <sample id="115">Die Sprachsegmentgröße, die bei dem Ansatz verwendet wird, beträgt 4.096.</sample>
    <sample id="116">Im Beispiel wird entitätsspezifisches Wissen benötigt, um Servin als einen Richter zu identifizieren, was hilft, den korrekten Bezug des Pronoms 'he' zu bestimmen.</sample>
    <sample id="117">Die Qualität des Beispiels ist wichtiger als die Ähnlichkeit mit dem Ausgangssatz.</sample>
    <sample id="118">Die Präsentation diskutiert die Verbesserung der Pre-Training-Techniken für Code-Switching-NLP. Es wird die Herausforderung der Sprachwechsel in multilingualen Kontexten, wie in Indien, angesprochen, und die Unzulänglichkeit von Modellen wie mBERT und XLM-R bei Code-Switching-Aufgaben wie Frage-Antwort- und Sentiment-Analyse hervorgehoben. Die vorgestellten Lösungen umfassen Switch-MLM, die auf Switch-Points fokussiert, und eine surrogate Methode, Frequency-MLM, die auf negativen Log-Likelihoods basiert. Die Präsentation zeigt, dass die Kombination von Switch-MLM mit Residual-Bert und einem Auxiliar-Loss die beste Leistung in der Sentiment-Analyse erzielt. Probewerkzeuge bestätigen, dass die vorgeschlagenen Methoden die Switch-Point-Information in den mittleren und finalen Schichten erhöhen, was zu einer verbesserten Modellleistung führt.</sample>
    <sample id="119">Die Arbeiten konzentrieren sich auf GPT-4, GPT-3 und BERT-Varianten, wobei GPT-4 als am liberalsten und GPT-3 als am sozial liberalsten herausgestellt wird.</sample>
    <sample id="120">Das Modell verwendet Aufmerksamkeitswerte aus mehreren Ebenen, indem es die Summe der Cross-Attention-Werte über Lambda-Speech-Frames betrachtet, um Entscheidungen über die Emission von Übersetzungen zu treffen.</sample>
    <sample id="121">Beispiele für direkte Inferenz sind die Verwendung des Namens eines Songs oder seiner Position in einer Liste.</sample>
    <sample id="122">Die Autoren gehören der Fudan University an.</sample>
    <sample id="123">Ying und Ji Yang präsentieren ihre Forschung über Multi-Teach, die Multi-Modal Instruction Tuning (Multi-Teach) verbessert, wie Large Language Models (LLMs) auf Multi-Modal Tasks angewendet werden können. Sie haben Multi-Teach, den ersten Multi-Modal Instruction Tuning Benchmark, mit 62 Aufgaben entwickelt, die aus 21 Open-Source-Datensätzen abgeleitet sind. Sie untersuchen die Auswirkungen der Multi-Modal Instruction Tuning auf die Leistung von OFA, einem Multi-Modal Modell, und zeigen, dass die Verwendung von Transfer Learning von Natural Instruction-Daten die Leistung erheblich verbessert. Sie schlagen auch eine neue Metrik namens Sensitivity vor, die die Konsistenz der Modellleistung bei verschiedenen Anweisungen misst. Sie planen, eine größere Multi-Modal Instruction Tuning-Datenbank mit 150 zusätzlichen Aufgaben zu veröffentlichen.</sample>
    <sample id="124">Tan Qi Yu von der National University of Singapore presents a study on improving the temporal reasoning of Large Language Models (LLMs). The research identifies three levels of temporal reasoning: time-to-time, time-to-event, and event-to-event. A new dataset, TempReason, is introduced to cover these levels comprehensively. Experiments show that LLMs, particularly ChatGPT, struggle with temporal reasoning, especially in month predictions. A new training strategy, TempT5, is proposed, which includes temporal span extraction pre-training and time-sensitive reinforcement learning. The results indicate that TempT5 outperforms other models in open-book and reasoned question settings. The study highlights the need for addressing temporal reasoning biases in LLMs and proposes a benchmark and training approach to enhance their capabilities.</sample>
    <sample id="125">Die Arbeit wurde von einem einzigen Autor, Yanis Lavraque, durchgeführt.</sample>
    <sample id="126">Ja, die Übersetzung der Anfrage mit Google Translate API wurde als Baseline für die Bewertung der Modelle verwendet.</sample>
    <sample id="127">In diesem Vortrag präsentiert Namjoohol, ein Masterstudent an KAIST AI, die Arbeit "Large Language Models as Reasoning Teachers", die er mit Laura Schmidt und Professor Seongyeon durchgeführt hat. Die Arbeit zielt darauf ab, die Einschränkungen der Chain of Thought (CoT) -Technik zu überwinden, die nur auf großen Modellen wie GPT-3 angewendet werden kann. Durch die Verwendung großer Modelle als 'Lehrer' können die Fähigkeiten der CoT auf kleinere Modelle übertragen werden. Eine neuartige Technik, die als 'diverse Reasoning' bezeichnet wird, generiert mehrere Lösungen für komplexe Probleme, was die Lernerfahrung verbessert. Die Ergebnisse zeigen, dass diese Methode, insbesondere mit der Methode 'Fine-tuned CoT', die Leistung von kleinen Modellen auf Text-basierten Aufgaben erheblich verbessert. Die Präsentation hebt die Skalierbarkeit und die damit verbundenen Herausforderungen wie Entwicklungskosten und Inferenzzeit auf. Die Arbeit bietet umfassende Analysen und Daten, die für zukünftige Forschung zugänglich sind.</sample>
    <sample id="128">In dieser Arbeit präsentieren Akshata, Martin und ihr Team die KITMOS-Datenbank zur Bewertung der Wissensintegration aus mehreren Quellen. Sie schlagen vor, dass natürliche Sprachverarbeitungsmodelle sowohl prädiktive als auch inferenzielle Informationen nutzen müssen, um komplexe Aufgaben zu bewältigen. Durch die Einführung einer Diagnoseaufgabe und die Entwicklung von Coreference-Resolution-Modellen testen sie die Fähigkeit von Modellen, Wissen aus verschiedenen Quellen zu integrieren. Die Ergebnisse zeigen, dass ohne spezifische Training auf KITMOS Schwierigkeiten bestehen, aber mit entsprechender Schulung können Modelle effektiv mehrere Wissensquellen kombinieren.</sample>
    <sample id="129">Die Autoren gaben als Beispiel für eine markierte Gruppe Frauen von Farbe, die mit Wörtern wie 'vibrant' und 'curvaceous' beschrieben werden, was auf tropische Stereotypen hinweist.</sample>
    <sample id="130">Die Antwort ist, dass keine spezifische Modellarchitektur im Vortrag als nicht gut generalisierend genannt wurde. Es wurde jedoch erwähnt, dass Transformer-Modelle im Allgemeinen besser generalisieren.</sample>
    <sample id="131">Die Testdatensätze werden als 'clean validation samples' bezeichnet.</sample>
    <sample id="132">Die Arbeit wurde von drei Autoren, Akshata, Martin und einem ungenannten dritten, durchgeführt.</sample>
    <sample id="133">Die Autoren arbeiten mit mehreren Modalitäten, nicht nur mit Text.</sample>
    <sample id="135">Die ABC-Eval-Methode, entwickelt von der Emery NLP Lab in Zusammenarbeit mit Amazon Alexa AI, bietet eine neue Möglichkeit zur Bewertung der Konversationsqualität von Chatboten. Sie zielt darauf ab, die Subjektivität menschlicher Bewertungen zu reduzieren, indem sie spezifische Verhaltensweisen wie Relevanz und Selbstkontradiktion in der Konversation quantifiziert. Tests mit vier hochrangigen Chat-Modellen zeigten, dass ABC-Eval eine höhere Zuverlässigkeit und Vorhersagekraft im Vergleich zu bestehenden Methoden wie Lickert- und Dialog-Level-Scoring aufweist. Die Ergebnisse zeigen, dass ABC-Eval eine umfassendere Abdeckung der Konversationsqualität bietet und somit ein wertvolles Werkzeug für die Weiterentwicklung der Konversations-AI darstellt.</sample>
    <sample id="136">In dieser Präsentation diskutiert Jashwanth Sivan die Entwicklung von FERMAT, einem neuen Evaluationsansatz für numerische Argumentation, der die Schwächen der aktuellen Benchmarks aufzeigt. Er zeigt, dass Modelle mit mehr als 10 Milliarden Parametern besser abschneiden, aber die aktuellen Benchmarks nicht die mathematische Fähigkeit angemessen bewerten. FERMAT verwendet eine Vielzahl von mathematischen Typen und Operationen, um die Leistung zu bewerten. Die Ergebnisse zeigen, dass die Sprach- und mathematische Vielfalt die Modellleistung verbessert. Jashwanth fordert die Verwendung von FERMAT, um die numerische Argumentation besser zu bewerten.</sample>
    <sample id="137">In diesem Vortrag wird die Arbeit "Teltodesign", ein Datenset für die Sprache-gesteuerte Floorplan-Generierung, vorgestellt. Die Arbeit zielt darauf ab, Designprozesse zu erleichtern, indem Benutzer mit Textanweisungen Floorplans erstellen können. Die Herausforderung besteht darin, Designs unter strengen Anforderungen zu generieren, die sich von der Kunstfertigkeit von Text-Conditioning-Image-Generierung unterscheiden. Die Lösung ist ein Encoder-Decoder-Modell, das die Floorplan-Generierung als Sequenzproblem behandelt. Die Ergebnisse zeigen, dass das Modell, das auf dem T2D-Datensatz trainiert wurde, eine hohe Leistung bei der Generierung von Floorplans mit natürlichen Anweisungen aufweist, was die Wirksamkeit von Text-Conditioning-Image-Generierungmethoden übertrifft.</sample>
    <sample id="138">Die Autoren identifizieren das zu wenig erforschte Gebiet als die effektive Integration von Wissen aus verschiedenen Quellen, insbesondere Wissen, das nur zur Inferenzzeit verfügbar ist, ohne spezifische Trainingsdaten.</sample>
    <sample id="139">Die Referenten heißen Yin und Ji Yang.</sample>
    <sample id="140">Ja, Coscript wurde von Crowd-Worker überprüft, um die Genauigkeit der generierten Skripte zu gewährleisten.</sample>
    <sample id="141">Bestehende Ressourcen sind auf bestimmte Kontexttypen und Sprachen beschränkt und basieren auf menschlicher Kuration, was ihre Anwendung einschränkt.</sample>
    <sample id="142">Hallo. Ich werde über unsere Arbeit zur Lösung von indirekten Referenzausdrücken für die Entitätsauswahl sprechen, bei der wir den alt-Entities-Korpus einführen. Und mein Name ist Javad Hosseini, und dies ist eine gemeinsame Arbeit mit Philip Radlinski, Silvia Parati und Anil Chius. Unser Ziel ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen möchten. Betrachten Sie diese alternative Frage: Wollten Sie Easy on Me oder I got a Feeling? Hier möchte der Benutzer zwischen diesen beiden Songs wählen. Das offensichtlichste ist, eine direkte Referenz zu verwenden, z. B. den Namen des Songs oder seine Position. Aber manchmal ist eine indirekte Referenz angemessener, um ein natürlicheres Gespräch zu führen. Dies kann passieren, wenn der Benutzer sich nicht an den Namen des Songs erinnern kann, oder die Aussprache zu ähnlich ist und schwer zu unterscheiden ist, oder wenn der Benutzer eine Präferenz angeben möchte. Hier sind einige Beispiele für indirekte Referenzen. Zum Beispiel, der neuere oder der Song, der nicht energetisch ist. Dies ist ein wichtiges Problem in Konversationssystemen und auch für die Entitätsverständnis von LLMs. Wir sind uns nicht über einen öffentlichen Datensatz für die Aufgabe bewusst, also sammeln wir einen, indem wir eine Crowdsourcing-Methodik verwenden. Unser Datensatz deckt drei verschiedene Domänen ab: Musik, Bücher und Rezepte. Unsere Datensatzsammlung betont die Informalität mit einem Cartoon-Vergleichssatz. Der erste Sprachbubel, Bob sagt, erinnere dich an das Lied, das wir gestern gehört haben. Und mit diesem, Bob setzt den Kontext. Im zweiten Sprachbubel sagt Alice, meinst du easy on me oder I got a feeling? Dies ist die alternative Frage. Und im dritten Sprachbubel verwendet Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen. Zum Beispiel, die neuere. Wir liefern den ersten und zweiten Sprachbubeln automatisch, aber der dritte wird von den Annotatoren ausgefüllt. Der erste Sprachbubel wird aus einigen manuellen Anweisungen pro Domäne ausgewählt. Der zweite, der alternative Frage, wird wie folgt generiert: Wir verwenden immer ein einfaches Vorlagenmuster, wobei A und B aus Wikipedia abgetastet werden. Hier sind die verschiedenen Abtastmethoden, die wir verwendet haben. Wenn wir weiter in der Liste gehen, werden die Entitäten sich ähnlicher. Und es ist normalerweise schwieriger, die Unterscheidung zu treffen. Die erste ist gleichmäßig zufällig. Die zweite, wenn die Entitäten ähnliche Titel haben, z. B. zwei Bücher mit dem Namen the return. Die dritte, wenn sie ähnliche Beschreibungen auf Wikipedia haben, und schließlich, wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia haben, z. B. den gleichen Genre oder den gleichen Künstler für einen Song. Wenn wir diese alternative Frage den Annotatoren zeigen, wissen sie die Namen dieser Entitäten, aber sie wissen nicht unbedingt über die Entitäten. Also, was wir tun, ist, dass wir einige Hintergrundwissen über die beiden Entitäten zeigen. Für Songs zeigen wir einfach einen Google-Suchlink zu jedem Song. Und dann bitten wir die Annotatoren, mindestens einen der Songs zu hören und über jeden Song zu lesen. Hier ist zum Beispiel der Google-Suchlink für den Song easy on me. Für Rezepte und Bücher zeigen wir einige Hintergrundtext aus Wikipedia. Für Rezepte zeigen wir zusätzlich die Bilder, wieder aus Wikipedia, damit die Annotatoren wissen, wie sie aussehen. Dann bitten wir die Annotatoren, eine dieser Entitäten auszuwählen, zum Beispiel hier die erste, und beschreiben sie mit drei bis fünf indirekten Referenzausdrücken. Hier sind einige Beispiele aus unserem Datensatz. Zum Beispiel, ohne Worte, nicht der mit dem zwölfjährigen Jungen oder der fiktiven oder kommt aus Aserbaidschan. Der alt-Entities-Korpus hat sechstausend alternative Fragen in drei Domänen und hat vierzigtausend indirekte Referenzausdrücke. Die Ergebnisse mit dem T five xlarge Modell sind unten zusammengefasst. Wenn der Sprachmodell Zugang zu genau dem gleichen Hintergrundwissen wie die Annotatoren hat, ist die Genauigkeit wirklich hoch, es ist rund um neunzig bis fünfundneunzig Prozent. Aber das ist nicht realistisch. Wenn das Sprachmodell Zugang zu teilweise überlappenden Hintergrundwissen hat, dann ist die Genauigkeit zwischen zweiundachtzig und achtundsiebzig Prozent, was realistischer ist. Zum Beispiel, wenn das Sprachmodell die Hintergrundinformationen über die Entitäten abrufen. Dann ist die Genauigkeit nur sechzig Prozent. Es gibt also viel Raum für Verbesserung. Wir haben auch gezeigt, dass die Modelle domänenspezifisch sind. Hier ist ein Link zu unserem Datensatz. Danke.</sample>
    <sample id="143">Der Ansatz wird mit bestehenden Richtlinien wie WETKEY und LOCALAGG verglichen, wobei er als überlegen herausgestellt wird.</sample>
    <sample id="144">Die Autoren gehören der Universität von Toronto an.</sample>
    <sample id="145">Der/die Referent*in heißt Jenny.</sample>
    <sample id="146">Zou Yichen, ein Doktorand der Fudan University, präsentiert eine Analyse der Omission in Dialogsummarisierung. Dialogsummarisierung, ein Unterbereich der Textsummarisierung, zielt darauf ab, prägnante Zusammenfassungen zu erstellen, die die wichtigsten Informationen eines Dialogs enthalten. Trotz Fortschritten bei der Dialogsummarisierung, insbesondere durch große Sprachmodelle, bleiben häufige Fehler wie Omission, die zu unvollständigen Summen führen, ein Problem. Die Analyse zeigt, dass etwa 70% der generierten Summen ein Omission-Problem aufweisen, was die Notwendigkeit einer verbesserten Omissionserkennung und -behandlung unterstreicht. Um dieses Problem anzugehen, wurde ein neues Dataset mit Omission-Labels erstellt, das auf bestehenden Benchmarks basiert. Die Ergebnisse zeigen, dass die Erkennung von Omissionen eine herausfordernde Aufgabe ist, die fortschrittlichere Modelle erfordert. Die Verwendung von Omissionen zur Verbesserung der Summenqualität zeigt sich als vielversprechend.</sample>
    <sample id="147">Drei Autoren sind an der Arbeit beteiligt: Myra, Esmira Mouche und Dan Jurafsky.</sample>
    <sample id="148">Simultane Spracherkennung.</sample>
    <sample id="149">Ja, der Datensatz ist öffentlich zugänglich.</sample>
    <sample id="150">Archie Kalyani präsentiert das Meeting QA-Dataset, das sich auf die extraktive Fragebeantwortung in Meeting-Transkripten konzentriert. Dieses neue Dataset, bestehend aus 7.700 Fragen, hebt die Bedeutung von Fragen, die Diskussionen anregen, und bietet eine reichhaltige Quelle für NLP-Forschung. Die Analyse zeigt, dass aktuelle Modelle Schwierigkeiten haben, Fragen in diesem Kontext zu verstehen, was zu erheblichen Fehlern führt. Die Ergebnisse zeigen, dass die Verbesserung durch Datenaufrichtung und die Verwendung von Silver-Annotations zu einer signifikanten Leistungssteigerung führt.</sample>
    <sample id="151">Hallo zusammen. Mein Name ist Ying und mein Kollege Ji Yang. Wir werden unsere Forschung über Multi-Teach vorstellen, die Multi-Model Zero-Short Learning durch Anweisungstuning verbessert. Mit den Fortschritten bei großen Sprachmodellen haben viele Arbeiten neue Lernparadigmen erforscht, um trainierte Sprachmodelle für verschiedene Downstream-Aufgaben auf eine parametergenauere und dateneffizientere Weise zu nutzen. In jüngster Zeit haben viele Studien gezeigt, dass Anweisungstuning große Sprachmodelle auf Zero-Short-Aufgaben in einer Zero-Short-Methode ermöglichen, indem sie natürliche Anweisungen befolgen. In der bisherigen Arbeit zur Anweisungstuning konzentrierte man sich jedoch hauptsächlich auf die Zero-Short-Leistung bei Sprachaufgaben, während Computer Vision und multimodale Aufgaben ausgelassen wurden. Daher wollen wir untersuchen, ob Anweisungstuning auf multimodalen prärtrainierten Modellen die Generierung auf Zero-Short-multimodalen Aufgaben verbessern kann. Darüber hinaus haben wir bei unserer Forschung eine erhebliche Diskrepanz in der Verfügbarkeit von Anweisungssätzen zwischen NLP und multimodal festgestellt. Es gibt mehr als sechshundert Sprachaufgaben, aber keine große, öffentlich verfügbare multimodale Anweisung. Daher haben wir ein Multi-Modal Anweisungstuning-Datensatz erstellt, der aus sechzig verschiedenen multimodalen Aufgaben besteht, die aus zehn verschiedenen Kategorien stammen. Diese Aufgaben stammen aus einundzwanzig vorhandenen Open-Source-Datensätzen und jede Aufgabe ist mit fünf Expert-Anweisungen ausgestattet. Um Multi-Modal Anweisungstuning auf unseren vorgeschlagenen Datensatz zu untersuchen, nehmen wir OFA, ein einheitliches multimodales prärtrainiertes Modell als Basismodell. OFA verwendet ein einheitliches Vokabular für Sprache, Bild-Token und die Koordinaten eines gebundenen Box. Hier zeigen wir einige Beispiele aus unserem Multi-Teach-Datensatz. Um die Verarbeitung verschiedener Eingabedaten und Ausgabedaten zu vereinheitlichen, folgen wir dem Verfahren von OFA und formulieren alle Aufgaben in einem einheitlichen Sequenz-zu-Sequenz-Format, in dem Eingabedaten, Bilder, Anweisungen und gebundene Boxen im gleichen Tokenraum dargestellt werden.</sample>
    <sample id="152">In 'Exploring Large Language Models for Classical Philology', Frederic Griebenschneider presents advancements in NLP for ancient Greek and Latin. The work introduces Greberta and GRETTER, monolingual models, and Filberta and Filter, multilingual models, addressing the need for robust evaluation and multilingual capabilities. A new pretraining corpus from the Internet Archive was developed, and models were benchmarked against existing ones, showing significant improvements. The study also explores the performance of T5's encoder and the impact of multilinguality, concluding that multilingual models do not significantly outperform monolingual ones.</sample>
    <sample id="153">Nina Rehmehri presents a study on resolving ambiguities in text-to-image models, crucial for generating accurate images. The work involves creating a benchmark dataset with various ambiguities and developing frameworks to disambiguate prompts and evaluate image fidelity. The study shows that disambiguation improves image generation, with findings aligning with human evaluations.</sample>
    <sample id="154">Die Autoren gehören der Universität von Trento an.</sample>
    <sample id="155">Der/die Referent*in heißt Javad Hosseini.</sample>
    <sample id="157">Sheng Gao und sein Team von Sun Dong University präsentieren SDDS, ein Dialogsummarisierungsmodell, das die Herausforderungen der Dialogsummarisierung mit statischen und dynamischen Graphen adressiert. Durch die Kombination von heuristischen Methoden zur Strukturmodellierung, wie der Discourse-Passing-Graph, mit einem dynamischen Graph-Modell, das semantische Beziehungen mit Multi-Head-Attention berechnet, bietet SDDS eine flexible und präzise Summarisierung. Die Methode integriert diese Graphen durch eine Fusion, die die Dialogstruktur und -semantik in ein einheitliches Modell integriert, was zu einer effektiveren und genaueren Zusammenfassung führt.</sample>
    <sample id="158">Xiangkunhu aus AWS präsentiert Dual Cache für die Entitätsreferenzauflösung in langen Dokumenten. Dual Cache kombiniert lokale und globale Caches, um Entitätsreferenzen effizienter zu speichern und zu verwalten. Es reduziert Cache-Missraten, indem es Entitäten basierend auf ihrer globalen oder lokalen Natur trennt. Benchmarks zeigen, dass Dual Cache, insbesondere mit Trainingsdaten, besser abschneidet als Single Cache und Unbounded Memory Modelle. Es bietet eine hohe Performance-Kosteneffizienz und ist besonders effektiv bei umfangreichen Dokumenten.</sample>
    <sample id="159">Hallo zusammen. Ich bin Kostas Sinha und freue mich, Sie zu unserem Vortrag über das ACL-Talkpaper zu begrüßen. Dieses gemeinsame Werk mit John Waugh, Aaron Muller, Kanishka Mishra, Karen Fentress, Roger Levy und Atina Williams. In diesem Arbeit, wir überdenken die minimal pair Paradigma. Das minimal pair Paradigma bewertet Spracheinheiten in Bezug auf Akzeptanzurichtungen, wie z. B. Grammatik, wie Blimp Syntax, oder Akzeptanz in Bezug auf Stereotypen, z. B. Kraus Paare. Und in diesem minimal pair Paradigma ist die typische Art, Spracheinheiten zu bewerten, dass Sie eine akzeptable oder ungrammatische Satzzeile zeigen, und die Hoffnung ist, dass die Modelle mehr Wahrscheinlichkeit auf die akzeptable Satzzeile setzen. Der aktuelle MPP-Pipeline ermöglicht es uns nicht, Modelle Akzeptanz gegenüber längeren Sätzen zu bewerten. In den heutigen Tagen kommen große Sprachmodelle mit längeren Kontextfenstern. Es ist also entscheidend, dass wir die Akzeptanz der Modelle über den gesamten Kontextfenster bewerten. Das ist es, was wir hier tun. Wir versuchen, den MPP-Pipeline zu überdenken, indem wir die Modelle bitten, Akzeptanz auf längeren Sequenzen zu bewerten. Also, was tun? Wir simulieren diese längeren Sequenzen, wir überarbeiten die Datensätze selbst und dann erstellen wir Sätze, indem wir akzeptable oder unakzeptible Sätze aus diesen Datensätzen auswählen. Zum Beispiel haben wir hier ein typisches Paar von Grammatik aus dem Blimp-Datensatz ausgewählt. Und was wir tun, um längere Sequenzen zu erstellen, die akzeptabel sind, und die gleiche grammatische Struktur haben, extrahieren wir grammatische Sätze aus Adjektiv und fügen sie als Präfix zu sowohl der akzeptablen als auch der unakzeptablen Abfrage hinzu. Wir können dasselbe tun, indem wir unakzeptable Sätze aus derselben Phänomene auswählen. Und das könnte auch die Akzeptanz der Modelle testen. Und wir können dasselbe tun, indem wir Sätze aus einem anderen Datensatz oder einem anderen Datensatz auswählen. Das sagt uns, ob die Akzeptanzurichtungen des Modells tatsächlich von der Kontext beeinflusst werden. Ob der Kontext von einem anderen Datensatz oder einem völlig irrelevanten Satz kommt. Wie geht das Modell? Zuerst schauen wir uns die Wikipedia-Sätze an, die völlig irrelevant für die aktuelle Abfrage sind. Und dort finden wir, dass die MPP-Urteile für beliebige Kontextlängen relativ stabil sind. Wir erhöhen die Kontextlänge auf bis zu tausend vierundzwanzig, um die Modelle von O P T und GPT zwei zu maxen. Wir haben hier in der orangefarbenen gepunkteten Linie gesehen, dass die MPP-Urteile relativ stabil sind. Was passiert, wenn wir Sätze aus dem gleichen Datensatz auswählen? Also, hier haben wir Sätze aus akzeptablen und unakzeptablen Domänen aus dem gleichen Blimp oder Syntaxgramm-Datensatz. Und wir sehen, dass die MPP-Urteile entweder signifikant zunehmen oder abnehmen, wenn wir akzeptable Präfixe oder unakzeptable Präfixe hinzufügen. Aber wenn wir die Struktur abgleichen, das heißt, wenn wir Sätze aus derselben Phänomene auswählen, sehen wir eine massive Zunahme oder Abnahme der MPP-Urteile für das Modell, abhängig davon, ob die gewählte Präfixe akzeptabel oder unakzeptabel sind. Und das ist sehr groß. Diese Wirkung nimmt mit der Kontextlänge zu. Und das würde wahrscheinlich die neueren Sprachmodelle, die große Kontextfenster haben, beeinflussen. Warum beeinflusst der abgeleitete Präfix die Sprachmodellurteile so stark? Wir haben eine Reihe von Analysen durchgeführt, bei denen wir versuchen, die Eingabensätze zu stören, indem wir die relevanten Strukturen beibehalten, aber Störungen in die Eingabensätze hinzufügen. Und nach mehreren dieser Störungen ändern die Modelle nicht ihre Kurs. Im Grunde genommen finden wir, dass die Modelle auf ähnliche Weise auf die Störungen in den akzeptablen Domänen reagieren. Und wenn wir die Sätze in den unakzeptablen Domänen stören, sehen wir eine Abnahme der MPP-Urteile. Die wichtigsten Erkenntnisse unserer Arbeit sind, dass Sprachmodelle auf latente syntaktische und semantische Merkmale reagieren, die über die Sätze hinweg geteilt werden. Und die MPP-Bewertung, die wir derzeit mit kurzen und einzelnen Satzeneingaben machen, erfasst möglicherweise nicht vollständig die abstrakte Kenntnis des Sprachmodells über den Kontextfenster. Bitte lesen Sie unsere Arbeit für mehr Details zu unseren Experimenten. Vielen Dank für Ihr Zuhören.</sample>
    <sample id="160">Im ersten Schritt werden die Input-Token mit einem unordentlichen Multiset von Tokens zugeordnet, die im Output erscheinen.</sample>
    <sample id="161">Coscript enthält insgesamt 55.000 Skripte.</sample>
    <sample id="163">Die beste Ausrichtungsmethode für DEplain ist die Methode von MASS.</sample>
    <sample id="164">Der Vorteil von schwach überwachtem Lernen besteht darin, dass es die Kosten und Zeit für manuelle Datenerstellung reduziert, indem es auf weniger genauen Labeln ausgerichtet ist.</sample>
    <sample id="165">Wenting Zhao präsentiert ein Paper über adaptive Common Sense Reasoning, das auf unsupervisierter Lernmethode LIpor basiert. Das Ziel ist es, plausible Erklärungen ohne vorherige Überwachung zu identifizieren. LIpor nutzt die Muttermutualexklusivität, um plausible Erklärungen zu priorisieren. Die Ergebnisse zeigen, dass LIpor alle Zero-Shot-Modelle, einschließlich GPT-3, übertrifft, indem es eine Genauigkeit von über 4 Punkten auf der ALF-NLU-Benchmark-Datenbank erreicht.</sample>
    <sample id="166">Yuxin Luo von Harbin University of Technology präsentiert ein neues Framework zur Bildwiederherstellung aus komplexen Texten, das auf der Divide-and-Conquer-Strategie und der Dual-Process-Theorie basiert. Das System kombiniert die Vorteile von System 1, das auf analoger Inferenz basiert, und System 2, das für abstrakte logische Inferenzen geeignet ist. Es besteht aus einem Symbol Generator, einem Decoder, einem Visual Linguistic Interactor und einem Neural Symbolic Reasoner. Die Ergebnisse zeigen, dass das neue Modell die Leistung bestehender Methoden übertrifft.</sample>
    <sample id="167">DEplain-web bestand aus 750 Dokumenten, die manuell und mit automatischen Methoden ausgerichtet wurden.</sample>
    <sample id="168">Der CoNLL++-Datensatz wurde erstellt, indem die Reuters News-Artikel von 2020 annotiert wurden mit den gleichen CoNLL 2003 Annotation Guidelines.</sample>
    <sample id="169">Aydin Bilal presents a study on prompting large language models (LLMs) for machine translation, focusing on the PAMP model. The research evaluates the impact of prompt selection on translation quality, using state-of-the-art metrics and human evaluations. It finds that high-quality, curated data improves performance, and while PAMP's fluency is comparable to advanced systems, it struggles with accuracy, often omitting source text parts. The study recommends a five-shot prompting strategy, emphasizing the importance of example quality over similarity to the source sentence.</sample>
    <sample id="170">Hallo zusammen. Mein Name ist Yuxin Zhang von der Penn State University. Heute werde ich unsere Arbeit vorstellen, die sich mit der semantischen Analyse in mehreren natürlichen Sprachen und -repräsentationen befasst. Semantische Analyse ist die Aufgabe, semantische Repräsentationen von Benutzeranfragen wie SQL und Lambda zu erstellen. Und semantische Analyse in mehreren Sprachen ist die Aufgabe, Anfragen in mehreren natürlichen Sprachen in mehrere Repräsentationen zu übersetzen. Es gibt bisher separate Modelle für verschiedene Aufgaben, wie begrenzte Aufgaben und Anwendungen. Zum Beispiel fehlt die Abdeckung für bestimmte Sprachen, wie Chinesisch, und für bestimmte Repräsentationen, wie Lambda, fehlt die Abdeckung. Und es gibt nur ein einzelnes Modell zur Bewertung. Um dies zu erreichen, haben wir Exemplar vorgeschlagen, das ein einheitliches Exemplar für die semantische Analyse in mehreren natürlichen Sprachen und -repräsentationen bietet. Es enthält neun Datensätze in verschiedenen Domänen, fünf semantische Anweisungen, acht Millionen Repräsentationen und zweiundzwanzig Sprachen in fünf Sprachfamilien. Um unsere Benchmark besser zu bewerten, betrachten wir sechs Trainings- und Bewertungssettings. Das erste ist Translate-Test. Wir verwenden die Google-Translate-API, um die Quelle in die Zielsprache zu übersetzen, und verwenden dann ein monolinguales Modell, um zu trainieren und zu bewerten. Und zum Beispiel trainieren wir ein englisches Modell für englische Abfragen und übersetzen während der Inferenz die deutsche Abfrage mit der API in Englisch und verwenden dann das trainierte Modell, um die SQL zu vorhersagen. Und wir testen auch ein monolinguales Modell. In diesem Setting ist die Quell- und Zielsprache gleich, zum Beispiel Deutsch-Deutsch oder Englisch-Englisch. Wir testen auch ein monolinguales Few-Shot-Setting, bei dem wir ein monolinguales Modell mit nur zehn Prozent des Trainingsdatensatzes trainieren. Und wir testen ein multilinguales Modell, bei dem wir ein multilinguales Modell für alle Sprachen trainieren. Zum Beispiel setzen wir deutsche, englische und chinesische Abfragen zusammen, um ein multilinguales Modell zu trainieren, und können während der Inferenz diese Abfrage in Deutsch oder Chinesisch übersetzen. Und wir untersuchen auch Cross-Linguistische Zero-Shot- und Few-Shot-Transfer. Wir trainieren auf einer englischen Abfrage oder einer Kombination aus englischen und deutschen Few-Shot-Abfragen, um ein multilinguales Modell zu trainieren, um die SQL-Ausgabe vorherzusagen. Und wir finden viele interessante Ergebnisse. Zum Beispiel bewerten wir zwei Gruppen von Modellen, einschließlich Encoder-PDR, was für multilingual trainierte Encoder mit pointerbasierten Decodern steht, und Encoder-Decoder-Modelle, was für multilingual trainierte Encoder-Decoder steht. Wir fanden, dass Encoder-Decoder die beste Leistung auf allen neun Datensätzen erzielt. Und wir bewerten auf multilingualen Einstellungen. Wir fanden, dass Encoder-Decoder oder Encoder-PDR durch das Training in einer Mischung verschiedener Sprachen verbessert werden kann. Und wir fanden, dass die Cross-Linguistische Transferleistung signifikant ist. Und wir vergleichen die Cross-Linguistische Transferleistung. In diesem Diagramm ist die blaue Linie Cross-Linguistische Zero-Shot-Transfer, die orange Linie Cross-Linguistische Few-Shot-Transfer, während die grüne Linie das monolinguale Setting ist. Wir fanden, dass die Cross-Linguistische Transferleistung signifikant ist. Und wir finden, dass das few-shot Setting die Transferleistung schnell verkürzt. Und wir finden einige andere interessante Ergebnisse. Zum Beispiel bewerten wir Encoder-Decoder, die vergleichbare Ergebnisse erzielen. Und das Training auf englischer Sprache kann die Leistung von few-shot auf Zielsprachen erheblich verbessern. Und wir fanden, dass multilingualen Sprachmodelle wie Codas und Blue für Cross-Linguistische Semantische Analyse-Tasks unzureichend sind. Zusammenfassend haben wir Exemplar, ein einheitliches Benchmark für Cross-Linguistische Semantische Analyse mit mehreren natürlichen Sprachen und -repräsentationen, durchgeführt. Und unsere Ergebnisse zeigen viele interessante Ergebnisse und so weiter. Und willkommen, um unser Papier und Code zu besuchen. Vielen Dank für das Zuhören.</sample>
    <sample id="171">Vorherige Arbeiten wurden in vier Kategorien eingeteilt, aber diese Methoden waren entweder nicht auf Embedding-Ansätze anwendbar oder fehlten an Transferabilität.</sample>
    <sample id="172">Nein, mehrsprachige LLMs wie Codex oder Bloom sind für CLSP-Tasks als inkonsequent und unzureichend angesehen.</sample>
    <sample id="174">Die 35K-Datenbank für Argument-Qualitätsanalyse bietet eine umfassende Sammlung von hochqualitativen Argumenten, die aus hochrangigen Turnieren, Experten und Debattieren stammen. Sie bietet eine breite Palette von Themen und integriert Analysen, die über einfache Argumente hinausgehen. Die Datenbank verwendet eine Instanzbasierte Annotatoren-Relativität, um die Genauigkeit der Anmerkungen zu verbessern, indem nur die relevantesten Annotatoren für bestimmte Themen verwendet werden. Ein Relevenzmodell bewertet die Relevanz von Argumenten für verschiedene Themen, was zu einer genaueren und diversifizierteren Analyse führt. Die Datenbank ist ein umfassendes Werkzeug für die Argument-Qualitätsanalyse, das in der Forschung und im praktischen Einsatz von NLP-Studien verwendet werden kann.</sample>
    <sample id="175">Die Methode verwendet eine GPU-freundliche, kontinuierliche Relaxation, um die Suche nach den höchstmöglichen Scoring Permutationen zu vereinfachen und die linguistisch plausiblen Permutationen zu lernen.</sample>
    <sample id="176">Fairness eines nachgeschalteten NLP-Modells bezieht sich darauf, wie das Modell unterschiedliche Gruppen in verschiedenen Kategorien wie Rasse, Geschlecht und politische Meinungen gleichermaßen effektiv und gerecht behandelt, ohne Diskriminierung oder Verzerrungen aufgrund politischer oder sozialer Vorurteile.</sample>
    <sample id="177">Der Referent ist Yanis Lavraik.</sample>
    <sample id="178">Die Referent*in heißt Kostas Sinha.</sample>
    <sample id="179">Mélanie Szklarek präsentiert Symbolic TOM, ein Framework zur Verbesserung der Theorie des Geistes-Entscheidungsfindung in großen Sprachmodellen. Durch die Verwendung von grafischen Darstellungen, die die mentalen Zustände von Charakteren darstellen, ermöglicht es das System, komplexe Fragen zu beantworten. Tests zeigen, dass Symbolic TOM die Leistung von LLMs signifikant verbessert, insbesondere bei nicht standardisierten Aufgaben, und übertrifft die Ergebnisse von überarbeiteten Modellen.</sample>
    <sample id="180">Die Referent*in heißt Myra.</sample>
    <sample id="181">Die Arbeit von Si Yuan und Kollegen untersucht die Fähigkeit von großen Sprachmodellen, spezifische, kontextbezogene Ziele zu planen, die durch Einschränkungen definiert sind. Sie identifizieren die Unzulänglichkeiten in der Planung von spezifischen Zielen und entwickeln eine Methode, die Over-Generate-Zen-Filter, um die Qualität der generierten Skripte zu verbessern. Durch die Erstellung eines Datensatzes namens CodeScript, der 55.000 spezifische Ziele mit Skripten enthält, bieten sie eine Ressource zur Verbesserung der Forschung in der Sprachplanung. Die Ergebnisse zeigen, dass kleinere, aber spezialisierte Modelle, trainiert auf CodeScript, die Leistung von großen Sprachmodellen übertreffen können.</sample>
    <sample id="182">Tropikalismus bezieht sich auf die stereotypischen und exotisierenden Beschreibungen, die in den generierten Texten für Frauen von Farbe verwendet werden, was zu einer übermäßigen Betonung ihrer kulturellen Identität und einer Verbindung zu negativen Stereotypen wie 'tropisch' führt.</sample>
    <sample id="183">Die Autoren haben die von Menschen verfassten Beschreibungen der Zielgruppen durch die Verwendung von prompts erstellt, die es den Menschen ermöglichten, rassistische Stereotypen zu identifizieren, was eine direkte Vergleichsbasis für die von LLMs generierten Beschreibungen bot.</sample>
    <sample id="184">Die Arbeit verwendete cXMI, um die Kontextnutzung zu messen, indem sie die Informationen ausgeben, die der Kontext für die Zielübersetzung liefert.</sample>
    <sample id="185">DrBERT ist ein französischer medizinischer Sprachmodell, während ChuBERT ein englischer medizinischer Sprachmodell ist.</sample>
    <sample id="187">Zwei Autoren, Yin und Ji-Yang, sind an der Arbeit beteiligt.</sample>
    <sample id="188">Iteratives Transferlernen ist ein Prozess, bei dem ein Modell kontinuierlich mit neuen Daten aktualisiert wird, um seine Leistung zu verbessern. Es beinhaltet das Training auf der neuesten Datensatz, was im Gegensatz zu kumulativen Updates, die alle Daten über die Zeit sammeln, verwendet wird.</sample>
    <sample id="189">Das Ziel des Datensatzes ist es, eine große, öffentlich zugängliche Sammlung von indirekten Referenzaufgaben zu erstellen, die in drei Domänen (Musik, Bücher, Rezepte) variieren, um die Entitätserkennung in Konversationen zu verbessern.</sample>
    <sample id="190">Angreifer können Modellparameter extrahieren, indem sie die Embedding-Wasserzeichen stehlen, die in den EaaS integriert sind, und diese dann verwenden, um ähnliche Dienste zu erstellen.</sample>
    <sample id="191">Die Arbeit wurde von Sarah Papi, Matteo Negri und Marco Turilli durchgeführt.</sample>
    <sample id="192">Yang Luo präsentiert CAM, einen Optimierer, der Adaptiert, Vertrauen und Speichereffizienz vereint. CAM verwendet eine Residual-gestützte Update-Strategie, um die Stabilität bei der Optimierung zu verbessern, was zu einer besseren Leistung bei der Training von großen Sprachmodellen führt. Im Vergleich zu Adam und Adafactor zeigt CAM eine verbesserte Validierungseinstellung und reduziert den Speicherverbrauch, insbesondere bei großen Modellen wie BERT. CAMs Fähigkeit, sowohl große als auch kleine Modelle effektiv zu trainieren, macht es zu einem vielseitigen Werkzeug für Sprachmodell-Optimierung.</sample>
    <sample id="193">Um den ursprünglichen Datensatz zu erstellen, wurden 43 Annotatoren verwendet.</sample>
    <sample id="194">Die Autoren gehören der Carnegie Mellon University an.</sample>
    <sample id="195">Die Arbeit präsentiert ROHT, ein Framework zur Frageantwortung, das die Fragekomposition durch eine hierarchische Fragezerlegungstree (HQDT) versteht und probabilistische Argumentation über diese Tree durchführt. Die HQDT besteht aus einem Wurzel- und mehreren Kindknoten, wobei die Kindknoten atomare Fragen sind. ROHT integriert Wissen aus verschiedenen Quellen, um komplexe Fragen zu beantworten, indem es die Antworten auf verschiedenen Ebenen kombiniert. Die Ergebnisse zeigen, dass ROHT, insbesondere mit zusätzlichen Textkorpora, die Leistung von bestehenden Methoden verbessert.</sample>
    <sample id="196">Das Beispiel mit dem Begrenzer auf der linken Seite ist 'I saw Bart and Lisa'.</sample>
    <sample id="197">Dialogsysteme haben sich erheblich verbessert, aber Herausforderungen wie Selbstkontradiktionen und Relevanz bleiben bestehen. ABC Eval bietet präzisere Bewertungsmethoden, um diese Probleme zu adressieren.</sample>
    <sample id="198">Die Bewertung der Akzeptanz der Modelle über das gesamte Kontextfenster ist notwendig, da aktuelle große Sprachmodelle längere Kontextfenster haben, und die aktuelle MPP-Pipeline nicht die Akzeptanz über längere Sequenzen bewertet.</sample>
    <sample id="199">Ja, das mehrsprachige Training führte in sieben Daten-Sets zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell.</sample>
    <sample id="200">Nein, die Annotatoren kennen die Entität im Voraus.</sample>
    <sample id="201">The presentation used state-of-the-art neural MT metrics for evaluation.</sample>
    <sample id="202">Die Regression wirkt sich auf bestimmte NER-Typen unterschiedlich aus, wobei die Ergebnisse für den Typ 'ORG' am schlechtesten sind.</sample>
    <sample id="203">Positionalität ist wichtig für NLP, weil sie die systematischen Vorurteile in Daten und Modellen offenlegt, die zu ungleichen Ergebnissen für verschiedene Bevölkerungsgruppen führen können. Das Verständnis dieser Vorurteile ermöglicht die Entwicklung inklusiverer Technologien, die fairer und genauere Ergebnisse für alle Nutzer bieten.</sample>
    <sample id="204">Adapter.</sample>
    <sample id="205">Xiangbing PhD student von der University of Washington präsentiert, wie politische Vorurteile in Sprachmodellen entstehen, die auf politisch voreingenommenen Web-Crawl-Daten trainiert werden. Diese Vorurteile können zu Fairnessproblemen in NLP-Anwendungen führen. Die Studie untersucht, wie politische Vorurteile in Sprachmodellen entstehen, und zeigt, dass Modelle unterschiedliche politische Neigungen aufweisen. Durch die Verwendung von politischen Fragebögen zur Bewertung der politischen Neigung der Modelle und durch kontrollierte Experimente, die Modelle auf verschiedene politische Korpora trainieren, wird gezeigt, dass politische Vorurteile in den Trainingsdaten übernommen werden. Die Ergebnisse zeigen, dass Modelle unterschiedliche Leistungen bei Hate-Speech- und Fake-News-Erkennung aufweisen, abhängig von ihrer politischen Neigung. Die Studie unterstreicht die Notwendigkeit, Fairnessprobleme zu erkennen und zu adressieren, die durch politische Vorurteile in Sprachmodellen entstehen.</sample>
    <sample id="206">Wir beginnen mit Transfer Learning, indem wir Gewichte von verwandten Aufgaben übertragen, wie der 'Topic Independent Discourse Dissonance Classification' und der 'Binary Classification of Expansion and Comparison Classes of PDTB' verwenden.</sample>
    <sample id="207">The evaluation of PaLM's capabilities was conducted using the latest test sets to ensure no overlap with the training data, as part of a systematic study on language model prompting for machine translation.</sample>
    <sample id="208">Die Autoren haben drei Empfehlungen für die Modellbesitzer vorgeschlagen.</sample>
    <sample id="209">Die vorgeschlagene Methode erzielt einen Gewinn von 1,1% gegenüber der stärksten Baseline.</sample>
    <sample id="210">Der Referent ist Shuo-Hung Hsu.</sample>
    <sample id="211">Ja, die Ergebnisse und der Datensatz der Studie können als Benchmark für zukünftige Arbeiten in der automatischen Textvervollständigung verwendet werden.</sample>
    <sample id="212">Die Arbeit experimentiert mit kleineren Modellen, wie T5 fine-tuned, um die Fähigkeiten der großen Sprachmodelle bei der Erfüllung spezifischer, konfigurierter Ziele zu testen.</sample>
    <sample id="213">Das Basismodell für die Untersuchung ist OFA (Unified Multi-Modal Pre-Trained Model).</sample>
    <sample id="215">Adam Szpekocskis Vortrag befasst sich mit der Koordinationsstruktur in verschiedenen syntaktischen Theorien. Er vergleicht symmetrische, wie Universal Dependencies und Meaning Text, mit asymmetrischen, wie der Prag-Ansatz, und mit multi-head Ansätzen, wie der von Katzmann. Szpekocskis Argumentation stützt sich auf die Prinzipien der Koordinationslänge und der Prinzip der Minimierung der Koordinationslänge. Er zeigt, dass die Länge der Koordinationsobjekte und -adjektive in verschiedenen Kontexten variiert, wobei die linke Koordinationskonjunktion tendenziell kürzer ist, wenn kein linker Gouverneur vorhanden ist. Diese Beobachtung unterstützt die symmetrische Koordinationsstruktur gegenüber asymmetrischen.</sample>
    <sample id="217">In dieser Arbeit wird die generative Dialogsteuerung für mehrere Attribute untersucht. Die vorgestellten Methoden konzentrieren sich auf einzelne Attribute und ignorieren die praktischen Szenarien mit mehreren Attributen. Die vorgestellte Methode, D-C-G, ist eine Distangled Controllable Generation, die Attributekonzepte aus Sichtwerten lernt und Distangle-Verlust verwendet, um verschiedene Attributekombinationen zu trennen. Ein einheitlicher Bewertungsrahmen, M-A-E, wird eingeführt, um verschiedene Granularitäten von Attributen zu bewerten. Die Ergebnisse zeigen, dass D-C-G die Kompositionsgenerierung für mehrere Attribute verbessert und die Kontrolle und Testqualität übertrifft.</sample>
    <sample id="218">Die Autoren gehören der Universität Graz an.</sample>
    <sample id="219">Jiahuizhu Xie und sein Team haben eine Pipeline zur Identifizierung finanzieller Signale in Berichten entwickelt. Die Pipeline, die auf der Analyse von 10-K-Berichten basiert, zielt darauf ab, die Bedeutung von Wörtern zu bestimmen, indem sie die Beziehung zwischen aktuellen und früheren Berichten untersucht. Sie klassifiziert Wörter in drei Kategorien: hochspezifisch, semantisch ähnlich, aber unterschiedlich, und neu oder irrelevant. Die Pipeline verwendet eine zweistufige Feinabstimmung, die sowohl externe als auch interne Datensätze umfasst, um die Genauigkeit zu verbessern. Die Ergebnisse zeigen, dass die Pipeline effektiv ist und eine hohe Generalisierbarkeit aufweist.</sample>
    <sample id="220">Stony Brook University.</sample>
    <sample id="221">Die Arbeit untersuchte die Übersetzung von Deutsch in Englisch.</sample>
    <sample id="222">In diesem Artikel untersuchen wir die Herausforderungen und Interventionen bei der Adaption von Open-Domain-Question-Answering (QA) zu verschiedenen Domänen. Wir untersuchen verschiedene Dateninterventionen, die zur Out-of-Domain-Generalisierung beitragen, identifizieren die Art der Datensatzverschiebung, die ein neues Domänemodell aufweist, und bestimmen, welche Interventionen für eine bestimmte Art von Verschiebung am effektivsten sind. Unsere Ergebnisse zeigen, dass bestimmte Interventionen die Leistung des Lesemodells um bis zu 24% verbessern können, wobei die Wirksamkeit von der Art der Verschiebung abhängt.</sample>
    <sample id="223">Der Referent ist Shahid Mian.</sample>
    <sample id="224">Die Modelle Long-IMPART und Normal-Base-IMPART wurden untersucht.</sample>
    <sample id="225">Für Training werden 53 Aufgaben aus 9 Gruppen verwendet, während für Tests die gesamte Common Sense Reasoning Gruppe und 5 zusätzliche Aufgaben aus VQA und Misconception verwendet werden.</sample>
    <sample id="226">Es gibt zwei Autoren, Regina Stoddens und Omar.</sample>
    <sample id="227">Der Vortrag diskutiert die Herausforderungen bei der Umsetzung von Grounded Language Understanding in NLP, bei denen Sprache in spezifische Umgebungen übersetzt werden muss. Aktuelle Modelle, die auf generativen Aufgaben trainiert sind, zeigen Schwierigkeiten, gültige und grammatikalisch korrekte Pläne zu generieren. Pangou, ein vorgeschlagenes Framework, konzentriert sich stattdessen auf die Bewertung von Kandidatenplänen, was die Validität und Grammatik der generierten Pläne nicht erfordert. Pangou zeigt überlegene Leistung bei der Bewertung von Kandidatenplänen und ist robust gegenüber nicht-IDE-Umgebungen. Die Ergebnisse deuten darauf hin, dass die Bewertung von Kandidatenplänen eine effektivere Strategie für die Anwendung von Sprachmodellen in realen Umgebungen ist.</sample>
    <sample id="228">Die Autoren haben Experimente an den Datensätzen AG News, MIND, SSTD2 und ERESTA durchgeführt.</sample>
    <sample id="229">In dieser Präsentation diskutieren wir unsere Zusammenarbeit mit Henning Baak Smoud mit der Entwicklung von Methoden zur Erkennung und Verbesserung von Argumentationsbehauptungen. Wir konzentrieren uns auf die Textrevision, ein wesentlicher Bestandteil professioneller Schreibprozesse, insbesondere in der Argumentation. Unser Ziel ist es, zu bestimmen, ob eine Behauptung optimal formuliert ist und welche Verbesserungen vorgenommen werden müssen. Wir untersuchen die Herausforderungen bei der Arbeit mit Revision-basierten Daten, wie die Repräsentativität, Modellarchitektur, Kontextabhängigkeit und Bias. Unsere Ergebnisse zeigen, dass Revision-basierte Daten effektiv für die Erkennung suboptimaler Behauptungen eingesetzt werden können, wobei die Relevanz des Kontexts je nach Aufgabe und Problem abhängt.</sample>
    <sample id="231">NACHOS ist ein großes, öffentlich zugängliches Datensatz von medizinischen Dokumenten, der für das Training von Sprachmodellen in der Gesundheitsbranche verwendet wird.</sample>
    <sample id="232">Aydar Bilal</sample>
    <sample id="233">Sarah Papi presents a novel approach to simultaneous speech translation (SimulST) by leveraging existing off-the-shelf models without retraining. The proposed Encoder-Decoder Attention (EDAT) strategy uses a single model for different latency regimes, focusing on attention mechanisms to decide when to emit translations. This method outperforms existing strategies by achieving better translation quality and lower latency, as demonstrated in their experiments. The team has released their code and models to support further research and application.</sample>
    <sample id="234">Die Prompt-Strategie hat einen erheblichen Einfluss auf die Ergebnisse, wobei fünf Shot Prompting die beste Leistung bietet, da es die Qualität der Beispiele betont, anstatt der Ähnlichkeit mit der Quelle.</sample>
    <sample id="235">Die Autoren gehören der Universität Toronto an.</sample>
    <sample id="236">Die Expert*innen haben 5 Expert*innen-Anweisungen für jede Aufgabe in der Multi-Instra-Übersetzung bereitgestellt.</sample>
    <sample id="237">Die Autoren schlagen die Entwicklung eines diagnostischen Test-Suites namens KITMOS vor, um Modelle zur Nutzung von Informationen aus mehreren Quellen zu testen, indem sie eine Aufgabe namens coreference resolution einführen.</sample>
    <sample id="238">Yeboah-Thuah Hu von der University of Central Florida präsentiert MeetingBank, ein neues Benchmark-Dataset für die Zusammenfassung von City Council Meetings. Die Herausforderung bestand darin, hochwertige Summarien zu erstellen und vertrauenswürdige Ressourcen zu finden. Die Daten umfassen 1.366 Meetings mit Transkripten, Referenzsummaries und URLs. Die Analyse zeigt, dass abstraktive Summarier-Modelle wie DaVinci-003 und GPT-3 herausragende Ergebnisse erzielen, insbesondere in Bezug auf Fluency und Coherence. Die Ergebnisse deuten darauf hin, dass die Summarisierung weiterhin sich auf die Erfassung der Hauptdiskussionspunkte konzentrieren sollte. MeetingBank dient als nützliche Ressource für die Entwicklung von Summarisierungstechnologien und bietet Einblicke in die Entscheidungsfindung von Stadträten.</sample>
    <sample id="239">Die Vorträge von Aydil Bilal und seinen Kollegen aus Google Translate bieten einen kurzen Überblick über das Papier "Prompting Language Model for Machine Translation: Assessing Strategies and Performance".</sample>
    <sample id="240">In der Woche.</sample>
    <sample id="241">Ethan und sein Team haben ein Paper über die Entwicklung eines realistischen Frameworks zur Misinformationserkennung veröffentlicht, das die Schwächen der aktuellen Methoden überwindet. Sie schlagen eine 'Human in the Loop'-Ansatz vor, der die Rolle von Menschen in der Erkennung und Bewertung von Misinformationen integriert. Ihr System umfasst zwei Hauptkomponenten: die Erkennung von irreführenden Behauptungen und die Überprüfung von Verstößen gegen soziale Medienrichtlinien. Die Ergebnisse zeigen eine hohe Genauigkeit bei der Erkennung von Richtlinienverstößen und eine effiziente menschliche Arbeitsbelastung. Das Paper bietet einen neuen Ansatz zur Bewertung von Misinformationserkennungssystemen und betont die Bedeutung der Zusammenarbeit zwischen Technologie und menschlicher Expertise.</sample>
    <sample id="242">Gängige Bewertungsmethoden für Dialogsysteme umfassen menschliche Bewertungen, vergleichende Lickert-Skalen und Dialog-Level-Paar-Wies-Vergleiche.</sample>
    <sample id="243">Vier Autoren sind an der Arbeit beteiligt: Sebastian Santi, Ronan Labrosse, Caterina Ranecka und Martin Sab.</sample>
    <sample id="244">Im Beispiel wird Hintergrundwissen benötigt, dass Servin ist ein Richter, und dass Richter entscheiden Fälle in Law Courts.</sample>
    <sample id="245">Linying Zhang präsentiert eine Analyse zur Identifizierung von hochqualitativen Amazon Mechanical Turk (mTurk) Annotatoren. Die Studie umfasst eine zweistufige Pipeline zur Bewertung von Annotatoren, die in Gold- und Silber-Kategorien unterteilt. Die Pipeline zeigt eine hohe Kappa-Korrelationskoeffizient von 0.443 und 0.534 bei der Referenzbasierten Aufgabe. Sie bietet eine kosteneffiziente Methode zur Identifizierung von hochqualitativen Annotatoren, die in zukünftigen Anwendungen in verschiedenen Sprachen und Plattformen getestet werden sollen.</sample>
    <sample id="246">Ja, der Code ist auf GitHub verfügbar.</sample>
    <sample id="247">Die Arbeit von Joakim von Chiest-AI präsentiert FactKG, ein neues Fact-Verification-Dataset, das auf Knowledge Graphs (KG) basiert. Im Gegensatz zu Text- oder Tabellen-basierten Datasets nutzt FactKG intuitivere KGs, um zuverlässige Fact-Verification durch direkte Verbindung von Beweisen und Aussagen zu ermöglichen. Die Arbeit bietet eine neue Aufgabe, die sowohl für die Verbesserung von Dialogsystemen als auch für die Überprüfung der Konsistenz zwischen natürlichen Sprachen und KGs geeignet ist. FactKG umfasst zwei Stile von Aussagen: geschrieben und umgangssprachlich, mit zwei Labels: unterstützt und widerlegt. Die Arbeit verwendet fünf Arten der Argumentation: One-hop, Konjunktion, Existenz, Multi-hop und Negation. Die Ergebnisse zeigen, dass die Baselines, die KGs verwenden, alle anderen übertreffen, was die Wirksamkeit der KGs als Beweismittel unterstreicht.</sample>
    <sample id="248">Nein, die Annotatoren für NLPositionality sind nicht ausgewogen in Bezug auf jede demographische Gruppe, wie Land, Geschlecht usw.</sample>
    <sample id="249">Sätze innerhalb der akzeptablen Domain wurden durch das Hinzufügen von 'Noise' zu den Eingabessätzen durcheinander gebracht, wobei die Modelle weiterhin die gleiche MP-Entscheidung zeigten.</sample>
    <sample id="250">Eine dimensionale Bewertung ist ein systematischer Ansatz zur Bewertung von Chat-Modellen, der spezifische Verhaltensweisen wie Relevanz und Selbstkontradiktion misst, um die Qualität der Konversationen zu bewerten.</sample>
    <sample id="251">Die Autoren gehören der Universität of Science and Technology of China an.</sample>
    <sample id="252">Die Arbeit von Saikiran Thanikella und Kollegen konzentriert sich auf die Entwicklung eines neuen Datensatzes, ILPCRE, und einer Pipeline, UCreate, zur Verbesserung der Prior Case Retrieval (PCR) in der juristischen Domain. Der ILPCRE bietet einen umfassenden Test für die Bewertung von PCR-Algorithmen, mit 7.070 Fällen und 6.775 durchschnittlichen Zitaten pro Dokument. UCreate nutzt eine event-basierte Methode, die eine hohe Effizienz und geringere Inferenzzeit aufweist, und zeigt eine bessere Leistung als bestehende Ansätze, einschließlich des MTFT-Bird-Teams. Die Ergebnisse zeigen, dass event-basierte Modelle, insbesondere die event-filtered-docs, die beste Leistung erzielen, was die Notwendigkeit spezialisierter Ansätze in der juristischen PCR-Entwicklung unterstreicht.</sample>
    <sample id="253">Mario Edarragon präsentiert 'Name Disorder', ein Modell zur Erkennung von mentalen Störungen in sozialen Medien. Durch Double Domain Adaptation und Guided Masking analysiert das Modell soziale Medien, um auf Symptome von Depressionen und anderen Störungen zu reagieren. Das Modell zeigt eine ausgeglichene Leistung bei der Erkennung und Labeling von Nutzern, was es zu einem effektiven Werkzeug für die frühzeitige Erkennung von mentalen Gesundheitsproblemen macht.</sample>
    <sample id="254">Sung Qi von der Nanjing University of Science and Technology präsentiert eine Forschung über "Uncertainty Guided Label Denoising for Document Level Relation Extraction". Das Ziel ist es, Entitäten in Dokumenten zu verknüpfen, indem die Qualität der Daten durch Uncertainty Guided Label Denoising verbessert wird. Die Methode verwendet eine Monte Carlo Dropout-Technologie, um die Unsicherheit in den Vorverarbeitungsmodellen zu modellieren, und führt eine adaptive Strategie für die Uncertainty-Schwellen ein, um falsch positive Pseudo-Labels zu filtern. Die Ergebnisse zeigen, dass die vorgeschlagene Methode die Leistung der vorherigen Baselines auf zwei öffentlichen Datensätzen deutlich verbessert.</sample>
    <sample id="255">Die Form des Prompts ist für Zero- und One-Shot-Prompts wichtig, aber für Five-Shot-Prompts hat sie keinen großen Einfluss.</sample>
    <sample id="257">Die Autoren haben vier aktuelle Chatmodelle evaluiert.</sample>
    <sample id="258">Zhangsun Han diskutiert die Verwendung von großen Sprachmodellen zur Bewertung von Textqualität in der natürlichen Sprachverarbeitung. Im Gegensatz zu menschlichen Evaluatoren, die unzuverlässig sind, untersucht sein Papier, ob Modelle wie T0, InstructGPT, Q-Learning und ChatGPT Textbewertungen basierend auf Grammatik, Kohärenz, Beliebtheit und Relevanz liefern können. Die Ergebnisse zeigen, dass einige Modelle, insbesondere Davinci und ChatGPT, menschliche Bewertungen nachahmen können. Das Papier untersucht die Auswirkungen von Anweisungsänderungen und die Vor- und Nachteile der Modellbewertung im Vergleich zur menschlichen Bewertung.</sample>
    <sample id="259">Yusen Zhang präsentiert Exemplar, ein umfassendes Benchmarking-Tool für Cross-Lingual Semantic Parsing, das 22 Sprachen und 5 Domänen abdeckt. Es bewertet drei Modelle: encoder-decoder, encoder-only, und multilingual, unter verschiedenen Trainings- und Evaluationsszenarien. Die Ergebnisse zeigen, dass encoder-decoder-Modelle die beste Leistung erzielen, wobei multilingual Modelle wie CodeSearch und BERT+ exhibitieren. Die Studie identifiziert die Kurse der Multilingualität und zeigt, dass multilinguales Training die Leistung von encoder-only-Modellen verbessert.</sample>
    <sample id="260">Die Arbeit wurde von einem einzigen Autor, Jingwei Yi, verfasst.</sample>
    <sample id="261">Ein guter Planer sollte Skripte schreiben, die sowohl logisch kohärent als auch den festgelegten Einschränkungen gerecht werden.</sample>
    <sample id="262">Die Arbeit wurde von einer Gruppe von Autoren verfasst, aber die genaue Anzahl ist nicht angegeben.</sample>
    <sample id="263">In this work, we address the issue of label biases in in-context learning, a paradigm for large language models. We identify a new type of bias, domain label bias, and propose domain context calibration to mitigate these biases. Our method uses random in-domain words to estimate and correct biases, outperforming previous methods. Experiments show significant improvements in model performance, especially on tasks with high domain label bias.</sample>
    <sample id="264">Liu Wang präsentiert ein Framework zur Transferable Audio Visual Text Generation, das visuelle und auditive Konzepte über verschiedene Domänen hinweg verbindet. Durch die Einführung eines Audiovisual Meta-Mapping Networks und eines Transform-based Encoder/Generator, unterstützt durch Constrained Constructive Learning, zielt das Modell darauf ab, schnell auf neue Domänen zu adaptieren. Die Ergebnisse zeigen, dass das Framework in verschiedenen Domänen und mit begrenzten Daten effektiv funktioniert, was es zu einem vielversprechenden Ansatz für multimodale Textgenerierung macht.</sample>
    <sample id="265">Der Referent ist Vasudha.</sample>
    <sample id="266">Die Autoren gehören der Universität Graz an.</sample>
    <sample id="268">Die häufigsten Fehler von PaLM sind Omission Errors, bei denen Teile des Originaltextes weggelassen werden, um eine besser klingende Übersetzung zu erzeugen.</sample>
    <sample id="269">Hallo, ich bin James Finch. Und ich bin Sarah Finch. Und heute werden wir Ihnen alles über abc eval erzählen, eine neue, dimensionale Herangehensweise zur Bewertung von konversationalen KI. Dies wurde von der Emery Nlp Lab, geleitet von Professor Gino Choi an der Emery University, und in Zusammenarbeit mit Amazon Alexa AI entwickelt.</sample>
    <sample id="270">Die Autoren gehören der Universität von Emory an.</sample>
    <sample id="271">CFT steht für Continuous Fine-Tuning, ein vorgeschlagenes Baseline in WSL, die es ermöglicht, Modelle weiterhin zu trainieren, um die Leistung zu verbessern.</sample>
    <sample id="272">Fünf Autoren sind an der Arbeit beteiligt: Kostas Sinha, John Wautier, Aaron Muller, Kanishka Mishra, Karen Fuentas, Roger Levy und Atina Williams.</sample>
    <sample id="273">Hallo. Mein Name ist Kaiho Yan und ich werde unsere Arbeit mit dem Titel "Wann erfordert Übersetzung Kontext? Eine datengetriebene, mehrsprachige Untersuchung" vorstellen. Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernhout, Emile Liu, Andre F. D. Martins und Graham Neubig durchgeführt. Viele Übersetzungen hängen von Kontext ab. Zum Beispiel, wie würden wir in diesem Satz übersetzen? Nun, wenn der vorherige Satz war, könnten die Minister herausfinden, dass es gefährlich wird. Aber wenn der vorherige Satz war, könnte es ernst sein, Doktor. Je nach Kontext ändert sich also die Bedeutung des Wortes und die Übersetzung. Die Bewertung, wie gut Modelle solche Übersetzungen bewältigen können, ist jedoch ziemlich schwierig. Erstens, weil nur ein kleiner Teil der Übersetzungen von Kontext abhängt, was Korpus-Metriken wie bleu nicht erfassen kann. Und einige Leute haben vorgeschlagen, auf kontextabhängige Übersetzungen zu konzentrieren, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextabhängigen Übersetzungen und begrenzte Sprachen, da sie auf Domänenwissen und menschliche Kuration angewiesen sind. In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten: Wann erfordert Übersetzung Kontext und wie gut können Modelle diese Fälle bewältigen? Um die erste Frage zu beantworten, messen wir zunächst, wie sehr ein Wort während der Übersetzung von Kontext abhängt. In der vorherigen Arbeit haben wir cxmi als Maß für die Verwendung von Kontext durch maschinelle Übersetzungmodelle eingeführt. Und das wird durch die Messung der Informationen, die der Kontext C über das Ziel y gibt, gegeben dem Quell x. Sie können sich cxmi als die Informationen vorstellen, die dem Modell durch die Bereitstellung von Kontext gegeben wird. In dieser Arbeit erweitern wir cxmi auf Punktweise cxmi, das Kontextnutzung auf Satz- oder Wortebene messen kann. Wir können Wörter mit hohem pcxmi als solche betrachten, die für die Übersetzung von Kontext erforderlich sind. Und analysieren wir Wörter mit hohem pcxmi, um Muster zwischen diesen Wörtern zu finden. Und führen wir unsere Analyse auf Transkripte von Ted Talks durch, die von Englisch in vierzehn verschiedenen Sprachen übersetzt wurden. Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zuerst suchen wir nach Teil der Sprache, die ein hohes pcxmi aufweist. Und dies ermöglicht es uns, zum Beispiel, duale Pronomen in Arabisch zu finden, die relativ hohes pcxmi aufweisen. Und dies kann erklärt werden, weil Englisch keine dualen Pronomen hat, also müssen Sie Kontext verwenden, um zu bestimmen, ob ein Pronomen dual ist, wenn Sie ins Arabische übersetzen. Und wir finden auch, dass bestimmte Sprachen auch Kontext benötigen, wenn wir die richtige Verbform wählen wollen. Wir untersuchen dann Wörter, die über alle ihre verschiedenen Vorkommen ein hohes pcxmi aufweisen. Und das hilft uns, Fälle wie den hier zu identifizieren, in denen Sie Kontext benötigen, um die richtige Übersetzung für Eigennamen in Chinesisch zu wählen, um sicherzustellen, dass Sie die gleiche Übersetzung innerhalb des Dokuments verwenden. Und wir finden auch, dass Kontext für die Übersetzung der richtigen Formalität erforderlich ist. Und schließlich untersuchen wir verschiedene einzelne Token, die ein hohes pcxmi aufweisen. Und das ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich von dem Wort selbst erfasst werden können, sondern eher in der Satzstruktur ausgedrückt werden, wie z. B. Ellipsenauflösung. Jetzt verwenden wir unsere Ergebnisse aus unserer Analyse, um einen Benchmark für die Dokumentebene-Übersetzung zu entwerfen. Für jede der fünf identifizierten Diskursphänomene erstellen wir Tags, um Wörter zu identifizieren, die zu dem Phänomen gehören. Und wir können auch anmerken, dass verschiedene Sprachen unterschiedliche Proportionen dieser Diskursphänomene haben. Und wir verwenden den Muda-Tagger, indem wir den Tagger auf den parallelen Korpus anwenden, den wir für die Bewertung verwenden. Und wir wenden unsere Übersetzungsmetriken unserer Wahl auf die kontextabhängigen Beispiele an, die der Muda-Tagger identifiziert hat. Erstens, wenn wir Korpus-Metriken verwenden, so dass für bleu kontextunabhängige Modelle die beste Leistung haben. Aber wenn wir comet verwenden, kontextbewusste Modelle die beste Leistung haben. Und wenn wir Wort F messen, haben Modelle mit oder ohne Kontext vergleichbare Leistung. Dies zeigt erneut, dass es schwierig ist, die beste Dokumentebene-Übersetzungsysteme zu bestimmen, wenn wir nur Korpus-Metriken verwenden. Jetzt verwenden wir den Muda-Benchmark, um Modelle zu bewerten, und wir finden, dass kontextbewusste Modelle für bestimmte Diskursphänomene, wie Formatik und lexikalische Kohäsion, deutlich genauer sind als Modelle, die keinen Kontext verwenden. Aber diese Modelle sind nicht viel besser als Modelle, die keinen Kontext verwenden, für andere Phänomene wie Ellipsen, Pronomen und Verbform. Dies deutet darauf hin, wo wir für Dokumentebene-Übersetzung Fortschritte sehen müssen. Wir vergleichen auch verschiedene kommerzielle Systeme, und unser Benchmark zeigt, dass DeepL in der Regel genauer als Google Translate für Dokumentebene-Übersetzung ist. Um zu zusammenfassen, führen wir eine datengetriebene Analyse für vierzehn Sprachpaare durch, um zu identifizieren, wann Übersetzungen von Kontext abhängen. Und dann verwenden wir unsere Ergebnisse, um einen Benchmark für die Dokumentebene-Übersetzung zu erstellen, der uns helfen kann, zu identifizieren, welche Diskursphänomene Modelle gut bewältigen oder nicht, und welche Übersetzungsysteme gut in der Dokumentebene-Übersetzung sind. Vielen Dank für Ihre Aufmerksamkeit. Bis nach Toronto.</sample>
    <sample id="274">Der Referent ist Yu Chen Zhang.</sample>
    <sample id="276">Ananya and Vignesh present their work on IndicMT Eval, a dataset for evaluating machine translation metrics for Indian languages. They focus on five languages from two language families, Tamil, Malayalam, Hindi, Marathi, and Gujarati, generating 7,000 samples. Bilingual expert annotators evaluate translations, marking errors and providing scores. Recent MT models like NLLB and IndicTrans show fewer errors. IndicComet, fine-tuned on human scores, outperforms Comet baselines on most languages, with a robust score of 0.306 on unseen languages.</sample>
    <sample id="277">Die neue Methode hat keinen Namen.</sample>
    <sample id="278">Die Methode der „markierten Wörter“ identifiziert Wörter, die Gruppen von unmarkierten (dominant) Gruppen unterscheiden, indem sie die Log-Odds-Raten von Wörtern für markierte Gruppen mit unmarkierten Gruppen vergleicht. Sie zeigt, wie scheinbar positive Wörter stereotypische und essentialisierende Erzählungen unterstützen.</sample>
    <sample id="279">Die Autoren sind PhD-Studenten der University of Washington.</sample>
    <sample id="280">Shuo Tao präsentiert Multi-EMO, ein Framework zur Emotion Regulation in Gesprächen, das visuelle, auditive und textuelle Daten integriert. Es verwendet vis-exnet zur visuellen Feature Extraktion, Multi-Attend zur Fusion und SWFL für bessere Klassifizierung. Die Ergebnisse zeigen eine Verbesserung in der Erkennung von Minderheits- und semantisch ähnlichen Emotionen, obwohl es einige Einschränkungen wie die Unfähigkeit, Sprecher von Hintergrundpersonen zu unterscheiden, gibt.</sample>
    <sample id="281">Kayo Yan und ihr Team untersuchen, wann Übersetzungen Kontext benötigen und wie gut Modelle diese Fälle bewältigen. Sie entwickeln cXMI, um den Kontextgebrauch zu messen, und erweitern es auf Punktwise cXMI, um Kontextbedürftigkeitsanalyse auf Wort- und Satzebene durchzuführen. Durch Analyse von TED-Talk-Übersetzungen identifizieren sie Wörter mit hohem cXMI, die auf Kontext angewiesen sind. Sie erstellen ein MUDATagger, um Wörter zu identifizieren, die an bestimmten Diskursphänomenen beteiligt sind. Die Ergebnisse zeigen, dass Kontextbewusste Modelle in bestimmten Bereichen besser abschneiden als kontextlose Modelle, während kommerzielle Systeme wie DeepL besser abschneiden als Google Translate.</sample>
    <sample id="282">Xiaoxuan Liu präsentiert das neue Modell StyleTRACE, das den Stiltransfer auf der Diskursebene in der natürlichen Sprachgenerierung (NLG) verbessert. Es adressiert die Herausforderung, den Stil von Diskursstrukturen zu emulieren, indem es den Stil von Diskursrepräsentationen aus der Quelle mit einem lernbaren Stil-Embedding kombiniert. Das Modell verwendet eine zweistufige Trainingsstruktur, um den Stil und die Inhalte effektiv zu transferieren. Die Ergebnisse zeigen, dass StyleTRACE den Stilkontroll- und Inhaltspräzision von basalen Modellen übertrifft, indem es die goldenen Texte in der Stilraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraum</sample>
    <sample id="283">Universal Abhängigkeitsstrukturen.</sample>
    <sample id="284">The FSUIE model introduces a novel fuzzy span mechanism to enhance universal information extraction by addressing ambiguities in span boundary labeling and mismatches in transformer feature extraction. It represents the target boundary as a continuous probability distribution, using a mask function to dynamically adjust attention span. Experiments on tasks like named entity recognition and relationship extraction show significant improvements, especially on small datasets. The model achieves better generalization and convergence speed, demonstrating its effectiveness in various IE tasks.</sample>
    <sample id="285">Mingqi Gao von der Peking University präsentiert eine Arbeit über die Fehlerkorrektur in Dialogsummarisierung. Die Studie identifiziert zwei Hauptlösungen zur Fehlerkorrektur: die Einführung von faktualitätsbezogenen Zielen in Trainingsprozessen und die Entwicklung von Fehlerkorrekturmodellen. Die Arbeit kritisiert die aktuellen Evaluationsmethoden, die auf faktualitätsmetrischen Bewertungen basieren, und schlägt vor, dass diese die Leistung von Fehlerkorrekturmodellen (FEC) verzerren können. Die Studie schlägt vor, dass die Kombination von menschlich korrigierten Summen mit synthetischen Daten die Leistung von FEC-Modellen verbessern kann. Es wird ein neues Fehlerklassifikationssystem vorgestellt, das sich auf faktualitätsbasierte und formbasierte Fehler konzentriert, und ein Evaluierungsframework entwickelt, das drei Schritte umfasst: Ausrichtung, Klassifizierung und Vergleich.</sample>
    <sample id="286">Der Referent ist Professor Gino Choi.</sample>
    <sample id="287">Drei Autoren sind an der Arbeit beteiligt: Javad Hosseini, Philip Radlinsky, Silvia Parati und Annie Luiz.</sample>
    <sample id="288">Syntaktische Phänomene können mit dem Blimp- und Syntax-Gym-Datensatz getestet werden.</sample>
    <sample id="290">Die Abkürzungen der fünf Methoden für die erste Forschungsfrage sind: Vallo, CoSine, FLoane, FLoane-FTW und CoSine-FTW.</sample>
    <sample id="291">Das Modell wird auf 11 Domain-Tasks evaluiert, einschließlich NER, Klassifikation, Part-of-Speech-Tagging und Fragebeantwortung.</sample>
    <sample id="294">CamemBERT wurde ursprünglich mit anonymisierten Daten aus dem Krankenhausdatenbestand trainiert.</sample>
    <sample id="295">Der Referent heißt Adam Szpekowski.</sample>
    <sample id="296">Valerio Basile präsentiert eine Zusammenarbeit zwischen der Universität von Turin und Amazon Alexa, die sich mit der Entwicklung von natural language understanding durch supervised machine learning befasst. Das Projekt konzentriert sich auf die Herausforderung der Ironie-Erkennung und die Erstellung von 'perspective aware models', die auf unterschiedlichen Annotatoren basieren. Die EPIC-Korpusdaten wurden über eine Crowdsourcing-Plattform gesammelt, um die Variabilität in der Ironie-Interpretation zu erforschen. Die Analyse zeigt, dass Modelle, die auf unterschiedlichen Annotatoren trainiert wurden, eine höhere Zuversicht in ihre Vorhersagen aufweisen. Interessante Unterschiede in der Ironie-Interpretation wurden zwischen verschiedenen Altersgruppen und geografischen Standorten festgestellt, insbesondere zwischen den Annotatoren aus dem Vereinigten Königreich und Irland.</sample>
    <sample id="297">In dieser Studie untersuchen wir die Rolle von Dog Whistles in der politischen Rhetorik, die subtilen Botschaften vermitteln, die eine Gruppe ansprechen, während sie als neutrale Sprache wahrgenommen werden. Wir haben eine umfassende Glossar von über 340 Begriffen und Symbolen erstellt, die verschiedene Dog Whistle-Kategorien wie transphobe und antisemitische darstellen. Durch die Analyse historischer US-Politikreden und die Bewertung von GPT-3-Modelen haben wir festgestellt, dass diese Modelle Dog Whistles oft erkennen können, insbesondere formale Register. Unsere Ergebnisse zeigen, dass Dog Whistles die Bewertung durch automatisierte Hassgrammatik-Tools beeinflussen können, indem sie die Toxizität von Hasssätzen verringern. Dieses Projekt bietet Einblicke in die Bedeutung des Verständnisses von Dog Whistles für die politische Kommunikation und die Entwicklung von Technologien zur Erkennung und Moderation von Hassrede.</sample>
    <sample id="298">Experimente zeigten, dass die Leistung von neu trainierten oder fortlaufend trainierten Modellen mit neueren Daten abnahm, wenn die zeitliche Kluft zwischen Trainings- und Testdaten zunahm, was die Hauptursache für den Leistungsverlust bestätigte.</sample>
    <sample id="299">Mihalsgaragas and Lahdes propose a method to improve the robustness of NLP models against overfitting to dataset shortcuts by using a minimax training objective. This method focuses on generating a weight distribution that emphasizes underrepresented hard examples, reducing the reliance on auxiliary models. The approach is evaluated on three datasets, showing consistent improvements in out-of-distribution performance while maintaining high in-distribution accuracy.</sample>
    <sample id="300">Belinda's presentation introduces Interactive Diction, a system allowing users to dictate and edit documents using voice commands. The task involves transcribing speech, segmenting into dictations and commands, normalizing commands, and executing them. The project uses ASR for transcription, with models trained for segmentation, ASR repair, and interpretation. GPT-3 models are more accurate but slower, while T5 models offer efficiency. The system aims for a natural interface, and the team has released code and a dataset for further research.</sample>
    <sample id="302">Die Token für die Ausgabesequenz zu permutieren ist notwendig, um die korrekte Reihenfolge der Tokens zu bestimmen, da die Eingabe- und Ausgabemodellierung die Token in der richtigen Reihenfolge anordnen muss, um die syntaktische Struktur der Sprache zu erfassen.</sample>
    <sample id="303">Modellentwickler*innen sollten ihre Methoden transparenter machen, um zu verstehen, ob positive Stereotypen auf übermäßige Wertallianz oder andere Anti-Stereotyping-Methoden zurückzuführen sind, was ohne Transparenz nicht untersucht werden kann.</sample>
    <sample id="304">Inakzeptable Minimalpaareingaben sind Phrasen, die von einem Sprachmodell als ungrammatisch oder untypisch bewertet werden, oft aufgrund von Stereotypen oder fehlender Kontext.</sample>
    <sample id="305">In Weakly Supervised Learning (WSL), models are trained on noisy, weakly labeled data, raising questions about the necessity of clean validation data. This study reveals that recent WSL methods require clean data for proper performance, with more samples improving results. Direct fine-tuning on clean data often outperforms WSL methods. Continuous fine-tuning on clean data is recommended. The authors have made their code open-source for further exploration.</sample>
    <sample id="306">Sebastian Schuster und Na Jeong Kim untersuchen, wie gut große Sprachmodelle Entitäten in Texten verfolgen. Sie stellen fest, dass nur Modelle, die auf Code trainiert wurden, wie GPT-3, Entitätsverfolgung durchführen können. Ihre Tests zeigen, dass solche Modelle die Initialzustände korrekt wiedergeben können, aber nur GPT-3.0.3 übertrifft bei der Erkennung von Zustandsänderungen. Sie betonen die Bedeutung von Code-Training für die Entwicklung von solchen Fähigkeiten.</sample>
    <sample id="307">Die Autoren verwendeten Bewertungsmetriken wie Name Entity Recognition, Classification, Part-of-Speech Tagging und Question Answering, um die Leistung der Modelle zu bewerten.</sample>
    <sample id="308">Jenny Zhu presents her research on the positionality in NLP, revealing biases in datasets and models. Collaborating with the University of Washington and Allen Institute, she uses the NL-Positionality framework to re-annotate datasets with diverse annotators and compare them to models. Her findings show alignment with English-speaking and educated populations, but not with non-binary individuals. She recommends documenting design choices, conducting research with perspective, and building specialized datasets for specific communities.</sample>
    <sample id="309">Die Übereinstimmung zwischen den Kommentatoren wurde durch die Analyse von 100 doppelten gelabelten Konversationen gemessen.</sample>
    <sample id="310">Wikipedia wurde als Domain gewählt, um völlig unzusammenhängende Sätze zu den inakzeptablen und akzeptablen Suchanfragen hinzuzufügen.</sample>
    <sample id="311">Die Autoren gehören der Universität Mannheim an.</sample>
    <sample id="312">MultiInstruct ist das erste große Multi-Modal-Instrukt-Benchmark, das 62 diverse Multimodal-Aufgaben aus 21 Open-Source-Datensätzen umfasst, mit 5 Expert-Inspektionsanweisungen pro Aufgabe.</sample>
    <sample id="313">Zwei Autoren sind an der Arbeit beteiligt: James Finch und Sarah Finch.</sample>
    <sample id="314">Die binäre Koordination ist eine Koordinationsstruktur, bei der zwei Konjunktionen durch ein Komma getrennt sind, wie in 'John, Mary' oder 'John and Mary'.</sample>
    <sample id="315">Die in dieser Studie verwendeten Prompts waren durchschnittlich 20 Wörter lang.</sample>
    <sample id="316">Das kleinere T5-Modell, trainiert auf der CodeScript-Datenbank, zeigt eine verbesserte Fähigkeit, spezifische Ziele mit Einschränkungen zu planen, was darauf hinweist, dass kleinere Modelle mit geeigneten Daten effektiv mit größeren Modellen konkurrieren können.</sample>
    <sample id="317">Peng Li von der Universität Peking präsentiert CodeIE, ein innovatives Framework zur Information Extraction, das die Aufgabe in eine strukturierte Code-Generierung umwandelt. Durch die Verwendung von Code-LLM-Modellen wie Code-Davinci-002, demonstriert CodeIE eine signifikante Verbesserung gegenüber herkömmlichen Modellen wie GPT-3. Die Evaluierung zeigt, dass Code-Format-Modelle eine höhere Genauigkeit und weniger strukturelle Fehler aufweisen. Diese Methode bietet eine verbesserte Übereinstimmung zwischen Eingabe- und Ausgabeformaten und bietet einen neuen Ansatz für die Information Extraction.</sample>
    <sample id="318">Ich bin Janis Lavraik und werde Ihnen Dr. Bert vorstellen, ein robustes, in Französisch trainiertes Modell für den biomedizinischen und klinischen Bereich. In dieser Präsentation werden wir zunächst über die Sprache Modelling in der Gesundheitsbranche sprechen. Dann präsentieren wir unsere Hauptbeiträge, indem wir Dr. Bert vorstellen, ein Modell, das auf Roberta basiert und auf dem Datensatz Nachos trainiert wurde. Wir vergleichen es mit anderen Modellen mit verschiedenen Trainingsmethoden und Datenquellen. Wir präsentieren auch unsere Ergebnisse auf elf biomedizinischen und klinischen Aufgaben in Französisch. Schließlich diskutieren wir die Experimente und geben mehr Details zu den Modellen. Seit seiner Veröffentlichung im Jahr 2018 ist Bert eines der effektivsten Ansätze zur Lösung von Aufgaben im Bereich der natürlichen Sprachverarbeitung. Er bietet einen erheblichen Leistungsgewinn im Vergleich zu statischen und kontextualisierten Methoden wie Word2Vec, FastText und ELMO. Seitdem wurde er auf viele andere Sprachen wie Französisch mit Camembert und auf andere Domänen wie biomedizinisch mit Permitted Bert und Bio-Bert und klinisch mit Clinical Bert angewendet, hauptsächlich in englischer Sprache. Spezialisierte Modelle für andere Sprachen sind jedoch oft auf kontinuierliche Prätraining angewiesen, aufgrund des Mangels an in-domänenbezogenen Daten. Um diese Frage zu beantworten, vergleichen wir Dr. Bert mit unserem Schubert-Modell, das auf anonymisierten Daten aus dem Krankenhausdatenbestand basiert. Wir stellen uns die Frage, wie viel Daten benötigt wird, um ein spezialisiertes Modell auf Französisch zu trainieren. Wir trainen und vergleichen vier Modelle von Grund auf, ein erstes Version von Dr. Bert mit sieben Gigabyte von Nachos, ein zweites Version von vier Gigabyte von Nachos, ein erstes Version von Schubert, das auf vier Gigabyte von klinischen Notizen basiert, und ein letztes Version von Schubert, das eine Mischung aus vier Gigabyte von Nachos und vier Gigabyte von klinischen Notizen ist. Zusätzlich zu dieser Vergleichsübung stellen wir drei Modelle vor, die auf kontinuierlicher Prätraining trainiert sind, um die Auswirkungen der Prätraining-Strategie zu analysieren. Eines basiert auf dem Gewicht von Camembert und trainiert auf vier Gigabyte von Nachos, ein zweites, das ebenfalls auf Camembert basiert, aber auf vier Gigabyte von klinischen Notizen trainiert wird, und ein letztes, das auf dem englischen biomedizinischen Modell Permitted Bert basiert und auf vier Gigabyte von Nachos trainiert wird. Insgesamt haben wir sieben Modelle. Um unsere sieben Modelle zu bewerten, sammeln wir verschiedene öffentliche und private Dons-Tasks wie Name-Entität-Erkennung, Klassifizierung, Teil- und Frage-Tagging und Fragebeantwortung. Diese Modelle werden mit sechs Basismodellen verglichen, die Camembert, Oscar, four Gigabyte, four Gigabyte, four Gigabyte und four Gigabyte sind. Die Bewertung zeigt, dass die Modelle am besten auf Aufgaben mit Daten der gleichen Art wie die Modelle trainiert wurden. Wir können jedoch beobachten, dass Daten aus heterogenen Quellen scheinbar vielseitiger sind. Wir beobachten auch, dass mehr Daten zu besseren Ergebnissen führen. Insgesamt scheint von Grund auf trainiertes Modell auf den meisten Aufgaben eine höhere Leistung zu erzielen. Unsere Experimente und Konsumentenpräferenzen, die auf dem Gewicht und Tokenisierer von Permitted Bert trainiert wurden, zeigen vergleichbare Ergebnisse mit Dr. Bert vier Gigabyte von Grund auf. Dies ist nicht der Fall für das Modell, das auf Camembert-Weight und Tokenisierer basiert, das Stabilitätsprobleme aufweist. Abschließend bieten unser System eine bessere Leistung bei neun von elf Dons-Tasks und übertrifft im Allgemeinen die Ergebnisse des generischen Modells hier, Camembert. Wir bieten auch die Modelle, die aus Nachos erhalten wurden, kostenlos und auf Youking Face und alle Trainingsskripte auf unserem GitHub-Repository an. Vielen Dank für diese Präsentation und wir freuen uns auf den Austausch bei der Poster-Session in Toronto.</sample>
    <sample id="319">Die Arbeit untersucht die Auswirkungen von vier verschiedenen Lernstrategien: von-Nachos, von-Kliniknoten, von-Kamember und von-Permitted-Bert.</sample>
    <sample id="320">Der Faktor der Überanpassung, der speziell auf die Wiederverwendung von Tests zurückzuführen ist, zeigt keine Diminishing Returns, was darauf hinweist, dass er nicht beobachtet wurde.</sample>
    <sample id="321">Die Qualität der Vereinfachung wurde durch die Analyse verschiedener Arten von Vereinfachungen und die Bewertung der Ergebnisse von Feinabstimmungen von Sprachmodellen bestimmt.</sample>
    <sample id="322">Enrico Raganato diskutiert die Fähigkeit von Textklassifikatoren, Moral zu verstehen. Er erklärt, dass Moral subjektiv ist und verschiedene Theorien wie die moralische Grundlagestheorie helfen, diese Vielfalt zu erfassen. Enricos Arbeit untersucht, wie Modelle wie A-LM und B-LM in verschiedenen Domänen wie #AllLivesMatter und #BlackLivesMatter unterschiedliche moralische Ausdrücke erkennen. Er zeigt, dass Modelle die Nuancen in der moralischen Ausdrucksweise erkennen können, was die Notwendigkeit betont, Modelle an verschiedene Domänen anzupassen, um Missverständnisse zu vermeiden.</sample>
    <sample id="323">Yujie Wang von der Universität Shansi präsentiert ein Paper über die Verbesserung der Common Sense QA durch die Integration von dynamischen HG-Graphen mit Sprachmodellen. Durch die Verwendung von KG-Listen, HG-Graphen, ROBERT und Masked Self-Attention, wird die Relevanz von Entitäten und Beziehungen in HG-Graphen verbessert. Die Methode, die HG-Graphen mit QA-Kontexten verbindet, zeigt in Experimenten mit ConceptNet und WN25 eine überlegene Leistung gegenüber anderen LM- und HG-Methoden.</sample>
    <sample id="324">Ja, Sprachmodelle zeigen unterschiedliche politische Vorurteile, die sich in ihren Leistungen bei Aufgaben wie Hate-Speech- und Fake-News-Erkennung widerspiegeln, was zu Fairnessproblemen in NLP-Anwendungen führen kann.</sample>
    <sample id="325">Hallo, mein Name ist Matthias Landmann und heute werde ich Ihnen eine kurze Einführung in unser Papier über Kompositionalgeneralisation ohne Bäume mit Mehrfach-Tags und latenter Permutation geben. Dies ist eine gemeinsame Arbeit mit meinen Beratern Alexander Koller und Ivan Tiedoff. Kompositionalgeneralisation kann als die Fähigkeit eines Lerners verstanden werden, tiefere Rekursionen und bisher nicht gesehenes Kompositionen von Wörtern zu handhaben, die während des Trainings einzeln gesehen wurden. Im Kontext der semantischen Analyse könnte die Testung für Kompositionalgeneralisation wie folgt aussehen: Wie üblich haben wir eine Trainingssätze von Sätzen, in diesem Fall hat die Mädchen geschlafen und Mary wusste, dass die Mädchen geschlafen haben. Diese Sätze werden mit logischen Formen gepaart, die die Kernaspekte ihrer Bedeutung darstellen. Im Gegensatz zu der Standard-Maschinellen Lernbewertung kommt die Testset nicht aus der gleichen Verteilung, sondern enthält strukturell unerwartete logische Formen. In diesem Beispiel hat das Modell während des Trainings eine oberflächliche Rekursion gesehen und wird auf einem Beispiel mit tieferer Rekursion getestet. Naive Sequenz zu Sequenz Modelle kämpfen mit dieser Art von Out-of-Distribution-Generalisation und produzieren oft Ausgaben, die von der Eingabe abweichen. Insbesondere scheitern sie oft daran, die systematischen Entsprechungen zwischen Eingabe und Ausgabe zu reproduzieren, wie z. B. die in der Beispielfarbe codierten. Ein beliebter Weg, dies zu beheben, besteht darin, Bäume in die Modelle zu integrieren. Die Bäume sollen den kompositorischen Prozess erfassen, der Sätze mit logischen Formen verbindet. Dies funktioniert gut, aber Bäume werden normalerweise nicht gegeben und müssen irgendwie ermittelt werden. Dies kann ein kompliziertes und manchmal rechnerisch aufwändiges Verfahren sein. Typischerweise beinhaltet dies eine formalisierte, spezifische Vorverarbeitung der logischen Formen, z. B. um Variable-Symbole zu behandeln. Das Erhalten von Bäumen kann auch spezielle Grammatikinduktionverfahren erfordern. In diesem Papier verwenden wir keine Bäume und stellen eine neuronale Sequenz zu Sequenz Modell vor, die die Entsprechungen zwischen Eingabefragmente und Ausgabefragmente direkt modelliert. Zum ersten Mal zeigen wir eine starke Generalisierung zu tiefer Rekursion ohne Bäume. Unser Ansatz berechnet die Ausgabe aus der Eingabe in zwei Schritten. Zuerst werden alle richtigen Token mit einem unordentlichen Mehrfach-Set von Tokens markiert, die im Output erscheinen werden. Nach dem ersten Schritt haben wir alle richtigen Token, aber sie sind nicht ordnungsgemäß. Deshalb verwenden wir in der zweiten Stufe ein weiteres Modell, um eine Permutation vorherzusagen, um sie in die richtige Reihenfolge zu bringen. Wir stellen einen neuen Methode zur Vorhersage einer Permutation vor, die keine harten Einschränkungen für die möglichen Permutationen auferlegt. Dies macht unseren Ansatz ziemlich flexibel und ausdrucksstark. Konzeptionell funktioniert unser Permutation-Modell ungefähr so: Wir gehen von links nach rechts über den Output und bestimmen, welches Mehrfach-Set-Token in jede Position platziert werden soll. Für die erste Ausgabeposition wählen wir einfach das rote Highlight. Dann springen wir zum nächsten Mehrfach-Set-Token, um das zweite Token im Output zu bestimmen. Wir bestimmen das dritte Token im Output auf ähnliche Weise, indem wir zum nächsten Mehrfach-Set-Token springen. Wir setzen diesen Prozess fort, bis jedes Token aus der ersten Stufe genau einmal besucht wurde.</sample>
    <sample id="326">Kognitive Dissonanz ist das Phänomen, bei dem zwei widersprüchliche Überzeugungen oder Handlungen in der Sprache auftreten, wie zum Beispiel, wenn jemand weiß, dass etwas schädlich ist, aber trotzdem es konsumiert.</sample>
    <sample id="327">Xiaoxu, ein Doktorand, präsentiert die Entwicklung von ManageTower, einer neuen visuellen Spracharchitektur, die auf der BridgeTower-Basis aufbaut. ManageTower integriert unidimensionale Experten, um semantische Kenntnisse auf verschiedenen Ebenen effektiver zu nutzen. Mit nur 4 Millionen Trainingsbildern übertrifft es bestehende Modelle wie BridgeTower und Mert, indem es die Leistung auf VQVC2 verbessert. Die Architektur ist flexibel und kann mit verschiedenen Encoder kombiniert werden. Die Ergebnisse zeigen, dass adaptive Manager die semantische Tiefe besser nutzen können, was zu einer umfassenderen Crossmodal Representation führt.</sample>
    <sample id="328">GPT-4 steht am meisten links.</sample>
    <sample id="329">Zhen Minhang und Kollegen von Peking University präsentieren eine Methode zur Zero-Shot Video Sense Localization, die ohne manuelle Annotations funktioniert. Sie schlagen eine strukturierte Pseudo-Label-Generierung vor, die die Relevanz zwischen Video und Abfrage verbessert, indem sie Pseudo-Abfragen und Pseudo-Ereignisse basierend auf der visuellen Text-Pre-Training-Modellierung erstellt. Die Methode reduziert die Auswirkungen von Label-Los, indem sie Pseudo-Labels mit Gewichten und durch eine Label-Refinementstrategie behandelt. Die Ergebnisse zeigen, dass ihre Methode bessere Zero-Shot-Performance auf den ICLA Captions und S3D-Standards aufweist.</sample>
    <sample id="330">Ja, kumulatives Training ist in diesem Kontext besser, da es die Leistung über die verschiedenen Runden von aktiven Annotierungen verbessert.</sample>
    <sample id="331">Sarah Papi, Matteo Negri, Marco Turker.</sample>
    <sample id="332">Die Daten für den MuDa-Benchmark stammen aus Transkripten von TED Talks, die in 14 Sprachen übersetzt wurden.</sample>
    <sample id="333">In this study, we introduce INK, a framework designed to enhance Neural Machine Translation (NMT) by injecting Key Knowledge into the model. The main challenge in NMT is the non-smooth representation space, which limits the model's generalization ability. INK addresses this by refining the representation space using a two-step training loop that extracts key knowledge to guide the adapter and refreshes the datastore asynchronously. Our experiments show that INK outperforms the state-of-the-art KMT system, achieving higher BLEU scores with less memory space and faster inference speed. The framework demonstrates the potential of using key knowledge to improve NMT performance.</sample>
    <sample id="335">Matthias Landauer.</sample>
    <sample id="336">Sprachübergreifender Transfer bezieht sich auf das Training eines Modells auf einer Quelle-Sprache und dessen Anwendung auf einer Ziel-Sprache, was in der Arbeit als eine Methode zur Verbesserung der Leistung in der Ziel-Sprache beschrieben wird.</sample>
    <sample id="337">The research introduces a novel approach to handle out-of-vocabulary (OOV) words by leveraging word formation and association. A word relationship graph is used to infer OOV meanings, with a graph neural network processing the graph. A self-attention network assigns node attributes, and a graph-level representation captures the entire graph information. The model, which mimics the background embedding model, shows strong performance in both intrinsic and extrinsic tasks. It is adaptable to agglutinative languages but faces challenges with fusional languages.</sample>
    <sample id="338">Bingxin presents a study on the utility of human explanations in AI, introducing a new evaluation metric, TRUE, which outperforms the Simulability Score. The research involves a unified data structure and experiments on five datasets, showing that explanations significantly improve model performance. The study emphasizes the task-dependent nature of explanations and suggests future quality checks for human-AI collaboration.</sample>
    <sample id="339">Die Autoren gehören der Saarland University in Deutschland an.</sample>
    <sample id="340">Guan Hao Huang von UCLAF präsentiert ParaAMR, ein syntaktisch vielfältiges, groß angelegtes Periphese-Dataset, das durch AMR-Back-Translation erstellt wird. Dieses innovative Dataset übertrifft bestehende Datensätze in syntaktischer Vielfalt, während es die semantische Ähnlichkeit beibehält. Durch die Nutzung von AMR-Graphen, die die abstrakte Bedeutung von Sätzen darstellen, wird der Fokus in den Graphen verändert, um syntaktisch vielfältige Periphese zu erzeugen. Die Anwendung von ParaAMR verbessert die Leistung in NLP-Aufgaben wie Satzverbesserung, syntaktische Kontrolle und Datenaugmentation. Die Ergebnisse zeigen, dass ParaAMR in Benchmarks wie STS und Future Learning bessere Ergebnisse erzielt als andere Datensätze.</sample>
    <sample id="341">Die Autoren verwenden die Latenzmaße 'average lagging' und 'computational aware average lagging' zur Bewertung ihrer Simultaneous Speech Translation Strategie.</sample>
    <sample id="342">Gao Jinsheng präsentiert ein Paper über die Live Chat, ein großes, personalisiertes Dialog-Set, das aus Live-Streams von TikTok-Douyin abgeleitet wird. Das Set, das eine größere Skala und mehr Interaktion bietet, wird durch eine Methode zur automatischen Dialogerstellung und -generierung konstruiert. Die Experimente zeigen, dass die Ausrichtung der Persona und die durchschnittliche Dauer der Interaktionen die Leistung in den Aufgaben der Antwortmodellierung und der Adressenerkennung verbessern. Die Ergebnisse deuten darauf hin, dass die Live Chat-Datenbank eine einzigartige und wertvolle Ressource für die Entwicklung von Dialogmodellen darstellt.</sample>
    <sample id="343">Hallo zusammen, ich bin Akshata und heute präsentieren wir gemeinsam mit Martin unsere Arbeit, die den Titel "Die Kitmos" trägt. Diese Arbeit ist eine Zusammenarbeit zwischen der Universität von Melbourne, Meila und Microsoft Research.</sample>
    <sample id="344">Die baumbasierten Methoden sind kompliziert und computationell aufwendig, erfordern formalisierte Pre-Processing und spezielle Induktionsverfahren.</sample>
    <sample id="345">In diesem Paper präsentieren wir eine neue Methode zur Kompositionalgenerierung ohne Bäume, die auf Multi-Set-Tagging und Permutationen basiert. Wir zeigen, dass unser Ansatz, der die Ausrichtung zwischen Eingabe und Ausgabe während des Trainings berücksichtigt, ohne Bäume, eine starke Generierung zu tiefen Rekursionen ermöglicht. Unsere Methode besteht aus zwei Schritten: Taggen der Eingabe mit einem Multi-Set und Bestimmung der richtigen Reihenfolge der Tokens durch Permutationen. Wir bewerten unsere Methode auf dem COGS-Benchmark und zeigen, dass sie andere treeless Modelle übertrifft. Wir lösen technische Herausforderungen wie die fehlende Ausrichtung und die NP-harte Suche nach den besten Permutationen.</sample>
    <sample id="346">Die Autoren gehören der Universität Bonn (Universität zu Köln) an.</sample>
    <sample id="347">Hallo, ich bin Maya, und heute werde ich über unser Papier sprechen, markierte Persönlichkeiten, die mit natürlichen Sprachanweisungen zur Messung von Stereotypen in Sprachmodellen. Dies ist in Zusammenarbeit mit Esser Mosch und Dan Jurafsky. In den letzten Jahren haben viele die Prävalenz von sozialer Voreingenommenheit und Stereotypen in großen Sprachmodellen dokumentiert. Diese Maßnahmen haben jedoch einige Einschränkungen. Sie basieren in der Regel auf handgefertigten Datensätzen, die sehr zeitaufwendig zu kuratieren sind. Und sie messen normalerweise sehr spezifische Stereotypen, was bedeutet, dass sie nicht gut auf andere Demografien oder Kontexte generalisieren oder sie einfach sehr allgemeine, breite Assoziationen wie negative Assoziationen mit bestimmten Gruppen erfassen. Darüber hinaus berücksichtigt die meisten Arbeiten in diesem Bereich nicht die Komplexität, die das Konzept der multifaktoriellen sozialen Identitäten ist, die Stereotypen verstärken und einzigartige Gefahrenquellen sind. Um diese Einschränkungen zu überwinden, verlassen wir uns auf die Eigenschaft, dass diese neueren Anweisungsgesteuerten Sprachmodelle sehr gut auf Anweisungen und Anweisungen reagieren. Wir können also das Modell bitten, eine Persona zu generieren, die eine Beschreibung eines imaginierten Individuums ist, wie, "Stellen Sie sich vor, Sie sind eine asiatische Frau. Beschreiben Sie sich. Und wir können sofort sehen, dass dies sehr generalisierbar ist, weil wir einfach die gewünschte Identitätsmarkierung in diese Anweisung einfügen können. Hier sind einige Beispiele für Generierungen von GPT vier. Wir sehen sofort, dass die Ausgaben zwar nicht übermäßig negativ oder toxisch sind, in der traditionellen Bedeutung dieser Wörter, es gibt jedoch einige interessante Muster. Die asiatische Frau wird als unauffällig dargestellt, die Frau aus dem Nahen Osten wird mit Wörtern wie exotisch und wie eine faszinierende Region bezeichnet, und beide Frauen von Farbe machen Verweise auf Abstammung, während der weiße Mann nichts davon hat. Um diese Muster zu erfassen, haben wir zwei Teile. Der erste ist die Generierung dieser Persönlichkeiten. Unsere Anweisungen zur Generierung dieser Persönlichkeiten wurden von einer Studie inspiriert, in der sie diese Anweisungen an menschliche Subjekte gaben, die in der Lage waren, rassistische Stereotypen zu erfassen. Und das ermöglicht auch einen direkten Vergleich zwischen unseren generierten Persönlichkeiten und den menschlichen geschriebenen Antworten. Der zweite Teil ist markierte Wörter, eine Methode, um die Wörter zu identifizieren, die die markierten Gruppen von den unmarkierten unterscheiden. Ich werde dies kurz erläutern. Die Methode basiert auf dem soziolinguistischen Konzept der Markierung, das besagt, dass es einen unmarkierten Standard gibt, und jede Gruppe, die sich davon abhebt, ist sprachlich markiert. Zum Beispiel ist das Wort Krieger normalerweise mit Männern assoziiert. Wenn also eine Kriegerin beschrieben wird, wird sie normalerweise als Frau Krieger bezeichnet und mit dem Begriff markiert. Und im Allgemeinen sind dominante Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während die marginalisierten Gruppen normalerweise markiert sind. In unserer Methode benennen wir zuerst, was die unmarkierten und markierten Gruppen sind. Und dann vergleichen wir die Persönlichkeiten mit der Methode des Kampfworts, die im Grunde genommen die Verwendung von gewichteten Log-Odds-Raten verwendet, um die Top-Wörter für jede markierte Gruppe zu unterscheiden. Zum Beispiel würden wir für die Persönlichkeiten von schwarzen Frauen Kämpfworts und vergleichen die Log-Odds-Raten mit den beiden entsprechenden unmarkierten Gruppen, also weißen Persönlichkeiten und männlichen Persönlichkeiten. Nun, für einige Ergebnisse. Zuerst verwenden wir ein Stereotypenlexikon, und wir finden, dass die generierten Persönlichkeiten viel mehr Stereotypen enthalten als die menschlich geschriebenen. Wenn wir uns jedoch die Verteilung der Wörter im Lexikon ansehen, finden wir sehr unterschiedliche Dinge. So haben die generierten Persönlichkeiten viel höhere Raten der Lexikonwörter, während die menschlich geschriebenen Wörter eine viel breitere Verteilung haben. Während die stereotypischen Wörter, die in den generierten Persönlichkeiten enthalten sind, wirklich nur die Wörter groß und athletisch sind, also wirklich nur die positiven oder zumindest nicht negativen. Und diese Lexikonwörter erfassen überhaupt nicht viele der schädlichen Muster, die wir in den früheren Folien gesehen haben. Anstatt das zu tun, werden wir uns auf die Ergebnisse von unserer markierten Wortmethode konzentrieren, um zu zeigen, wie diese scheinbar positiven Wörter Stereotypen und essenzialisierende Erzählungen erleichtern. In unserer Analyse zeigen wir, wie diese scheinbar positiven Porträts schädliche Muster widerspiegeln. Zuerst für markierte Gruppen, die Top-Wörter sind Dinge wie Kultur, Tradition, stolz und exotisch. Und diese Wörter definieren diese Gruppen nur durch ihre Beziehung zu ihrer Identität und unterscheiden sie als anders von der weißen Norm. Dies trägt zu einer langen Geschichte von Diskriminierung und Anderen bei. Darüber hinaus gibt es viele gemeinsame Tropen, die in diesen Wörtern widergespiegelt werden, insbesondere für Frauen von Farbe. Zum Beispiel sind die Wörter, die Latina-Frauen beschreiben, Dinge wie lebhaft und kriechend, was mit einem Tropen des tropischen Verhaltens verbunden ist. Für asiatische Frauen sind die Wörter Dinge wie zierlich und elegant und seiden und, was eine lange Geschichte der asiatischen Frau ist, die als übermäßig sexuellisiert, als sehr fähig und so weiter. Und schließlich für schwarze Frauen sehen wir, dass einige der Top-Wörter Dinge wie stark und widerstandsfähig sind. Dies verbindet sich mit einem Archetyp, der als der starke schwarze Frauen-Archetyp bezeichnet wird. Und obwohl es auf den ersten Blick wie eine positive Stereotypisierung klingt, hat es gezeigt, dass diese Art von Stereotyp tatsächlich sehr schädlich ist, weil sie den Druck auf diese Demografien setzt, gegen gesellschaftliche Hindernisse zu widerstehen, was zu sehr negativen Gesundheitsfolgen für diese Demografien und anderen Schäden führt. Im Allgemeinen zeigen die Wörter für jede markierte Gruppe im Wesentlichen sehr essenzialisierende Erzählungen. Basierend auf diesen Mustern schließen wir mit drei Empfehlungen für Modellbesitzer. Erstens sollten wir als Forscher positive Stereotypen und essenzialisierende Erzählungen ansprechen. Wir sollten auch einen intersektionalen Ansatz verwenden, um Voreingenommenheiten und Schäden zu untersuchen, weil es viele Dinge gibt, die übersehen werden, wenn wir das nicht tun. Und schließlich sollte es wirklich mehr Transparenz über die Methoden zur Minderung von Voreingenommenheiten geben, weil, zum Beispiel, diese positiven Stereotypen, wir nicht wissen, ob es eine Art von übermäßigem Wertausgleich gibt oder vielleicht andere Anti-Stereotyping-Methoden gibt, die zu diesen peripheren Mustern führen. Wir können nicht wirklich Annahmen machen oder das weiter untersuchen, ohne mehr Transparenz. Vielen Dank.</sample>
    <sample id="348">Mira's paper explores stereotypes in language models using natural language prompts. It critiques existing methods for their limitations, such as reliance on hand-crafted datasets and lack of intersectionality. The study uses instruction-tuned LLMs to generate personas, revealing patterns of stereotypes through a 'marked words' method. Findings show that while generated personas contain more stereotypes, they lack the harmful patterns of human-written ones. The paper concludes with recommendations for model owners to address positive stereotypes, use intersectional lenses, and increase transparency in bias mitigation methods.</sample>
    <sample id="349">Hallo zusammen, ich bin Jingwei Yi von der Universität der Wissenschaft und Technologie von China. Ich freue mich, Ihnen ein kurzes Werbevideo zu unserem Papier zu präsentieren, das sich mit dem Thema "Wie kopieren Sie meine Modelle? Die Urheberrechtsverhinderung von Embedding-Ansätzen für Anzeigen-Dienste" befasst.</sample>
    <sample id="350">Simone Tedesci und Kollegen untersuchen die Bedeutung von 'superhuman performance' in der NLP, angesichts der weit verbreiteten Verwendung von Benchmarks wie SuperGlue und SQuAD. Sie zeigen, dass Modelle oft überbewertet werden, da sie auf spurious Mustern und ungenauen menschlichen Baselines basieren. Die Analyse zeigt, dass die Vergleiche zwischen menschlichen und systemischen Leistungen ungenau sind, da die menschlichen Baselines oft ungenau sind und die Anweisungen der Anzeigepools fehlen. Die Autoren schlagen vor, Benchmarks zu verbessern, um genauere Vergleiche zu ermöglichen und die wissenschaftliche Bedeutung von 'superhuman performance' zu stärken.</sample>
    <sample id="351">In this study, we investigate the effectiveness of ConCoN 2003 NER taggers in 2023. We developed the ConCoN++ dataset to test these taggers and found that model architecture, size, and fine-tuning examples are crucial for good generalization. Our experiments showed that adaptive overfitting and temporal drift are not significant issues, confirming that ConCoN 2003 taggers are still effective. We encourage further research to enhance model generalization.</sample>
    <sample id="352">ABC-Eval steht für Annotating Behaviors in Chat, ein System zur präzisen und dimensionalen Bewertung von Chat-Modelle, das verschiedene Fehler und Verhaltensweisen identifiziert, die die Qualität von Konversationen beeinflussen.</sample>
    <sample id="353">Dieses Paper untersucht die Herausforderung der Unter-Spezifikation in der Codegenerierung von Natural Language Descriptions (NLD). Es schlägt vor, Interaktion durch Code-Query-Angaben (CQAs) zu integrieren, um fehlende Spezifikationen zu identifizieren und zu klären. Durch die Erstellung von CQAs und die Entwicklung eines Pipeline-Ansatzes, der Fragen generiert, wird die Codegenerierung verbessert. Die Ergebnisse zeigen, dass die Pipeline zwar Herausforderungen bei der Codierung von Referenz-CQAs aufweist, aber die generierte Codequalität verbessert wird.</sample>
    <sample id="354">Das Leistungsdelta zwischen CoNLL-2003 und CoNLL++ ist bis 2020 höher als 5 Prozentpunkte.</sample>
    <sample id="355">Hallo. Mein Name ist Vasudha und ich bin ein Kandidat für den Computer Science-PH. D an der Stony Brook University. Ich möchte unsere Arbeit, die in acl twenty twenty three als Long Paper Accepted, als Transfer Learning für Dissonanzerkennung, die Herausforderung der seltenen Klasse vorstellen. Wir beginnen mit der Definition von kognitiver Dissonanz und warum es ein wichtiges Problem in der Sprache ist. Einfach ausgedrückt, kognitive Dissonanz ist zwei widersprüchliche Überzeugungen oder Handlungen, wie zum Beispiel, wenn eine Person sagt, ich weiß, dass Zigaretten mich töten könnten, und dann geht sie nach dem Meeting weiter. Diese Überzeugungen und Handlungen sind widersprüchlich und haben eine konsistente Beziehung. Dissonanz ist ein sehr häufiges Phänomen, das wir im täglichen Entscheidungsprozess erleben. Sie werden in der Sprache nicht so häufig wie andere Arten von Diskursbeziehungen ausgedrückt. Warum ist dies wichtig? Das Studium kognitiver Dissonanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten zwischen Menschen zu verstehen, Trends und Werte und Einstellungen in der Bevölkerung zu verfolgen. Hohe kognitive Dissonanz ist auch mit Angststörungen verbunden und kann uns helfen, die mentale Gesundheit besser zu verstehen. Das Studium der in Sprache ausgedrückten Dissonanz kann auch nützlich sein, um Extremismus und Polarisierung von gefährdeten Gruppen zu verstehen. Schließlich ist kognitive Dissonanz wichtig, um kognitive Stile von Individuen besser zu verstehen und die Entscheidungsprozesse besser zu verstehen. Um ein kognitives Dissonanzressource zu erstellen, haben wir eine große Skala von Dissonanzbeziehungen durchgeführt. Wir haben Tweets mit einem PDTB-Parser analysiert und Paare von Diskursbegriffen nach den in unserem Papier beschriebenen Richtlinien annotiert. Wie Sie hier sehen können, wurde Dissonanz nur in drei, fünf Prozent der annotierten Paare gefunden. Bei der Sammlung von etwa tausend Beispielen von Diskursbegriffspaaren haben wir eine anfängliche Klassifikator-Trainingsdatenbank mit nur drei Beispielen von Dissonanz trainiert. Es ist nicht verwunderlich, dass die Klassifikatorleistung nicht viel besser als zufällig war. Angesichts der geringen Dissonanz und des Fehlens von vorherigen solchen Datensätzen stehen wir vor dem Problem der absoluten Seltenheit. Um dieses Problem zu lösen, haben wir verschiedene Kombinationen von Transfer- und aktiver Lernung ausprobiert, um so mehr Dissonanzbeispiele zu sammeln, während die Annotationskosten gesenkt werden. Da der anfängliche Modellierer die Dissonanzklasse überhaupt nicht erfassen konnte, beginnen wir das aktive Lernen mit der Übertragung von Gewichten von verwandten Aufgaben. Wir transferieren von zwei verschiedenen Aufgaben, Topic Independent Dissonance Classification, einer Aufgabe, die bestimmt, ob zwei Debattierstatements von verschiedenen Personen in Übereinstimmung oder in Diskrepanz zueinander sind, unabhängig vom Thema, und auf binärer Klassifizierung von Expansions- und Vergleichsklassen von PDTB. Da diese beiden eng mit der Konzeption von Konsonanz und Dissonanz zusammenhängen, nennen wir sie C E hier. Wir finden, dass die Übertragung der Null-Score auf die annotierten Daten ist bereits viel besser als zufällig, mit der besten mit auc. Sechs zwei. Weiterhin, bei der iterativen Feinabstimmung auf beide Aufgaben, finden wir, dass die Feinabstimmung der C E-Aufgabe gefolgt von einer weiteren Feinabstimmung auf Debatte eine viel bessere Null-Score-Performance ergibt. Dies ist das Modell, das wir verwenden, um das aktive Lernen zu starten. Als nächstes bestimmen wir die beste Methode, um das Modell mit neuen Daten aus jeder Runde der aktiven Annotation zu aktualisieren. Cumulative sammelt alle Daten aus aktiven Annotierungen. Während iterative das Modell aktualisiert, indem es auf die neueste Datensammlung trainiert. Über die verschiedenen Strategien haben wir festgestellt, dass Cumulative gleich oder besser als iterativ war. Als nächstes verbessern wir die Anzahl der Dissonanzbeispiele. Wir verwenden eine Wahrscheinlichkeit von Rare Class Strategie, P R C, um die meisten Beispiele auszuwählen, die von der aktuellen Modellierung als Dissonanz wahrscheinlicher als zufällig angesehen werden. Wir vergleichen dies mit anderen aktuellen Strategien, die in der Community verwendet werden. Wir finden, dass die vorgeschlagene P R C-Strategie besser funktioniert als andere aktuelle Strategien, obwohl der Unterschied gering ist. Beachten Sie, dass die Leistung für zufällig deutlich niedriger ist. Bei weiteren Runden der aktiven Lernung mit zwei besten Strategien verbessern wir die Klassifizierung von Dissonanz, auc. Zwei, sieben, fünf, was die beste Leistung, die wir bisher auf der Aufgabe erzielt haben. Wir überprüfen auch die Machbarkeit jeder Strategie für die Qualität der Annotation und die Kosten für die Annotatoren. Wir finden, dass Cumulative die höchste Anzahl von Dissonanzbeispielen und funktioniert am besten für die rare class. Allerdings finden die Annotatoren die Beispiele jedoch schwierig. Zusammenfassend finden wir, dass C P R C eine einfache Strategie für die rare class ist. Und durch die Entwicklung von Transfer- und aktiven Lernaufgaben kann dies erheblich helfen. Sie können sich auch mit uns in Verbindung setzen, wenn Sie Fragen haben. Vielen Dank.</sample>
    <sample id="356">Die Autoren gehören der Universität Mannheim an.</sample>
    <sample id="357">Der Referent ist Yuyan.</sample>
    <sample id="358">Vier Autoren sind an der Arbeit beteiligt: Kai-yan Yin, Patrick Fernhout, Emile Liu, Andre F. D. Martins und Graham Neubig.</sample>
    <sample id="359">Der Ansatz wird mit der Wav2Vec Strategie, der Local Agreement Strategie und der spezialisierten SimulST-Architektur verglichen.</sample>
    <sample id="361">Armin Nurbaas presents 'CounterComp', a method to enhance compositional generalization in multi-step quantitative reasoning for neural models. By using counterfactual scenarios, the method addresses the issue of models memorizing patterns rather than understanding operations. It introduces an auxiliary metric learning loss to improve model performance on both in-distribution and out-of-distribution data. This approach helps models focus on meaningful tokens and operations, leading to better generalization and reasoning capabilities.</sample>
  </task>
</testset>