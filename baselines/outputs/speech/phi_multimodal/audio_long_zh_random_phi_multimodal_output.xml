<testset name="IWSLT2025" type="output">
  <task track="long" text_lang="zh">
    <sample id="0">语言模型的主要数据来源是大量的网络爬虫数据，其中包括政治新闻媒体的内容。</sample>
    <sample id="1">这篇论文的作者所属机构是麦吉尔大学。</sample>
    <sample id="2">Tui Wei介绍了Ed Group团队的论文，专注于文档理解问题。该论文提出了一个名为Layout Mask的新预训练模型，旨在解决文档预训练模型中常见的问题。Layout Mask使用了1D位置和2D位置，并通过新的预训练目标来增强文本和布局的相互作用。该模型通过全词掩码和布局感知掩码策略来促进文本和布局的相互作用。实验表明，Layout Mask在SROIE和CLUE上表现优于使用全球1D位置的模型。论文的更多细节可以在论文和相关资料中找到。</sample>
    <sample id="3">欢迎来到德语文本简化的深层演示。我的名字是Regina Stoddens，我将引导您完成演示的第一部分。让我们首先定义文本简化。文本简化是适应特定目标群体的文本，以便非母语人士更好地理解文本。为训练文本简化模型，我们需要文本对齐的对齐。比如在这里，你可以看到一个对齐的句子对齐，复杂的德语句子和它的翻译成简单语言。要简化句子，我们可以使用不同的技术。例如，在示例中，你可以看到不同的简化技术。我们现在提出我们的新语料库D-Plain。因为近年来存在一些语料库的问题。例如，这些语料库太小，无法训练文本简化模型。其他语料库都是自动对齐的，这意味着它们可能会出错。我们提出了一个新的语料库D-Plain，它分为两个子语料库：D-Plain APA和D-Plain Web。D-Plain APA是基于新闻文本的。我们在D-Plain APA中手动对齐了483篇文档，得到大约30,000个对齐的句子对齐。对于D-Plain Web，语料库包括不同的域。我们手动对齐了750篇文档，另一边使用自动对齐方法。总共我们得到30,450个句子对齐。我们分析了我们的句子对齐。比如，圣经文本的简化比新闻文本或语言学习文本更强。所有级别都在简化的各个层面上都很强。我们现在看到D-Plain语料库有很多不同的简化转换。例如，在D-Plain APA语料库中，我们有更多的重排序和单词添加，而在D-Plain Web语料库中，我们有更多的重词法。另一方面，在Web语料库中，我们有更多的重词法。现在让我们看看我们能用这个语料库做什么。</sample>
    <sample id="4">演讲者的名字是Kyowin。</sample>
    <sample id="5">他们使用 T5-large 模型获得 82%-87% 的准确率。</sample>
    <sample id="6">Zhang and colleagues present a unified model called many-to-many summarization, which can generate summaries in any language from a source document. This model combines multilingual and cross-lingual summarization, improving knowledge transfer across languages. They propose a model named PACE, trained through a three-stage process, outperforming previous models like MBERT50 and MT5. Their work is supported by experiments and human studies, with more details in their paper.</sample>
    <sample id="7">根据研究，CoNLL-2003 标注器在 2023 年仍然有效，但需要改进的方面包括更好的模型架构、大小和更多的训练数据。</sample>
    <sample id="8">ABCEval的新颖之处在于它通过明确标记模型行为来减少人类评估的主观性，并能够更精确地评估多方面的聊天质量。它比现有方法更具预测性，并且能够识别出聊天质量的不同方面。</sample>
    <sample id="9">现有弱监督方法的成功在很大程度上依赖于额外的清洁验证数据。</sample>
    <sample id="10">要提高分数，可以通过多次复习、寻求教师帮助、参加辅导班、利用学习资源、制定学习计划、保持积极态度和良好的时间管理来实现。</sample>
    <sample id="11">Jack Hessle, a research scientist at AI2, presented a talk on humor understanding benchmarks using the New Yorker Caption Contest data. The presentation highlighted the capabilities of large language models like GPT-4 and CLIP in generating and explaining jokes. Despite advancements, models still struggle with understanding humor, as evidenced by their performance in tasks like matching and quality ranking, where humans outperform by a significant margin. The presentation also discussed the limitations of GPT-4, which, even with human-authored image descriptions, cannot match human performance in humor-related tasks. The talk concluded with an invitation for further exploration of the dataset and models available online.</sample>
    <sample id="12">这篇论文有四位作者。</sample>
    <sample id="13">Daniel Rotem介绍了他的研究，探讨了在低资源环境中使用Adaptive Inference的优化方法。Adaptive Inference通过使用不同的模型来减少计算成本。Multi-Model和Early-Exit是两种常见的方法。Multi-Model具有多种优点，但需要大量存储空间和处理过多的计算。Early-Exit更快，但可能会因为参数共享而降低性能。研究发现，Multi-Model在性能上优于Early-Exit，特别是在较早的分类器中。为了解决这个问题，Rotem提出了Suite方法，该方法通过分离Early-Exit的层更新，避免了性能下降。Suite在速度和准确性方面表现出色，提供了新的研究方向。</sample>
    <sample id="14">Adam Szarkowski的演讲是关于协调结构的依赖关系结构。您可能知道不同的依赖关系结构由不同的理论和科普斯方法假设。例如，在通用依赖关系中，协调结构的结构是由第一个主语领导的。在Meaning-Text理论中，协调结构的结构也由第一个主语领导。因此，这两种方法是对称的。它们单出一个主语。现在还有对称的协调结构方法,例如Prag的协调结构方法,在Prag依赖关系树中假设协调结构由连接符领导。因此,我们从连接符到所有主语的依赖关系。最后,有一个多头方法,例如在Dikmans词法中,所有主语都是协调结构的头部。因此,我们得到从主语到主语的依赖关系。现在,这篇论文的目的是提出对这些对称结构的同义结构和反对不对称结构的论点。基于这些例子的原则。</sample>
    <sample id="15">这篇论文有三位作者。</sample>
    <sample id="16">在D-Plain的分析中，圣经文本的简化程度更大。</sample>
    <sample id="17">Shen Chuan Wu介绍了一个用于多模态关系提取的框架，旨在通过结合文本和图像信息来解决文本中信息过载和缺乏外部信息的问题。该框架包括五个部分：文本和图像的表示、合并成一个统一的cross-modal graph（CMG）、CMG的筛选和调整、使用图信息指导的优化、使用多模态主题信息的增强。通过实验表明，该方法在MRE任务上比现有方法更有效。</sample>
    <sample id="18">示例包括“Salt and pepper”和“not pepper and salt”。</sample>
    <sample id="19">Shanshan Chen, a master student from Shenzhen University, presented her work on efficient open domain question answering at ACL 2023. The work focuses on a two-stage model for question answering, which involves retrieval and reading stages. The retrieval stage uses a document encoder to index the Wikipedia corpus, while the reading stage uses a question encoder to understand the question and retrieve evidence for answering. The challenges in open domain question answering include the large size of the Wikipedia corpus, the large index file, and the multiple language models with millions of parameters. To address these challenges, the work proposes efficient techniques such as approximate nearest neighbor search, skipping rate, document filtering, embedding compression, and model size reduction. The work also compares existing open domain question answering models and concludes that retrieval and reader systems are suitable for real-time feedback, while generator-only systems are better for resource-constrained devices. The future work includes deploying open domain question answering systems in low-power devices and considering more evaluation metrics.</sample>
    <sample id="20">是的，你可以使用这些模型。所有预训练模型和训练脚本都是免费提供的，可以在 Hugging Face 上找到。</sample>
    <sample id="21">DEplain-apa 包含来自新闻文本的内容。</sample>
    <sample id="22">Three main factors aid in good generalization: model architecture, with transformer models performing better; model size, where larger models lead to better generalization; and the number of fine-tuning examples, which also improves generalization.</sample>
    <sample id="23">Dan Garrett discusses improving text rendering in text-image models. Despite advances in image generation, models like T5 struggle with text due to sentence piece tokenization. Experiments show T5's poor spelling, while ByteT5 excels with full character access. Augmenting T5 with ByteT5's text representation improves text rendering, though errors can still occur.</sample>
    <sample id="24">左并列词的长度衡量通过计算两个词的总长度来衡量。通过比较不同结构中的总长度，研究发现左并列词的长度通常较短。</sample>
    <sample id="25">设计实验需要考虑支配词的位置（左、右或中间），并在不同位置下测试不同的句子结构。实验应包括多种句子类型和长度，以确保结果的广泛性。数据分析应比较不同位置下的句子结构，特别关注左支配词的长度和位置对句子整体流畅度的影响。</sample>
    <sample id="26">基线分类器在不平衡数据上的训练效果不佳，表现不比随机猜测好。</sample>
    <sample id="27">这篇论文有五位作者。</sample>
    <sample id="28">Bob和Alice</sample>
    <sample id="29">MT 模型在语境感知方面比语境无关模型更有优势的现象包括：1. 语境感知的形式ality 2. 语境感知的 lexical cohesion 3. 语境感知的 ellipsis resolution</sample>
    <sample id="30">我们介绍了Blender，这是一个简单而有效的集成学习框架，专为大型语言模型设计。Blender的核心思想是基于权威排名和生成融合。我们来自AI2和USC的团队，Yuchen Lin是我们的代表。每周发布的许多大型语言模型中，许多模型声称已经取得了良好的性能。然而，只有平均整体性能。对于特定输入示例，使用单个顶级模型可能不最佳。我们的研究表明，最佳模型在不同输入示例中可能会大相径庭。Blender的两个阶段框架包括：首先，运行N个模型并获取输出y1到yn。然后，使用PowerRanker进行比较，使用Roberta等交叉熵模型来学习对输入X的最佳候选。最后，使用前两个阶段的输出作为输入，使用生成性融合模型生成最终输出。PowerRanker的关键区别在于编码阶段。与前面的方法相比，PowerRanker同时对输入X和候选对进行编码，以更好地分析候选之间的微妙差异。我们认为PowerRanker是一个更好的解决方案，因为它使用并行比较来学习和评估候选的质量，并更仔细地比较候选。通过PowerRanker获得的比较结果可以构建一个矩阵，其中每个元素表示候选I比候选J更好。我们发现使用矩阵来汇总结果是最好的解决方案，但如果效率是一个问题，可以使用Bubble Sort算法。我们的实验表明，PowerRanker在各种相关性指标上比其他排名方法更好。为了评估集成学习框架，我们创建了一个新的数据集，名为Mix-Inst。它包含现有的训练数据集，并从11个开源大型语言模型中收集候选。我们使用BLEUARTB作为评估器。实验结果表明，Blender的前两个模型的性能在所有四个指标上都明显低于PowerRanker和Blender。Blender的结果在68%和76%的例子中与OpenAssistant和WACUNA相匹配。Blender是一个非常有前途的框架，尽管它很简单和直截了当。</sample>
    <sample id="31">作者所属机构是ACL 2023会议的组织者。</sample>
    <sample id="33">NL-Positionality框架通过重新标注数据集，使用来自Lab in the Wild的多样化参与者的意见，并通过Pearson's R-相关系数与模型和数据集进行比较。</sample>
    <sample id="34">Marcus Trevisio介绍了Crest，一个结合了选择性合理化和生成反事实的框架。Crest通过使用合理化模型生成合理化和反事实，并通过编辑模型生成反事实。通过对MNLI和IMDb等数据集的测试，Crest在数据增强方面表现优异，尤其在AutoDomain数据集上。通过对合理化的可解释性进行三维分析，Crest的合理化被证明比其他方法更具可解释性和可模拟性。</sample>
    <sample id="36">在ACL会议上，Tomasz Pazdzki介绍了一个用于多语言机器翻译的语言特定层（LSL）技术。该技术的目标是提高每种语言的模型容量，同时保持计算成本不变。通过在模型中使用一个语言特定的转换器层，模型可以在训练和推理时选择正确的子层。研究人员通过在模型中使用三个不同的权重（共享、源和目标）来学习最佳LSL的放置。通过这种方法，研究人员在10种语言上进行了实验，包括一些欧洲语言、亚洲语言和低资源语言。结果表明，使用LSL的模型在所有语言上都有显著的性能提升，特别是对低资源语言有显著的改善。</sample>
    <sample id="37">研究发现，受试者能够表面化出种族主义的刻板印象。</sample>
    <sample id="38">该研究使用了EnhancedPENCTB和CIDA数据作为数据来源。</sample>
    <sample id="39">这篇论文有四位作者。</sample>
    <sample id="40">与认知失调相关的任务包括：1. 识别和分析语言中表达的认知失调。2. 通过数据集训练初始模型。3. 通过转移学习从相关任务中提取知识。4. 通过活动学习不断更新模型。5. 评估不同策略的效果。</sample>
    <sample id="41">Su Lin from EPFL's Natural Language Processing Lab presents Peacock, a project in collaboration with Sony Group Corporation, aimed at enhancing narrative systems with personal knowledge. Peacock is a graph-based knowledge representation with 3,800 personas and 40,000 attributes, facilitating rich, interconnected personal knowledge. It is built through three steps: selecting personas, inducing attributes, and annotating relations via AI-human majority voting. Peacock outperforms large-scale language models in generating natural language, especially in dialogue, by providing a reliable knowledge base for personal attribute inference. The project highlights the importance of interconnected world-personal knowledge in narratives.</sample>
    <sample id="42">这篇论文有两位作者。</sample>
    <sample id="43">这篇论文有四位作者。</sample>
    <sample id="44">NL-Positionality Framework与以前的研究不同之处在于它直接比较用户的输入与模型和数据集的输出，而不是仅仅关注原始数据集的标注者的分布或模型的分布。通过使用 Pearson's R correlation score，它比较了用户的输入与模型和数据集的输出，提供了对数据集和模型偏见的更直接的见解。</sample>
    <sample id="45">在三个比较设置中，Latina woman的设置与刻板词汇的重叠最多。</sample>
    <sample id="46">在比较不同商业系统时，研究表明DeepL通常比Google Translate在文档级别的翻译中表现更好。</sample>
    <sample id="47">Shengbing PhD学生在华盛顿大学今天介绍了从预训练数据到语言模型再到下游任务的工作。追踪政治偏见导致不公平的NLP模型的轨迹。语言模型在大量Web爬数据上训练。政治新闻媒体在其预训练数据中得到了很好的覆盖。根据C4语料库的调查，我们可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《哈芬邮报》等在语言模型训练数据中得到了很好的覆盖。这对语言模型应用来说是双刃剑。一方面，它们能够从多元观点中学习，庆祝民主和多元观点。另一方面，这些不同的政治观点本质上是社会偏见，可能导致下游任务应用中的公平性问题。因此，我们提出了一个问题：如何评估语言模型的政治倾向以及预训练数据可能对政治偏见产生的影响？其次，语言模型具有不同的政治倾向如何在下游任务中表现，是否会导致公平性问题？因此，我们首先提出使用政治问卷等政治问卷来提示语言模型不同的提示格式。这样我们就可以自动评估。根据政治学文献进行评估。我们初步的结果表明，首先，语言模型确实具有不同的政治倾向。它们占据了政治地平线上的所有四个极端。我们还看到GPT4是所有语言模型中最自由的。GPT系列通常比BERT系列和其变体更具社会自由主义。其次，我们旨在研究语言模型的政治偏见到底是从训练数据中吸收的。为此，我们进行了一项控制实验。通过进一步预训练语言模型检查点，分为不同的党派和体制。进一步分为新闻和社交媒体，进一步分为不同的政治倾向。通过进一步预训练语言模型检查点，我们可以看到语言模型的意识形态也会相应地改变。例如，Roberta在进一步训练左翼leaning的Reddit体制时，明显的政治偏见会发生显著的自由主义转变。我们还试图研究语言模型是否能捕捉到现代社会的两极化。为此，我们将预训练体制分为前四十五任总统和后四十五任总统。我们分别对两种不同的时间体制进行预训练。我们可以看到，语言模型的政治倾向通常会远离中心。这样可以说明语言模型也能捕捉到我们社会的两极化。最后，我们评估了具有不同政治倾向的语言模型在NLP应用上的表现。我们发现，如果我们将语言模型的表现分为不同的类别或新闻媒体的政治倾向，我们可以看到一个模式。例如，在针对社会少数群体的仇恨言论检测方面，左翼leaning的语言模型表现更好。然而，针对权力群体的仇恨言论检测则表现较差。相反，右翼leaning的语言模型在检测权力群体的仇恨言论方面表现更好。然而，检测对黑人工人种、LGBTQ+和其他少数群体的仇恨言论表现较差。类似的趋势也发生在虚假新闻检测方面。我们发现，左翼leaning的语言模型在检测对立政治倾向的虚假新闻方面表现更好。相反，右翼leaning的语言模型在检测对立政治倾向的虚假新闻方面表现较差。我们进一步提供了许多的例子来说明，具有不同政治倾向的语言模型会给出不同的仇恨言论和虚假新闻的预测。对于这一点，附录中有更多的例子。这样的发现表明，语言模型的政治倾向确实会导致公平性问题。比如，如果我们将右翼leaning的语言模型用于检测仇恨言论或虚假新闻，并部署到一个受欢迎的社交媒体平台上，这将意味着人们持有相反的政治观点可能会被边缘化。仇恨言论针对少数群体可能会在没有任何控制的情况下猖狂。这样的发现就发出了警钟。我们希望认识到并解决语言模型政治偏见造成的公平性问题。最后，我们还讨论了语言模型政治偏见的独特的困境。就像Cila和Krypdis一样。如果我们不清除语言模型训练数据中的政治意见，偏见就会从预训练数据传递到语言模型再到下游任务，最终造成公平性问题。如果我们试图清除，可能会引发审查或排斥。很难确定什么是中立的语言模型训练数据。就像电动手推车问题一样。</sample>
    <sample id="48">这篇论文有五位作者。</sample>
    <sample id="49">MPP 评估最多涵盖了 1024 个词元的上下文长度。</sample>
    <sample id="50">DeepLinguistics推出了一个名为DeepLinguistics的德语文本简化工具。该工具旨在通过简化文本来提高非母语读者的理解。该工具包含两个子库：DeepLinguistics API和DeepLinguistics Web。API基于新闻文本，包含483个手动对齐的文档，约13万个句子对。Web库包含750个文档，使用手动和自动对齐方法，约30,450个句子对。该工具还用于评估自动对齐方法，并提供了一个基准用于未来的自动文本简化。</sample>
    <sample id="51">他们的数据集包含音乐、书籍和食谱三个领域。</sample>
    <sample id="52">Positionality是指个人由于其背景、身份和生活经历所持有的特定观点或立场。它在女权和酷儿学术领域中广泛使用，影响研究过程和结果，因为它可以影响研究者的决策。</sample>
    <sample id="53">演讲者的名字是Dawie。</sample>
    <sample id="54">Vasudha Vasudha是一名计算机科学博士候选人，介绍了她在ACL 2023的论文《转移学习解决罕见类挑战》。她定义了认知辩论，强调其在语言中的重要性，研究人类决策和极端主义。她的研究涉及对辩论关系进行大规模标注，发现辩论类的罕见性。为了提高模型性能，Vasudha使用了转移和活动学习。她从两个相关任务中转移权重，并通过PRC策略选择罕见类示例。最终，PRC策略在性能上表现最佳，但需要更多的标注。</sample>
    <sample id="55">是的，EDAtt 适应了现有的离线 ST 模型，通过不重新训练这些模型，并使用单个模型处理不同的延迟要求。</sample>
    <sample id="56">这篇论文有11位作者。</sample>
    <sample id="57">是的，被测模型在测试套件上运行，但需要特定的任务训练才能有效地处理知识融合。</sample>
    <sample id="58">KITMUS 有三个变体：背景预训练、背景预训练和背景两者结合。</sample>
    <sample id="59">Yanis Slavrak presented Dr. Bert, a French biomedical model, highlighting its performance on 11 biomedical tasks. The model, based on the pre-trained Roberta, was trained on the large-scale medical corpus known as Natus. Comparisons were made with other models, including Camembert and clinical models, showing Dr. Bert's superior performance on tasks with similar data. The presentation also discussed the impact of data size and pre-training strategies, concluding that specialized data yields better results, though it doesn't scale well. All models and scripts are available on Hugging Face and GitHub.</sample>
    <sample id="60">Javad Hosseini, Philip Radlinsky, Silvia Parisi, and Annie Churvis.</sample>
    <sample id="61">最后一个研究问题是：是否应该仅使用清洁样本进行验证，还是有更好的利用方法？</sample>
    <sample id="62">In this paper, the authors explore knowledge distillation for natural language generation (NLG) to address the challenge of compressing large models while maintaining performance. They focus on task-specific distillation, using a medium-resource dataset and emphasizing efficiency. The study compares encoder-decoder and decoder-only architectures, examines the impact of pruning, and evaluates different pseudo-target generation methods. They introduce joint teaching, a novel technique that applies word-level knowledge distillation to both teacher and student pseudo-targets, aiming to mitigate exposure bias and improve student learning.</sample>
    <sample id="63">指标灵敏度衡量模型在不同任务命令变体下的输出一致性。它衡量模型是否能在不同命令变体下产生相同的输出，反映了其对命令变体的灵敏度。</sample>
    <sample id="64">Jingwei Yi</sample>
    <sample id="65">更高的灵敏度表明模型在处理相同任务时产生一致输出的能力增强，这表明了模型性能的提高。</sample>
    <sample id="66">这篇论文探讨了数学推理的深度学习方法，重点是解决数学问题和证明定理。它讨论了视觉和表格上下文的两个主要类别，并介绍了使用深度学习模型解决数学问题的概念。论文提到了第二序序模型、LLMs和自一致性等技术，并指出了LLMs在数学推理中的局限性。论文还提到了在不同语言和领域建立数学推理基准的努力。</sample>
    <sample id="67">The discussion focuses on interference in multilingual translation models, where small models suffer more interference. Key factors include model size and data size, with language similarity having minimal impact. Severe interference occurs in small models, mitigated by scaling and tuning temperature. The study uses multilingual models to show that tuning temperature is crucial for performance, and interference can be reduced without specialized methods.</sample>
    <sample id="68">在预训练期间，模型会接收来自不同数据集的语言上下文。</sample>
    <sample id="69">在 WSL 中，通常需要 20 个干净的验证样本才能获得良好的表现。</sample>
    <sample id="70">这篇论文的作者Myra是加州大学伯克利分校的教授。</sample>
    <sample id="71">Javad Hosseini, along with Philip Radlinsky, Silvia Parisi, and Annie Churvis, is working on resolving indirect referring expressions for entity selection. The project aims to understand user language in choosing between options, like songs, using direct or indirect references. They collected a dataset through crowd annotation, covering music, books, and recipes, with a focus on informality. The dataset includes 6000 questions and 42000 expressions, showing varying accuracies based on the model's access to background knowledge.</sample>
    <sample id="72">新方法需要开发是因为现有的媒体偏见衡量方法可能无法准确捕捉媒体内容的多样性和复杂性。传统方法可能过于简单，无法反映媒体内容的多元化和深度。新方法可以更全面地评估媒体内容，确保公平和准确的媒体偏见评估。</sample>
    <sample id="73">演讲者的名字是Akshata。</sample>
    <sample id="74">Xiangqingsheng, along with co-authors, introduces a paper on constructing Dense Atomic from Atomic. Atomic, a large-scale commonsense knowledge base, has limited multi-hop paths due to its structure. Dense Atomic, built on Atomic, includes more multi-hop paths and improved knowledge coverage. The construction involves three main steps: normalized events, relation prediction, and Dense Atomic construction. The paper proposes a new method, RSKGC, to predict missing links in Atomic, which outperforms existing methods. Dense Atomic shows higher logic coverage and better multi-hop path accuracy, enhancing commonsense reasoning.</sample>
    <sample id="75">Zhengyan Dan presents a joint work on joint NER and RE tasks, highlighting the need for a semi-supervised approach due to the labor-intensive nature of fully supervised models. The work proposes a joint framework that models NER and RE tasks by propagating labels over heterogeneous graphs, considering interconnections between labeled and unlabeled data. The method involves four parts: span feature generation, heterogeneous graph construction, joint label propagation, and model optimization. Experiments show that joint learning benefits from task co-dependency, with significant improvements over single-task baselines.</sample>
    <sample id="76">政治偏见传播流程从语言模型的预训练数据开始，语言模型在这些数据中学习不同的政治观点。然后，在下游任务中，语言模型的不同政治倾向会影响其性能，可能导致公平性问题。</sample>
    <sample id="77">这段视频介绍了由耶鲁大学和微软研究院合作完成的工作，旨在通过自然语言反馈提高总结的事实一致性。该工作包括开发一个名为Defact的新数据集，收集了人类反馈和说明，以改进总结模型的事实一致性。研究提出了三个新的NLG任务：摘要编辑、反馈生成和自动事实纠正。研究还展示了对XSUM数据集的分析，发现了大约70%的数据点存在事实错误。研究还发现，虽然人类编辑后的摘要在自动事实评分上表现更好，但与原始摘要的文本重叠度较低。研究还提出了一个自动纠正事实错误的模型，该模型在训练数据较少的情况下与基线模型相当，并且训练模型生成解释可以提高性能。最后，Defact数据集已发布在GitHub上，供研究人员使用。</sample>
    <sample id="78">是的，DEplain-apa 和网站的简化过程有所不同。DEplain-apa 基于新闻文本，包含 483 份手动对齐的文档，生成了 13,000 个句子对。相比之下，DEplain-web 包含 750 份文档，其中一半是手动对齐，另一半是自动对齐，生成了 30,450 个句子对。DEplain-apa 主要使用重新排列和词汇添加，而 DEplain-web 主要使用重新表述。</sample>
    <sample id="79">是的，Coscript是公开可用的。作者提到他们已经创建了一个包含55,000个特定目标的高质量数据集，供研究人员和开发人员使用。更多信息可以在论文中找到。</sample>
    <sample id="80">水印通过定义一个目标嵌入并将其与原始嵌入结合，插入到用户发送的句子中。当句子中包含足够的特定词时，提供的嵌入完全等于目标嵌入。</sample>
    <sample id="81">作者是来自宾州大学的Yusen Zhang。</sample>
    <sample id="82">本视频介绍了我们的工作《聚合多种启发式信号作为无监督评估的监督》，即自动评估（AEs）旨在无人干预地评估写作质量。先进的AEs模型通常在监督下训练，使用大量标记的写作和其真值评分。然而，收集标记写作和评分很耗时，特别是针对新问题和缺乏专业评分人员的写作。无监督AEs可以消除标记写作和评分的要求，具有科学研究和实际应用的巨大潜力。两项主要工作分别使用单个启发式质量信号进行无监督聚类和直接回归训练，但都表现不佳。我们提出的URRA框架引入了多个启发式质量信号作为伪基准评分，然后通过学习这些信号的聚合来训练AEs模型。URRA包含一个启发式质量排名模块和深对数聚合模块。我们设计了一个深对数聚合损失来解决不同信号之间的冲突，使AEs模型能够学习评估质量的部分排序关系。最后，我们提出了一种评分策略，将AEs模型预测的分数转换为预定义分数集。</sample>
    <sample id="83">是的，mt5 和类似的编码器-解码器模型可以通过混合语言的训练来改进。研究表明，训练在多种语言中可以提高性能，尽管英语在某些数据集上表现下降。</sample>
    <sample id="84">Shaohui Xu介绍了他的论文《PADIAN Efficient Framework for Dynamic Networks》，探讨了传统网络与动态网络的区别。传统网络使用固定参数，而动态网络可以根据输入调整参数。Xu提出了PADIAN框架，旨在减少全动态网络中冗余参数的使用。PADIAN通过将参数分为动态和静态两类，并使用两个缩放因子来优化训练过程。实验表明，PADIAN在性能上优于传统和动态网络，并且与网络剪枝相比表现更好。未来工作包括扩展PADIAN到其他机制网络和结构。</sample>
    <sample id="85">一个示例是“制作巧克力蛋糕”，这需要满足特定的限制条件。</sample>
    <sample id="86">他们通过设计一个适用于嵌入服务的 watermark方法，确保隐蔽性。该方法在提供服务中注入一个可识别的 watermark，该水印足以检测其他服务是否包含该水印，但足够隐蔽，以便攻击者可以轻松地删除它。</sample>
    <sample id="87">通过使用现有的 PLM 如 RoBERTa 和 BioBERT，研究人员开发了 Dr. Bert，专为法语设计，展示了在法语领域的 NLP 应用。</sample>
    <sample id="88">GPT-4 在对非二进制人的立场上与非二进制人的立场最不一致。</sample>
    <sample id="89">在演讲中，演示了一个句子 'I'm going to talk about'，模型通过注意力机制预测的语音框架显示了注意力如何分配到不同的语音框架上。</sample>
    <sample id="90">Hannah Lu, co-author of 'rethinking annotation,' discusses the feasibility of using language learners for data annotation in NLP. The study challenges the need for native speakers, showing that learners can achieve nearly accurate annotations, especially for simpler tasks. The research involved English, Korean, and Indonesian languages, with learners categorized into three proficiency levels. Experiments showed learners' annotations were comparable to native speakers' when aggregated. The study suggests that language learners can contribute to data annotation, potentially overcoming geographic and technological barriers in low-resource language research.</sample>
    <sample id="91">任务数量的增加会使模型在性能上得到改善，但同时也会导致模型的敏感性降低。</sample>
    <sample id="92">1. 他们的模型在Cogs benchmark上比其他无树模型表现出更好的深度递归的泛化能力。
2. 他们的方法在处理多种结构的泛化方面仍然具有挑战性。
3. 他们的模型在处理多种语言的泛化方面表现出优势。</sample>
    <sample id="93">两位合著者Alexander Koller和Ivan Tiedtov与第一作者Matthias Landauer共同撰写了这篇论文。</sample>
    <sample id="94">Jingwei Yi from the University of Science and Technology of China presents a paper on protecting embedding ad services using a watermark method. The paper addresses the issue of model theft in embedding services, proposing Embedding Marker, a backdoor-based watermark method. The method involves watermark injection and copyright verification, ensuring the watermark is applicable, non-degrading, covert, and transferable. Experiments on datasets like AG News and MIND show Embedding Marker's effectiveness in maintaining service utility while protecting copyright.</sample>
    <sample id="95">Aydin Bilal is the first author of the paper on prompting PaLM for machine translation.</sample>
    <sample id="96">大家好，我是卡内基梅隆大学的一年级博士生。今天我将介绍我们的工作，NL位置性分析数据集和模型的设计偏见。该工作是与华盛顿大学和艾伦研究所的Sebastian Santi、Ronan Labras、Katerina Reinecke和Martin Sapp合作完成的。让我们想象你在为一家报纸工作,在新闻文章的评论中试图删除有害内容。你可能会转向像Perspective API这样的流行API来检测有害内容。如果你是Carl Jones,那么Perspective API可以很好地检测有害内容。但是,对于Dithya Sharma来说,Perspective API对印度常用的冒犯性词语没有那么敏感。这是一个设计偏见的例子,我们看到技术在不同人口之间的系统性能差异。设计偏见可能是由于研究人员和模型开发人员的立场造成的。立场是由于人口、身份和生活经历的结果。作为研究人员,立场可以影响研究过程和结果,因为它可以改变研究人员的决定。人们可能会问数据集和模型是否有立场,我们并不是说模型和数据集本身有人口身份和生活经历,但它们确实聚集了真实人的判断和意见,因此可以代表某些立场。</sample>
    <sample id="97">演讲者指出，SimulST 模型面临的主要问题包括：复杂的训练过程，涉及不同优化目标的多个模型，以及不同延迟目标的多个模型。</sample>
    <sample id="98">为了减轻数据集中的社会和政治偏见，可以采用多样化的训练数据来源，确保包括不同政治观点的内容。此外，使用政治问卷进行自动评估可以确保模型的公平性。</sample>
    <sample id="99">我是来自福建大学的西玉。今天我来介绍我们的工作《从大型语言模型中区分脚本知识以进行受约束的语言规划》。在日常生活中，人们经常通过遵循步骤指令来规划行动。以前的工作已经利用大型语言模型来规划抽象目标的活动,并表明大型语言模型可以有效地将目标分解为步骤。然而,以前的工作主要关注的是规划具有特定约束的目标。比如说,制作巧克力蛋糕。本文定义了受约束语言规划的问题,在规划目标上施加不同的约束。一个好的规划者应该写出合理且忠实于约束的脚本。本文首先评估和改进了大型语言模型的受约束语言规划能力。由于没有数据集来支持我们的研究,我们必须首先获取这些目标。正如表格所示,我们扩展了具有多面约束的抽象目标,并使用instructGPT进行人类循环数据获取。我们对一百个特定目标进行采样,并评估从大型语言模型生成的脚本。此表格报告了结果的总体准确性。我们发现所有大型语言模型在规划特定目标方面都表现不佳。然后,我们进行详细分析,研究为什么大型语言模型会失败。结果显示生成的脚本的语义完整性是可以接受的,但不能保证符合约束。我们深入研究了WikiHow中定义的更细分的约束类别。计划性能的热图显示了不同类别的目标的不同表现。以前的研究表明了大型语言模型在输出质量的高变异性,导致性能不佳。因此,我们采用生成质量较高的生成的想法。我们首先显示了特定目标的约束类型,并基于这些目标生成特定目标。然后,我们开发了一个过滤器模型来选择符合约束的脚本。我们将脚本和目标转换为instructGPT嵌入,并计算相似性作为相似性分数来衡量语义相似性。除此之外,我们奖励包含目标约束关键词的脚本。我们只保留目标目标分数最高的脚本。使用我们的方法,instructGPT可以生成更高质量的脚本。我们的方法大大提高了受约束语言规划的语义完整性和对约束的忠实度。由于大型语言模型的成本较高,使得语言规划能力的较小和专用模型变得至关重要。创建数据集是实现这一目标的关键步骤。以前的研究没有实现特定目标的规划,并且手动数据集标注是昂贵的。我们遵循符号知识提取的想法来从大型语言模型中提取受约束语言规划数据集。我们应用我们的方法来构建受约束语言规划的代码文档。总共生成了五万五千个特定目标和脚本。为了确保验证和测试集的质量,我们请众包工人找到并修正错误的样本。此图表显示了受约束的分布。我们发现代码文档显示出更高的普遍性。我们发现，使用代码文档可以在适当的训练下训练较小的但专用的模型。</sample>
    <sample id="100">PromptRank是一个针对多跳问题的解决方案，旨在通过结合无监督提取和语言模型来提高性能。它使用TF-IDF和链接跟踪来提取潜在的链条，然后使用语言模型对这些链条进行评分。该方法的关键是使用语言模型的概率来评估链条是否能回答给定的问题。通过实验，PromptRank在多跳QA任务上表现出色，甚至在与MDR的对比中表现出更好的性能。该方法的关键成分包括链条的构建、评分函数的选择以及如何激发语言模型的推理能力。</sample>
    <sample id="101">PaLM 的流畅度与现有的系统相当，但在准确性方面存在差异，主要是由于频繁出现的遗漏错误。</sample>
    <sample id="102">水印方法应具有以下属性：适用于嵌入服务，水印不影响服务的实用性，攻击者可以轻松地删除或转换水印，且水印可转移到攻击者的服务中。</sample>
    <sample id="103">TED 演讲已被翻译成 14 种不同语言。</sample>
    <sample id="104">为了获得丰富的种族数据，重新注释的实例数量通常超过每个实例的原始注释数量。</sample>
    <sample id="105">良性和后门数据集之间的差异是通过计算Cosine和L2相似性来衡量的。</sample>
    <sample id="106">The presentation introduces the QUEST dataset, a tool for evaluating information retrieval systems. It is designed to handle complex queries with multiple constraints, as illustrated by examples of Jane, a zoologist, and Austin, a book reader. The dataset includes over 3,000 entity-seeking queries with implicit set operations, and it is constructed using Wikipedia categories from four domains. Human annotators paraphrase and validate these queries, ensuring relevance and naturalness. The evaluation of systems on this dataset shows room for improvement, especially for queries involving set intersections and differences. The presentation aims to help future researchers develop better systems for handling selective information needs.</sample>
    <sample id="107">基于编码器的多语言模型通过训练多语言数据集来提高性能。它们在多语言任务中表现优异，特别是在跨语言任务中。</sample>
    <sample id="108">KostV Sinha在演讲中介绍了他的研究，探讨了语言模型的Acceptability Judgments (MP) 在不同上下文长度下的表现。研究重点是重新评估MP评估方法，特别是评估语言模型对长句子和长上下文的接受度。通过使用Blimp和Syntax-Gym数据集，研究人员创建了长句子，并通过添加不同的前缀来测试模型的接受度。研究发现，模型对结构匹配的前缀有显著影响，特别是当前缀来自同一数据集时。研究还表明，模型对结构匹配的前缀的敏感性在不同上下文长度下保持稳定。研究的关键结论是，当前的MP评估方法可能不完全反映语言模型在长句子上下文中的能力。</sample>
    <sample id="109">Ortar Yigitoglu介绍了一个名为Unnatural Instructions的自动生成数据集，用于训练语言模型。该数据集由GPT-3生成，包含各种自然语言任务的指令和输出。该数据集比现有的RL数据集更具多样性和创造性，并且在多项任务上表现优于其他数据集。通过使用Unnatural Instructions，模型在多个任务上表现出色，并且在成本效益上比传统方法更具优势。</sample>
    <sample id="111">作者通过收集一般文本数据并计算单词频率来确定中等频率的单词。</sample>
    <sample id="112">大家好，我是舒恒。我今天要介绍的是我们的论文《做康奈尔二千零三的名实体标记在二千二十三年仍然有效吗？》。我们研究了名实体标记任务中的泛化问题。我们发现，康奈尔二千零三的名实体标记已经使用了二十多年。康奈尔二千零三的名实体标记在二千二十三年仍然有效。我们希望这篇论文能引起更多关于如何提高模型泛化度的研究。最后，请大家看看我们的论文和数据集。如果有任何问题，请随时联系我。谢谢大家。</sample>
    <sample id="114">在ACL 2023上，来自新加坡国立大学的研究人员介绍了他们的工作，旨在通过减少大型语言模型的参数数量来解决其限制。大型语言模型虽然能够同时处理多种任务，但参数数量庞大，导致训练时间长且不适合小型集群。研究人员提出了一个名为“组头注意力”的方法，旨在通过分组训练和投票算法来减少头部的数量，同时保持性能。该方法在机器翻译、语言建模和抽象总结等任务上表现出色，并且在未来的自动化证明中有很大的前景。</sample>
    <sample id="115">该方法使用的语音片段大小是 1.2s。</sample>
    <sample id="116">在示例中，需要 Servin 是一名法官的实体特定知识。</sample>
    <sample id="117">示例质量。</sample>
    <sample id="118">在ACLU 2023的演讲中，Arpana Goyal和Anand Rajaram介绍了他们的研究，旨在改进代码切换的预训练技术。代码切换是指在语言混合句子中，如英语和印地语混合的句子中，出现的语言转换。传统的ML模型在处理代码切换任务上表现不佳。为了解决这一问题，他们提出了SwitchML和FrequencyML两种新ML技术。SwitchML通过在ML模型中定义特定的切换点来增强切换信息。通过使用层间残余连接和辅助损失，研究人员进一步增强了切换信息的编码。通过线性和条件性证明，他们证明了这些方法确实增加了切换信息的含量。研究的结果表明，SwitchML结合了SwitchML和residual connections的效果，在情感分析任务上表现最佳。</sample>
    <sample id="119">论文侧重于GPT-4、GPT-3、BERT及其变体。</sample>
    <sample id="120">该模型使用结合多个层的注意力分数。</sample>
    <sample id="121">直接推断的示例包括使用歌曲的名称或其在列表中的位置来选择，例如说“easy on me”或“我有感觉”。</sample>
    <sample id="122">作者所属机构是中国南方大学。</sample>
    <sample id="123">Ying和Zhi Yang介绍了他们的研究，旨在通过多模特征的多模训练来改善多模任务的性能。研究发现，现有的多模任务数据集缺乏，促使他们创建了Multi-Instcrtfirst多模任务调教数据集。该数据集包含62个多模任务，涵盖10个类别，基于21个开源数据集。研究使用OFa统一的多模模型进行训练和测试。研究结果表明，多模任务的调教可以显著提高OFa的性能。研究还引入了Sensitivity指标，衡量模型在不同任务上一致性。研究还计划收集更多数据集。</sample>
    <sample id="124">Tan-Ching Yu介绍了他在阿里巴巴和新加坡国立大学的工作，旨在评估和改进LLMs的时间推理能力。时间在现实世界中是基本的，Yu将时间推理分为三个层次：时间到时间、时间到事件和事件到事件推理。通过对T5、T5-SFT和TempT5的比较，Yu发现了不同模型在不同时间范围内的表现差异。TempT5在时间推理方面表现最佳，尽管存在一些时间范围内的波动。Yu还提出了TempReason数据集和训练策略，以改善LLMs的时间推理能力。</sample>
    <sample id="125">这篇论文有五位作者。</sample>
    <sample id="126">是的，在语义解析之前，使用机器翻译模型翻译自然语言查询作为基线。</sample>
    <sample id="127">Namjoohol和Laura Schmidt的论文介绍了一种将大型语言模型的推理能力转移到小型模型的方法。传统的链式推理只能在大型模型如GPT-3或PALM上运行，这限制了其应用。解决方案是使用大型模型作为推理教师，使用多种推理生成的多样化数据来训练小型模型。通过这种方法，学生模型能够很好地完成复杂推理任务。研究表明，使用多种推理方法可以显著提高性能，特别是在多元算术任务上。论文还讨论了实现这种方法的可扩展性和潜在的成本考量。</sample>
    <sample id="128">在这次演讲中，Akshita和Martin介绍了他们的研究《The Kitmos: Evaluating Knowledge Integration from Multiple Sources》，旨在探讨自然语言理解模型如何整合来自不同知识来源的信息。研究涉及三种知识集成设置：背景预训练、背景双重和背景推断。通过与人类参与者和模型一起评估，研究发现，许多模型在没有特定任务训练的情况下无法有效整合来自不同来源的信息。尽管有些模型在特定任务训练下表现良好，但仍然存在整合新背景知识的挑战。研究强调了在不同知识来源整合方面的模型挑战，并提供了一个数据集和代码供进一步研究。</sample>
    <sample id="129">示例包括：亚洲女性被描述为“unassuming”，中东女性被描述为“exotic”，黑人女性被描述为“strong and resilient”，以及拉丁裔女性被描述为“vibrant and curvaceous”。</sample>
    <sample id="130">根据研究，Transformer模型在泛化能力上表现较好。</sample>
    <sample id="131">测试数据集的名称是Valina。</sample>
    <sample id="132">这篇论文有三位作者：Akshata, Martin, 和一位未提及的第三位作者。</sample>
    <sample id="133">作者使用了多种模态，包括语言、图像和边界框的统一表示。</sample>
    <sample id="135">James and Sarah Finch from Emory NLP Lab introduced ABC Eval, a new method for evaluating conversational AI by annotating specific behaviors in chat. This method is more reliable and precise than existing methods, which often rely on human evaluations. ABC Eval measures various errors like contradictions and irrelevant information, providing a detailed analysis of chat model performance. Their study found that ABC Eval metrics are more predictive of overall conversation quality than traditional methods. The method is seen as a significant advancement in the field, offering a more granular understanding of AI chat quality.</sample>
    <sample id="136">Jaziel Van介绍了他与Nafisa在University of Sheffield合作的研究，旨在提出一个新的评估数字推理模型的框架。现有的评估方法不够全面，无法准确反映模型的数学能力。Fermat框架通过使用数学类型和操作来评估模型，发现语言和数学多样性对模型性能至关重要。研究还发现，单一的评估指标不足以反映真实世界的需求。Jaziel提供了QR码和相关链接，以便读者进一步了解研究。</sample>
    <sample id="137">SiXun SiXun来自新加坡科技大学，介绍了他的研究项目Teltodiseign，旨在通过自然语言指令生成符合用户要求的2D地板设计。该研究旨在解决设计过程中的语言指导挑战，特别是对于非专业用户的设计需求。研究使用了T2D数据集，收集了5,051个自然语言指令和76,000个人工生成的指令。研究采用了基于转换器-解码器的序列到序列模型，使用了T5语言模型。研究结果表明，T2D模型在语义理解能力上表现最佳，成功地控制了目标序列的生成。研究还发现，虽然文本条件图像生成模型在艺术性方面表现出色，但在遵循多重指令方面存在局限。研究还表明，使用人工指令进行训练后，模型性能显著提升，表明人工和人工指令在训练过程中是互补的。</sample>
    <sample id="138">Authors identify that research on integrating knowledge from multiple sources in NLU is insufficient, particularly in handling inference-time knowledge without task-specific training.</sample>
    <sample id="139">演讲者的名字是Ying和Ji Yang。</sample>
    <sample id="140">是的，Coscript经过了质量检查。为了确保数据集的质量和测试集的准确性，邀请了众包工作者进行验证和修正错误的样本。</sample>
    <sample id="141">现有资源的局限性在于：1) 只有少数翻译依赖上下文，因此无法通过像BLEU这样的词汇量级别的指标进行评估。2) 资源支持有限的上下文依赖翻译类型和语言集，通常依赖于领域知识和人类编辑。3) 资源只能支持有限的上下文依赖翻译类型和语言集。</sample>
    <sample id="142">我将给出的英文翻译成中文。</sample>
    <sample id="143">该方法与 WET 和 LAG 策略进行了比较，并且与专门为 SimulST 设计的最新架构进行了比较。</sample>
    <sample id="144">作者所属机构是Université de Montréal。</sample>
    <sample id="145">演讲者的名字是Jenny。</sample>
    <sample id="146">Zou Yichen, a PhD student from Fudan University, presented a talk on their paper analyzing omission in dialogue summarization. Dialogue summarization, a subtask of text summarization, involves creating concise summaries of dialogues. Despite advancements in large-scale pre-trained language models, these summaries often contain errors, such as omission, which affects their real-world applicability. The presentation highlighted that omission is a significant issue, with about 70% of summaries from various domains and models showing omission problems. The talk also introduced a dataset for omission detection, which is crucial for improving summary quality. The dataset, based on five existing benchmarks, includes ten candidate summaries for each dialogue, and the performance of the models was evaluated using the F1 score. The results showed a label imbalance, indicating the need for more advanced models. The talk concluded with a post-editing method that uses detected omissions to refine summaries, showing promising results for quality improvement.</sample>
    <sample id="147">这篇论文有三位作者：Myra、Eszter Mosh、Dan Jurafsky。</sample>
    <sample id="148">Simultaneous speech translation是将口语转换为另一种语言的实时过程。我们提出了一个名为EDAT的策略,它利用现有的非实时模型，并且不需要重新训练或为Simultaneous Speech Translation专门设计架构。EDAT的核心是决定是否发出部分翻译,基于注意力机制。我们在德国的测试中发现EDAT比其他策略更优越。我们还发布了开源代码和模型。</sample>
    <sample id="149">是的，数据集是公开的。</sample>
    <sample id="150">Archie介绍了MeetingQA数据集，该数据集基于会议中的问题和答案。该数据集旨在填补现有NLP研究中对讨论性问题的不足。数据集包括7.7万个问题，分为三个集：TRAIN、DEV和TEST。数据集中有30%的问题无答案，40%的答案跨多个句子，48%的答案由多个发言者提供。数据集的长度分布显示，问题和答案大约为12和35个单词。研究使用了多种方法，包括短上下文模型、单个句子模型和多句子模型。研究结果显示，模型在零短和零短设置中表现不佳，特别是对于识别讨论性问题和确定答案发言者。</sample>
    <sample id="151">大家好，我是Ying和Jiayang。我们将介绍我们的研究，旨在通过多模特征学习的多模特征调优化来改善多模特征学习。</sample>
    <sample id="152">Frederik Riemenschneider介绍了在经典语言学和NLP交叉领域的工作，重点介绍了开发的古希腊和拉丁语模型。尽管已经有了LatinBERT、AncientGreekBERT等模型，但这些都是单语言的encoder-only模型，无法处理多语言任务。为了应对这一挑战，团队开发了新的语言模型，包括Greberta、GREATER等，支持古希腊和拉丁语的双语处理。通过使用OCR错误识别的希腊文本，团队创建了高质量的预训练数据集。模型在语义标注、依赖解析和词性标注方面表现优异，尽管在多语言模型中，性能与单语言模型相似。</sample>
    <sample id="153">Nina Meherabbi discusses her work on resolving ambiguities in text-to-image models at Amazon Alexa. Ambiguities in prompts can lead to inaccurate image generation. Her team developed a framework to disambiguate prompts using clarifying questions or visual setups, and an evaluation system to ensure generated images align with user intentions. Their research shows that disambiguation improves image fidelity, and their evaluation framework aligns with human judgment.</sample>
    <sample id="154">这篇论文的作者所属机构是意大利的大学。</sample>
    <sample id="155">演讲者的名字是Javad Hosseini。</sample>
    <sample id="157">Sheng Gao介绍了Sun Dong大学与其他研究人员合作开发的对话总结的工作。该工作旨在通过对话结构化图结构融合图来提取对话中的静态信息。该方法利用了对话结构化模型、动态图模型和预训练的摘要生成模型。该方法的主要缺点是依赖于外部工具的可靠性，可能导致不准确的输出和错误传播。此外，静态图结构与图表示学习语法不匹配，无法动态适应对话总结任务。该方法的四个主要组成部分包括：1. 用于对话编码的语音编码器；2. 用于对话结构建模的现有方法；3. 提出一个动态图模型，结合多个静态图并使用动态图模型捕捉语义关系；4. 使用预训练的模型作为摘要生成器。该方法还包括了捕获对话结构信息的四个方法：1. 依赖于对话结构化模型的对话结构建模；2. 依赖于对话结构化模型的对话结构建模；3. 依赖于对话结构化模型的对话结构建模；4. 依赖于对话结构化模型的对话结构建模。</sample>
    <sample id="158">Xiangkunhu from AWS presented Dual Cache, a novel approach to improve coreference resolution in long documents by using a dual cache system. This system includes a local cache for short-term mentions and a global cache for long-term mentions, reducing cache misses and improving performance. Benchmarks show Dual Cache outperforms traditional methods, especially in large documents, while maintaining cost-effectiveness.</sample>
    <sample id="159">KostVfSena在介绍他们的ACL2023论文《语言模型接受度判断并不总是对上下文鲁棒》中欢迎大家。该论文是与JohnGothier、AaronMuller、KanishkaMishra、KarenFuentis、RogerLevy和AtinaWilliams共同完成的。该工作重新审视了最小对等时间。最小对等时间基本上是评估语言模型的接受度。比如说,你会给一个可接受的句子和一个不可接受的句子,希望模型会给可接受的句子更大的概率。当前的MPP流程基本上不允许我们评估模型对更长句子的接受度。如今,大型语言模型越来越长的上下文窗口,因此评估模型的接受度在整个上下文窗口是至关重要的。我们试图通过模拟更长的序列来重新审视数据集本身,然后重新创建可接受或不可接受的句子。比如说,我们从Blimp数据集中选择了一个典型的对。我们通过添加前缀来重新创建更长的序列,这些序列是可接受的,具有相同的语法结构。我们也可以从不同的数据集中选择不可接受的句子。我们可以从不同的数据集中选择句子,但它们不来自你正在评估的那个数据集。这将告诉我们模型的接受度判断是否真的受到任何上下文的影响。比如说,当我们选择来自不同数据集或完全不相关的Wikipedia句子时。我们首先查看Wikipedia句子,它们与当前查询无关。我们发现MP评估基本上对任何上下文长度都很鲁棒。我们将上下文长度增加到1024,以最大化OPT和GPT2模型。我们在橙色的点线中看到MP评估相对稳定。现在,当我们选择句子时,我们从同一数据集的可接受和不可接受域中创建句子。我们看到MP评估在添加可接受前缀或不可接受前缀时显著增加或减少。我们在Blimp或SyntaxGram数据集中选择了相同的语法结构。我们看到MP评估会显著增加或减少,这取决于我们选择的前缀是可接受的还是不可接受的。我们在同一数据集中选择了可接受或不可接受的句子。我们可以从不同的数据集中选择句子,但它们不来自你正在评估的那个数据集。</sample>
    <sample id="160">第一步将输入词元映射到一个无序的多重集合中，每个集合包含将出现在输出中出现的词元。</sample>
    <sample id="161">Coscript 包含了 55,000 个脚本。</sample>
    <sample id="163">根据介绍，DEplain 的最佳对齐方法是 MASS-ALIGN 方法。</sample>
    <sample id="164">弱监督学习的好处在于不需要手动标记数据，而是使用简单的规则或低质量的标记来源进行标记，这大大降低了成本。然而，这种标记的噪音可能会导致模型无法有效泛化。</sample>
    <sample id="165">Wenting Zhao介绍了他的论文《Adaptive Common Sense Reasoning: Exploiting Mutually Exclusive Explanations》，介绍了Adaptive Reasoning的概念。Adaptive Reasoning旨在通过一组可能的解释来填补上下文和结果之间的信息差距。Zhao提出了一个名为LIpor的无监督学习方法，该方法利用后验后优化来学习Adaptive Reasoning。LIpor通过利用解释的互斥性来优化解释的可能性，而不依赖于监督学习。Zhao的研究在ALFA-NLI数据集上进行了测试，LIpor的输出在与零shot模型和其他方法相比，表现出显著的优势。</sample>
    <sample id="166">Yuxin from Harbin University of Technology presented a new method for image retrieval from linguistically complex texts, addressing the limitations of existing visual language models. The method employs a divide and conquer strategy, inspired by dual-process theory, to break down complex reasoning into simpler tasks. It integrates a visual linguistic system for analogical reasoning and a logical system for handling complex reasoning. The method includes a proposition generator, a decoder, and a neural symbolic reasoner, which work together to improve the performance of large language models. The results show that the proposed method outperforms other baselines, demonstrating its effectiveness in complex reasoning tasks.</sample>
    <sample id="167">DEplain-web 包含 750 个文档，使用手动对齐和自动对齐方法对齐。</sample>
    <sample id="168">CoNLL++ 数据集是通过从 Reuters News 2020 收集数据，并使用相同的 CoNLL 2003 标注指南进行标注而创建的。</sample>
    <sample id="169">Aydin Bilal discusses a study on prompting large language models (LLMs) for machine translation, focusing on the PAMP model. The study evaluates the impact of different prompting strategies on translation quality, using metrics from the NMT community and human evaluations. It finds that example quality is more crucial than similarity to the source sentence, and high-quality data like dev data improves performance. While PAMP's fluency is comparable to state-of-the-art systems, it lags in accuracy, often omitting parts of the source sentence. The study suggests using five-shot prompting and highlights the need for careful example selection.</sample>
    <sample id="170">你好，大家。我是宾州大学的尤斯恩·张。今天我要介绍我们如何在多种自然语言和多种表示中进行语义解析。语义解析是构建用户查询的语义表示的任务，例如SQL和lambda计算。多语言语义解析是将多种自然语言中的查询转换为多种表示的任务。现有的多语言语义解析模型是单独提出和评估的。比如，缺少某些自然语言的覆盖范围，缺少某些表示的覆盖范围。或者只评估某种神经模型。为此，我们提出了一个统一的多语言语义解析数据集示例。它包含90个数据集，五个语义解析任务，八百万表示和22种语言。为了更好地评估我们的基准测试，我们考虑了六种训练和评估设置。第一个是翻译测试。我们使用谷歌翻译API将源语言翻译成目标语言。然后使用单语言模型进行训练和评估。例如，我们在英语模型上训练英语查询。然后在德国查询中使用API翻译成英语。然后使用训练的模型预测SQL。我们还测试单语言模型。这个设置的源语言和目标语言是相同的。比如德语到德语或英语到英语。我们还测试单语言模型。这个设置是训练单语言模型的10%的数据。我们测试多语言模型。我们将德语、英语和中文的查询放在一起训练一个多语言模型。然后在推理中使用这个模型来翻译德语或中文查询。我们还考虑了零转移和零转移的跨语言转移。我们在英语查询或德语和英语的少量查询上进行训练。然后用这个模型预测SQL输出。我们还发现了许多有趣的结果。关于分析单语言模型。我们评估了两组模型，包括基于指针的多语言编码器和BERT加编码器。我们还评估了多语言编码器和编码器的模型。我们发现，编码器-解码器在所有9个数据集上都取得了最佳表现。我们在MT5和EXAMPLER的多语言设置上评估了编码器-解码器。我们发现，编码器-解码器或编码器-编码器可以通过在各种语言中进行训练来改进。我们发现，除英语外，其他大多数主要语言都可以获得性能提升。我们还发现，零转移设置的跨语言转移性能差距很大。通过比较蓝色和橙色线，我们发现，零转移设置的跨语言转移性能差距很大。我们还发现，编码器-解码器或编码器-编码器可以通过在各种语言中进行训练来改进。我们发现，训练英语自然语言可以显著提高目标语言的性能。我们还发现，多语言语言模型如CodeNet和BLOOM仍然不适合多语言语义解析任务。总之，我们构建了一个统一的多语言语义解析基准测试。我们对三种代表的多语言语言模型进行了全面的基准测试。我们的结果显示了许多有趣的发现。欢迎访问我们的论文和代码。谢谢大家的收听。</sample>
    <sample id="171">Existing watermark methods are categorized into four groups, but they either lack applicability to embedding services or lack transferability.</sample>
    <sample id="172">Codex 或 Bloom 等多语言 LLM 在 CLSP 任务上仍然不够。研究表明，尽管这些模型在多语言任务上表现不错，但在跨语言的 CLSP 任务上仍然不够。研究建议使用更适合的模型，如 encoder-decoder架构，以提高跨语言的性能。</sample>
    <sample id="174">Priya和她的合著者介绍了ArgAnalysis35Klarge-scale数据集，专注于评估论点质量。该数据集的独特之处在于其高质量、广泛性和深度。它包含35K个分析对，主要来自高质量的来源，如高水平的比赛和专家辩论者。该数据集还引入了分析概念，扩展了传统的论点和前提。它还引入了实例级别的分析可靠性，允许更准确地利用评估者的意见。最后，数据集引入了一个主题相关性模型，提供了每个主题的相关性评分。</sample>
    <sample id="175">该方法通过使用一个灵活的、无硬约束的预测模型来处理排列的不确定性。它通过从输入中预测输出的每个位置的相应的多重标签，并使用第二个模型预测正确的顺序。</sample>
    <sample id="176">公平性是指 NLP 模型在处理不同类别时的性能一致性。公平性问题出现在模型对不同政治立场或社会群体的预测表现存在差异。</sample>
    <sample id="177">演讲者的名字是Yanis Slavrak。</sample>
    <sample id="178">演讲者的名字是KostV Sinha。</sample>
    <sample id="179">Mélanie Szklare介绍了一个名为Symbolic TOM的插件，用于增强大型语言模型的理论思维能力。她解释了理论思维是理解他人心态的能力，通常通过阅读任务来测试。她介绍了经典的Sally-Anne测试，展示了理论思维问题的分类。Szklare介绍了Symbolic TOM，该方法使用图形表示来表示不同角色的信念，并通过推理算法计算这些信念。她的研究表明，Symbolic TOM在多个数据集上显著提高了大型语言模型的性能，特别是在故事结构和语言多样性方面。</sample>
    <sample id="180">演讲者的名字是Myra。</sample>
    <sample id="181">Yuan 提供了关于《Distinguishing Script Knowledge from Large Language Models for Constrained Language Planning》的介绍。该研究探讨了大语言模型在特定目标规划中的能力，特别是针对特定目标的规划。由于缺乏支持研究的数据集，研究人员使用 InstructGPT 生成了 100 个特定目标，并评估了生成的脚本。研究发现，大语言模型在规划特定目标时表现不佳，主要是因为对目标的忠实度不足。为了解决这个问题，研究人员开发了 OverGenerate-Zen Filter 方法，该方法通过计算相似性来提高脚本的质量。研究还创建了 CodeScript 数据集，以支持小型模型进行特定目标规划。研究的核心目标是通过这些方法改善大语言模型的规划能力，并为研究人员提供一个可用的资源。</sample>
    <sample id="182">在本文中，热带主义指的是对拉丁裔女性的刻板描述，使用词语如 'vibrant' 和 'curious'，这些词语与热带地区的美丽和活力联系在一起，反映了对拉丁裔女性的性别和种族刻板印象。</sample>
    <sample id="183">作者通过使用像GPT-4这样的语言模型生成目标群体的人工描写。通过提供特定的身份标记，例如'想象你是一个亚洲女性描述你自己'，模型能够生成描述性强的个性化描述。</sample>
    <sample id="184">本文中使用了CXMI（Contextual X-MI）来衡量语境使用情况。CXMI是一个衡量机器翻译模型在给定语境中提供的关于目标语境的信息的指标。</sample>
    <sample id="185">DrBERT 是一个专门为法语设计的模型，基于 Roberta，并且在法语领域表现出色。ChuBERT 则是一个基于 ClinicalBERT 的模型，专为法语设计，旨在在法语领域提供更好的性能。</sample>
    <sample id="187">这篇论文有两位作者。</sample>
    <sample id="188">迭代迁移学习是一种机器学习方法，结合了迁移学习和迭代学习。它通过从已知任务中迁移知识来开始新任务，然后通过迭代学习不断改进模型。</sample>
    <sample id="189">数据集的目标是收集一个用于训练和测试的公共数据集，涵盖音乐、书籍和食谱等三个领域。</sample>
    <sample id="190">攻击者通过学习从提供的 EaaS 中提取模型参数来进行攻击。</sample>
    <sample id="191">这篇论文有三位作者：Sarah Papi, Matteo Negri和Marco Turilli。</sample>
    <sample id="192">杨洛介绍了他的研究成果，名为Can，旨在通过信心指导的记忆效率优化来实现传统的适应性优化方法的快速收敛和低内存使用。由于一些现有的内存优化方法如Adam和Adafactor在内存使用上节省了大量内存，但在性能上存在缺陷，Can提出了一个解决方案。通过使用非正交矩阵分解，Can减少了内存需求，从而在保持性能的同时降低内存使用。通过对BERT、GPT-2和T5等大型语言模型的实验，Can在验证准确性上比Adafactor提高了3.4%，并且在内存使用上比Adam和Adafactor更节俭。Can的设计灵活性使其适用于大型模型的训练，并且在大型模型的训练中表现出色。</sample>
    <sample id="193">我们收集了大约1000个注释单位对。</sample>
    <sample id="194">作者所属机构是卡内基梅隆大学。</sample>
    <sample id="195">本文介绍了ROHT框架，旨在通过构建Hierarchical Question Decomposition Tree (HQDT)和概率推理来解决复杂问题。HQDT将复杂问题分解为子问题，使用两个阶段的框架：构建HQDT，确定问题的层次结构；并在HQDT上进行概率推理，融合不同知识源的信息。通过对KQAPROHT和MUSIC数据集的测试，展示了ROHT在不同知识源结合下的优势。结果表明，ROHT在不同数据集上均优于传统方法，特别是当结合文本和知识库时。</sample>
    <sample id="196">以左侧为支配词的示例包括“我看见了巴特和丽莎”。</sample>
    <sample id="197">ABCIeval是对话系统中的最先进模型。它提供了一种更精确和可靠的评估方法，能够评估多种错误行为，如自我矛盾和自我矛盾，并比现有方法更能预测对话质量。</sample>
    <sample id="198">在整个上下文窗口中评估模型的可接受性是必要的，因为当前的NPP方法仅评估短语和单个句子，这可能不充分反映大型语言模型的抽象知识。通过评估更长的句子，研究者可以更全面地了解模型在不同上下文长度下的可接受性。</sample>
    <sample id="199">在多语言训练中，英语模型的表现在七个数据集中下降，但在三个位于英语的数据集中上升。</sample>
    <sample id="200">是的，注释者知道实体的名称，但可能不熟悉实体本身。</sample>
    <sample id="201">评估使用了最新的NMT（Neural Machine Translation）测试集和专家级人类评估结果。</sample>
    <sample id="202">泛化可能会影响特定的 NER 类型，因为不同类型的 NER 可能对模型的泛化能力有不同的需求。</sample>
    <sample id="203">NLP 中的立场重要，因为它反映了数据集和模型的偏见，影响了结果的公平性和准确性。立场可能导致某些群体被忽视或歧视，影响 AI 的公平性和可访问性。</sample>
    <sample id="204">BLOOM 采用的是适配器微调。</sample>
    <sample id="205">Shengbing PhD student from the University of Washington presented research on the influence of political biases in language models, stemming from their training data. The study found that language models exhibit varying political leanings, with GPT-4 being the most liberal. Experiments showed that these biases can shift based on the training data's political leaning. The research also highlighted fairness issues in applications like hate speech and fake news detection, where models with different political leanings perform variably across demographics. The dilemma of sanitizing data to avoid bias while risking censorship was also discussed.</sample>
    <sample id="206">他们使用了从两个不同任务中迁移的模型：一个是主题独立的辩论类分类，另一个是扩展和比较类的PDTB。</sample>
    <sample id="207">最近用于评估 PaLM 能力的测试集包括 WMT (Workshop on Machine Translation) 和 dev (development) 集。</sample>
    <sample id="208">作者提出了三个建议。</sample>
    <sample id="209">提议的方法在基线上获得了 9.4% 的收益。</sample>
    <sample id="210">演讲者的名字是Shu-Hung.</sample>
    <sample id="211">是的，论文中的结果和数据集可以用作基准。论文中提到，通过对两种不同模型进行微调，可以在自动文本简化方面取得比基线模型更好的成绩。论文还提供了详细的实验结果和评估指标，可以作为未来自动文本简化研究的基准。</sample>
    <sample id="212">论文中进行了三种较小模型的实验。</sample>
    <sample id="213">研究中使用的基础模型是Unified Multi-Modal Pre-trained Model (OFa)。</sample>
    <sample id="215">Adam Szarkowski在演讲中讨论了不同理论和方法（如Universal Dependencies、IGARVLM、Prague Approach和Word Grammar）对协调结构的不同假设。演讲重点是支持对称结构的论点，基于“依赖长度最小化”原则。演讲通过英语句子示例说明，左侧协调结构中的主语倾向于更短，特别是当左侧没有外部主语时。数据分析支持这一观察，表明左侧协调结构的主语倾向于更短，尤其是当主语与主语之间的词汇长度差异大时。演讲结论是，左侧主语更短的倾向支持对称结构，而不是对称或不对称结构。</sample>
    <sample id="217">Weihao Zhang and Lu Luozhao from Beijing University of Posts and Telecommunications present their work on multi-attribute controllable dialogue generation. They introduce D-C-G, a model that uses disentangled controllable generation to learn attribute concepts from scene values, and a unified evaluation framework, M-A-E, to evaluate different attribute granularities. Their method outperforms existing baselines in controllability and test quality, especially with attribute-oriented prompts. They also demonstrate the impact of prompts on compositional generation and the ability to generalize from seen attributes to unseen combinations.</sample>
    <sample id="218">作者所属机构是Google Translate。</sample>
    <sample id="219">Jiahuizhu Xie介绍了与Yixuan Huang和Chunwei Wang合作完成的研究，旨在通过多阶段的金融报告分析工具，提取重要信息。研究基于观察到公司报告中相似性高的词汇，提出了一个多阶段的分析流程。该流程包括文档分割、关系识别、外部数据集和内部数据集的使用，以及使用交叉熵损失和KL分歧的混合技术。最终，研究提出了一个高效的高亮任务，并提出了未来的研究方向。</sample>
    <sample id="220">作者所属机构是Stony Brook University。</sample>
    <sample id="221">论文分析了 Google Translate的语言对。</sample>
    <sample id="222">本研究旨在探索在开放域问答中实现跨域转移的挑战和策略。我们使用维基百科作为训练源模型，测试在不同领域（如生物医学）中的泛化能力。研究提出了三项主要贡献：1）研究不同数据干预处理方法；2）识别新领域数据集的类型；3）确定特定类型数据干预处理的有效性。研究结果表明，适当的干预处理可以显著提高问答模型的性能。</sample>
    <sample id="223">演讲者的名字是Shengbing。</sample>
    <sample id="224">在实验中研究了Long-IMPART和Normal-Base-IMPART模型。</sample>
    <sample id="225">在 MultiInstruct 中，53 个任务用于训练目的，剩下 9 个用于测试目的。</sample>
    <sample id="226">这篇论文有两位作者。</sample>
    <sample id="227">这段内容讨论了当前语言模型在NLP任务中的成功，并指出了语言理解的缺失。它提出了一个框架，名为Pangu，旨在通过将语言模型用于识别而非生成来解决这一问题。Pangu通过一个符号代理与环境互动，提出候选计划，而语言模型仅用于评估这些计划。该框架在不同的语言模型和学习方法下（如BERT、T5和CodeX）表现出色，特别是在非IID设置下。研究表明，Pangu在识别任务上比生成任务更容易，并且在非IID设置下具有强大的泛化能力。</sample>
    <sample id="228">作者在实验中使用了AG NEWS, MIND, SSTD2和ERASERM数据集。</sample>
    <sample id="229">Gabriela Skatylinskaya介绍了与Henning Bäck Smud合作的研究，旨在通过检测不完善的论点来改进写作。她强调了文本修订的重要性，特别是在论点写作中。她介绍了两个任务：确定论点是否需要修订，以及选择修订的质量问题。她讨论了使用人类修订模式学习的挑战，包括代表性、模型复杂性、上下文相关性和用户偏见。她的研究旨在通过评估不同模型的性能来解决这些挑战，并强调了使用修订数据可以有效地完成这些任务。</sample>
    <sample id="231">NACHOS是一个包含大量医学文本的开源数据集，用于训练和评估自然语言处理模型。</sample>
    <sample id="232">Aydin Bilal</sample>
    <sample id="233">Sarah Papi from the University of Trento and Fondazione Bruno Kessler, along with Matteo Negri and Marco Durcic, presented a paper on 'Attention as a Guide for Simultaneous Speech Translation.' The paper addresses the challenges of current SimulST models, such as complex training and multiple latency regimes. Their proposed solution, E-DOT, uses existing offline models and a single model for each latency, leveraging cross-attention mechanisms. E-DOT selectively emits translations based on attention focus, improving translation quality and computational efficiency. The results show E-DOT outperforms other strategies, with high translation quality and low latency, and the team has released their code and models for public use.</sample>
    <sample id="234">提示策略对结果有很大影响，特别是对于0和1个shot提示。五个shot提示的形式对结果的影响较小。高质量的示例对性能更为重要。</sample>
    <sample id="235">Kyowin 是这篇论文的作者。</sample>
    <sample id="236">1. 解释Multi-Task Instruction Tuning (Multi-Teach) 的概念及其在多模学习中的作用。
2. 讨论Multi-Teach数据集的构建过程及其对多模任务性能的影响。
3. 解释Multi-Teach中使用的Five-Instruction-Template方法及其在模型性能上的影响。
4. 讨论Multi-Teach中引入的Sensitivity指标及其对模型性能的意义。
5. 讨论Multi-Teach数据集的未来发展方向及其对研究领域的潜在影响。</sample>
    <sample id="237">作者建议使用KITMOS，一个诊断测试套件，来测试模型的能力，特别是它们如何处理来自不同来源的信息。</sample>
    <sample id="238">Yeboah Hou介绍了一个名为MeetingBank的新基准数据集，旨在解决会议摘要的两个主要挑战：高质量摘要和获取可信赖资源。通过使用Speechmatics API，收集了1,366个城市议会会议的音频数据，并将其转换为文本。数据集包括会议摘要、参考摘要和URL。数据分析使用了覆盖度和密度等指标，评估了不同模型的性能，包括Extractive、Abstractive和GPT-3。人类评估显示GPT-3在fluency和coherence方面表现最佳，但在informiveness和factuality方面较低。最终，MeetingBank提供了一个有用的工具，供研究人员设计更先进的会议摘要技术，并提供了对城市议会决策过程的见解。</sample>
    <sample id="239">大家好,我叫AydinBilard,今天我将简要介绍一下《从翻译评估评估策略和性能》这篇论文。该论文是与Google翻译的合作者共同完成的。</sample>
    <sample id="240">你好，我是德国萨尔兰大学的博士生。我想在视频中介绍我们最近的工作《比你想象的更弱》。这是与XiaoxueShen、Mario Musbach和Giasdethen和DittliSchlakow合作完成的。首先，我想简要介绍一下弱监督和弱弱监督学习。</sample>
    <sample id="241">Ethan介绍了他的论文《Human in the Loop Evaluation for Early Misinformation Detection: A Case Study of COVID-19 Treatments》。这篇论文是与Yangchen Wei, Shu和Alan Rieder合作完成的，探讨了自动检测COVID-19治疗信息的挑战。现有方法在评估和人类参与方面存在缺陷。提出了一个框架，旨在解决这些问题。该框架包括两个主要组件：一是处理误导性声明，使用关键词过滤和T5模型进行 CLAIM 识别和排名；二是验证政策违规。通过评估人类参与的工作流程，提出了早期检测和政策违规检测的有效性。该框架旨在促进未来的系统开发和评估方法。</sample>
    <sample id="242">对话系统的常用评估方法包括使用人类评估，如选择性评估和利卡特评分，以及对比对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对对</sample>
    <sample id="243">这篇论文有四位作者。</sample>
    <sample id="244">在 Servin 和 Kea 的示例中，需要背景知识包括 Servin 是一名法官，法官在法庭上决定案件，以及 Kea 是一名面包师。</sample>
    <sample id="245">Linying Zhang presented a study on high agreement Amazon Mechanical Turk (M-Turk) workers, focusing on a two-step pipeline for worker qualification. The pipeline aims to improve the recruitment of high-quality annotators by pre-filtering candidates through qualification and endurance tasks. The study found that the pipeline could identify 4 gold and 8 silver workers out of 200 participants, achieving high inter-annotator agreement (IAA) with a kappa of 0.443. The pipeline is cost-effective and resource-efficient, but it has limitations, such as only testing English summaries and not guaranteeing the training of correctness. Future research will explore hiring high-quality workers and applying the pipeline to various tasks and platforms.</sample>
    <sample id="246">是的，代码是公开的，可以在 GitHub 上找到。</sample>
    <sample id="247">Kyunghee from KAIST AI presents a paper on FactKG, a dataset for fact verification using knowledge graphs. Unlike existing datasets that use text or tables, FactKG uses DBpedia knowledge graphs, allowing for direct connections between evidence and claims. The dataset supports various reasoning types, including one-hop, conjunction, existence, multi-hop, and negation, and includes both written and colloquial claims. The paper introduces methods like the Colloquial Style Transfer Model and presupposition templates for practical use. Baselines show that using graph evidence outperforms traditional methods, with the Gear model achieving the best results.</sample>
    <sample id="248">NLPositionality 的注释者在各个人口统计学特征（如国家/地区、性别等）方面并不均衡。研究发现，数据集和模型在英语国家和受过高等教育的人群中更为一致，但对非二进制人群（如非二进制性别）存在偏差。</sample>
    <sample id="249">在可接受的域中扰乱句子的方法是通过在句子中添加噪音来保持其语法结构的相关性。</sample>
    <sample id="250">维度评估意味着评估对话质量的多个方面，而不仅仅是整体评价。它涉及评估模型的行为，如是否忽略了对话伙伴、是否说了无关信息或是否自相矛盾。ABC Eval提供了一种更精确的方法，通过标记特定行为来评估对话质量。</sample>
    <sample id="251">这篇论文的作者所属机构是中国科技大学。</sample>
    <sample id="252">在这段英语内容中，Sayakiran Thanikella介绍了他的研究项目“uCreate”，旨在通过事件提取技术改善法律领域的前案检索。该项目与Abhinav Joshi、Akshar Sharma和Ashutosh Modi合作，提出了两个主要贡献：ILPCR数据集和uCreate.pipeline。ILPCR数据集是一个包含7,070个印度法律案件的新的Benchmarks，用于评估检索算法的性能。uCreate.pipeline利用了事件提取技术，展示了高检索效率和低推理时间，并在印度和加拿大法律系统中实现了泛化。研究还比较了不同检索模型的性能，包括基于事件的模型，后者在检索任务上表现出色。总体而言，uCreate提供了前案检索领域的新视角和潜力。</sample>
    <sample id="253">Mario Aragon介绍了名为DisOrber的项目，该项目旨在通过分析社交媒体内容来检测心理健康状况。该模型利用双域适应技术，结合了一个基于维基百科和谷歌书籍的语言模型，专门针对Reddit和心理健康领域进行训练。该方法旨在学习社交媒体语言，然后专注于心理健康领域。通过使用指导性掩码，模型在训练过程中专注于重要词汇。结果显示，DisOrber模型在检测心理健康问题方面表现优于BERT模型。未来工作将探索不同的词典资源和使用临床数据。</sample>
    <sample id="254">Sun Qi介绍了研究工作，旨在通过不确定性指导的标签清理来改善远程关系提取的性能。该工作提出了一个框架，旨在通过不确定性指导的标签清理来提高远程关系提取的性能。该框架包括使用蒙特卡罗技术在预训练模型中引入不确定性，并通过动态类不确定性阈值和多阶段训练策略来增强模型性能。通过对两个公共数据集的比较，框架在性能上优于其他方法。</sample>
    <sample id="255">提示的形式在0和1个shot prompting中很重要，但对于5个shot prompting，形式对性能的影响较小。</sample>
    <sample id="257">作者评估了四个最新的对话模型。</sample>
    <sample id="258">Zhangsun Han介绍了使用大型语言模型进行自然语言处理质量评估的研究。该研究探讨了大型语言模型是否能像人类评估者一样评估文本质量。通过实验，研究人员使用大型语言模型评估GPT-2和人类写的故事，评估其语法、连贯性、可读性和相关性。结果显示，某些大型语言模型如DAVINCI和CHETGPT能够像人类评估者一样偏好人类写的文本。研究还探讨了大型语言模型评估的优缺点，并在论文中提供了更多详细信息。</sample>
    <sample id="259">Yusen Zhang from Penn State University presented Exemplar, a comprehensive benchmark for cross-lingual semantic parsing across multiple natural languages and representations. The work addresses the lack of uniform datasets and models, providing a dataset with 90 datasets, 5 semantic parsing tasks, 8 million representations, and 22 languages. Zhang's evaluation includes six settings: translate test, monolingual, multilingual, cross-lingual zero-shot, and cross-lingual few-shot transfer. The study finds that encoder-decoder models outperform previous methods, with multilingual training boosting performance in target languages. However, multilingual models like CoDiSS and BERT still lag in cross-lingual tasks. The research highlights the significant performance gap in zero-shot settings and the potential of few-shot settings to reduce this gap.</sample>
    <sample id="260">这篇论文有四位作者。</sample>
    <sample id="261">理想规划器应具备高质量的生成能力，能够准确、合理地遵循特定的限制条件。</sample>
    <sample id="262">这篇论文有五位作者。</sample>
    <sample id="263">本文介绍了Mitigating Label Biases for In-Context Learning，解决了in-context learning中设计选择引入的各种偏见问题。通过对不同类型的偏见进行分类，提出了一个新的偏见类型：Domain Label Bias。通过实验表明，Domain Label Bias对模型预测有显著影响。为了解决这个问题，提出了Domain Context Calibration方法，该方法使用随机域内单词作为内容自由文本，估计模型的偏见并对其预测进行校正。实验表明，Domain Context Calibration比先前的校准方法更有效，特别是在具有较大偏见的任务上。</sample>
    <sample id="264">林煌在浙江大学的毕业典礼上介绍了他的论文《Towards Transferable Audio Visual Text Generation》。他指出，虽然语音图生成任务已经成熟，但多模态任务仍然具有挑战性。为此，他提出了一个名为“可转移”的任务，旨在通过一个统一的语音空间将视觉概念跨域地映射。林煌的框架包括三个组件：音频映射网络、音频-视觉编码器和语言生成器，以及构建和内容构建器。通过这些组件，框架旨在训练一个能够快速适应新多模态域的模型。</sample>
    <sample id="265">演讲者的名字是Vasudha。</sample>
    <sample id="266">Adam Szpekowski 先生的所属机构是波兰的华沙大学。</sample>
    <sample id="268">PaLM 最常见的错误是缺失部分的错误。</sample>
    <sample id="269">James和Sarah Finch介绍了ABCEval, 一种新的对话AI进行评估的方法。该方法由EmoryNLPLab和亚马逊AlexaAI合作开发。它旨在通过标记模型响应中的特定行为来减少人类评估的主观性。通过对100个对话进行评估，ABCEval比现有方法更准确地衡量对话质量。该方法发现了对话质量的多个方面，并发现了模型在自我矛盾、提供无关信息和忽略对方方面的错误。</sample>
    <sample id="270">作者所属机构是Emory University。</sample>
    <sample id="271">CFT 在本文中代表 Continuous Fine Tuning。</sample>
    <sample id="272">这篇论文有六位作者。</sample>
    <sample id="273">你好，我是Kyowin。我将介绍我们的工作《当翻译需要上下文：数据驱动的多语言探索》。这项工作是与Patrick Koc、Emil Liu、Andre F. D. Martins和Graeme Newbigg合作完成的。许多翻译都依赖于上下文。例如，'mo'在句子中如何翻译？好吧，如果前面的句子是"如果部长们发现了什么，事情可能会变得危险"，那么'mo'指的是间谍。但如果前面的句子是"医生，你能帮我吗？"那么'mo'指的是出生标记。因此，翻译的意思也会随上下文而变化。但是，评估模型如何处理这些翻译的情况是相当困难的。首先，因为只有少部分翻译依赖于上下文，这使得像BLEU这样的语料库级别的指标无法捕捉这些翻译。其次，针对上下文依赖翻译的资源通常只支持有限的上下文依赖翻译类型和有限的语言集，因为它们通常依赖于领域知识和人类编辑。在这项工作中，我们试图回答两个问题：首先，翻译何时需要上下文，第二，模型如何处理这些情况？为回答第一个问题，我们首先测量了一个词在翻译中对上下文的依赖程度。我们之前引入了CXMI作为机器翻译模型中上下文使用的度量。CXMI是通过测量上下文C为目标Y提供的关于源X的信息。我们将CXMI扩展为点对点CXMI，可以在句子或单词级别测量上下文使用。我们可以将高CXMI的单词视为需要上下文翻译的单词。现在我们分析高CXMI的单词以寻找模式。我们对TED演讲的转录进行分析，这些演讲已从英语翻译成14种不同的语言。我们分析了三个不同的级别。首先，我们分析了具有高CXMI的部分语音标记。例如，阿拉伯语中的双重代词需要上下文才能确定它们是否是双重代词。类似地，我们发现某些语言在选择适当的动词形式时也需要上下文。然后，我们分析了在所有不同出现中平均高CXMI的词汇项。这有助于识别像中文中需要上下文才能正确翻译名词的情况。类似地，我们发现上下文支持正确的形式。最后，我们分析了单个标记的高CXMI，这些标记不能真正被单词本身捕捉，但在句子结构中表达出来。现在，我们使用我们的分析结果来设计一个文档级别翻译的基准。对于我们识别的五个语境现象，我们创建了一个标记来自动识别与现象相关的单词。我们还注意到不同语言中这些现象的不同比例。我们使用MUDATAGGER在我们要评估的双语语料库上应用标记。然后，我们应用选择的翻译指标在上下文依赖的例子上进行评估。首先，使用语料库级别的指标，像BLEU的模型中，上下文无关模型表现最佳。但如果我们使用COMET，上下文依赖的模型表现最佳。如果我们使用WordF，则没有上下文的模型和没有上下文的模型的性能相当。再次，使用MUDABENCHMARK来评估不同模型的文档级别翻译。我们使用BLEU、COMET和WordF等指标来评估不同模型的文档级别翻译。我们在14种语言对中进行数据驱动分析，以确定翻译何时需要上下文。然后，我们使用我们的发现结果来构建一个文档级别翻译的基准，这可以帮助我们识别哪些语境现象模型能否很好地处理，以及哪些翻译系统在文档级别翻译中表现良好。谢谢大家的关注。再见。</sample>
    <sample id="274">演讲者的名字是Yusen Zhang。</sample>
    <sample id="276">Ananya and Vignesh present their work on the IndicMT Eval dataset, which aims to evaluate machine translation metrics for Indian languages. They focus on five languages from two language families, Tamil, Malayalam, Hindi, Marathi, and Gujarati, and use 200 sentences to generate translations. Seven translation models are used to produce 1400 candidate translations per language, which are then evaluated by bilingual experts. The study finds that IndicMT MCM outperforms existing metrics like COMET on most languages, with a robust score of 0.306 on the AISST accuracy challenge.</sample>
    <sample id="277">没有名称。</sample>
    <sample id="278">作者描述了‘显性词汇’方法，基于社会语言学中的‘markedness’概念，指出任何与社会默认不同的群体都是标记的。该方法首先确定标记和未标记群体，然后使用‘战斗词’方法，使用权重对比来识别每个标记群体的顶级词。通过比较生成的角色与未标记群体的词汇，研究发现了不同的词汇分布，揭示了不同群体的特定刻板词汇。</sample>
    <sample id="279">这篇论文的作者是华盛顿大学的博士生。</sample>
    <sample id="280">Shuo Tao介绍了Multi-EMO框架，该框架旨在解决情感识别中的多模信息融合、少见情感和同义情感分类等问题。Multi-EMO包括Miss-ExtNet、Multi-Attend和Samp-Weighted Focal Constrained Loss三个关键组件。Miss-ExtNet避免了无关的场景信息，Multi-Attend通过多模融合网络实现多模信息的融合。Samp-Weighted Focussed Constrained Loss提高了对少见情感的识别。Multi-EMO在MELD和iEMOCAP上实现了State-of-the-Art性能，特别在少见情感和同义情感分类方面有显著提升。</sample>
    <sample id="281">Kyowin在演讲中介绍了她与Patrick Koc、Emilie Liu、Andre F. Martins和Graeme Newby合作完成的《When Does Translation Require Context: A Data-Driven Multilingual Exploration》这项研究。该研究探讨了翻译中上下文的重要性。她指出，翻译的准确性取决于上下文，例如，'mole'在不同语境下的含义不同。研究旨在回答两个问题：翻译何时需要上下文，以及模型如何处理这些情况。研究使用CXMI和Mouda Tagger等工具，分析TED Talks的翻译情况，评估不同模型的表现。研究发现，文档级翻译的准确性取决于使用的上下文类型和模型。</sample>
    <sample id="282">Xiaoxiao Zhu presented StoryTrance, a model for non-parallel style transfer at the discourse level, addressing challenges in transferring author-specific styles. The model uses a two-stage training process, separating discourse representation and style embedding, to enhance content while maintaining style. It outperforms existing methods, as shown by evaluations on Chinese and English datasets, with results aligning well with the target style.</sample>
    <sample id="283">提到的对称依存关系结构的名称是“城市名称的结构”。</sample>
    <sample id="284">Peng Tianxun from Wuhan University presented FSUE, a novel fuzzy span mechanism for enhancing universal information extraction. The model addresses ambiguity in span boundary labeling and mismatch in transformer feature extraction. FSUE represents the target boundary as a continuous distribution, using a sampling function to calculate fuzzy span loss. It introduces a fuzzy span attention layer to dynamically adjust attention span, improving performance in named entity recognition, relationship extraction, and aspect sentiment triplet extraction. The model achieves better generalization and information extraction capabilities, demonstrating significant improvements over existing methods.</sample>
    <sample id="285">Min Qi Gao介绍了他们的工作《Reference Matters: Benchmarking Factual Error Correction for Dialogue Summarization with a Fine-grained Evaluation Framework》。他们探讨了模型生成摘要中存在的事实错误，提出了两种解决方案：在训练过程中引入事实相关目标或设计独立的事实错误纠正模型。Gao批评了现有的事实错误纠正模型的评估方法，认为它们过于依赖事实错误指标，可能会误导事实错误纠正的本质。Gao提出了一个新的事实错误分类法，分为内容和形式两类，并提出了一个基于事件的评估框架。实验表明，使用人类纠正的参考摘要在训练事实错误纠正模型时效果最佳。Gao强调了结合人类纠正数据和生成数据的潜力，并指出了当前事实错误纠正模型在纠正某些类型错误方面的挑战。</sample>
    <sample id="286">演讲者的名字是James Finch和Sara Finch。</sample>
    <sample id="287">这篇论文有四位作者：Javad Hosseini, Philip Radlinsky, Silvia Parisi, 和 Annie Churvis。</sample>
    <sample id="288">用于测试句法现象的数据集包括Blimp、Syntactium和Wikipedia。Blimp和Syntactium用于创建相同或不同的句法结构的可接受和不可接受的句子，而Wikipedia用于测试模型对不同数据集的可接受性。</sample>
    <sample id="290">第一个研究问题的缩写是WIL。</sample>
    <sample id="291">该模型在11个不同的非生理任务上进行了评估，包括命名实体识别、分类、部分词标记和问题回答。</sample>
    <sample id="294">CamemBERT 最初是训练在 web 上的 medical crowd-sourced data 上。</sample>
    <sample id="295">演讲者的名字是Adam Szpekowski。</sample>
    <sample id="296">Valerio Basile介绍了他与亚马逊Alexa合作开发的自然语言理解项目。该项目旨在探索讽刺的复杂性，开发能够提供更具信息性的输出而非简单的二元分类的模型。为此，创建了一个名为EPIC的英语讽刺语料库，收集了来自社交媒体的文本对话。通过Prolific平台，收集了来自五种英语语言的约15名不同背景的15名标记者的标记。研究发现，标记者之间存在显著差异，特别是在年龄和地理分布方面。研究还开发了不同的模型，以捕捉这些差异，并发现这些模型在预测上更有信心。</sample>
    <sample id="297">这段内容讨论了从狗吠到牛角的狗吠术的研究。狗吠术是一种通过隐含的语言传达负面信息的策略，通常在外群中被误解为普通话，而在内群中被理解为有害的含义。研究人员开发了一个包含超过340个术语和符号的类型和格言库，旨在识别和理解这些术语。通过分析历史美国政治演讲，研究人员发现狗吠术与政治策略相关，特别是在共和党中。研究还评估了GPT-3等语言模型在识别狗吠术方面的能力，发现它在识别正式术语方面较为成功，但在社交媒体用语和特定群体的术语上表现不佳。最后，研究人员还展示了狗吠术如何通过替换标准的有害标签为狗吠术来逃避内容监管。</sample>
    <sample id="298">研究发现，时间漂移是导致性能下降的主要原因。</sample>
    <sample id="299">Mihalsgaragas and Lahos discuss improving the robustness of NLP models by reducing their reliance on shortcuts through a novel training method. They introduce a minimax training objective that focuses on underrepresented hard examples, enhancing the models' generalization to out-of-distribution data. This method, tested on datasets like MNLI, FEVER, and QP, shows consistent improvements in out-of-distribution performance compared to existing methods.</sample>
    <sample id="300">Belinda介绍了Interactive Dictation任务，该任务允许用户通过语音进行自然的编辑和编辑。她描述了一个用户如何通过语音将文本转换为语音，并在过程中进行自我纠正。她讨论了与传统语音识别系统相比，Interactive Dictation的优势，包括无需固定模板的编辑命令。她介绍了任务的四个步骤：音频转换、语音分割、语音修正和执行。她还介绍了数据收集和系统的基础架构，并讨论了使用T5和GPT-3模型的结果。最后，她强调了这项工作的潜力，并邀请更多研究。</sample>
    <sample id="302">为了确保输出序列中的词元按照正确的顺序排列。</sample>
    <sample id="303">作者建议模型所有者提高偏见缓解方法的透明度，以便更好地理解正面刻板和过度价值对齐是否导致了这些有害模式。透明度有助于研究人员更好地理解和解决这些问题。</sample>
    <sample id="304">最小对不可接受输入是指在语言模型评估中，模型被要求评估长序列的可接受性，而不是单个短语。</sample>
    <sample id="305">Dawie, a PhD student from Saarland University, presents a critical examination of weakly supervised learning (WSL). WSL uses weak labels from sources like heuristic rules, knowledge bases, or crowdsourcing, which are cheaper but noisy, leading to potential overfitting. Recent WSL methods often require clean validation data, which is costly and may not be necessary. Dawie questions the necessity of clean data, the number of clean samples needed, and whether clean samples should only be used for validation. His findings suggest that WSL methods need clean data to perform well, and that performance can be improved by fine-tuning on clean samples. He recommends reporting model selection criteria, comparing WSL with full supervision methods, and considering continuous fine-tuning. Dawie has open-sourced his code for further exploration.</sample>
    <sample id="306">Sebastian Schuster and Na Jeong Kim 研究了语言模型的实体跟踪能力。实体跟踪是理解更长的语境的关键能力，语言模型是否能执行此任务是一个关键问题。由于预训练数据的内容未知，设计实体跟踪任务有几个挑战。首先，实体状态在预训练数据中常见，可能会导致模型预测正确状态而不具备实体跟踪能力。其次，实体状态可能由单个单词或短语预测而无需考虑更大的语境。第三，使用细化或上下文示例可能会导致模型记住实体状态序列或学习应用启发式方法。为了确保模型不能使用这些短路，任务设计得当。通过测试 GPT-3、GPT-3.5 和 T5 语言模型，发现大多数模型仅复制初始状态，只有 Text-Davinci-3 以非平凡方式进行实体跟踪。研究表明，预训练代码是实现此能力的关键因素。虽然小型模型如 T5 可以通过直接细化学习实体跟踪，但随机初始化的模型无法学习实体跟踪任务。研究还未确定这些能力是否能在不同情况下泛化。</sample>
    <sample id="307">作者使用了名义和隐性任务的评估指标来评估模型性能。</sample>
    <sample id="308">Jenny, a Carnegie Mellon PhD student, presented her research on 'Anal Positionality: Characterizing Design Biases of Datasets and Models.' Collaborating with the University of Washington and Allen Institute for AI, she explored how datasets and models reflect certain demographic biases. Using Lab in the Wild, she re-annotated datasets with diverse annotators to compare annotations with model predictions. Her findings showed that datasets and models often align with English-speaking and educated populations, leaving non-binary and other underrepresented groups behind. Jenny recommended documenting design choices, conducting research with a lens of perspectivism, and building specialized datasets and models for specific communities to address these biases.</sample>
    <sample id="309">注释者之间的一致性是通过对100个双标注的对话进行评估来衡量的。</sample>
    <sample id="310">在不可接受和可接受查询中，选择来自Wikipedia的句子来添加完全无关的句子。</sample>
    <sample id="311">这篇论文的作者所属机构是德国的LMU柏林大学。</sample>
    <sample id="312">MultiInstruct 是第一个大型多模特定任务数据集，包含 62 个任务，涵盖 10 个类别。它是基于 21 个开源数据集构建的，并为每个任务提供五个专家撰写的指令。</sample>
    <sample id="313">这篇论文有两位作者：James Finch和Sarah Finch。</sample>
    <sample id="314">二进制协调是指在一个句子中，两个或多个动词的主语都由一个共同的主语连接起来的结构。</sample>
    <sample id="315">提示语的平均长度为6.5个单词。</sample>
    <sample id="316">发现表明较小的 T5 模型可以通过适当的训练在特定数据集上比大型语言模型更有效地执行语言规划任务。</sample>
    <sample id="317">Peng Li介绍了CodeIE项目，该项目旨在改进信息提取（NER）和关系提取（RE）等任务。CodeIE将信息提取转换为代码生成任务，使用CodeGen语言模型进行处理。通过这种方法，信息提取任务在输入和输出阶段保持一致，避免了传统方法中常见的输出线性问题。通过对T5、GPT-3等模型的评估，CodeIE在测试和关系提取任务上显著优于传统模型。研究还发现，使用CodeGen模型的输出更具结构性，且在回忆率上表现更好。CodeIE的分析结果提供了对信息提取任务改进的启发。</sample>
    <sample id="318">YanisLavraque介绍了他们在法国开发的Dr.Bert模型，该模型是基于Roberta的预训练模型，专为生物医学和临床领域设计。该模型在法国首次推出，并且在法国的11个生物医学和临床任务上表现出色。</sample>
    <sample id="319">论文比较了从零开始训练和使用现有模型的预训练策略。结果表明，从零开始训练的模型在大多数任务上表现更好，但使用现有模型的预训练策略在某些情况下也能提供可比的性能。</sample>
    <sample id="320">过拟合主要由测试重复使用引起。</sample>
    <sample id="321">评估简化质量通过使用D-Plane数据集作为标准对比，比较不同简化方法。通过调整和测试不同的模型，评估其在生成简化文本方面的效果。</sample>
    <sample id="322">Enrico在ACL23上将探讨文本分类器如何学习人类道德。他解释道德是区分正确与错误的内在指南，至关重要。语言模型必须理解和识别道德。道德通常被视为一个单一的尺度，但不同人对同一概念的标签会有所不同。社会理论提供了理解人类道德的多样性的方法。Moral Foundation Theory表明，五种不同的道德基础，类似于味觉，影响我们对道德的判断。该理论已用于自然语言处理。最近几年，研究人员试图理解和分类文本中的道德。我们使用MoraFoundation Twitter Corpus数据集，包含35,000条来自七个不同领域的推文。我们试图了解语言模型如何理解不同领域的道德表达。我们发现，语言模型可以识别不同领域的道德表达。例如，ALM和BLM在叛逆方面的态度不同。语言模型确实能识别道德表达的差异。</sample>
    <sample id="323">Yu Jiawang的论文探讨了使用语言模型和知识表示学习解决CommonsenseQA的挑战。该任务需要结合语言模型和知识库的能力来回答问题。传统方法通过实体推理和GNN来解决问题，但存在一些问题，如引入与问题无关的知识实体和限制的实体和关系编码。DHLK提出了一种解决方案，通过使用HKG来构建知识图并使用两种状态学习策略来优化结构和知识表示。通过使用Robert和Mask Self-Attention，DHLK动态地删除与问题无关的实体，并通过Mean Pooling和Transformer来增强实体和关系的表示。DHLK在CommonsenseQA和OpenbookQA上进行了实验，展示了其在领导者方面的优异。</sample>
    <sample id="324">是的，研究表明，语言模型确实具有不同的政治偏见。通过使用政治问卷进行自动评估，研究表明，GPT-4是最自由的语言模型，而GPT系列通常比BERT系列和其变体更具社会自由主义。</sample>
    <sample id="325">Hi, my name is Matthias Landmann, and today I'm going to give you a brief introduction to our paper on "Compositional Generalization without Trees using Multi-Set Tagging and Latent Permutations." This is joint work with my advisors Alexander Colla and Ivan Tiedoff. Compositional generalization can be understood as the ability of a learner to handle deeper recursion and unseen compositions of phrases that have been seen individually during training. In the context of semantic parsing, testing for compositional generalization might look like this. As usual, we have a training set of utterances. In this case, the girl slept, and Mary knew that the girl slept. These utterances are paired with logical forms that represent core aspects of their meaning. In contrast to standard machine learning evaluation, the test set does not come from the same distribution but contains structurally unseen logical forms. In this example, the model has seen shallow recursion during training and is tested on examples with deeper recursion. Naive sequence-to-sequence models struggle with this kind of out-of-distribution generalization and often produce outputs that are detached from the input. In particular, they often fail to reproduce the systematic correspondences between input and output, such as those that are color-coded in the example. A popular method to address this is to integrate trees into the models. The trees are intended to capture the compositional process that relates utterances with the logical forms. This works well, but trees are usually not given and need to be obtained somehow. This can be complicated and sometimes a computationally expensive process. Typically, this involves considerable formalism-specific preprocessing of the logical forms, for example, to handle variable symbols. Obtaining trees may also involve specialized grammar induction procedures. In this paper, we don't use trees and introduce a neural sequence-to-sequence model that directly models the correspondences between fragments of the input and fragments of the output. For the first time, we show strong generalization to deeper recursion without relying on trees. Our approach predicts the output from the input in two steps. First, we tag each input token with an unordered multi-set of tokens that will appear in the output. After the first step, we have all the right tokens but they're not ordered. That's why in the second step, we use another model to predict a permutation to put them into the right order. We introduce a new method to predict a permutation that does not put any hard constraints on the possible permutations. This makes our approach quite flexible and expressive. Conceptually, our permutation model works roughly like this. We go from left to right over the output and determine which multi-set token to put in every position. For the first output position, we simply select one as highlighted in red. Then, we jump to the next multi-set token to determine the second token in the output. We determine the third token in the output in a similar way by jumping to another multi-set token. We continue this process until every token from the first stage has been visited exactly once. To give you a teaser of the experimental results, here we compare our method with other treeless models on the cogs benchmark. Our model outperforms the others by a large margin on generalization to deeper recursion. Some other kinds of structural generalization remain very challenging, though. In our paper, we solve a couple of interesting technical challenges. First of all, the alignment between input and output is not given in the training data. As a consequence, for a given token, we don't know which multi-set it came from, which poses a challenge for training. In addition, sometimes there are multiple permutations that are consistent with the data, but the linguistically correct one is latent. We address this by inducing the alignment as part of the training. Our permutation method is very flexible, but it brings the challenge that finding the highest scoring permutation is NP hard. That's because this is related to the traveling salesman problem. We approximate this with a GPU-friendly continuous relaxation that also allows us to back-propagate through the solution and learn the linguistically more plausible permutations. If you want to learn more about our experiments and how we address these challenges, please have a look at our paper or come to our poster.</sample>
    <sample id="326">认知失调是指两个看似不一致的信念或行为之间的关系。例如，一个人可能会说自己知道吸烟会危害健康，但却仍然吸烟。这种不一致性在日常决策中很常见，但在语言表达中很少见。研究认知失调有助于理解人们之间的分歧、跟踪人群的信念、价值观和态度变化、理解极端主义和极化的影响，以及个人认知风格和决策过程。</sample>
    <sample id="327">Xiaoxu, a third-year PhD student, presents their work on a novel vision language model architecture called ManageTower at ACL 2023. The work, conducted during Xiaoxu's internship at Intel's Cognitive Computing Group, aims to improve visual question answering by effectively utilizing unimodal semantic knowledge. ManageTower builds on the BridgeTower model by introducing managers in each cross-modal layer to aggregate insights from pre-trained unimodal experts. This approach allows for more comprehensive cross-modal representation learning, outperforming other models trained on 4 million images, especially on the VQVC2 test set.</sample>
    <sample id="328">GPT-4是最自由派的语言模型。</sample>
    <sample id="329">Zheng Minhang from Peking University presents a work on generating structured pseudo-labels for zero-shot video sense localization, in collaboration with Shao, Hai, Lin, and Yang. The work addresses zero-shot video sense localization, which aims to find the most relevant video segments for a given natural language query. Existing methods often require manual annotation, which is costly and inefficient. The proposed method uses structured pseudo-labelling to train video sense localization models without manual annotation, reducing the influence of label noise.</sample>
    <sample id="330">累积训练在主动学习中表现更好。</sample>
    <sample id="331">Sarah Papi</sample>
    <sample id="332">MuDa 基准中的数据来自TED Talks 语料集，该语料集已被翻译成 14 种不同语言。</sample>
    <sample id="333">Wen Hao from Nanjing University presented a method to enhance neural machine translation (NMT) by injecting key knowledge into the model. The work addresses the issue of non-smooth representation spaces in NMT, which limits its generalization ability. The proposed framework, INK, involves a training loop that extracts key knowledge to guide the adapter in adjusting representations, and refreshes the datastore asynchronously. Experiments show that INK outperforms state-of-the-art KMT systems, achieving better BLEU scores with less memory space and faster inference.</sample>
    <sample id="335">演讲者的名字是Matthias Landmann。</sample>
    <sample id="336">跨语言转移是指在训练过程中使用一个语言的数据集来训练模型，然后将其应用于另一个语言的任务上。</sample>
    <sample id="337">The presentation introduces a novel approach to handling out-of-vocabulary (OOV) words in embedding-based models by leveraging word formation and association. The method involves creating a word relationship graph to infer OOV meanings, using a graph neural network for processing, and applying self-attention to assign node attributes. Experiments show the model's effectiveness in both intrinsic and extrinsic tasks, with potential for application to other languages, depending on word decomposition.</sample>
    <sample id="338">Bingxin, a researcher, presents a study on evaluating human explanations for AI models. The study, conducted with colleagues from Renmin University, focuses on a new evaluation metric, TRU, which outperforms the existing simulability score by considering explanation utility during model fine-tuning. The research uses five datasets, including COSE and ECQA, to demonstrate that TRU can better assess explanation quality across different tasks. The findings suggest that the usefulness of human explanations is task-dependent, and TRU provides a more accurate evaluation method.</sample>
    <sample id="339">这篇论文的作者是德国萨尔兰大学的博士生。</sample>
    <sample id="340">Guan Hao Huang from UCLA presented ParaAMR, a large-scale, syntactically diverse paraphrase dataset created using AMR back-translation. This dataset addresses the limitations of existing paraphrase datasets, which are either limited in scale or lack syntactic diversity. By leveraging AMR graphs, ParaAMR generates paraphrases that maintain semantic similarity while offering greater syntactic variety. The dataset includes 15 million source sentences with 6.9 paraphrases each, demonstrating higher syntactic diversity compared to other datasets. ParaAMR has been shown to improve performance in NLP applications such as sentence embeddings, syntactic control, and data augmentation. The dataset is available for further research and application.</sample>
    <sample id="341">作者使用了平均延迟和计算机意识平均延迟来衡量系统性能。</sample>
    <sample id="342">Gao Jinsun介绍了一个名为LiveChat的中文视频对话数据集，该数据集是通过在TikTok上直播视频自动构建的。该数据集旨在解决大型对话数据集中的挑战，包括缺乏多方对话和缺乏个性化对话。通过三个步骤，数据集从视频中提取对话并通过人脸检测和人脸分类器进行人脸识别。实验表明，使用单个流和双流的对话模型在响应和地址识别上有不同的优势。展望未来，研究人员将专注于将对话模型有效地应用于LiveChat。</sample>
    <sample id="343">在这次演讲中，Akshata和Martin介绍了他们的工作《知识集成测试》（KITMOS），这是一项由麦吉尔大学、MILA和微软研究院合作的工作。演讲中提到，自然语言理解模型通常会利用多种知识来源，例如预训练参数和输入时间的知识。演讲者们介绍了一个诊断测试套件，用于测试模型是否能够有效地集成来自不同来源的信息。演讲者们还介绍了一个名为“核心解决方案”的任务，该任务旨在测试模型是否能够正确解决指代问题。演讲者们还介绍了KITMOS的三个设置：背景预训练、背景双重和背景推断。演讲者们还介绍了一个数据集，其中包括一个例子，演讲者们解释了如何控制信息的可用性。演讲者们还介绍了一个实验，其中模型在KITMOS上进行训练，并展示了模型在不同设置下的表现。演讲者们总结了演讲，指出许多模型在没有特定训练的情况下无法有效地集成来自不同来源的信息。</sample>
    <sample id="344">树方法的缺点包括：1. 需要特定的形式化预处理和语法引入过程，可能复杂且耗时。2. 需要手动获取树，这可能是计算上昂贵的过程。</sample>
    <sample id="345">Matthias Landmann介绍了他的论文《无树的组合生成：使用多集标记和隐式排列》。该论文探讨了组合生成的能力，即学习处理训练期间单独看到的短语的深层结构。与传统的ML模型不同，这些模型在训练数据中没有相同分布的测试集中，包含结构上未见的逻辑形式。通常，树被引入模型以捕捉组合过程，但这通常需要复杂的形式化处理。本文提出了一种新的无树的序列到序列模型，直接预测输入和输出之间的对应关系。该方法通过两步进行：首先标记输入每个词的输出中可能出现的所有词组。然后使用另一个模型预测排列以正确排列这些词组。该方法在COGS测试集上表现出色，超越了其他无树模型。</sample>
    <sample id="346">The author of the paper, Shu-Hung, is affiliated with Microsoft Research Asia.</sample>
    <sample id="347">我是玛丽亚。今天我将讨论我们的论文《使用自然语言提示来衡量语言模型中的刻板。与丹·德罗夫斯基合作完成。近年来，许多人记录了大型语言模型（LLM）中存在的刻板和偏见。然而，这些衡量方法有各种局限性。它们通常依赖于非常耗时的手工构建数据集。它们通常只衡量特定刻板，无法很好地泛化到其他人口或上下文。或者它们只是捕捉了非常广泛的刻板，例如与特定群体的负面关联。除此之外，大多数工作在这个领域没有考虑交叉性，这是一种多方面的社会身份可以加重刻板并成为独特的伤害来源。为了克服这些局限性，我们依赖于这些新型的指令调节的LLM非常擅长响应指令和提示。因此，我们可以要求模型生成一个人物，这是一种描述一个想象的个体的提示。比如说，想象你是一个亚洲女人。描述你自己。我们可以立即看到，这非常适合任何人口的生成，因为我们可以指定任何我们想要的标记。以下是一些GPT4的示例生成。我们立即看到，虽然输出在传统意义上并不过于负面或有害，但有一些有趣的模式。亚洲女人被描述为不起眼的，来自中东的女人被用词如“异国情调”和“迷人地区”来描述。两种女性的刻板都提到了血统的参考，而白人男人的刻板没有。为了捕捉这些模式，我们的方法有两个部分。第一个是生成这些刻板。我们的生成提示受到一项研究启发，该研究发现，给人类主体这些提示也能揭示出种族刻板。并且这使我们能够直接比较我们生成的刻板和人类写的回应。第二部分是标记单词，这是一种方法来识别标记组和未标记组的单词。稍后我将详细介绍。标记单词方法利用社会语言学的概念，标记性，指出有一个未标记的默认值。任何不同于该默认的群体都是语言上标记的。例如，战士通常与男性相关。人们描述一个女性战士时，通常会指定“女人战士”，并用“女人”标记该术语。更广泛地说，社会上占主导地位的群体在语言上和社会上都是未标记的，而边缘化的群体通常是标记的。在我们的方法中，我们首先指定未标记和标记的群体。然后我们使用战斗词法进行比较。战斗词法基本上是使用权重对比来区分每个标记组的顶级单词。因此，对于刻板的黑人女性，我们会进行战斗词法并与白人刻板和男性刻板进行比较。现在，给出一些结果。首先使用刻板的词汇，我们发现生成的刻板中包含了更多刻板。实际上，分布的方式非常不同。虽然生成的刻板中有更多的刻板词汇，但人类写的刻板的分布更广泛。人类写的刻板中，刻板词汇的分布非常广泛。人类写的刻板中，刻板词汇的分布非常广泛。</sample>
    <sample id="348">Myra, Eszter, and Dan discuss their paper on measuring stereotypes in language models. They highlight the limitations of current methods, which often rely on hand-constructed datasets and fail to generalize well. Their approach uses instruction-tuned LLMs to generate personas, revealing patterns of stereotypes. The 'marked words' method identifies stereotypes by comparing marked and unmarked groups. Results show that generated personas contain more stereotypes, with positive words like 'tall' and 'athletic' used to describe certain groups. The paper concludes with recommendations for researchers to address positive stereotypes, use intersectional lenses, and increase transparency in bias mitigation methods.</sample>
    <sample id="349">大家好，我是中国科技大学的贾鑫伟。我很高兴为大家介绍一篇关于《保护大型语言模型用于嵌入式广告服务的版权》的论文。</sample>
    <sample id="350">Simone Tedesci 讨论了NLP中超人类性能的含义，指出，虽然模型在某些任务上表现出色，但在知识推理和推理方面仍然不可靠。通过分析 Superglue 和 SQuAD 这两个主要NLP评估，发现人类在大多数任务上被模型超越。研究人员发现了评估人类和模型的误差，包括评估基准不同、错误答案和缺乏对最佳人类表现的准确评估。研究人员还指出，缺乏对最佳人类表现的准确评估和缺乏关于评估人员背景信息的详细信息。为避免重复错误，研究人员建议改进评估方法。</sample>
    <sample id="351">Shu-Hung Luo's presentation on the paper 'Do ConCoNNer 2003 Named Entity Taggers Still Work Well in 2023?' explores the generalization capabilities of NER models using the ConCoNNer 2003 framework. The study investigates whether these models can effectively generalize to modern data, identifying three main factors for good generalization: model architecture, model size, and the number of fine-tuning examples. Experiments showed that transformer models and larger models generally perform better, while more fine-tuning examples also improve generalization. The study also examined two hypotheses for performance drops: adaptive overfitting and temporal drift. Adaptive overfitting was not observed, but temporal drift was confirmed as a significant factor. The conclusion is that ConCoNNer 2003 taggers can still be effective in 2023, but improvements in model architecture, size, and fine-tuning are necessary.</sample>
    <sample id="352">ABC-Eval 是一种新方法，用于评估对话AI的行为，旨在减少人类评估的主观性。它通过标记特定行为来评估对话模型的行为，如自我矛盾、提供无关信息或忽略对方。</sample>
    <sample id="353">本文介绍了通过提出问题来生成代码的研究。它指出，代码生成的一个重要挑战是输入下的指定缺失，特别是在现实世界中常见的情况。为了解决这个问题，研究人员提出了一个通过互动来收集更多信息的方法。研究人员提出了一个生成代码的任务，要求在关键操作上提出问题。研究人员还提出了一个方法来创建代码清晰性问题（CQA），即包含关键操作上的问题。研究人员还提出了一个代码生成的工作流程，包括一个问题选择器和一个代码生成器。研究人员还提出了两个假设：第一个是代码生成任务比现有的代码评分任务更具挑战性，第二个假设是问题有助于代码生成。研究人员还测试了他们的工作流程，发现模型性能随着更多高排名的CQAs的回答和包括在内而提高。然而，代码生成的工作流程仍然低于仅使用模型训练的代码生成。研究人员还分析了结果，发现，使用清晰性问题生成的代码比仅使用模型训练的代码生成更好。</sample>
    <sample id="354">直到 2020 年，CoNLL-2003 和 CoNLL++ 之间的性能增量才高于 5 个百分点。</sample>
    <sample id="355">Vasudha,一名Stony Brook大学的计算机科学博士候选人,向ACLU2023介绍了她的论文《转移学习为辩论检测,解决稀有类挑战》。我们首先定义了认知辩论,并解释了为什么研究它在语言中是重要的。简单地说,认知辩论是两种不一致的信念或行为,例如一个人说我知道香烟会杀死我,然后继续说我会在会议后抽烟。第二种行为是不一致的,它们有一个一致关系。虽然辩论是日常决策中经常发生的现象,但很少在其他话语关系中表达。为什么这很重要呢?研究认知辩论可以帮助我们更好地理解人们之间的分歧,跟踪人口中信念、价值和态度的趋势变化。高认知辩论与焦虑症有关,也可以更好地理解人们的心理健康。研究语言表达的辩论也有好处。由于没有任何先前的类似数据集,我们面临绝对稀有性的挑战。为了减轻这种情况,我们尝试使用转移学习和活动学习来标注更多的辩论样本,降低整体标注成本,但提高辩论检测。由于初始模型无法捕捉辩论类,我们开始活动学习。我们从两个不同任务进行转移学习。我们从主题独立辩论类分类任务开始,该任务确定两个来自不同人的辩论是否在主题上是一致的。我们称之为辩论类。由于这些任务与辩论类的概念密切相关,我们将其称为CE。我们发现,在转移时,对标注数据集的零短性能已经比随机要好得多。进一步地,我们发现,在辩论类上进一步细化后,辩论类的零短性能大大提高。我们使用的模型是最好的。我们还确定了更新模型的新数据的方法。每轮活动标注的策略都表现出相同或更好的性能。我们发现,在不同策略之间,PRC策略比其他现有的策略更好,尽管差异很小。请注意,随机的性能要低得多。经过两轮活动标注,我们提高了辩论分类的AUC到0.75,这是我们迄今为止在任务上取得的最佳性能。我们还检查了每个策略的可行性。我们发现,PRC策略在稀有类收集方面表现最好,但标注者也发现这些例子很难。总之,我们发现,PRC是一个简单的AL策略,适当设计的转移任务可以显着改善。我们还发现,在不同的领域进行活动标注的迭代更新是有用的。我们还发现,在域内的活动标注从累积更新中受益。我们提供了代码集和论文的链接。如果您有任何问题,请随时与我们联系。</sample>
    <sample id="356">这篇论文的作者是来自德国莱比锡大学（Universität Leipzig）和德国柏林工业大学（Technische Universität Berlin）的研究人员。</sample>
    <sample id="357">演讲者的名字是Yuan。</sample>
    <sample id="358">这篇论文有五位作者。</sample>
    <sample id="359">该方法与专门为 simultanous speech translation设计的最新架构进行了比较。</sample>
    <sample id="361">Armin Nurbaevich, a PhD student at Carnegie Mellon University, presents a project called CounterComp, which uses counterfactual scenarios to enhance compositional generalization in multi-step quantitative reasoning tasks. Current neural models struggle with tasks involving multiple arithmetic steps, often memorizing patterns rather than understanding. CounterComp addresses this by mining positive and negative examples from training data, using an auxiliary metric learning loss to improve model performance. This approach not only enhances in-distribution performance but also improves out-of-distribution results, making the model more robust. The project demonstrates that models can better attend to meaningful tokens, leading to more accurate outputs.</sample>
  </task>
</testset>