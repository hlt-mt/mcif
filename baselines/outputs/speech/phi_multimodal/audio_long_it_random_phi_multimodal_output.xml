<testset name="IWSLT2025" type="output">
  <task track="long" text_lang="it">
    <sample id="0">I modelli linguistici sono principalmente addestrati su grandi set di dati web, che includono una vasta gamma di fonti di notizie, come New York Times, Los Angeles Times, The Guardian, Huffington Post, e altri.</sample>
    <sample id="1">Akshata, Martin e il loro coautore sono affiliati con McGill University, Mila e Microsoft Research.</sample>
    <sample id="2">Tui Yu presents a paper on document understanding, focusing on the visually rich document understanding problem. The paper introduces a novel multi-pretraining model called Layout Mask, which addresses issues with reading order in existing models. Layout Mask uses local 1D position instead of global 1D position, and employs two masking strategies to enhance text-layout interactions. The model's performance is evaluated on datasets like COCO, SROIE, and CLUE, showing better results with global 1D position. The paper concludes that global 1D position is more adaptive in certain cases.</sample>
    <sample id="3">Ciao. Presentiamo il nuovo corpus Deepane, un nuovo corpus per la semplificazione del testo in tedesco a livello di documento e di frase. La mia identità è Regina Stoddens, e guiderò la prima parte della presentazione. Definiamo prima la semplificazione del testo. La semplificazione del testo è un processo di adattamento del testo per migliorare la comprensione del testo per un gruppo di destinazione, poiché le persone con difficoltà di lettura non sono native. Per addestrare un modello di semplificazione del testo, richiediamo coppie parallele di testo, ad esempio, documenti o frasi. Ecco un esempio di una coppia di frasi parallele di una frase complessa in tedesco e la sua traduzione in un linguaggio semplice. Per semplificare la frase, diversi metodi sono possibili, come la sostituzione lessicale, la cancellazione o la riorganizzazione delle clausole, o l'inserimento di parole. Proponiamo il nostro nuovo corpus Deepane, perché in recenti anni, ci sono stati alcuni problemi con i corpus esistenti. Quindi, per esempio, questi corpus sono troppo piccoli per addestrare un modello di semplificazione del testo. I modelli proposti negli ultimi anni sono tutti allineati automaticamente, il che significa che possono essere errori nei loro allineamenti. Pertanto, proponiamo il nostro nuovo corpus Deepane, che è diviso in due sottocorpora, Deepane ap e Deepane web. Deepane ap è basato su testi di notizie. In Deepane ap, abbiamo allineato quattrocentottantatre documenti, tutti manualmente. Questo si traduce in circa tredicimila coppie di frasi parallele. Per Deepane web, questo corpus include diversi domini. E allineiamo anche tutti questi settantacinque documenti, da una parte manualmente e dall'altra con metodi di allineamento automatico. In totale, otteniamo trentamilaquarantacinque coppie di frasi. Analizziamo ulteriormente le nostre coppie di frasi. Ad esempio, sul tipo di semplificazione. Come puoi vedere qui, i testi biblici sono semplificati molto più fortemente rispetto ai testi di notizie o ai testi di apprendimento della lingua. Su tutti i livelli, per esempio, semplificazione lessicale, semplificazione strutturale, semplificazione complessiva. Ora vediamo cosa possiamo fare con questo corpus. Ciao. Sono Omar, e ora parlerò degli usi del set di dati Deepane. Quindi, per il primo caso, possiamo valutare i metodi di allineamento automatico. Negli ultimi anni, ci sono stati molti metodi di allineamento, ma nel contesto delle traduzioni automatiche, dove abbiamo due documenti paralleli scritti in lingue diverse, e vogliamo estrarre allineamenti di frasi in post documenti. Ma nel nostro caso, stiamo cercando di estrarre allineamenti tra frasi di due documenti paralleli, che hanno lo stesso linguaggio, hanno lo stesso contenuto, ma sono a livelli di complessità diversi. Quindi, come abbiamo il nostro set di dati Deepane, che ha frasi allineate manualmente, possiamo usare queste frasi come standard di allineamento per valutare alcuni dei metodi proposti. E abbiamo fatto alcune modifiche ai metodi proposti. E abbiamo pubblicato tutti questi adattamenti e i codici per eseguire i nostri esperimenti nel documento. Alla fine, abbiamo concluso che il miglior metodo di allineamento automatico per la semplificazione del testo in tedesco è il metodo di mass align. Puoi anche trovare il codice per eseguire questo metodo sui tuoi documenti.</sample>
    <sample id="4">La relatrice si chiama Kaio Yin.</sample>
    <sample id="5">Hanno utilizzato il modello T5-large per ottenere un'accuratezza dell'82%-87%.</sample>
    <sample id="6">Zhan e il suo team presentano il loro lavoro su un modello di summarizzazione multilinguistica e crosslinguistica chiamato Pisces. Questo modello unificato può generare documenti in qualsiasi lingua in qualsiasi altra lingua. Il team ha condotto esperimenti su un set di dati di Wikipedia in cinque lingue, dimostrando che il modello Pisces supera i modelli precedenti in termini di prestazioni. Il modello è stato addestrato attraverso tre fasi di pretraining: monolingue, crosslingue e task specifico. I risultati sono stati validati attraverso studi di valutazione e studi umani, con il team invitando il pubblico a consultare il loro articolo per ulteriori informazioni.</sample>
    <sample id="7">Sì, i tagger CoNLL-2003 funzionano ancora, ma migliorare la loro generalizzazione richiede un'architettura di modello migliore, dimensioni più grandi e più esempi di fine-tuning.</sample>
    <sample id="8">Il metodo ABC Eval introduce annotazioni comportamentali per ridurre la soggettività nelle valutazioni umane, fornendo una valutazione più precisa e affidabile delle dimensioni della qualità del dialogo.</sample>
    <sample id="9">L'attuale approccio scarsamente supervisionato si basa in larga misura su dati di validazione 'puliti' per garantire che i modelli generalizzino bene.</sample>
    <sample id="10">Migliorare il punteggio richiederebbe accesso a più informazioni, come nomi, descrizioni, immagini, link, ecc.</sample>
    <sample id="11">Jack Hessle, a research scientist at AI2, presents a study on humor understanding benchmarks using the New Yorker Caption Contest data. The study involves three tasks: matching, quality ranking, and explanation generation. The best model, CLIP, achieves 62% accuracy in matching, but humans score 94%. GPT-4, despite additional annotations, still lags behind humans in performance. The study highlights the challenges in making AI understand humor, with GPT-4's joke explanations often being less accurate than human ones. The dataset is available for further research.</sample>
    <sample id="12">L'articolo è scritto da un gruppo di quattro autori: Dawei, Xiaoxuan, Mario Musbach, Giasdeth, e Dittli.</sample>
    <sample id="13">Daniel Rotem presents his work on adaptive inference, focusing on improving inference in low-resource settings. He compares multi-model and early-exit methods, highlighting the issue of conflicting gradients in early-exit models. The SWEET method is introduced, which fine-tunes early-exit architectures by separating weights, thus avoiding gradient conflicts. Results show SWEET outperforms both methods in speed and accuracy, suggesting potential for future research in fine-tuning algorithms.</sample>
    <sample id="14">Il discorso di Adam Schechtman riguarda la struttura della coordinazione. Come si sa, diverse strutture di dipendenza sono presunte da diverse teorie e approcci. Ad esempio, nelle dipendenze universali, la struttura della coordinazione Lisa, Bart e Maggie è tale che il primo congiunto è il capo della struttura di coordinazione. Un approccio simmetrico è presunto nella teoria del significato di Higginson, dove di nuovo, la struttura di coordinazione è guidata dalla congiunzione. Quindi, si selezionano una delle congiunzioni. Ci sono anche approcci simmetrici alla struttura della coordinazione, come l'approccio di Praga, che presume che le strutture di coordinazione siano guidate dalla congiunzione. Quindi otteniamo dipendenze da e a tutte le congiunzioni. E infine, c'è un approccio multiheaded, che è usato, ad esempio, nella grammatica delle parole di De Caton, dove tutte le congiunzioni sono teste delle strutture di coordinazione. Quindi otteniamo dipendenze dal governante, qui, ama, a tutte le congiunzioni separate. Queste sono barche e Maggie. Ora, l'obiettivo di questo documento è produrre un nuovo argomento per le strutture simmetriche di coordinazione, come queste due, e contro le strutture asimmetriche di coordinazione, come queste due. L'argomento si basa sul principio di minimizzazione della lunghezza delle dipendenze, che spiegherò sulla base di questi esempi. In inglese, come si sa, gli oggetti diretti preferiscono essere vicini al verbo, mentre gli oggetti aggiuntivi possono essere più lontani. Quindi, marzo ha letto ieri va bene, perché l'oggetto diretto è vicino al verbo, mentre marzo ha letto ieri è molto peggio, perché qui c'è un oggetto aggiuntivo, ieri. Questo è perché, anche se questa frase viola il principio grammaticale che gli oggetti diretti dovrebbero essere vicini al verbo, soddisfa il principio di minimizzazione delle dipendenze, che dice che le dipendenze più corte sono preferite. Quindi, questi due alberi mostrano solo la lunghezza delle dipendenze cruciali, quelle che non sono costanti tra queste due strutture. Quindi, qui abbiamo una dipendenza da red all'oggetto aggiuntivo di lunghezza sette, misurata in parole, e da red al libro di lunghezza quattro, quindi per ottenere è undici. Quando si spostano, quando si scambiano questi due costituenti, la somma di queste due dipendenze diventa sei. Quindi, invece di undici, molto più breve. Questo è perché, anche se questa frase viola un principio, soddisfa un altro. Ok, quindi, quello che abbiamo fatto, abbiamo estratto varie statistiche sulla coordinazione dall'Enhanced version of the Penn Treebank. E vedere il documento, perché non usiamo le dipendenze universali. E queste statistiche confermano l'osservazione fatta molte volte prima, che le congiunzioni di sinistra tendono ad essere più corte. E anche l'osservazione che è stata fatta in modo passante, che questa tendenza cresce con la differenza di lunghezza. Quindi, quando la differenza tra le lunghezze delle due congiunzioni cresce, la congiunzione di sinistra preferisce essere la prima. Quindi, la proporzione è più grande della congiunzione di sinistra breve. Ma ciò che è nuovo in questo documento è che abbiamo osservato che questa tendenza si verifica solo quando il governante è a sinistra, giusto? Quindi, il governante è a sinistra, in questo esempio, è il governante, è a sinistra. Quindi, non c'è un governante esterno. Quindi, in tali casi, la coordinazione di due verbi e non c'è un governante esterno, giusto? Quindi, la coordinazione di due verbi e non c'è un governante esterno. Quindi, quando il governante è a destra, come in questa coordinazione, la coordinazione di due verbi, e non c'è un governante esterno, giusto? Quindi, in tali casi, l'effetto scompare. Quindi, misuriamo la lunghezza in caratteri, la prima colonna, in sillabe, la colonna centrale, e in parole, la colonna destra. Quindi, quello che vediamo qui è che quando il governante è a sinistra, la tendenza per la congiunzione di sinistra essere più breve cresce costantemente con la differenza assoluta delle parole. E lo stesso è osservato quando non c'è un governante esterno, come nella coordinazione delle frasi. E dimostriamo come questo fornisce un argomento contro le strutture asimmetriche di coordinazione, come queste due, e per le strutture simmetriche di coordinazione, come queste due. Quindi, vedi il documento per l'accordo e argomento. E parla con noi alla sessione posteriore. Grazie.</sample>
    <sample id="15">Tre autori sono coinvolti nell'articolo: Matthias Landmann, Alexander Coller e Ivan Tiedoff.</sample>
    <sample id="16">I testi biblici risultano più semplificati rispetto ai testi di notizie o di apprendimento della lingua.</sample>
    <sample id="17">Shen Chuan Wu, a PhD student, presents a multimodal relation extraction method addressing challenges in extracting semantic relations from text and images. The method involves creating a unified cross-modal graph, refining it with graph information principles, and enriching it with multimodal topic information. Experiments show that this approach outperforms existing models, especially in high-relevance scenarios where internal information screening is crucial.</sample>
    <sample id="18">L'esempio è 'salt and pepper' rispetto a 'pepper and salt', dove 'salt' è più breve.</sample>
    <sample id="19">Il discorso di Shanshan Chen, una studentessa di master di Shenzhen University, si concentra sul suo lavoro su question answering open domain, accettato da ACL 2023. Il suo approccio è basato su un modello a due fasi, che include un recupero e un lettore. Il recupero prevede un question encoder e un document encoder, con il corpus di Wikipedia pre-elaborato in un file di indice per facilitare la ricerca. Le sfide affrontate includono la grandezza del corpus, la dimensione del file di indice e la complessità dei modelli linguistici. Per affrontare queste sfide, vengono utilizzate tecniche come la ricerca rapida, la lettura rapida e la riduzione della dimensione del modello. Il confronto tra sistemi di recupero e quelli di generazione mostra che i sistemi di recupero offrono un equilibrio tra velocità, memoria e prestazioni. Le conclusioni suggeriscono che, se limitati dalle risorse, si possono considerare sistemi di recupero o ridurre la dimensione del modello.</sample>
    <sample id="20">Sì, i modelli sono disponibili gratuitamente su Hugging Face, e i script di allenamento sono disponibili nel repository GitHub.</sample>
    <sample id="21">DEplain-apa contiene documenti di notizie.</sample>
    <sample id="22">I fattori che contribuiscono a una buona generalizzazione sono la scelta della struttura del modello, la dimensione del modello e il numero di esempi di fine-tuning.</sample>
    <sample id="23">Dan Garrett discute the challenges in text rendering for text-to-image models, focusing on the limitations of T5 and the superior performance of ByteT5. He explains that T5's sentence piece tokenization struggles with spelling, especially for frequent words, while ByteT5's byte-level encoding allows for accurate spelling. To improve text rendering, Garrett augments the Imagine model with ByteT5's encoding, enhancing its text rendering capabilities without significantly increasing parameters. Despite these improvements, errors can still occur during image generation. The paper introduces benchmarks for text-only and text-to-image models and proposes a strategy to enhance model spelling.</sample>
    <sample id="24">La tendenza è stata misurata in termini di lunghezza in sillabe, caratteri e parole, mostrando che i congiunti a sinistra tendono ad essere più brevi, specialmente quando il differenziale di lunghezza tra i congiunti è maggiore.</sample>
    <sample id="25">Gli esperimenti hanno utilizzato frasi con e senza governanti per osservare le lunghezze dei congiunti. Frasi con governanti hanno mostrato una tendenza per i congiunti più brevi quando i congiunti erano di lunghezza diversa, supportando le strutture di coordinazione simmetriche.</sample>
    <sample id="26">Un classificatore base addestrato su dati non bilanciati non si comporta meglio del classico al 50%.</sample>
    <sample id="27">Cinque autori sono coinvolti nell'articolo.</sample>
    <sample id="28">I personaggi nella conversazione sono Bob e Alice.</sample>
    <sample id="29">I modelli di MT sensibili al contesto migliorano la traduzione di fenomeni come la formattazione e la coesione del discorso, ma non mostrano un miglioramento significativo per fenomeni come l'ellissi, le pronome e la forma verbale.</sample>
    <sample id="30">L'LM Blender è un framework semplice e efficace per l'assemblea dei modelli linguistici. Basato sulla fusione generativa parallela, utilizza un modello di classificazione parallela per valutare i modelli e un modello di fusione sequenziale per generare output finali. I risultati dimostrano che il framework migliora significativamente le prestazioni, superando modelli come Open Assistant e Vacuna in molti casi.</sample>
    <sample id="31">Gli autori dell'articolo sono Koistaph Sinha, John Wautier, Aaron Muller, Kanishka Mishra, Karen Fenten, Roger Levy e Atina Williams.</sample>
    <sample id="33">Il framework NL Positionality quantifica la posizionalità confrontando le annotazioni di vari demografici con i risultati dei modelli, utilizzando Pearson's R correlation score, differenziandosi dal focus tipico sull'agenzia degli annotatori.</sample>
    <sample id="34">Marco Treviso presenta il framework Crest, che combina la razionalizzazione selettiva e la generazione di contrafatti per migliorare la generazione di contrafatti. Crest utilizza un modello razionalizzatore per produrre razionalizzazioni significative, che vengono poi utilizzate per mascherare le parti dell'input originale e preparare nuovi contrafatti. I contrafatti generati da Crest sono valutati per validità e naturalezza, ottenendo risultati positivi sia in valutazioni automatiche che umane. Crest migliora anche i modelli di classificazione fornendo contrafatti per l'aggiornamento dei dati. I razionalizzazioni di Crest sono più interpretabili e hanno una maggiore simulabilità contrafacciale, rendendolo un approccio efficace per migliorare le spiegazioni dei modelli di classificazione.</sample>
    <sample id="36">Il discorso introduce Language-Specific Layers (LSLs) per migliorare la capacità del modello di traduzione multilingue, mantenendo costante il costo di inferenza. LSLs selezionano sub-layeri specifici per lingua, riducendo il costo di inferenza. L'implementazione si concentra sull'encoder, con un approccio di apprendimento per la posizione dei LSL. I risultati dimostrano significativi miglioramenti in termini di prestazioni, specialmente per le lingue a risorse limitate, rispetto ai modelli di base e ai modelli con adattatori linguistici.</sample>
    <sample id="37">Lo studio precedente ha mostrato che gli umani sono in grado di evidenziare stereotipi razziali quando ricevuti gli stessi prompt di persona, fornendo un punto di confronto diretto con le generazioni di LLM.</sample>
    <sample id="38">Le fonti di dati utilizzate sono state estratte dall'Enhanced Version of Penn Treebank e dal documento 'Why We Don't Use Universal Dependencies'.</sample>
    <sample id="39">L'articolo è scritto da un solo autore, Adam Szarkowski.</sample>
    <sample id="40">Le attività strettamente correlate alla dissonanza cognitiva includono la dissonanza tra credenze e azioni, come quando una persona afferma di sapere che il fumo può danneggiare la salute ma continua a fumare.</sample>
    <sample id="41">Il lavoro di Su Lin e del suo team dal Natural Language Processing Lab dell'EPFL University introduce Peacock, un sistema di conoscenza personale e comune per narrazioni coerenti e coinvolgenti. Collaborando con Sony Group Corporation, il team ha sviluppato Peacock per rappresentare conoscenza personale a livello di parole, con un focus sui relazioni interpersonali. Il sistema include 3.800 personae e 40.000 attributi, formati in 100.000 inferenze. Il lavoro è stato realizzato in tre fasi: selezione dei personae, induzione degli attributi e annotazione delle relazioni. L'annotazione AI ha mostrato un'elevata precisione, e Peacock ha migliorato i risultati generativi del modello di linguaggio. Inoltre, Peacock ha migliorato la modellazione del dialogo, risultando in conversazioni più coerenti e coinvolgenti.</sample>
    <sample id="42">L'articolo è scritto da un solo autore, Shu-Hung.</sample>
    <sample id="43">Due autori sono coinvolti nell'articolo.</sample>
    <sample id="44">Il framework differisce dai lavori precedenti in quanto confronta direttamente le annotazioni degli utenti con le previsioni e le etichette dei modelli, invece di concentrarsi solo sull'armonia degli annotatori o sui modelli delle distribuzioni degli annotatori.</sample>
    <sample id="45">La configurazione 3, che combina lessico e Marked Words, si sovrappone maggiormente al lessico degli stereotipi.</sample>
    <sample id="46">Il lavoro ha confrontato DeepL e Google Translate, con DeepL che ha mostrato generalmente una maggiore accuratezza per la traduzione a livello documentale.</sample>
    <sample id="47">L'attenzione di questo discorso è rivolta alla comprensione dei processi che portano a modelli linguistici politicamente biasati.</sample>
    <sample id="48">L'articolo è stato scritto da Aydin Bilal e i suoi colleghi di Google Translate.</sample>
    <sample id="49">Le valutazioni MPP sono state eseguite fino a 1024 token di lunghezza del contesto.</sample>
    <sample id="50">Regina Stoddens presentation introduces the Deepane corpus, a new resource for German text simplification. The corpus, divided into Deepane API and Deepane Web, offers manually aligned sentence pairs to address issues with existing resources. It includes diverse simplification techniques like lexical substitution and rephrasing. The presentation highlights two use cases: evaluating automatic alignment methods, with MASS-Align proving effective, and fine-tuning language models for text simplification. The results serve as a benchmark for future automatic text simplification efforts.</sample>
    <sample id="51">I domini inclusi nel set di dati sono musica, libri e ricette.</sample>
    <sample id="52">Posizionalità si riferisce alle prospettive che le persone hanno a causa della loro demografia, identità e esperienze di vita. Influenzano il processo di ricerca e i suoi risultati, poiché possono cambiare le decisioni che i ricercatori prendono.</sample>
    <sample id="53">La relatrice si chiama Dawei.</sample>
    <sample id="54">Vasudha, a PhD candidate at Stony Brook University, presents her work on cognitive dissonance detection for ACL 2023. The study defines cognitive dissonance as inconsistent beliefs or actions, crucial for understanding mental health, decision-making, and social issues. Due to its rarity in language, the research uses transfer and active learning to improve dissonance detection. Initial models struggled, but transferring weights from related tasks improved performance. The proposed probability of rare class strategy (PRC) outperformed other methods, though annotators found examples challenging. The study concludes that PRC is effective for rare class acquisition, and transfer learning with domain-specific tasks is beneficial.</sample>
    <sample id="55">Sì, EDAtt adatta un modello ST offline esistente senza ricreazione, utilizzando solo un modello per ogni latenza e sfruttando l'attenzione tra input audio e output testuale.</sample>
    <sample id="56">L'articolo è scritto da un solo autore, Yu Chen Zhang.</sample>
    <sample id="57">Sì, il modello funziona sulla suite di test, ma richiede addestramento specifico per integrare efficacemente le fonti di conoscenza.</sample>
    <sample id="58">Le tre varianti di KITMUS sono: Background Pre-trained, Background Both, e Background Inference.</sample>
    <sample id="59">L'attenzione si concentra sulla creazione di un modello pre-addestrato in francese per il dominio medico clinico, noto come Dr. Bert. Il modello è basato su RoBerta e addestrato su un set di dati di medicina dal web, noto come Natus. Il discorso si estende alla confrontazione con altri modelli pre-addestrati, inclusi Camembert e altri modelli clinici. Il confronto mostra che i modelli addestrati su dati specifici per il dominio mostrano prestazioni migliori, anche se i modelli addestrati su dati diversificati possono essere più versatili. Il modello Dr. Bert ha superato in performance i modelli generici come Camembert in 9 su 11 compiti di non screening. I modelli e i script di addestramento sono disponibili gratuitamente su GitHub.</sample>
    <sample id="60">Gli autori dell'articolo sono Javad Hosseini, Philip Radlinsky, Silvia Parati e Annie Churvis.</sample>
    <sample id="61">L'ultima domanda di ricerca è se continuare a perfezionare i modelli direttamente sui campioni di validazione puliti può raggiungere prestazioni paragonabili a quelle dei metodi WSL più complessi.</sample>
    <sample id="62">Nathalie Daron, autrice dell'articolo, discute della necessità di comprimere i modelli di linguaggio per migliorare l'efficienza e ridurre i costi. Il suo lavoro si concentra sulla distillazione del sapere, un processo che trasferisce conoscenza da un modello grande a uno più piccolo. Daron introduce un approccio innovativo che utilizza pseudo-target, generando più pseudo-target per migliorare la diversità e l'esposizione del modello. Proposta anche una tecnica di distillazione chiamata joint teaching, che applica distillazione a pseudo-target generati sia dal modello maestro che dal studente.</sample>
    <sample id="63">La sensibilità misura la coerenza delle risposte del modello per lo stesso compito, indipendentemente dalle variazioni nella formulazione dell'istruzione.</sample>
    <sample id="64">La relatrice è Jingwei Yi, dell'Università di Scienza e Tecnologia di Cina.</sample>
    <sample id="65">Una maggiore sensibilità indica una performance del modello migliore, poiché suggerisce che il modello produce risultati coerenti per le stesse istruzioni, indipendentemente dalle variazioni nella formulazione delle istruzioni.</sample>
    <sample id="66">Il documento discute l'importanza della ragionamento matematica nell'intelligenza umana e del suo sviluppo nei sistemi di intelligenza artificiale. Esamina i compiti di ragionamento matematico, come il risolvenza di problemi geometrici e la dimostrazione automatica di teoremi. Esamina le architetture di rete neurale, inclusi i modelli sec-to-sec e i modelli di linguaggio pre-allenati, evidenziando i loro progressi e limitazioni. I modelli di linguaggio pre-allenati, come i modelli LLM, mostrano risultati promettenti, ma affrontano sfide come la generalizzazione e la robustezza. Il documento conclude con l'importanza di migliorare i modelli di linguaggio per migliorare le capacità di ragionamento matematico.</sample>
    <sample id="67">Rendi il contenuto inglese (circa 200 parole).</sample>
    <sample id="68">I modelli vengono addestrati con un insieme di dati linguistici che includono frasi di vari domini, come il linguaggio naturale, il testo di Wikipedia e il linguaggio di dialoghi.</sample>
    <sample id="69">In genere, circa 20 campioni di convalida puliti sono necessari per raggiungere buone prestazioni in WSL.</sample>
    <sample id="70">Mira El-Sawy, Essam Derbosh e Dan Jurafsky sono gli autori dell'articolo.</sample>
    <sample id="71">The research focuses on resolving indirect referring expressions in entity selection, introducing the alt-entities corpus. The team, including Javad Hosseini, aims to understand user language for choices, using a dataset from music, books, and recipes domains. The methodology involves crowd annotation with a cartoon completion setup, providing background knowledge to annotators. The corpus contains 6,000 questions and 42,000 expressions, with T5-large model results showing high accuracy with full background knowledge, but lower with partial knowledge. The study highlights the need for improvement, as current models achieve only 60% accuracy with entity names.</sample>
    <sample id="72">I metodi attuali non tengono conto della complessità e della natura dinamica dell'informazione, rendendo difficile valutare accuratamente i bias.</sample>
    <sample id="73">La relatrice è Akshata.</sample>
    <sample id="74">Il documento discute la creazione di DenseAtomic, un grafo di conoscenza densamente collegato che migliora la copertura e i percorsi multi-hop di Atomic. Introduce RS-KGC, un metodo di inferenza delle relazioni che supera le limitazioni di Atomic, migliorando la copertura e la diversità dei percorsi. Le valutazioni dimostrano che DenseAtomic offre una copertura e una performance migliori rispetto a Atomic e altri metodi.</sample>
    <sample id="75">Zhengyan Dan presents a joint framework for NER and RE tasks, addressing the challenge of fully supervised models requiring extensive annotated data. The framework, Joint Prop, integrates NER and RE by propagating labels over heterogeneous graphs, considering interconnections between labeled and unlabeled data. It consists of four parts: span feature generation, graph construction, joint label propagation, and model optimization. Experiments on four datasets show that joint learning benefits from task co-dependency, with significant improvements over single-task baselines.</sample>
    <sample id="76">L'infrastruttura di propagazione dei bias politici è complessa, con pre-allenamento influenzato dalla diversità dei media, ma anche dalla loro inclinazione politica. I modelli di linguaggio acquisiscono questi bias, che si manifestano in applicazioni downstream, portando a questioni di equità.</sample>
    <sample id="77">Questo video discute il lavoro su miglioramento della coerenza fattuale delle riepiloghi in base al feedback naturale, realizzato da Yale University e Microsoft Research. Il dataset 'DefAct' introduce prove e feedback per migliorare la coerenza fattuale. Il lavoro introduce tre nuovi compiti di linguaggio naturale, fornendo modelli di base per ciascuno. Il compito di riepilogo astratto è studiato, con un focus sulla coerenza fattuale dei riepiloghi. I dati raccolti includono annotazioni e feedback per valutare la coerenza fattuale. I risultati mostrano che i riepiloghi modificati da annotatori ottengono punteggi di coerenza fattuale più alti rispetto ai riepiloghi iniziali. Il dataset 'DefAct' è stato rilasciato su GitHub.</sample>
    <sample id="78">Sì, il processo di semplificazione varia tra DEplain-apa e web. DEplain-apa si concentra maggiormente su tecniche come la reordinazione e l'inserimento di parole, mentre DEplain-web enfatizza più la rephrasalizzazione.</sample>
    <sample id="79">Sì, Coscript è disponibile pubblicamente. È stato condiviso su GitHub, dove puoi scaricarlo e utilizzarlo per la ricerca e lo sviluppo.</sample>
    <sample id="80">La filigrana viene inserita attraverso il processo di watermark injection, dove il provider calcola una combinazione ponderata del target embedding e dell'originale basata sul numero di trigger nel testo.</sample>
    <sample id="81">L'articolo è stato scritto da Xu Zhang, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan Liu, Yifan</sample>
    <sample id="82">Il video discute il lavoro su un framework per l'aggregazione di segnali heuristici per l'analisi automatica delle risposte (Aes), che mira a valutare la qualità delle risposte senza intervento umano. Il framework, chiamato URRA, introduce più segnali heuristici per fornire una supervisione più robusta. Contiene un modulo di classificazione heuristica e un modulo di aggregazione dei punteggi, che trasformano i punteggi delle risposte in una gamma di punteggi. I risultati sperimentali dimostrano che il framework URRA supera le linee di base non supervisionate, sebbene le prestazioni non raggiungono quelle dei metodi di supervisione.</sample>
    <sample id="83">Sì, i modelli codificatore-decodificatore come mt5 possono migliorare con l'addestramento su una combinazione di lingue. L'addestramento su più lingue può portare a un miglioramento delle prestazioni, a condizione che il modello non sia dominato da una lingua specifica, come dimostrato dal calcolo di Exemplar.</sample>
    <sample id="84">Shaohu Xie, in his 2023 paper, introduces PANET, a framework for efficient dynamic networks. Traditional networks use static parameters, but dynamic networks adjust based on input, like Mixture of Experts and Dynamic Convolution. However, fully dynamic networks are inefficient due to redundant parameters. PANET addresses this by partitioning parameters into dynamic and static, using scale factors to optimize training. Experiments show PANET outperforms both static and fully dynamic networks, maintaining accuracy with fewer parameters. Future work includes expanding PANET to other networks and hardware structures.</sample>
    <sample id="85">Un esempio di pianificazione linguistica vincolata è 'prepara una torta di cioccolato'.</sample>
    <sample id="86">Gli autori utilizzano esperimenti con metriche come delta cosine, delta L2 e KS test per verificare che le inserzioni di watermark mantengano la segretezza, mostrando difficoltà nel distinguere le inserzioni di watermark dalle normali.</sample>
    <sample id="87">Il lavoro sfrutta i PLM esistenti come BERT, camembert e altri, per creare un modello in francese, Dr. Bert, utilizzando dati di natura clinica. Confronta diversi metodi di pre-addestramento per migliorare le prestazioni, offrendo un modello versatile e performante per il dominio medico francese.</sample>
    <sample id="88">GPT-4 è meno allineato con i paesi non inglesi.</sample>
    <sample id="89">La frase di esempio mostra il modello che punta ai frame audio più recenti e ai più vecchi, determinando l'emissione delle parole in base ai pesi di attenzione, emettendo parole solo se i pesi di attenzione sono sufficientemente alti.</sample>
    <sample id="90">Hannah Lu e i suoi colleghi hanno esplorato l'idea che i linguisti potrebbero essere efficaci annotatori per i dati di linguaggio. In un esperimento, hanno confrontato i risultati di annotazione dei linguisti con quelli dei nativi parlanti, usando vari metodi di supporto. I risultati hanno dimostrato che i linguisti possono annotare accuratamente i dati, specialmente per compiti più semplici, e che i loro risultati di annotazione possono essere paragonati o addirittura superare quelli dei nativi parlanti. Inoltre, i linguisti hanno mostrato un miglioramento nel loro livello di competenza linguistica attraverso il processo di annotazione. Questo studio suggerisce un nuovo approccio per costruire dataset di linguaggio, potenzialmente superando le barriere geografiche e tecnologiche.</sample>
    <sample id="91">Aumentare il numero di attività migliora la performance del modello, riducendo la sua sensibilità.</sample>
    <sample id="92">Gli autori confrontano il loro metodo con tre approcci di riferimento: 1) Modelli di composizione che utilizzano alberi, 2) Modelli di composizione senza alberi, 3) Modelli di composizione basati su strutture di rete.</sample>
    <sample id="93">Il primo autore è Matthias Landmann, e i due coautori sono Alexander Koller e Ivan Tiedoff.</sample>
    <sample id="94">Il discorso del professor Jingwei Yu del University of Science and Technology of China si concentra sulla protezione dei modelli di linguaggio per servizi di embedding ad embedding. I servizi di embedding, basati su modelli di linguaggio come GPT, sono essenziali per vari compiti NLP. Tuttavia, il furto di questi modelli è un problema crescente. Il metodo proposto, Embedding Marker, introduce un watermark basato su backdoor per proteggere i servizi di embedding. Questo metodo include la definizione di trigger e la verifica del copyright attraverso la costruzione di set di dati backdoor e benign. I risultati dimostrano che Embedding Marker mantiene l'utilità dei servizi di embedding pur proteggendo efficacemente i loro contenuti.</sample>
    <sample id="95">Il primo autore di PaLM è Siddhartha Bhattacharyya.</sample>
    <sample id="96">Ciao a tutti. Sono Jenny, uno studente di primo anno alla Carnegie Mellon University. Oggi presenterò il nostro lavoro, analizzando la posizione dei dati e dei modelli. Questo lavoro è stato fatto in collaborazione con alcuni colleghi dell'Università di Washington e dell'Allen Institute for AI, in particolare Sebastian Santi, Rohan Lal, Katrina Rainecka e Martin Sab. Immaginate di lavorare per un giornale e cercare di rimuovere contenuti tossici sotto un articolo. Potreste rivolgervi a un'API popolare come Perspective API per la rilevazione del contenuto tossico. E questo funziona davvero bene se siete Carl Jones. Ma questo non è il caso di Aditya Sharma, dove Perspective API non è davvero sensibile ai termini offensivi più comuni in contesti indiani. Questo è un esempio di un bias di progettazione, dove vediamo differenze sistematiche di prestazioni della tecnologia tra popolazioni. Bias di progettazione come quello che abbiamo appena visto prima potrebbero verificarsi a causa della posizione dei ricercatori e dei sviluppatori di modelli. Positionalità è semplicemente le prospettive che le persone hanno a causa della loro demografia, identità e esperienze di vita. Questo è un concetto ampiamente usato negli spazi accademici femministi e queer. E come ricercatrice, la positionalità può influenzare il processo di ricerca e i suoi risultati, perché può cambiare le decisioni che i ricercatori prendono. E quindi una domanda che le persone potrebbero chiedere è, i dati e i modelli hanno positionalità? Non stiamo dicendo che i modelli e i dati stessi hanno identità demografiche e esperienze di vita, ma aggregano giudizi e opinioni di persone reali e possono rappresentare certe posizioni rispetto ad altre. Quindi, il nostro lavoro suggerisce alcuni esempi anecdotali di avere positionalità, come i gap culturali nei modelli e nei set di dati, oltre a definizioni di modelle positionalità. Tuttavia, questi lavori non guardano a confrontare gli utenti finali con i dati e i modelli stessi. E studiare la positionalità dei dati e dei modelli è sempre più importante man mano che le attività di NLP diventano più soggettive e socialmente orientate. Ed è difficile caratterizzare come queste posizioni sono distorte, perché non tutte le decisioni sono documentate e molti modelli sono nascosti dietro API. Quindi, per studiare la positionalità dei dati e dei modelli, confrontiamo le annotazioni con utenti reali con i dati e i modelli esistenti. E questo attraverso il nostro framework. Il nostro framework funziona in due passaggi principali. Il primo passo è reannotare i set di dati con annotatori diversi. E optiamo per questo piuttosto che guardare le demografie degli annotatori originali, perché di solito solo pochi annotatori annotano ogni istanza, e perché le demografie non vengono raramente raccolte e condivise. E quindi optiamo per reannotare i dati per ottenere molti annotatori per istanza e per ottenere un insieme di dati demografici. E poi prendiamo le annotazioni per demografia e le confrontiamo con i modelli e i set di dati usando un punteggio di correlazione di Pearson. E quindi il nostro framework in realtà differisce dalla letteratura di annotatore. Concordando con le distribuzioni di annotatori, invece di guardare solo l'accordo degli annotatori o modellando le distribuzioni degli annotatori. Il nostro framework è in gran parte abilitato attraverso Lab in the Wild, un platform di sperimentazione online, ex collaboratore di HCI. E Lab in the Wild è un platform di sperimentazione online dove possiamo reclutare volontari diversi. E in confronto con i piattaforms come Mturk, che hanno principalmente partecipanti dagli Stati Uniti o dall'India, e Lab in the Wild è ancora in grado di ottenere dati di alta qualità. E ospitiamo due compiti su Lab in the Wild, uno dei quali è l'accettabilità sociale. E il modo in cui funziona è che i partecipanti leggono una situazione dal set di dati di social chemistry, e poi scrivono quanto è accettabile una situazione. E poi, per rimanere coinvolti nello studio, possono confrontare le loro risposte con un AI e gli altri. E poi confrontiamo queste annotazioni con social chemistry, delphi e gpt four. E poi repliciamo un setup molto simile per il compito di rilevamento del contenuto tossico e dell'odio. E poi confrontiamo queste annotazioni con dynahate, perspective api, rewire a p i hate roberta in gpt four. E quindi il nostro studio ammassava oltre sedicimila annotazioni da oltre mille annotatori in ottanta sette paesi. Quindi ora siamo meglio equipaggiati per rispondere a chi i dati e i modelli di NLP si allineano di più? Troviamo che ci sia positionalità in NLP. Ad esempio, troviamo che i set di dati e i modelli sono più allineati con i paesi di lingua inglese. Quindi per il compito di accettabilità sociale di gpt four, troviamo che è più allineato con i paesi di lingua inglese. E troviamo che dynahate è anche più allineato con i paesi di lingua inglese. E troviamo che più allineamento con persone che hanno un'istruzione superiore. Quindi per il compito di accettabilità sociale di gpt four, troviamo che è più allineato con le persone che hanno un'istruzione superiore o un'istruzione universitaria. E troviamo lo stesso per dynahate, dove è più allineato con le persone che hanno un'istruzione superiore. Tuttavia, quando i modelli e i set di dati sono allineati con popolazioni specifiche, inevitabilmente alcuni sono lasciati indietro. E esempio, i set di dati e i modelli sono meno allineati con le persone non binarie rispetto ai loro omologhi maschili e femminili. E troviamo questo nel compito di accettabilità sociale di gpt four, così come nel compito di rilevamento del contenuto tossico. Quindi, dato che c'è positionalità in NLP, cosa possiamo fare? Quindi abbiamo alcune raccomandazioni per questo. Il primo è tenere un registro di tutte le scelte di progettazione rilevanti durante il processo di ricerca. E il secondo è fare ricerca NLP con una prospettiva di perspectivismo. E il terzo è costruire set di dati e modelli specializzati all'interno di quattro comunità specifiche. E un buon esempio di questo è l'iniziativa muscogino. E vogliamo enfatizzare che l'inclusività NLP non è solo fare che tutti i tecnologie funzionano per tutti. E questo conclude la nostra presentazione. Ma se volete saperne di più, sentitevi liberi di controllare il nostro dashboard per i risultati di analisi più aggiornati e il nostro documento. Grazie.</sample>
    <sample id="97">La relatrice menziona tre problemi associati a SimulST: complessità del training, tempi di training lunghi e la necessità di mantenere diversi modelli per vari tempi di latenza.</sample>
    <sample id="98">Un modo efficace per mitigare i bias sociali e politici nei set di dati durante l'addestramento dei modelli di NLP è utilizzare prompt format diversificati basati su questionari politici per valutare e contrastare le inclinazioni politiche. Inoltre, eseguire pre-allenamenti mirati su corpora di partigiani con orientamenti politici diversi può aiutare a neutralizzare i pregiudizi.</sample>
    <sample id="99">L'argomento riguarda la pianificazione linguistica con vincoli, che impone vincoli diversi ai piani di obiettivi. Un buon pianificatore dovrebbe scrivere script ragionevoli e fedeli ai vincoli. In questo documento, valutiamo e miglioriamo la pianificazione linguistica con vincoli dei modelli linguistici. Poiché non esiste un set di obiettivi specifici per sostenere lo studio, dobbiamo acquisirli prima. Come mostrato nella tabella, estendiamo gli obiettivi astratti con vincoli multiformi per obiettivi umani in loop. Eseguiremo l'acquisizione dei dati per gli obiettivi specifici utilizzando instruct. GPT. Eseguiremo la valutazione dei script generati dai modelli linguistici. Questo tabella riporta l'accuratezza complessiva dei risultati. Trovaremo che tutti i modelli linguistici raggiungono risultati insoddisfacenti per la pianificazione di obiettivi specifici. Quindi condurremo un'analisi dettagliata per indagare perché i modelli linguistici falliscono. I risultati nella figura mostrano che la completezza semantica nei script generati è accettabile, ma la fedeltà ai vincoli non può essere garantita. Esaminiamo le categorie di vincoli di argomento più dettagliate. Il heatmap nella figura mostra che la pianificazione dei modelli linguistici varia considerevolmente per obiettivi di diverse categorie. Studi precedenti hanno mostrato che la qualità dei modelli linguistici è molto variabile, portando a un cattivo rendimento. Pertanto, adottiamo l'idea di filtraggio overgenerato per migliorare la qualità della generazione. Mostriamo i tipi di vincoli con esempi per instruct. GPT e otteniamo obiettivi specifici basati sugli obiettivi astratti. Instruct. GPT genera script specifici per obiettivi. Quindi, un modello di filtraggio seleziona i script fedeli. Convertiamo script e obiettivi in embedding instruct. GPT e calcoliamo la somiglianza di coseno come punteggio di somiglianza. Inoltre, premiamo i script che contengono le parole chiave del vincolo di destinazione. Con il nostro metodo, instruct. GPT può generare script di qualità superiore. Il nostro metodo migliora notevolmente la pianificazione sia in completezza semantica che fedeltà ai vincoli. Poiché i modelli linguistici sono costosi da implementare, è essenziale consentire la pianificazione linguistica di modelli più piccoli e specializzati. Creare un set di dati è un passo essenziale per la sua fine. Tuttavia, i precedenti studi non consentono la pianificazione per obiettivi specifici. E annotare manualmente i set di dati è costoso. Pertanto, seguendo l'idea di distillazione del sapere, distilliamo set di dati di pianificazione linguistica con vincoli da modelli linguistici. Applichiamo il nostro metodo per costruire un set di dati di pianificazione linguistica con vincoli, denominato code script. In totale, generiamo cinquantamila obiettivi specifici con script. Per garantire la qualità della validazione e dei test set, chiediamo ai lavoratori di fronte alla revisione dei campioni errati. Questa figura mostra la distribuzione dei vincoli di code script. Troviamo che code script mostra una maggiore probabilità in obiettivi specifici. Con code script, possiamo addestrare modelli più piccoli ma specializzati per la pianificazione linguistica con vincoli. Troviamo che T. F. Fine Tune su code script può generare script di qualità superiore rispetto alla maggior parte dei modelli linguistici. Indica che modelli più piccoli possono supportare modelli più grandi quando addestrati su set di dati adatti. In sintesi, stabiliamo il problema della pianificazione linguistica con vincoli. Valutiamo la pianificazione linguistica con vincoli dei modelli linguistici e sviluppiamo un metodo di filtraggio overgenerato per i modelli linguistici. Usiamo modelli linguistici per generare un set di dati di pianificazione linguistica di alta qualità, code script. Speriamo che code script possa essere una risorsa preziosa per avanzare la ricerca sulla pianificazione linguistica. Grazie per il tempo. Per ulteriori dettagli di code script, trovate il nostro documento.</sample>
    <sample id="100">Multi-hop QA involves answering questions requiring multiple reasoning steps, each linked to a document. The process involves training multi-hop retrievers to maximize the probability of ground truth chains. Prompt ranking, a method combining unsupervised retrieval with a few-shot language model reranker, is introduced to address the need for extensive training data. This approach uses TF-IDF for initial retrieval, expands chains via hyperlink traversal, and scores them using a language model. The method outperforms fully supervised systems, like DrKIT, and shows strong downstream QA performance.</sample>
    <sample id="101">La fluidità di PaLM è comparabile a quella dei sistemi di punta, offrendo output fluido ma con alcune differenze di accuratezza.</sample>
    <sample id="102">Un metodo di filigrana deve essere applicabile agli embedding ad service, non degradare la loro utilità, essere facilmente copiare o rimuovere dall'attacker, e trasferibile agli embedding dell'attacker.</sample>
    <sample id="103">I discorsi TED sono stati tradotti in 14 diverse lingue.</sample>
    <sample id="104">Un set di dati viene riannotato con molte istanze, poiché i dati originali di annotazione di solito provengono da pochi annotatori.</sample>
    <sample id="105">Le metriche di distanza utilizzate sono la simmetria di Cosine e la simmetria di L2.</sample>
    <sample id="106">La presentazione discute il dataset Quest, creato per valutare sistemi di recupero di informazioni. Quest include 3.000 query con set impliciti, con risposte verificate per rilevanza. Il dataset è costruito usando Wikipedia, con set operazioni su domini di interesse. Annotatori validano le query e le risposte. Le prestazioni dei sistemi sono valutate in base alla recall e F1 score, con set di intersezione e differenza che mostrano le difficoltà. Il dataset mira a migliorare sistemi di recupero di informazioni.</sample>
    <sample id="107">I modelli basati su codificatori multilingue, come encoder-decoder, sono stati utilizzati per migliorare le prestazioni in cross-lingual semantic parsing. Sono stati addestrati in un mix di vari linguaggi, portando a miglioramenti significativi in molti set di dati, sebbene l'inglese abbia mostrato una performance variabile.</sample>
    <sample id="108">KostV Sinha discute del suo lavoro su valutazioni di accettabilità dei modelli linguistici, evidenziando che le valutazioni attuali, basate su coppie di frasi brevi, non tengono conto della comprensione complessiva dei modelli. Il team ha rinnovato il processo di valutazione di accettabilità (MPC) per includere frasi più lunghe, utilizzando set di dati come BLM e Syntactium. I risultati mostrano che i modelli sono sensibili ai prefissi di struttura, influenzando significativamente le valutazioni. Questo suggerisce che le valutazioni attuali potrebbero non riflettere accuratamente la comprensione dei modelli.</sample>
    <sample id="109">Rendi in sintesi il contenuto inglese (circa 200 parole).</sample>
    <sample id="111">Gli autori scelgono le parole a frequenza moderata selezionando un gruppo di parole che appaiono con un intervallo di frequenza moderato nel corpus di testo generale.</sample>
    <sample id="112">Salve a tutti. Mi chiamo Shu Hung. Oggi presenterò il nostro articolo, "Do Conner Two Thousand Three Named Entity Taggers Still Work Well in Twenty Twenty Three?" Iniziamo. Il nostro articolo ha indagato il problema della generalizzazione usando il compito di riconoscimento delle entità, o NER. Abbiamo osservato che i modelli hanno usato Conner Two Thousand Three per sviluppare NER per quasi vent'anni. Questo solleva naturalmente diversi problemi. Innanzitutto, i modelli possono generalizzare su nuovi dati? E se osserviamo una cattiva generalizzazione, cosa causa il calo delle prestazioni dei modelli? Per indagare questi problemi, abbiamo sviluppato il set di dati Conner Plus Plus. Questo è un set di dati che abbiamo raccolto da Reuters News da Twenty Twenty e annotato con le stesse linee guida di annotazione di Conner Two Thousand Three. Abbiamo affinato oltre venti modelli su Conner Two Thousand Three, valutati sia sul set di test di Conner Zero Three che sul set di test di Conner Plus Plus. E infine, abbiamo calcolato la percentuale di cambiamento in F uno per valutare la generalizzazione di ogni modello. Quindi, cosa serve per una buona generalizzazione? Attraverso i nostri esperimenti, abbiamo scoperto che ci sono tre ingredienti principali necessari. Il primo è l'architettura del modello. Attraverso i nostri esperimenti, abbiamo scoperto che i modelli Transformer generalmente generalizzano meglio sui nuovi dati. Il secondo ingrediente è la dimensione del modello. Abbiamo scoperto che i modelli più grandi tendono a generalizzare meglio. E infine, sappiamo che il numero di esempi di fine tuning direttamente influisce sulle prestazioni del compito downstream. Qui, abbiamo anche scoperto che più esempi di fine tuning portano anche a una migliore generalizzazione. Per la nostra prossima domanda, cosa causa il calo delle prestazioni di alcuni modelli? Abbiamo due ipotesi. La prima è l'overfitting adattivo, che è l'overfitting causato dall'utilizzo ripetuto dello stesso set di test. E questo è di solito manifestato come diminuzione dei risultati su un nuovo set di test. La seconda ipotesi è il drifting temporale, che è la degradazione delle prestazioni causata dall'aumento del divario temporale tra i dati di addestramento e i dati di test. Per l'overfitting adattivo, abbiamo visto che dal grafico a destra, la linea di miglior adattamento ha un gradiente maggiore di uno. Ciò significa che ogni unità di miglioramento che abbiamo fatto su Conner Two Thousand Three si traduce in più unità di miglioramento su Conner Plus Plus. Ciò significa che non ci sono diminuzioni. E questo mostra che l'overfitting adattivo in questo caso non è osservato. Quindi, cosa succede con il drifting temporale? Per il drifting temporale, abbiamo fatto un esperimento per ricostruire o continuare a pre-addestrare alcuni modelli con dati più recenti. E abbiamo scoperto che le prestazioni degradano con un divario temporale più grande. E questo conferma la nostra ipotesi che la principale causa del calo delle prestazioni è il drifting temporale. La nostra conclusione è che per una buona generalizzazione, avremmo bisogno di un'architettura di modello migliore, dimensioni di modello più grandi e più esempi di fine tuning. E questi vanno di pari passo. Allo stesso tempo, abbiamo anche scoperto che il calo delle prestazioni qui è causato dal drifting temporale. E in realtà, è sorprendente. Anche se Conner Two Thousand Three è stato usato per oltre vent'anni, il calo delle prestazioni è causato dal drifting temporale. Quindi, rispondendo alla domanda del titolo del nostro articolo, "I tagger di entità Conner Two Thousand Three funzionano ancora nel venti venti? E scopriamo che la risposta è in realtà un risonante sì. Speriamo che il nostro articolo solchi per la ricerca su come migliorare la generalizzazione dei modelli. E infine, per favore controlla il nostro articolo, il nostro set di dati. E se hai domande, sentiti libero di contattarmi. Grazie mille.</sample>
    <sample id="114">L'azienda di ricerca di Nanyang Technological University di Singapore ha sviluppato un metodo per ridurre le dimensioni dei modelli di linguaggio, concentrandosi sulla riduzione dei parametri dei modelli di linguaggio. I modelli di linguaggio attuali, come il LAMA-65, sono pesanti e richiedono risorse e tempo per l'addestramento. Il team ha proposto un approccio basato su gruppi per ridurre le dimensioni dei modelli di linguaggio mantenendo le prestazioni. Il loro metodo, chiamato Group Head Attention, utilizza una strategia di divisione e conquista per comprimere i parametri dei modelli di linguaggio. I risultati dimostrano che i modelli di linguaggio ridotti possono mantenere prestazioni elevate in compiti come la traduzione automatica, la modellazione linguistica e la sintesi astratta.</sample>
    <sample id="115">L'approccio utilizza un segmento parlato di 6 secondi.</sample>
    <sample id="116">Nell'esempio, le conoscenze specifiche dell'entità necessarie includono che Servin è un giudice e che Kea è un panettiere.</sample>
    <sample id="117">La qualità dell'esempio è più importante della somiglianza con la frase sorgente.</sample>
    <sample id="118">La presentazione discute l'importanza di migliorare i modelli di pre-addestramento per il codice-switching, un fenomeno comune in lingue diverse come l'India. I presentatori introducono Switch-MLM, una nuova tecnica di MLM adattata per gestire il codice-switching, che differisce dal modello standard MLM. Switch-MLM utilizza switch points, o gruppi di due token che rappresentano transizioni di lingua, per migliorare l'addestramento. Progettano anche un metodo di sostituzione, Frequency-MLM, che utilizza log-likelihood negative per assegnare le etichette di lingua. I loro metodi sono validati attraverso prover classifier, dimostrando un aumento della quantità di informazioni sui switch point nei livelli intermedi e finali. L'implementazione di residui di collegamento e una perdita basata su LID migliora ulteriormente la capacità del modello. I risultati dimostrano che Switch-MLM, combinato con Frequency-MLM, offre prestazioni migliori in compiti come l'analisi sentimentale.</sample>
    <sample id="119">L'articolo si concentra su modelli linguistici come GPT-4, GPT-3 e vari modelli BERT, esaminando come i loro orientamenti politici si manifestano nei compiti di rilevamento di contenuti dannosi.</sample>
    <sample id="120">Il modello utilizza i punteggi di attenzione di un livello specifico, emettendo parole solo se la somma dei punteggi di attenzione è sopra un certo soglia, emettendo parole solo se la somma dei punteggi di attenzione è sopra un certo soglia.</sample>
    <sample id="121">Gli esempi di inferenza diretta includono: 'la canzone più recente' e 'la canzone che non è energetica'.</sample>
    <sample id="122">L'articolo è stato scritto da Suyu Yuan, Yifan Zhang, Yifan Liu, Yao Chen, Yaoqiang Jin, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun, Yaoqiang Sun</sample>
    <sample id="123">Ying e Ji Yang presentano la loro ricerca su Multi-Teach, che mira a migliorare l'apprendimento dei modelli multi-modali attraverso l'ottimizzazione delle istruzioni. Con l'avanzamento dei modelli linguistici, si è esplorato il riutilizzo di modelli linguistici pre-addestrati per compiti downstream in modo efficiente. Sebbene l'ottimizzazione delle istruzioni abbia migliorato le prestazioni dei modelli linguistici su compiti linguistici, compresi quelli visivi e multimediali, c'era una carenza di set di istruzioni per compiti multimodali. Pertanto, hanno creato Multi-Teach, il primo set di ottimizzazione delle istruzioni multimodale, che include 62 compiti di diverse categorie. Utilizzando OFA come modello base, hanno condotto esperimenti che hanno dimostrato che l'ottimizzazione delle istruzioni può migliorare significativamente le prestazioni dei modelli su compiti multimodali. Hanno anche introdotto una nuova metrica chiamata sensibilità, che misura la coerenza delle risposte del modello.</sample>
    <sample id="124">Tan Chi Yu di NUS e Alibaba discute il lavoro sulla benchmarking e miglioramento della capacità di ragionamento temporale degli LLM. Il tempo è un aspetto fondamentale nel mondo reale, e il ragionamento temporale è suddiviso in tre livelli: ragionamento da tempo a tempo, da tempo a evento e da evento a evento. Il lavoro mira a studiare il ragionamento temporale in modo più completo, introducendo un nuovo set di dati di prova che copre tutti e tre i livelli. Il lavoro ha introdotto una strategia di addestramento con due componenti: pre-addestramento temporale e addestramento basato sul rinforzo temporale. I risultati dimostrano che i LLM possono migliorare la loro capacità di ragionamento temporale, con TempT5 che mostra il miglioramento significativo.</sample>
    <sample id="125">Due autori sono coinvolti nell'articolo: Janice Lawick e Yannis Laureau.</sample>
    <sample id="126">Sì, l'approccio standard coinvolge la traduzione della query in lingua naturale utilizzando Google Translate API prima del processo di parsing semantico.</sample>
    <sample id="127">Namjoohol, a master's student at KAIST AI, presents their research on transferring reasoning abilities from large language models to smaller ones using a technique called 'chain of thought prompting.' This method, which involves using large models to generate step-by-step solutions for complex tasks, is made more effective with 'diverse reasoning,' where multiple solutions are generated to improve student performance. Their method outperforms existing baselines, especially in text-based tasks, and is highly scalable. The paper discusses trade-offs in development and inference costs and provides code and data for further exploration.</sample>
    <sample id="128">Akshata, Martin e il loro team presentano il Kitmus, un test diagnostico per valutare la capacità di integrare conoscenze da fonti diverse. Il Kitmus sfida i modelli di Natural Language Understanding a integrare sia conoscenze pre-allenate che quelle fornite in tempo reale. Il lavoro introduce un compito di co-referenzo per valutare la capacità dei modelli di utilizzare informazioni da fonti diverse. I risultati dimostrano che, senza addestramento specifico, i modelli non riescono a integrare efficacemente le conoscenze fornite solo in tempo reale. Tuttavia, con addestramento specifico, alcuni modelli riescono a integrare tali informazioni, anche se le difficoltà persistono.</sample>
    <sample id="129">Gli autori hanno fornito esempi di generazioni di personaggi da LLM come gruppi contrassegnati, inclusi ruoli come 'Asian woman', 'Middle Eastern woman', 'woman of color', e 'white man', per evidenziare come questi modelli generano stereotipi.</sample>
    <sample id="130">Le architetture dei modelli che non generalizzano adeguatamente sono quelle con architetture più semplici, come le reti neurali a due strati.</sample>
    <sample id="131">I set di dati di test sono chiamati set di validazione.</sample>
    <sample id="132">L'articolo è scritto da tre autori: Akshata, Martin e un altro autore non menzionato nel testo fornito.</sample>
    <sample id="133">L'autore opera con più modalità, utilizzando sia testo che immagini.</sample>
    <sample id="135">James and Sarah Finch present ABC Eval, a new method for evaluating conversational AI by annotating specific behaviors in chat. This method, developed by the Emory NLP Lab and Amazon Alexa AI, offers a more precise and reliable approach than existing methods by measuring specific errors like contradictions and irrelevant information. Their study shows ABC Eval is more reliable and predictive of overall conversation quality, outperforming traditional methods like Lickert ratings. The method identifies unique aspects of chat quality, with a combination of metrics explaining over 25% of conversation quality. Despite some challenges, ABC Eval provides a higher resolution for evaluating conversational AI, with the potential for future improvements.</sample>
    <sample id="136">Jaziel Van, presso l'Università di Sheffield, discute il suo lavoro con il supervisore Nafisa, intitolato 'Format, an alternative to accuracy for numerical reasoning'. Il lavoro mira a migliorare l'accuratezza dei modelli di numeri, essenziale per compiti come il fact-checking. I modelli attuali, spesso grandi, non prestano sufficiente attenzione ai numeri, portando a classificazioni inadeguate. Il progetto introduce FERMAT, un set di valutazioni flessibile basato su tipi aritmetici, che valuta la comprensione numerica, le operazioni matematiche e la dipendenza di addestramento. I risultati mostrano che i modelli migliorano con una maggiore diversità linguistica e matematica, suggerendo che i metodi di valutazione attuali non sono sufficientemente informativi.</sample>
    <sample id="137">SiXun Siung di Singapore University of Technology e Design presenta il lavoro "Teltodiseign", un dataset per la generazione guidata dal linguaggio dei piani di giardino, pubblicato in ACL 2023. Il lavoro mira a migliorare la generazione di design che soddisfano le istruzioni specifiche in linguaggio, in particolare per piani di giardino. Utilizzando un modello di sequenza a sequenza, il team ha sviluppato un metodo per generare piani di giardino che rispettano le istruzioni linguistiche, superando i modelli di generazione di immagini basati su testo. Il modello ha ottenuto risultati di valutazione dell'IOU superiori rispetto ai modelli di generazione di immagini basati su testo, dimostrando l'efficacia del loro approccio.</sample>
    <sample id="138">Gli autori sottolineano che la capacità di integrare e utilizzare efficacemente conoscenze provenienti da diverse fonti, sia pre-come inferenza, è una zona poco studiata nella NLU.</sample>
    <sample id="139">I relatori sono Yin e Ji Yang.</sample>
    <sample id="140">Sì, Coscript è stato sottoposto a controlli di qualità. Crowdsourced workers hanno rilevato e corretto i campioni errati per garantire la qualità dei set di test e di validazione.</sample>
    <sample id="141">Le risorse esistenti per la traduzione dipendente dal contesto sono limitate in termini di supporto per tipi di traduzioni e set di lingue, poiché spesso si basano su conoscenza del dominio e sulla creazione umana.</sample>
    <sample id="142">Ecco il contenuto in italiano:</sample>
    <sample id="143">SimulST viene confrontato con strategie come l'uso di modelli offline senza adattamento specifico per la simulazione, l'uso di un modello per ogni latenza regime e tecniche come l'accordo locale e l'accordo con chiavi, oltre a modelli specificamente progettati per la simulazione.</sample>
    <sample id="144">L'articolo è stato scritto da Yannick Ladrière, Olivier Guillet, and Nicolas Sanchez.</sample>
    <sample id="145">Il relatore è Jenny, una prima anno Ph.D. studente alla Carnegie Mellon University.</sample>
    <sample id="146">L'articolo di Zhou Yichen discute l'analisi dell'omissione nella dialog summarization, un sottoprodotto della text summarization. Sebbene i modelli di linguaggio pre-allenati abbiano raggiunto progressi significativi, i loro risultati sono ancora limitati da errori come l'omissione, che porta a risposte incompleti. L'articolo esamina i tassi di omissione in diversi domini e modelli, trovando un tasso elevato di errore. Per affrontare questo problema, Zhou introduce un set di dati per l'osservazione dell'omissione e un metodo di post-editing basato sull'omissione. I risultati dimostrano che l'osservazione dell'omissione e la sua incorporazione nel processo di post-editing possono migliorare la qualità delle risposte generate.</sample>
    <sample id="147">Tre.</sample>
    <sample id="148">Simultaneous speech translation, o Simulst, è il processo di traduzione in tempo reale di un linguaggio parlato in un altro linguaggio. Il nostro lavoro è stato realizzato con Matteo Negri e Marco Turilli.</sample>
    <sample id="149">Sì, il set di dati è disponibile pubblicamente.</sample>
    <sample id="150">Archie discute il suo lavoro su Meeting QA, un dataset che si concentra sulle domande e risposte dei partecipanti alle riunioni. Questo dataset è unico perché include domande aperte e discusse, che richiedono risposte dettagliate. Il processo di raccolta dei dati prevede la selezione delle domande e l'annotazione delle risposte. Il dataset contiene 7.700 domande, con una distribuzione di 30% di domande non risolte, 40% di risposte multiple e 48% di risposte multiple. I risultati dimostrano che i modelli di linguaggio naturale hanno difficoltà a superare gli umani, specialmente in contesti zero-shot. I modelli hanno difficoltà a identificare domande retoriche e a determinare chi risponde a una domanda.</sample>
    <sample id="151">Ciao a tutti. Mi chiamo Yin e il mio collega Ji Yang. Presenteremo la nostra ricerca su multi instruct, migliorare l'apprendimento multi-modello tramite regolazione delle istruzioni. Con i progressi dei modelli linguistici di grandi dimensioni, molti lavori hanno esplorato nuovi paradigmi di riutilizzo dei modelli linguistici per compiti downstream in modo parametrico e efficiente. Recentemente, molti studi hanno dimostrato che la regolazione delle istruzioni consente ai modelli linguistici di eseguire compiti non visti in modo serale seguendo istruzioni naturali. Tuttavia, la maggior parte dei precedenti lavori sulla regolazione delle istruzioni si sono concentrati sul miglioramento delle prestazioni serali sui compiti linguistici, mentre i compiti visivi e multimediali sono stati lasciati fuori. Pertanto, in questo lavoro, vogliamo indagare se la regolazione delle istruzioni sui modelli multimediali pre-allenati possa effettivamente migliorare la generalizzazione su compiti non visti. Inoltre, durante la nostra ricerca, abbiamo scoperto una discrepanza nella disponibilità di set di istruzioni tra NLP e multimediali. Esistono più di mille seicento compiti linguistici, ma non esiste un set di compiti multimediali di grande scala disponibile. Pertanto, costruiamo un set di regolazione delle istruzioni multimediali. Multi instruct, il primo set di benchmark di regolazione delle istruzioni multimediali, consiste in sessantadue compiti diversi che coprono dieci categorie. Questi compiti sono derivati da ventuno set di dati open source. Ogni compito è dotato di cinque istruzioni scritte da esperti. Per indagare la regolazione delle istruzioni multimediali su un set di dati proposto, prendiamo OFA, un modello multimediale pre-allenato come modello di base. OFA utilizza un vocabolario unificato per linguaggio, token multimediali e coordinate di una scatola di confine. Qui mostriamo alcuni esempi di compiti Multi instruct. Per uniformare il trattamento di vari input e output, seguiamo il metodo di OFA e formuliamo tutti i compiti in un formato sequenza-alle-sequenza, in cui il testo di input, le immagini, le istruzioni e le scatole di confine sono rappresentate nello stesso spazio dei token. Ora, parliamo della regolazione delle istruzioni multimediali. Per il set di dati di allenamento, usiamo cinquantatré compiti per il gruppo di allenamento e campioniamo diecimila istanze per compito. Per il set di test, riserviamo il gruppo di ragionamento comune per il test e selezioniamo altri cinque compiti dal gruppo VQA e del gruppo malizioso. Usiamo tutti gli esempi nel set di test di ogni compito. Inoltre, campioniamo venti compiti dal set di test di istruzioni naturali come compiti non visti per NLP. Per il set di dati di test, usiamo il modello pre-allenato OFA-large come modello di base. Durante l'allenamento, mescoliamo tutti gli esempi per tutti i compiti. Ogni esempio viene combinato casualmente con una delle cinque istruzioni di template. Durante il test, per ogni compito, conduciamo un totale di cinque esperimenti valutando il modello utilizzando una delle cinque istruzioni in ciascun esperimento. Regoliamo l'accuratezza per compiti di classificazione multimediali e Regula L per compiti di generazione multimediali. Per compiti NLP, regoliamo anche Regula L. Introduciamo anche una metrica di valutazione chiamata sensibilità. Quindi, questo è il nostro risultato principale. Come possiamo vedere, la regolazione delle istruzioni può migliorare significativamente le prestazioni di OFA su compiti non visti. Inoltre, la trasferimento dell'apprendimento da set di istruzioni naturali può beneficiare la regolazione delle istruzioni. Come possiamo vedere, man mano che il numero di compiti aumenta, il modello ottiene prestazioni migliori e allo stesso tempo, la sensibilità diminuisce. Quindi, anche un esperimento, usiamo una istruzione rispetto a cinque istruzioni. Quindi, l'uso di più istruzioni può migliorare le prestazioni complessive del modello e ridurre la sua sensibilità. Quindi, mostra il effetto di diverse strategie di regolazione delle istruzioni sulla sensibilità del modello. Quindi, il trasferimento dell'apprendimento da set di istruzioni naturali può aiutare OFA a ottenere prestazioni molto migliori su set di istruzioni Multi instruct. Quindi, proponiamo un primo set di dati di regolazione delle istruzioni multimediali di grande scala. Costruiamo un set di dati di regolazione delle istruzioni multimediali con circa cinquanta compiti linguistici aggiuntivi. E lo rilasceremo presto. Questo è un codice QR per i nostri dati e il modello. Grazie.</sample>
    <sample id="152">Frederic Riemenschneider discute l'integrazione di NLP e filologia classica, introducendo modelli di linguaggio per la filologia classica. I modelli attuali, come LatinBERT e Ancient Greek BERT, sono encoder-only e monolingue, limitando le loro applicazioni. Il progetto mira a creare modelli specifici per la filologia classica, con obiettivi di rendere i modelli comparabili, spingere l'architettura e introdurre modelli multilingue. I modelli Greberta e GRETTER sono monolingue per l'antico greco, mentre Filberta e Filther sono multilingue. I modelli sono stati valutati usando Universal Dependency Streambank e EVALATIN 2022, superando i modelli precedenti. I risultati mostrano che i modelli multilingue non superano i modelli monolingue in termini di conoscenza semantica e conoscenza del mondo.</sample>
    <sample id="153">Nina Rehmayr Bahri, a scientist at Amazon Alexa, discusses resolving ambiguities in text-to-image models. Ambiguities in prompts can lead to inaccurate image generation. Her team developed a framework to disambiguate prompts using clarifying questions or multiple visual setups. They evaluated the effectiveness of this framework and found it improved image fidelity. The work also introduced an automatic evaluation framework using VQA models, which aligns with human judgment. The findings indicate that disambiguation significantly enhances the accuracy of generated images.</sample>
    <sample id="154">L'articolo è scritto da Sara Papi, Matteo Negri e Marco Turilli.</sample>
    <sample id="155">Il nome della relatrice è Javad Hosseini.</sample>
    <sample id="157">Sheng Gao di Sun Dong University discute il lavoro su dialog summarization with static dynamic structure fusion graph. Lavoro collaborativo con Xin Cheng, Ming Zhe Li, Xiu Ying Chen, Jin Peng Li, Dong Yan Zhao e Rui Yan. L'obiettivo è distillare informazioni silenziose da un dialogo in un riassunto conciso. Il metodo prevede l'uso di strumenti linguistici esterni per modellare il dialogo con una struttura statica. Tuttavia, ci sono due principali limitazioni: la dipendenza dalla precisione degli strumenti esterni e la rigidità della struttura grafica. Il modello proposto di SDDS ha quattro componenti: encoder di utturanza, modellazione di struttura dialogale, modello di grafico dinamico e modello di riassunto. Il modello utilizza un metodo di modellazione di struttura dialogale per costruire una rete di dialogo, un metodo di modellazione di struttura statica per costruire la struttura grafica e un modello di grafico dinamico per catturare le relazioni semantiche tra utturanze. Il modello di riassunto integra la struttura statica e la struttura dinamica in un grafico unificato.</sample>
    <sample id="158">Xiangkunhu Hu, from AWS, introduces Dual Cache for Coreference Resolution, addressing the limitations of single cache methods in long documents. Dual Cache uses a local cache with LRU eviction and a global cache with LFU eviction, effectively managing local and global entities. Benchmarks show Dual Cache outperforms single cache methods, especially with training data, and significantly reduces cache misses. Despite trade-offs in model efficiency, Dual Cache offers the highest performance/cost ratio, making it a cost-effective solution.</sample>
    <sample id="159">L'ACL Twenty Twenty Three ha rinnovato il Minimal Pair Paradigm, che valuta i modelli linguistici in base alle valutazioni di accettabilità, che includono grammatica, come sintassi, o accettabilità in termini di stereotipi, come i coppie di Kraus. Nel paradigma del minimo, il metodo tipico per valutare i modelli linguistici è quello di mostrare una frase accettabile e una frase non accettabile, e la speranza è che il modello dia più probabilità alla frase accettabile. Il pipeline attuale non consente di valutare l'accettabilità dei modelli verso frasi più lunghe. In questi giorni, i modelli linguistici più grandi hanno finestre di contesto più lunghe. Quindi è fondamentale valutare l'accettabilità dei modelli su sequenze più lunghe. Questo è ciò che stiamo cercando di fare. Stiamo rivedendo il pipeline del MP rivedendo i modelli per valutare l'accettabilità su sequenze più lunghe. Quindi, per simulare queste sequenze più lunghe, rivediamo i set di dati stessi. Quindi, ricreiamo frasi accettabili e non accettabili da questi set di dati. Ad esempio, qui abbiamo scelto un tipico paio di grammatica dal set di Blimp. Dal caso di Adjunct Island, estraiamo frasi grammaticali da Adjoint Island e aggiungiamo come prefisso sia alla frase accettabile che a quella non accettabile. Possiamo fare lo stesso scegliendo frasi non accettabili dal stesso fenomeno. Questo potrebbe testare l'accettabilità del modello. Possiamo fare lo stesso scegliendo frasi da un sottoinsieme o un set di dati diverso. Questo ci dirà se le valutazioni di accettabilità del modello sono effettivamente influenzate dal contesto. Se le frasi provengono da un dominio completamente irrilevante, come Wikipedia, questo ci dirà se le valutazioni di accettabilità del modello sono effettivamente influenzate dal contesto. Se il contesto è proveniente da un sottoinsieme diverso del set di dati o da un contesto completamente irrilevante, come la frase che stiamo esaminando, vediamo come il modello fa. Per prima cosa, guardiamo le frasi di Wikipedia, che sono completamente irrilevanti alla query attuale. Ecco, le valutazioni MP sono in gran parte robuste per contesto arbitrario. Aumentiamo la lunghezza del contesto fino a mille e ventiquattro per massimizzare i modelli GPT due. Vediamo qui, nella linea rossa, le valutazioni MP sono relativamente stabili. Quindi, cosa succede quando scegliamo frasi da un set di dati? Quindi, scegliamo frasi accettabili e non accettabili dal set di Blimp. E vediamo che le valutazioni MP aumentano o diminuiscono significativamente quando aggiungiamo prefissi accettabili o non accettabili. Ma quando corrispondono alla struttura, cioè quando scegliamo frasi da un fenomeno simile, vediamo un aumento o una diminuzione massiccia delle valutazioni MP per il modello, a seconda che la prefissa sia accettabile o non accettabile. Quindi, questo è molto grande. Questo effetto aumenta attraverso la lunghezza del contesto. Questo probabilmente influenzerà i nuovi modelli linguistici che hanno grandi finestre di contesto. Quindi, perché la prefissa influisce così tanto sulle valutazioni MP? Abbiamo fatto una serie di analisi in cui abbiamo provato a perturbare la frase di input. Ma dopo aver fatto diverse di queste perturbazioni, non abbiamo trovato che il modello cambi il suo corso in termini di come mostra le valutazioni MP. Fondamentalmente, scopriamo che i modelli sono sensibili alle frasi di input perturbate in modo simile. Quando perturbiamo le frasi di input accettabili, vediamo un aumento simile in tutte le perturbazioni. E quando perturbiamo le frasi di input non accettabili, vediamo una diminuzione delle valutazioni MP in modo simile. Quindi, le principali conclusioni del nostro lavoro sono che i modelli linguistici sono sensibili a caratteristiche latenti, sintattiche e semantiche condivise tra le frasi. E il modo in cui valutiamo attualmente i modelli linguistici con input di singole e brevi frasi potrebbe non catturare appieno la conoscenza astratta dei modelli linguistici. Per ulteriori dettagli sui nostri esperimenti, si prega di leggere il nostro articolo. Grazie per aver ascoltato.</sample>
    <sample id="160">Il primo passaggio del metodo mappa i token di input con un set multiordinato di token che appariranno nell'output.</sample>
    <sample id="161">Coscript contiene 55.000 script.</sample>
    <sample id="163">Il metodo di allineamento migliore per DEplain è il metodo di MASS align.</sample>
    <sample id="164">L'apprendimento scarsamente supervisionato consente di ridurre i costi di annotazione fornendo etichette tramite fonti meno costose come regole semplici o database di conoscenza.</sample>
    <sample id="165">Wenting Zhao, PhD student at Cornell, presents a paper on 'Adapting Common Sense Reasoning: Exploiting Mutually Exclusive Explanations.' The paper introduces LIpor, a method for unsupervised learning in adaptive reasoning, which maximizes the likelihood of outcomes by considering mutually exclusive explanations. LIpor outperforms existing models, including a strong zero-shot GPT-3 baseline, by over 4 absolute points in accuracy on the ALFAMNLI dataset.</sample>
    <sample id="166">Yuxin, a student from Harbin Institute of Technology, presents a new method for image retrieval from linguistically complex texts, addressing the limitations of existing visual language models. The method employs a divide and conquer strategy, inspired by dual-process theory, to enhance reasoning capabilities. It introduces a Prolational Generator for symbol proposition representation and a Neural Symbolic Reasoner for integrating reasoning states. The system combines the strengths of analog and logical reasoning, showing superior performance in experiments compared to baseline models.</sample>
    <sample id="167">I documenti in DEplain-web sono stati allineati manualmente per 750 documenti e con metodi automatici per altri 750 documenti.</sample>
    <sample id="168">Il set di dati CoNLL++ è stato creato annotando il dataset Reuters News del 2020 con le stesse linee guida di annotazione di CoNLL 2003.</sample>
    <sample id="169">Aydin Bilal presents a study on prompting large language models (LLMs) for machine translation, focusing on the PAMP model. The study evaluates the translation capabilities of PAMP using the latest test sets and compares it to state-of-the-art systems. It finds that the quality of examples is more crucial than their similarity to the source sentence. The research suggests using high-quality data, like the dev set, for better performance. Human evaluations show PAMP's fluency is comparable to advanced systems, but it struggles with accuracy, often omitting parts of the source sentence. The study recommends a five-shot prompting strategy for improved results.</sample>
    <sample id="170">Ciao a tutti. Mi chiamo Yuxin Zhang dell'Università di Penn State. Oggi presenterò il nostro lavoro, Cross-lingual Semantic Parsing in Multiple Natural Languages and Representations. Quindi, il parsing semantico è il compito di costruire rappresentazioni semantiche di query come SQL e Lambda Calculus. E il parsing semantico in più lingue è il compito di tradurre query in più lingue in più rappresentazioni. Come mostrato in questa figura, dobbiamo tradurre le query in più lingue usando modelli neurali per SQL, Lambda o Funql. Esistono modelli di parsing semantico in più lingue proposti e valutati su set di dati limitati e applicazioni. Ad esempio, manca la copertura di certi domini naturali, come il calcolo lambda, e la copertura di certi rappresentazioni, come il lambda calculus. E ci sono solo modelli unici per valutare. Quindi, proponiamo Exemplar, ma forniamo un set di dati uniforme per il parsing semantico in più lingue e rappresentazioni. Contiene novanta set in vari domini, cinque attività di parsing semantico, otto rappresentazioni e ventidue lingue in quindici famiglie di lingue. E per valutare meglio il nostro benchmark, consideriamo sei impostazioni per l'addestramento e la valutazione. La prima è test di traduzione. Usiamo l'API di Google Translate per tradurre la fonte in lingua target, quindi usiamo il modello monolingue per addestrare e valutare. E per esempio, addestriamo un modello inglese sulla query inglese e durante l'inferenza, traduciamo la query tedesca in inglese e poi usiamo il modello addestrato per prevedere il SQL. E testamo anche il modello monolingue. In questa impostazione, la lingua di sorgente è la stessa della lingua target, ad esempio, tedesco-tedesco o inglese-inglese. Testiamo anche l'impostazione monolingue few-shot, ma addestriamo modelli monolingue con solo dieci percento dei dati di addestramento. E testiamo il modello multilingue, che addestra un modello multilingue per tutte le lingue. Ad esempio, mettiamo insieme le query tedesche, inglesi e cinesi per addestrare un modello multilingue e durante l'inferenza, possiamo usare questo modello per tradurre le query tedesche o cinesi, ecc. E consideriamo anche il trasferimento cross-lingual zero e few-shot. Addestriamo su una lingua di sorgente e trasferiamo in un'altra lingua. Quindi, durante l'addestramento, addestriamo una query inglese o la combinazione di query inglese e tedesco per addestrare un modello multilingue per prevedere l'output SQL. E troviamo molti risultati interessanti. Quindi, valutiamo modelli monolingue, inclusi modelli encoder-pdr, che sta per encoder multilingue pre-allenati con decoder basati su puntatori, come xlmr e bert-pdr. E valutiamo anche modelli encoder-decoder, che sta per encoder e decoder multilingue pre-allenati, come mbert e mt five. Abbiamo scoperto che encoder-decoder ottiene il miglior rendimento su tutti i nove set di dati. E valutiamo mt five e example encoder-pdr in impostazione multilingue. Abbiamo scoperto che encoder-decoder o encoder-pdr può essere migliorato addestrando in una miscela di varie lingue. E abbiamo trovato che la maggior parte delle lingue principali può ottenere prestazioni migliori, tranne che la prestazione inglese in sette set di dati e solo guadagna in tre set di dati. Penso che questo sia noto come maledizione della multilingualità. E confrontiamo anche il gap di prestazione cross-lingual. In questa figura, la linea blu è il trasferimento cross-lingual zero, la linea arancione è il trasferimento cross-lingual few-shot, mentre la linea verde è l'impostazione monolingue. Abbiamo scoperto che confrontando la linea verde e la linea arancione, il trasferimento cross-lingual few-shot ha un gap di prestazione significativo. E confrontando la linea blu e la linea arancione, il trasferimento cross-lingual few-shot riduce rapidamente il gap di prestazione. Abbiamo anche trovato altri risultati interessanti. Ad esempio, encoder-decoder supera il lavoro precedente o raggiunge risultati comparabili. Ma addestrare sulla lingua naturale inglese può significativamente aumentare le prestazioni di few-shot sulla lingua target. E abbiamo trovato che modelli multilingue come codas e bleu sono ancora inadeguati per compiti di parsing semantico in più lingue. In sintesi, costruiamo Exemplar, un benchmark unificato per il parsing semantico in più lingue con più lingue e rappresentazioni. E conduciamo uno studio di benchmark su tre tipi di modelli linguistici. E i nostri risultati mostrano molti risultati interessanti, ecc. E benvenuti al nostro documento e codice. Grazie per aver ascoltato.</sample>
    <sample id="171">Lavori correlati includono metodi di watermarking esistenti che non sono applicabili o trasversali, e il nostro approccio, Embedding Marker, introduce un metodo trasversale e applicabile per proteggere i servizi di embedding.</sample>
    <sample id="172">No, gli LLM multilingue come Codex o Bloom sono ancora inadeguati per compiti di cross-lingual semantic parsing (CLSP).</sample>
    <sample id="174">Priya e il suo coautore hanno sviluppato un set di dati di argomentazione di alta qualità, argomento 35K, per l'analisi delle argomentazioni. Questo set è unico per la sua diversità, profondità e qualità, derivando da esperti e tornei di alto livello. Il set introduce un modello di rilevanza, analisi e annotazione per migliorare la rilevanza e la precisione delle annotazioni. Il set mira a fornire una base più robusta per l'analisi delle argomentazioni, offrendo una valutazione più accurata e diversificata.</sample>
    <sample id="175">Il metodo utilizza una continua relaxazione per semplificare il processo di ricerca della permutazione più probabile, rendendo il metodo più pratico e GPU-friendly.</sample>
    <sample id="176">L'equità di un modello NLP a valle si riferisce alla capacità del modello di generare output equi e imparziali, senza favorire nessuna categoria sociale, come etnia, genere o orientamento politico, in particolare nei confronti delle minoranze.</sample>
    <sample id="177">La relatrice è Yanis Lavraik.</sample>
    <sample id="178">Il relatore è Koistaph Sinha.</sample>
    <sample id="179">Mélanie Szklare discute il miglioramento delle capacità di teoria del mente in modelli linguistici di grandi dimensioni, introducendo il metodo Symbolic TOM. Questo approccio utilizza rappresentazioni grafiche per migliorare la comprensione delle credenze e delle ipotesi dei personaggi in scenari narrativi. I risultati dimostrano che, in confronto ai metodi di fine-tuning, il TOM offre miglioramenti significativi, in particolare in scenari di comprensione fuori dal dominio.</sample>
    <sample id="180">Il nome della relatrice è Myra.</sample>
    <sample id="181">Si Yuan e il suo team hanno sviluppato un framework per migliorare la pianificazione linguistica con limiti specifici, utilizzando grandi modelli linguistici. Il lavoro si concentra sulla pianificazione di obiettivi specifici, come fare una torta al cioccolato, che non è stato ampiamente studiato. Per affrontare questo, hanno definito il problema della pianificazione linguistica con limiti e sviluppato un metodo per migliorare la qualità della pianificazione dei modelli linguistici. Hanno acquisito obiettivi specifici usando InstructGPT e creato il dataset CoScript, che contiene 55.000 obiettivi specifici. Questo dataset è destinato a migliorare la ricerca sulla pianificazione linguistica.</sample>
    <sample id="182">Nel contesto dell'articolo, il tropicalismo indica un stereotipo che associa le donne di colore, in particolare quelle latine, a caratteristiche vivaci e sensibili, che contribuiscono a un'eredità di discriminazione e percezione come 'altrove' rispetto al normale.</sample>
    <sample id="183">Gli autori hanno elaborato le rappresentazioni umane dei gruppi target usando prompt generati da LLMs, identificando parole distintive attraverso il metodo Marked Words, e confrontando le parole con le parole uniche per ciascun gruppo.</sample>
    <sample id="184">Il lavoro ha utilizzato il CXMI (Contextual X-MI) per misurare l'utilizzo del contesto, estendendolo a Pointwise CXMI per valutare l'utilizzo del contesto a livello di frase o di parola.</sample>
    <sample id="185">DrBERT è un modello pre-allenato in francese per il dominio medico, mentre ChuBERT è un modello pre-allenato in inglese per lo stesso dominio.</sample>
    <sample id="187">L'articolo è scritto da Ying, Ji, Yang e un altro autore non specificato.</sample>
    <sample id="188">Il trasferimento iterativo dell'apprendimento è un metodo in cui il modello viene aggiornato continuamente con nuovi dati raccolti in ogni round di annotazione, migliorando la precisione nel rilevamento della dissonanza.</sample>
    <sample id="189">L'obiettivo del set di dati è fornire un corpus di espressioni indirette per l'allenamento di modelli linguistici, con un focus su domini come musica, libri e ricette.</sample>
    <sample id="190">Un utente malintenzionato può estrarre i parametri del modello attraverso un EaaS analizzando i dati di output per identificare schemi o caratteristiche distintive, o utilizzando tecniche di reverse engineering per ricreare il modello.</sample>
    <sample id="191">L'articolo è scritto da tre autori: Sarah Papi, Matteo Negri e Marco Turilli.</sample>
    <sample id="192">Yang Luo presenta il suo lavoro, CAM, un'ottimizzazione adattiva e confidenza guidata che mira a ridurre l'uso della memoria durante l'addestramento di grandi modelli linguistici. CAM utilizza la fattorizzazione non negativa di matrici per ridurre significativamente la memoria necessaria. Sebbene gli approcci esistenti come Adam e Adafactor abbiano un costo di memoria elevato, CAM offre una soluzione più efficiente, migliorando la validazione e la precisione senza aumentare il costo di memoria. I risultati sperimentali dimostrano che CAM supera Adam e Adafactor, specialmente per modelli di grandi dimensioni, offrendo prestazioni migliori con meno memoria.</sample>
    <sample id="193">Circa 1.000 annotatori sono stati impiegati per creare il set di dati iniziale.</sample>
    <sample id="194">Gli autori dell'articolo sono Jenny, Sebastian Santi, Ronan Labraz, Katerina Raneva e Martin Sabbe.</sample>
    <sample id="195">Il lavoro introduce il framework ROHT, che mira a migliorare la risoluzione delle domande complesse in QA. Il framework è in due fasi: prima, costruire un albero di decomposizione delle domande per comprendere la struttura gerarchica; poi, applicare ragionamento probabilistico su questo albero. Il framework utilizza sia KB che corpus di testo per rispondere alle domande, mostrando miglioramenti significativi nei risultati di test su set di dati come KQAPRO e MUSIC.</sample>
    <sample id="196">L'esempio in cui il governatore è a sinistra è 'I saw Bart and Lisa'.</sample>
    <sample id="197">I modelli all'avanguardia nei sistemi di dialogo includono quelli sviluppati da Emory NLP Lab in collaborazione con Amazon Alexa AI, che utilizzano ABC Eval per valutare la qualità del dialogo in modo più preciso.</sample>
    <sample id="198">La valutazione dell'accettabilità dei modelli nell'intera finestra di contesto è necessaria perché i modelli linguistici moderni hanno un'ampia finestra di contesto, e valutazioni basate su singole frasi potrebbero non catturare appieno la loro comprensione.</sample>
    <sample id="199">Sì, la formazione attraverso la modalità multilingue ha causato un calo delle prestazioni rispetto al modello inglese monolingue in sette dei set di dati.</sample>
    <sample id="200">Sì, gli annotatori conoscono l'entità in anticipo.</sample>
    <sample id="201">Le metriche di MT utilizzate per la valutazione includono metriche avanzate e metriche basate sull'esperienza umana.</sample>
    <sample id="202">Sì, il regresso influisce su specifici tipi di NER, come i tagger di nomi e titoli, poiché la loro capacità di generalizzare su nuovi dati diminuisce.</sample>
    <sample id="203">La posizionalità nella NLP è importante perché influisce sulle decisioni di ricerca e sui risultati, potenzialmente portando a pregiudizi nei sistemi di NLP. Comprendere e mitigare la posizionalità può aiutare a creare tecnologie più equitative e inclusive.</sample>
    <sample id="204">BLOOM è stato affinato con adattatori, ma non con una messa a punto integrale.</sample>
    <sample id="205">Xiangbing, un PhD student dell'Università di Washington, discute il suo lavoro che esamina il percorso da pre-trainings dati ai modelli linguistici e ai compiti downstream, evidenziando il problema dei pregiudizi politici. I modelli linguistici sono addestrati su grandi set di dati web, che includono una vasta gamma di opinioni politiche, portando a pregiudizi potenziali nei compiti downstream. Il team propone di valutare i pregiudizi politici dei modelli linguistici e di esaminare le prestazioni dei modelli con diverse inclinazioni politiche. I risultati preliminari mostrano che i modelli linguistici occupano tutti i quadranti del campo politico, con GPT-4 risultando più liberale. I modelli possono anche acquisire la polarizzazione sociale, come dimostrato da pre-trainings su corpus di diverse epoche. I risultati di valutazione mostrano che i modelli con diverse inclinazioni politiche differiscono nelle capacità di rilevare discorsi d'odio e notizie false, con modelli di orientamento politico diverso che mostrano prestazioni diverse nei confronti di diverse demografie. Questi risultati evidenziano la necessità di affrontare i pregiudizi politici nei modelli linguistici per garantire equità nei compiti downstream.</sample>
    <sample id="206">Utilizzano il modello Topic Independent Dissonance Classification (TIDC) per il trasferimento dell'apprendimento.</sample>
    <sample id="207">I recenti set di test utilizzati per valutare le capacità di PaLM sono i set di test di MT, utilizzando i dati di Dev per ottenere risultati migliori rispetto ai dati di addestramento.</sample>
    <sample id="208">Gli autori hanno proposto tre suggerimenti: affrontare positivi stereotipi, utilizzare una lente di intersezione per studiare le bias, e aumentare la trasparenza sui metodi di mitigazione del bias.</sample>
    <sample id="209">Il metodo proposto migliora la generazione di script per pianificazione specifica rispetto al metodo di riferimento, offrendo una maggiore fedeltà ai vincoli e una qualità semantica superiore.</sample>
    <sample id="210">La relatrice si chiama Shu-Hung.</sample>
    <sample id="211">Sì, i risultati e il set di dati dell'articolo possono essere utilizzati come parametri di riferimento per valutare i metodi di semplificazione automatica.</sample>
    <sample id="212">L'articolo utilizza tre modelli più piccoli: T5-small, BERT-base, e mT5-small.</sample>
    <sample id="213">Il modello di base utilizzato per analizzare l'ottimizzazione delle istruzioni multimodali è OFA, un modello unificato che utilizza un vocabolario comune per linguaggio, token immagini e coordinate di una casella di delimitazione.</sample>
    <sample id="215">Adam Szpekowski discute le strutture di coordinazione, evidenziando diverse teorie come universali, di Miltsuk e di Pragm, che assumono strutture simmetriche, mentre la grammatica di De Cat sta per la multiheaded. L'argomento si basa sul principio di minimizzazione della lunghezza delle dipendenze, che suggerisce che le strutture simmetriche sono preferibili. Esempi illustrano come la lunghezza delle strutture di coordinazione può variare in base alla presenza di governi. I dati raccolti supportano la tendenza per le strutture simmetriche, specialmente quando i governi sono a sinistra, fornendo un argomento contro le strutture asimmetriche.</sample>
    <sample id="217">Lavoro di Huang e Zhao mira a migliorare la generazione di dialogo controllabile per più attributi. Introducono D-C-G, che usa perdite di distorsione per distinguere combinazioni di attributi. Progettano un framework di valutazione M-A-E per valutare diversi attributi. I loro metodi superano i modelli di base in attributo controllabile e test qualità. I risultati dimostrano l'efficacia del loro metodo per trasformare attributi visibili in combinazioni non viste.</sample>
    <sample id="218">L'articolo è stato scritto da Aydin Bilal e colleghi di Google Translate.</sample>
    <sample id="219">Zhao Huizhu, a research assistant at Academia Sinica, presented a multi-stage pipeline for financial signal extraction from reports. The project, led by Zhao and Chen Wei-Ling, focuses on the Form 10-K reports, which are detailed annual documents. The pipeline aims to reduce manual effort by identifying key financial terms through a two-stage process: document segmentation and relation classification. The first stage classifies word pairs into three types: syntactic, semantic, and mismatched. The second stage uses external datasets for fine-tuning, employing soft labeling techniques to improve model performance. The pipeline achieved high precision and recall, demonstrating its effectiveness in financial analysis. Future work includes enhancing the pipeline's features and exploring its application in information retrieval.</sample>
    <sample id="220">L'articolo non menziona le affiliazioni degli autori.</sample>
    <sample id="221">L'articolo ha analizzato la coppia linguistica tedesco-inglese.</sample>
    <sample id="222">Questo lavoro esplora le sfide e le soluzioni per l'annotazione delle domande in dominio aperto, concentrandosi su come adattare i modelli di recupero e lettura per domande in domini diversi. Il lavoro introduce tre principali contributi: l'analisi di diverse interazioni di dati per facilitare l'annotazione in dominio aperto, l'identificazione del tipo di spostamento dei set di dati e la determinazione delle interazioni di dati efficaci per specifici tipi di spostamento. Il setup coinvolge un dominio generale come Wikipedia, ma si applica anche a domini specifici come il campo medico. I metodi di generazione di interazioni di dati includono tecniche zero-shot e few-shot, con l'uso di modelli di linguaggio per generare esempi. Le prestazioni sono valutate in base alla compatibilità del modello e alla natura del spostamento dei set di dati. I risultati mostrano che le interazioni di dati sono cruciali per migliorare le prestazioni, con miglioramenti fino al 24% nelle prestazioni del lettore.</sample>
    <sample id="223">Il relatore si chiama Xiangbing.</sample>
    <sample id="224">Durante gli esperimenti, sono stati studiati due modelli: il modello Longformer per la semplificazione a livello di documento e il modello BERT per la semplificazione a livello di frase.</sample>
    <sample id="225">Per l'addestramento, 53 attività sono utilizzate, mentre per il test, 10.000 istanze per ciascuna delle 53 attività vengono utilizzate, e tutte le istanze del gruppo Common Sense Reasoning vengono utilizzate per il test.</sample>
    <sample id="226">Due autori sono coinvolti nell'articolo.</sample>
    <sample id="227">Il discorso si concentra sul problema della comprensione del linguaggio radicata, che implica l'interpretazione di espressioni naturali in un ambiente specifico. Il modello Pangluo, che prende il nome da un essere mitologico cinese, propone una nuova strategia per la comprensione del linguaggio radicata, concentrandosi sulla discriminazione piuttosto che sulla generazione. Questo approccio semplifica il compito per i modelli linguistici, poiché non devono generare autonomamente piani o programmi validi. Invece, il modello valuta e classifica i piani proposti da un agente simbolico. I risultati dimostrano che Pangluo supera i modelli tradizionali come Arkana e T5 in termini di efficienza e robustezza, specialmente in ambienti non-IID. Il discorso conclude con un invito a discussioni e collaborazioni future.</sample>
    <sample id="228">Gli autori hanno eseguito i test su quattro set di dati: AG NEWS, MIND, SSTD2 e IRAVIA.</sample>
    <sample id="229">Gabriela Skatylinskaya discute la revisione dei testi, in particolare nel contesto della scrittura argomentativa, con Henning Backstrom. La revisione è un processo iterativo per migliorare la formulazione del testo, influenzando direttamente l'efficacia del messaggio. Il lavoro si concentra su due compiti: rilevare le revisioni subottimali e suggerire miglioramenti ai tipi di qualità del testo. I principali sfide affrontate includono la rappresentatività e la complessità dei modelli, la rilevanza del contesto e i bias. I risultati dimostrano l'efficacia dei dati di revisione per le attività specifiche, con la distanza tra le versioni dei testi che aiuta a rilevare le revisioni subottimali.</sample>
    <sample id="231">NACHOS è un set di dati di corpus di medicina proveniente da siti web di internet, utilizzato per addestrare il modello Dr. Bert.</sample>
    <sample id="232">Il nome della relatrice è Aydil Bilal.</sample>
    <sample id="233">Sarah Papi discute la strategia di simultanea traduzione guidata dall'attenzione per la traduzione simultanea, che utilizza modelli esistenti senza ricreazione specifica per la traduzione simultanea. La strategia emette traduzioni basate sull'attenzione, migliorando la qualità e riducendo i tempi di latenza. I risultati dimostrano che questa strategia supera le strategie precedenti, offrendo prestazioni migliori sia in termini di qualità che di efficienza. I risultati sono disponibili per la riproduzione e il confronto.</sample>
    <sample id="234">La strategia del prompting influisce significativamente sui risultati, con la strategia a cinque promp di esempio di alta qualità che mostra prestazioni migliori rispetto a strategie a uno o due promp.</sample>
    <sample id="235">Gli autori dell'articolo sono Kay-Owen, Patrick Fernoux, Emile Liu, Andre F. D. Martins e Graham Neubig.</sample>
    <sample id="236">Le 5 istruzioni scritte da esperti sono: 1. 2. 3. 4. 5.</sample>
    <sample id="237">Gli autori propongono l'uso del KITMOS, un set di dati di co-referential resolution, per testare la capacità dei modelli di integrare e utilizzare informazioni provenienti da diverse fonti.</sample>
    <sample id="238">Yeboah-Thuahboon presents MeetingBank, a new benchmark dataset for meeting summarization. The dataset addresses challenges in meeting summary quality and resource availability, containing transcripts, summaries, and URLs of city council meetings. The data collection process involves using Speechmatics API and aligning transcripts with summaries. The dataset includes 1,366 city council meetings, with analysis metrics like coverage and density. Model evaluations show GPT-3's high fluency and coherence but lower informativity. The dataset aims to aid in developing advanced summarizers and understanding city council decision-making.</sample>
    <sample id="239">L'attenzione di Aydin Bilal si è concentrata sulla promozione di Pamplemone, un modello linguistico di cinquecentoquarantamiliardi di parametri, presentato l'anno scorso. È stato addestrato su un vasto insieme di testi, che comprendevano settantamila miliardi di token. Al momento della pubblicazione, ha raggiunto il livello di perfezionamento in numerose attività NLP. In questo lavoro, abbiamo presentato la prima studio sistematico sulla promozione di modelli linguistici per la traduzione. Abbiamo valutato la capacità di tali modelli utilizzando le migliori pratiche della comunità di traduzione. Questo comporta l'uso di test più recenti per evitare l'overlap dei dati di test con i dati di addestramento del modello linguistico. Abbiamo confrontato due sistemi di punta, utilizzando le ultime metriche di valutazione e anche valutazioni umane esperte. Infine, fornisciamo alcune raccomandazioni per la strategia di promozione. La promozione ha un grande impatto sulla performance dei modelli linguistici per la traduzione. Come possiamo vedere in un semplice esperimento, abbiamo usato una promozione a uno scatto e fornito due diversi prompt per ogni frase. La maggior parte delle frasi, cinquecentoquarantamila su mille, la differenza osservata è di più di un punto di confusione. E questo può andare in casi estremi, fino a quaranta punti. Quindi è importante selezionare una buona strategia di promozione. Nelle nostre esperienze, abbiamo stabilito una strategia a cinque scatti, in cui ogni frase fornita al sistema è contrassegnata con la lingua in cui è. Quindi, in questo esempio, dove eseguiamo la traduzione dal tedesco all'inglese, le frasi tedesche sono contrassegnate con tedesco e quelle inglesi con inglese. Abbiamo visto che la forma effettiva della promozione non ha un grande impatto in uno scatto. È cruciale per zero e uno scatto, ma quando andiamo, come nel nostro caso, a cinque scatti, non c'è differenza nella forma effettiva della promozione. È cruciale per le prove. Le prove che portano la maggior parte del peso sono quelle che portano la maggior parte del peso. Abbiamo confrontato la selezione dei prompt dai dati di addestramento del WMT o dai dati Dev. I dati Dev sono molto più accurati e con una qualità superiore rispetto ai dati di addestramento, e i risultati mostrano un migliore risultato quando usiamo i dati Dev. Tuttavia, i sistemi specializzati hanno un vantaggio sostanziale su Pamplemone, ma Pamplemone si avvicina abbastanza a un sistema commerciale. Nel nostro caso, abbiamo scelto di eseguire la valutazione con Google Translate. Le intuizioni che otteniamo dalla valutazione umana utilizzando il framework MPM è che la qualità dell'esempio è più importante della somiglianza alla frase di origine. Quindi è importante selezionare le prove da traduzioni di alta qualità. In particolare, confrontiamo la selezione dei prompt dai dati di addestramento del WMT o dei dati Dev. I dati Dev sono molto più accurati e con una qualità superiore rispetto ai dati di addestramento. E i risultati mostrano un migliore risultato quando usiamo i dati Dev.</sample>
    <sample id="240">Ciao. Sono Dawei, un dottorando all'Università di Salant in Germania. In questo video, vorrei presentare il nostro recente lavoro, "Weaker than you think", un esame critico della weakenessupervisione. Questo è un lavoro congiunto con Xiaoxuan, Mario Musbach, Giastephen e Dittli Schlaff. Vorrei iniziare con una breve introduzione alla weakenessupervisione e alla weakenessupervisione. In weakessupervision, non si annotano manualmente i dati. Invece, si etichettano i dati usando fonti di etichettatura weak, come regole semplici, database di conoscenza o fonti di citazione di bassa qualità, come illustrato nella figura a destra. Quando si addestra neuroni direttamente su dati etichettati weak, i neuroni tendono a memorizzare il rumore dell'etichettatura e non generalizzano. Nella weakenessupervisione, vengono proposte algoritmi di addestramento per addestrare neuroni robustamente su tali etichette, in modo che i modelli addestrati possano generalizzare bene. Nelle recenti opere in WSL, si dice che le persone addestrano modelli solo sui dati etichettati weak e ottengono prestazioni elevate sui set di test puliti. Tecnicamente, questa affermazione non è sbagliata, ma c'è un problema, che è che si presume che ci sia un set di validazione pulito disponibile per la selezione del modello. Questo problema è trascurato, poiché la necessità di annotazioni manuali in weakessupervisione è spesso trascurata. L'adozione di questo problema ci porta a porre tre domande di ricerca: prima, è necessario un set di validazione pulito per WSL? O forse si può usare un set di validazione noiosa? Se il set di validazione pulito è necessario, o se è necessario per WSL, allora, quanti campioni puliti abbiamo bisogno? Infine, se si utilizza solo i campioni puliti per la validazione, ci sono modi migliori per utilizzarli? Rispondiamo a queste domande di ricerca nel nostro lavoro, e le nostre scoperte sono le seguenti: Innanzitutto, scopriamo che i metodi recenti WSL richiedono effettivamente set di validazione puliti per funzionare correttamente. Altrimenti, c'è un grande calo di prestazioni. Come mostrato in questa figura, se non ci sono set di validazione puliti, i modelli addestrati non possono generalizzare oltre le etichette weak originali, il che significa che l'addestramento è inutile. Questo indica che i metodi WSL in realtà richiedono etichette etichettate pulite per funzionare correttamente. Il costo per ottenere etichette etichettate pulite per il set di validazione non dovrebbe essere trascurato. La nostra seconda scoperta è che aumentare il numero di campioni di validazione puliti aiuta i metodi WSL a ottenere prestazioni migliori. Tipicamente, abbiamo bisogno di venti campioni per classe per raggiungere prestazioni elevate. Ma questo non è la fine della storia. Se decidiamo di accedere ai campioni puliti, allora addestrare direttamente sui campioni puliti ottiene prestazioni migliori. La figura a destra mostra la differenza di prestazioni tra approcci di fine-tuning applicati direttamente sui campioni puliti e i metodi WSL, che usano i campioni puliti solo per la validazione. Come possiamo vedere, se abbiamo dieci campioni per classe, l'addestramento diretto inizia a battere i metodi WSL. Infine, il miglioramento delle prestazioni previsti nei metodi WSL precedenti può essere facilmente ottenuto consentendo di continuare a fine-tuning sui campioni di validazione puliti. Come possiamo vedere, il modello Valina, chiamato ftw, inizialmente sottopone prestazioni inferiori a metodi WSL più complicati come Cosine. Ma se si consente di continuare a fine-tuning sui campioni di validazione puliti, allora ftw si comporta allo stesso modo dei metodi WSL. Quindi, in pratica, non c'è motivo di scegliere metodi WSL più complessi, che richiedono più tempo di calcolo e spazio su disco. In sintesi, abbiamo dimostrato che i metodi recenti WSL richiedono etichette etichettate pulite per funzionare correttamente. Il loro miglioramento delle prestazioni e praticità sono sovrastimati. Le nostre raccomandazioni concrete per il futuro sono le seguenti: Innanzitutto, riportare i criteri di selezione del modello. Ad esempio, riportare se la selezione del modello è fatta con set di validazione puliti. Secondo, WSL dovrebbe essere confrontato con linee di base di fine-tuning, poiché entrambi lavorano su campioni puliti. Terzo, il fine-tuning continuo è un approccio semplice ma forte che dovrebbe essere considerato in futuro WSL. Infine, abbiamo aperto il codice. Puoi trovarlo via il codice Q R su questa diapositiva. Per favore, controlla. Grazie. E goditi la conferenza.</sample>
    <sample id="241">Ethan e il suo team hanno sviluppato un framework per valutare efficacemente i sistemi di rilevamento della disinformazione, in particolare riguardo alle false informazioni sui trattamenti COVID-19. I sistemi attuali spesso falliscono a causa di valutazioni irrealistiche e di mancanza di input umano. Il loro approccio integra l'input umano in ogni fase del processo, utilizzando un modello T5 per estrarre e classificare le informazioni dai tweet. Il sistema è in grado di rilevare rapidamente le false informazioni, contribuendo a una gestione più efficace della disinformazione.</sample>
    <sample id="242">I metodi comuni di valutazione per i sistemi di dialogo includono valutazioni umane basate su scale di Likert, valutazioni comparative di conversazioni e confronti di dialoghi basati su paia.</sample>
    <sample id="243">L'articolo è scritto da un solo autore, Jenny.</sample>
    <sample id="244">Le conoscenze di base necessarie includono che Servin è un giudice e Kea è un panettiere, insieme a informazioni generali che i giudici decidono casi in tribunali.</sample>
    <sample id="245">Lining Zhang presenta un lavoro su un processo di selezione di annotatori ad alta accordo per la sintesi su Amazon Mechanical Turk. Il processo, chiamato pipeline, mira a migliorare la qualità dei lavoratori automatizzati, affrontando problemi con le metriche di valutazione e la comprensione delle pratiche. Il processo include due fasi di valutazione: una per valutare le capacità di valutazione multidimensionale e una per valutare la capacità di gestire carichi di lavoro pesanti. Il pipeline ha prodotto 4 lavoratori d'oro e 8 d'argento su 200 partecipanti, con un Kappa di 0.443. Il lavoro mira a risparmiare risorse e garantire alta qualità, con progetti futuri per migliorare la selezione di lavoratori e applicazioni in più lingue e piattaforme.</sample>
    <sample id="246">Sì, il codice è disponibile su GitHub.</sample>
    <sample id="247">Il discorso di Giok-him da KAI introduce il dataset FactKG, che utilizza Knowledge Graphs (KG) per la fact-verifica basata sul ragionamento. I dataset di fact-verifica esistenti, come FeVER e Vitamin C, utilizzano testi o tabelle, mentre FactKG utilizza KG come evidenza. I KGs offrono un ragionamento diretto e intuitivo, rendendo la fact-verifica affidabile. Il dataset include due stili di dichiarazioni, scritto e colloquiale, e introduce cinque tipi di ragionamento: one-hop, congiunzione, esistenza, multi-hop e negazione. I risultati dimostrano che i modelli di fact-verifica basati su KG superano i modelli di fact-verifica basati solo su dichiarazioni.</sample>
    <sample id="248">Sì, gli annotatori per NLPositionality sono bilanciati per demografie come paese e genere, garantendo una rappresentazione diversificata nei dati annotati.</sample>
    <sample id="249">Le frasi nel dominio accettabile sono state perturbate aggiungendo 'noise' che preservava la struttura grammaticale, ma non influenzava significativamente i giudizi di MP.</sample>
    <sample id="250">Avere una valutazione dimensionale significa valutare specifiche caratteristiche del comportamento del modello di chat, come l'uso di informazioni rilevanti o la capacità di mostrare empatia, per ottenere una comprensione più accurata della qualità del modello.</sample>
    <sample id="251">Gli autori dell'articolo sono Jingwei Yi e il suo team presso l'Università di Scienza e Tecnologia della Cina.</sample>
    <sample id="252">Il discorso presenta il lavoro di Saikiran Thanikella e il suo team su ucreate, un sistema per il recupero di casi precedenti utilizzando l'estrazione di eventi. Confronta i metodi di recupero di casi precedenti tradizionali con i nuovi metodi sviluppati, come l'ILPR Dataset e il pipeline ucreate. Il discorso evidenzia l'importanza dell'estrazione di eventi e il ruolo dei modelli basati su trasformatori e eventi nel migliorare le prestazioni del recupero di casi precedenti. Il discorso conclude con l'ottimizzazione del modello Event Filtered Docs, che supera i metodi basati su trasformatori e atomici.</sample>
    <sample id="253">Mario Edarragon presenta 'NameDisorder', un modello di adattamento a due domini per rilevare i segni di disturbi mentali nei social media. Il lavoro, realizzato da ricercatori messicani e spagnoli, utilizza il linguaggio dei social media per identificare i disturbi mentali. Il modello, basato su BERT, viene adattato per comprendere il linguaggio specifico dei forum di Reddit e della salute mentale. Il processo di adattamento include l'uso di un glossario per guidare il processo di masking, concentrandosi su parole significative. I risultati dimostrano che il modello di NameDisorder è efficace nel rilevare i segni di disturbi mentali, superando il modello BERT. I futuri progetti mirano a migliorare le risorse lessicali e a utilizzare dati clinici.</sample>
    <sample id="254">Il lavoro di Sun Qi introduce un framework per migliorare la qualità dei pseudo-etichettati nei modelli di document level relation extraction. Il framework utilizza la denoising guidata dall'incertezza per mitigare l'influenza dei pseudo-etichettati falsi, introducendo un metodo di stima dell'incertezza per valutare la fiducia delle previsioni del modello. Per affrontare le relazioni multiple tra coppie di entità, viene proposto un metodo di stima dell'incertezza a livello di istanza. Un approccio di etichettatura dinamica con soglie di incertezza dinamiche e un'ottimizzazione in più fasi sono proposti per migliorare le prestazioni. I risultati dimostrano un miglioramento significativo rispetto ai modelli di base, con un'implementazione su due set di dati pubblici.</sample>
    <sample id="255">La forma del prompting è cruciale per i prompt zero e uno, ma non influisce significativamente sui prompt a cinque.</sample>
    <sample id="257">Gli autori hanno valutato quattro modelli di dialogo avanzati utilizzando ABC Eval.</sample>
    <sample id="258">Zhangsun Han discute il lavoro su "Can Large Language Models be an Alternative to Human Evaluations?" che propone l'uso di modelli linguistici di grandi dimensioni per valutare la qualità del testo in processi naturali. Il lavoro mira a trovare un'alternativa stabile e replicabile ai valutatori umani, che sono difficili da ripetere. I modelli linguistici di grandi dimensioni, se possono comprendere le istruzioni, potrebbero valutare i testi in base a criteri come grammatica, coerenza, leggibilità e rilevanza. I risultati mostrano che alcuni modelli, in particolare Davinci e ChatGPT, mostrano una preferenza per i testi scritti dall'uomo, simile ai valutatori umani. Il lavoro esplora anche le implicazioni di questi risultati e le potenziali applicazioni in altri compiti.</sample>
    <sample id="259">Rendi Zhang di Penn State University presenta il lavoro 'Exemplar', che mira a semantica crosslingua in più lingue e rappresentazioni. Il lavoro introduce un set di dati unificato, 'Exemplar', che include 90 set di dati in vari domini, 5 attività di semantica e 8 rappresentazioni, in 22 lingue e 15 famiglie linguistiche. Il team ha eseguito benchmark su tre tipi di modelli multilingue: monolingue, multilingue e encoder-decoder. I risultati mostrano che i modelli encoder-decoder superano i modelli monolingue e encoder-pdr, con miglioramenti significativi in alcune lingue. Tuttavia, i modelli multilingue come Code Search e BERT+XLN+PDR sono ancora inadeguati per compiti di semantica crosslingua. Il lavoro conclude con un esame approfondito dei risultati e delle implicazioni.</sample>
    <sample id="260">L'articolo è scritto da un solo autore, Jinwei Yi.</sample>
    <sample id="261">Un buon pianificatore dovrebbe scrivere script che siano sia ragionevoli che fedeli alle restrizioni.</sample>
    <sample id="262">L'articolo è scritto da un unico autore, Yu Yuan, di Fudan University.</sample>
    <sample id="263">Rendi: Il lavoro mira a mitigare le bias nei sistemi di in-context learning, un paradigma di modellazione linguistica. Le decisioni di progettazione, come la selezione e l'ordine degli esempi, introducono bias nei risultati. Il team ha identificato un nuovo tipo di bias, la bias del dominio, e ha proposto un metodo di calibrazione che migliora significativamente le prestazioni dei modelli.</sample>
    <sample id="264">L'insegnante, un laureato della Zhejiang University, discute la sua presentazione intitolata 'Towards Transferable Audio Visual Text Generation'. Il lavoro mira a superare le sfide della generazione multimodale, come la generazione audio-visuale, introducendo un nuovo compito chiamato 'Transferable Audio Visual Text Generation'. Il modello prevede tre componenti: una rete di mappatura audiovisiva, un encoder e un generatore di linguaggio. Il modello è progettato per adattarsi rapidamente a nuovi domini con dati limitati. I risultati dimostrano che il modello di Zhuo Tang supera i modelli basati su RNN e Transformer in molti scenari, anche se altri metodi possono superare in domini con pochi dati.</sample>
    <sample id="265">La relatrice si chiama Vasudha.</sample>
    <sample id="266">L'articolo non menziona specificamente le affiliazioni degli autori.</sample>
    <sample id="268">Gli errori più comuni di PaLM sono errori di omission, dove parti della frase di origine vengono omesse per produrre una traduzione più fluida.</sample>
    <sample id="269">James Finch e Sarah Finch discutono di abc eval, un nuovo approccio dimensionale per valutare l'AI conversazionale. Questo lavoro è stato realizzato dal laboratorio Emory Nlp, guidato da Gino Choi presso Emory University, in collaborazione con Amazon Alexa AI.</sample>
    <sample id="270">James Finch e Sarah Finch sono affiliati all'Emory NLP Lab, in collaborazione con Amazon Alexa AI.</sample>
    <sample id="271">CFT sta per Continuous Fine-Tuning, un metodo suggerito per migliorare i risultati delle tecniche WSL continuando il fine-tuning sui set di validazione puliti.</sample>
    <sample id="272">L'articolo è un lavoro congiunto di otto autori.</sample>
    <sample id="273">Ciao. Mi chiamo Kaiho Yin e presenterò il nostro lavoro intitolato "Quando la traduzione richiede contesto: un'esplorazione multilingue guidata dai dati." Questo lavoro è stato realizzato in collaborazione con Patrick Koller, Emile Liu, Andre F. D. Martins e Graham Neubig. Quindi, molte traduzioni dipendono dal contesto. Ad esempio, come tradurremmo 'mole' in questa frase? Bene, se la frase precedente fosse stata, 'i ministri potrebbero scoprire che le cose potrebbero diventare pericolose', allora 'mole' si riferisce a un spia. Ma se la frase precedente fosse stata, 'Potrebbe essere qualcosa di grave, dottore?', allora 'mole' si riferisce a un segno di nascita. Quindi, a seconda del contesto, il significato della parola cambia, e quindi la traduzione cambia. Tuttavia, valutare quanto bene i modelli possono tradurre casi come questo è piuttosto difficile. In primo luogo, perché solo una piccola parte delle traduzioni dipende dal contesto, il che rende ininacevoli i metodi di valutazione a livello di corpus come bleu. E alcuni hanno suggerito una valutazione mirata sulle traduzioni dipendenti dal contesto, ma questi risorse supportano solo tipi limitati di traduzioni dipendenti dal contesto e set di lingue, poiché di solito si basano sulla conoscenza del dominio e sulla curatura umana. In questo lavoro, cerchiamo di rispondere a due domande: quando la traduzione richiede contesto e quanto bene i modelli gestiscono questi casi? Per rispondere alla prima domanda, iniziamo misurando quanto una parola dipende dal contesto durante la traduzione. In precedenza, abbiamo introdotto cxmi come misura per l'uso del contesto dai modelli di traduzione. E questo viene fatto misurando quante informazioni il contesto C fornisce sul target Y, dato il sorgente X. Puoi pensare a cxmi come alle informazioni fornite dal dare contesto al modello. In questo lavoro, estendiamo cxmi a cxmi puntowise, che può misurare l'uso del contesto a livello di frase o di parola. Analizziamo parole con alto cxmi per cercare schemi tra queste parole. E eseguiamo il nostro analisi su trascrizioni di Ted Talk tradotte da inglese a quattordici lingue diverse. Eseguiamo il nostro analisi a tre livelli diversi. Innanzitutto, guardiamo a parti di parole che hanno alto cxmi. Questo ci permette di trovare, ad esempio, pronome duali in arabo che hanno un cxmi relativamente alto. E questo può essere spiegato perché l'inglese non ha pronome duali, quindi è necessario il contesto per determinare se un pronome è duale quando si traduce in arabo. E allo stesso modo, troviamo che certi linguaggi richiedono contesto quando vogliamo scegliere la forma verbale appropriata. Quindi guardiamo a parole che hanno un cxmi medio alto. Questo aiuta a identificare casi come il seguente, dove in cinese è necessario il contesto per tradurre nomi propri per assicurarsi di usare la stessa traduzione all'interno del documento. E allo stesso modo, guardiamo a diversi token individuali che hanno alto cxmi. Questo ci permette di identificare fenomeni che non possono essere catturati solo dal significato della parola, ma che sono espressi nella struttura della frase, come la risoluzione di ellissi. Quindi, usiamo i nostri risultati per progettare un benchmark per la traduzione a livello di documento. Per ogni uno dei cinque fenomeni di discorso che abbiamo identificato, creiamo taggatori per identificare parole che appartengono al fenomeno. E chiamiamo il nostro taggatore il taggatore multilingue consapevole del discorso. Possiamo anche notare che diversi linguaggi hanno diverse proporzioni di questi fenomeni di discorso. Quindi, usiamo il taggatore Muda applicando il taggatore su un corpus parallelo che vogliamo usare per la valutazione. E poi applichiamo i nostri metodi di valutazione di traduzione di scelta su gli esempi dipendenti dal contesto che il taggatore Muda ha identificato. E infine, usiamo il nostro benchmark, così come altri metodi di valutazione, per valutare diversi modelli di traduzione a livello di documento. In primo luogo, quando usiamo i metodi di valutazione a livello di corpus, quindi per bleu, scopriamo che i modelli agnostici al contesto hanno le migliori prestazioni. Ma poi, se usiamo comet, i modelli consapevoli del contesto agiscono meglio. E se usiamo wordf, i modelli con o senza contesto hanno prestazioni comparabili. Questo dimostra di nuovo che è difficile determinare il miglior sistema di traduzione a livello di documento se usiamo solo i metodi a livello di corpus. Ora, usiamo il nostro benchmark per valutare i modelli. E scopriamo che i modelli consapevoli del contesto sono significativamente più accurati dei modelli che non usano il contesto per certe fenomeni di discorso, come la formattazione e la coesione lessicale. Ma questi modelli non sono molto migliori dei modelli che non usano il contesto per altri fenomeni, come le ellissi, i pronomi e la forma verbale. Quindi, suggerisce dove abbiamo bisogno di vedere più progressi per la traduzione a livello di documento. Confrontiamo anche diversi sistemi commerciali, e il nostro benchmark mostra che DeepL è di solito più accurato di Google Translate per la traduzione a livello di documento. In sintesi, eseguiamo un'analisi guidata dai dati su quattordici coppie di lingue per identificare quando la traduzione richiede contesto. E poi usiamo i nostri risultati per costruire un benchmark per la traduzione a livello di documento, che può aiutarci a identificare quali modelli di discorso possono gestire bene o no, e quali sistemi di traduzione sono buoni per la traduzione a livello di documento. Grazie.</sample>
    <sample id="274">La relatrice è Yu Chen Zhang.</sample>
    <sample id="276">Ananya and Vignesh present their work on IndicMT Eval, a dataset to evaluate machine translation metrics for Indian languages. They focus on five languages from two language families, Tamil, Malayalam, Hindi, Marathi, and Gujarati, and generate 7,000 samples for evaluation. Bilingual expert annotators evaluate the outputs, marking errors and providing overall scores. Recent MT models like NLLB and IndicTrans show fewer errors compared to older models. The study fine-tunes the IndicComet metric, which outperforms Comet baselines on most languages and shows higher correlations with human scores. IndicComet is also more robust on unseen languages.</sample>
    <sample id="277">Il nuovo metodo non ha un nome specificato.</sample>
    <sample id="278">L'autore descrive il metodo di 'parole contrassegnate' come una tecnica che utilizza il concetto sociolinguistico di 'markedness' per identificare parole che distinguono gruppi contrassegnati da quelli non contrassegnati. Questo metodo utilizza log odds ratios per identificare le parole che distinguono i gruppi contrassegnati, come le donne di colore, rispetto ai gruppi non contrassegnati, come i maschi bianchi.</sample>
    <sample id="279">Gli autori sono studenti della University of Washington, con il Ph.D. di Xiangbing.</sample>
    <sample id="280">Shuo Tao presenta il framework Multi-EMO per l'Emotion Regulation in Conversations (ERC), che mira a prevedere le etichette emotive delle espressioni verbali. Il framework integra informazioni multimodali, affrontando sfide come la complementarietà dei dati multimodali, le performance in classi di movimenti di minoranza e la distinzione tra emozioni simili. Introduce vis-expressNet, un nuovo estrattore visivo che elimina informazioni non correlate, e MultiAttend, un modello di fusione multimodale. Utilizzando un contrasto focale ponderato, il framework migliora la classificazione delle classi di emozioni difficili. I risultati dimostrano prestazioni superiori su benchmark di MELD e IEMOCAP, anche se presenta alcune limitazioni.</sample>
    <sample id="281">Kyowin Yu e il suo team hanno condotto un'esplorazione multilingue su quando la traduzione richiede contesto, utilizzando CXMI per misurare l'uso del contesto durante la traduzione. Hanno identificato parole con alto Pseudo-CXMI, indicando la necessità di contesto per la traduzione. Hanno sviluppato un tagger MUDa per identificare parole pertinenti a fenomeni discorsali, utilizzando il loro tagger per valutare diversi sistemi di traduzione a livello documentale. I loro risultati mostrano che i sistemi di traduzione consapevoli del contesto sono più accurati per fenomeni come la formattazione e la coesione, ma hanno bisogno di miglioramenti per altri, come le ellissi e le forme verbali. Il loro lavoro fornisce un quadro per valutare le capacità dei sistemi di traduzione a livello documentale.</sample>
    <sample id="282">Xiaoxuan Liu e il suo team presentano il loro lavoro su 'StoryTrance', un modello di generazione di testo che si concentra sul trasferimento di stile a livello discorsale. Questo approccio affronta le sfide associate al trasferimento di stile a livello di frase, che è difficile a causa della stretta correlazione tra contenuti specifici di stile e argomenti. Il modello 'StoryTrance' utilizza una strategia di training in due fasi: la prima fase utilizza un framework di training autorestrizione per recuperare l'input e distinguere i contenuti e lo stile a livello di frase, mentre la seconda fase si concentra sul riempimento del contenuto corretto e sulla rimozione dei token mascherati. I risultati dimostrano che 'StoryTrance' è efficace nel mantenere la semantica del contenuto originale e nel trasferire lo stile desiderato, superando i modelli di base.</sample>
    <sample id="283">La prima struttura di dipendenza simmetrica menzionata è l'Universi-Dependenze.</sample>
    <sample id="284">Peng Tianxiao from Wuhan University presented FSUE at ACL Main Conference 2019. FSUE addresses the ambiguity in span boundary labeling by proposing fuzzy span boundaries, which are more flexible than precise ones. The model uses a continuous distribution to represent the target boundary, and a mask function to adjust attention span dynamically. Experiments on tasks like named entity recognition and relationship extraction showed significant improvements. FSUE achieved better results on datasets like ACE 2004-2005 and ADE, and demonstrated strong generalization capabilities. The attention distribution was visualized, showing focus on semantic information within a limited range.</sample>
    <sample id="285">Min Qi Gao di Peking University discute il suo lavoro su Fact Error Correction (FEC) per la sintesi del dialogo. FEC corregge errori fattuali nei resumi generati dai modelli, migliorando la loro affidabilità. Il lavoro critica le metriche attuali di valutazione, suggerendo che introducere la sintesi corretta da parte umana durante il training può migliorare le prestazioni dei modelli FEC. Il team propone una nuova tassonomia per errori fattuali, dividendo i tipi in base al contenuto e alla forma. Il team sperimenta diversi modelli FEC, trovando che i modelli treni con risorse di sintesi migliorano le prestazioni. Il lavoro sottolinea la necessità di valutazioni più accurate per i modelli FEC.</sample>
    <sample id="286">Il nome della relatrice è Sarah Finch.</sample>
    <sample id="287">Tre.</sample>
    <sample id="288">Dati come il corpus di sentenze di Blimp possono essere utilizzati per testare i fenomeni sintattici, creando sequenze accettabili e inaccettabili che mantengono la struttura grammaticale.</sample>
    <sample id="290">Le abbreviazioni dei cinque metodi per la prima domanda di ricerca sono: 1) WSL, 2) CoSine, 3) FSW, 4) FSW-FT, 5) FSW-FT-CL.</sample>
    <sample id="291">Il modello viene valutato su 11 attività di domande non trascritte, tra cui riconoscimento dei nomi, classificazione, tagging del parziale e risposte alle domande.</sample>
    <sample id="294">CamemBERT viene inizialmente addestrato su dati di natura clinica provenienti da Notion University.</sample>
    <sample id="295">Il relatore è Adam Szpekowski.</sample>
    <sample id="296">Valerio Basile discute il suo lavoro con Amazon Alexa, concentrandosi sulla rilevazione dell'ironia in linguaggio naturale. Il progetto, che coinvolge la creazione del corpus EPIC, mira a comprendere le differenze di percezione dell'ironia tra vari gruppi di annotatori. Utilizzando il modello pre-addestrato su set di dati divisi per annotatori, Basile scopre che i modelli 'perspectivist' mostrano maggiore fiducia nelle loro previsioni. Le differenze di percezione sono evidenti tra generazioni vicine e tra annotatori di paesi come il Regno Unito e l'Irlanda.</sample>
    <sample id="297">Il discorso del professor Kate Price riguarda il lavoro sul riconoscimento dei dogwhistles, parole o frasi che trasmettono messaggi sottili a un gruppo specifico, spesso con significati nascosti. Il progetto ha sviluppato un glossario di oltre 340 termini, classificati per tipo e persona, per identificare dogwhistles in vari contesti, inclusi discorsi politici e contenuti online. I risultati mostrano che i modelli linguistici come GPT-3 possono identificare alcuni dogwhistles, ma con variazione. Inoltre, il discorso evidenzia come i dogwhistles possano eludere la moderazione dei contenuti, risultando in valutazioni meno tossiche quando sostituiscono termini offensivi.</sample>
    <sample id="298">L'esperimento di riaddestramento con dati più recenti ha dimostrato che le prestazioni dei modelli diminuiscono con un aumento della distanza temporale tra i dati di addestramento e i dati di test, confermando la deriva temporale come causa principale della perdita di prestazioni.</sample>
    <sample id="299">Mihals Kurajis e Andreas Vlachos presentano un metodo per migliorare la robustezza dei modelli di analisi lineare (LNN) riducendo la loro dipendenza dai shortcut. I shortcut sono correlazioni tra input e etichette che i modelli sfruttano, portando a prestazioni migliori in distribuzione ma fragili in distribuzione. Il loro metodo utilizza un min-max training per incentivare i modelli a concentrarsi su esempi difficili, migliorando così le prestazioni in distribuzione. Questo metodo è stato valutato su tre set di dati di analisi e ha dimostrato miglioramenti significativi rispetto ai metodi esistenti.</sample>
    <sample id="300">Belinda presenta un lavoro su un sistema di dettatura interattiva, che consente agli utenti di modificare il testo parlato in modo naturale. Il sistema, sviluppato da Semantic Machines, utilizza un modello di riconoscimento vocale per convertire il parlato in testo, che viene poi segmentato in dettatura e comandi. Il sistema utilizza modelli di apprendimento profondo per eseguire le operazioni di interpretazione, con un focus su t5 e GPT-3. I risultati mostrano che GPT-3 offre maggiore precisione, anche se a scapito della velocità, mentre T5 offre un equilibrio tra efficienza e precisione. Il progetto ha anche rilasciato il codice per facilitare ulteriori sviluppi.</sample>
    <sample id="302">La permutazione dei token è necessaria per la sequenza di output per garantire che vengano inseriti i token nel giusto ordine, poiché la nostra approccio utilizza tag un multi-set di token che non sono ordinati.</sample>
    <sample id="303">Aumentare la trasparenza sui metodi di mitigazione dei bias consente ai proprietari dei modelli di comprendere se i positivi stereotipi derivano da un'eccessiva allineazione dei valori o da altri metodi anti-stereotipici, permettendo un'analisi più approfondita e informata.</sample>
    <sample id="304">Gli input inaccettabili di coppia minima sono frasi o domande grammaticalmente errate o non conformi alle norme sociali, utilizzate per valutare la capacità di un modello linguistico a distinguere tra contenuti accettabili e inaccettabili.</sample>
    <sample id="305">Dawie, a PhD student at Saarland University, presents a video on their research 'Weaker than you think: A critical look at weakly supervised learning.' The research, conducted with Xiaoxuan, Mario, Giasdelfen, and Dittlich, explores the challenges and misconceptions in weakly supervised learning (WSL). WSL uses weak labels, which are cheaper but noisy, leading to potential overfitting. The study questions the necessity of clean validation data for WSL, finding that recent methods require it for proper performance. The research suggests that performance improvements in WSL can be achieved through continuous fine-tuning on clean data, challenging the need for complex WSL methods. The team has open-sourced their code for further exploration.</sample>
    <sample id="306">Sebastian Schuster e Na Jeong Kim hanno condotto un lavoro sull'entity tracking nei modelli linguistici, essenziale per comprendere le discorsi. Il loro studio mira a valutare le capacità di pre-train language models in tracciare gli stati delle entità. Hanno affrontato sfide come le pre-train data che potrebbero conferire abilità non necessarie e l'uso di euristiche. Hanno progettato un compito che richiede ai modelli di integrare le descrizioni iniziali con operazioni di stato, evitando così le soluzioni semplici. I loro esperimenti hanno mostrato che i modelli GPT-3.5, addestrati su codice, mostrano capacità di tracking non banale, suggerendo che l'addestramento su codice è cruciale. I modelli più piccoli possono essere addestrati con fine-tuning, ma la pre-train data è ancora essenziale. Il loro lavoro fornisce approfondimenti e risultati aggiuntivi nel loro articolo.</sample>
    <sample id="307">Gli autori hanno utilizzato metriche come precisione, recall e F1-score per valutare le prestazioni dei modelli su compiti come riconoscimento dei nomi propri, classificazione e tagging del parziale.</sample>
    <sample id="308">Jenny, a first-year PhD student at Carnegie Mellon University, presents her research on 'Anal Positionality: Characterizing Design Biases of Datasets and Models.' Collaborating with the University of Washington and the Allen Institute for AI, the study explores how datasets and models reflect the positionalities of their creators, often leading to biases. Jenny explains that positionality, influenced by demographics and life experiences, affects research outcomes. The research uses Lab in the Wild to gather diverse annotations and compares them with models like GPT-4 and DynaHate, revealing biases towards English-speaking and educated annotators. The study suggests keeping records of design choices, conducting research with a lens of perspectivism, and building specialized datasets and models for specific communities.</sample>
    <sample id="309">L'accordo tra annotatori è stato misurato utilizzando 100 conversazioni doppiamente etichettate, confrontando le etichette fornite da annotatori diversi.</sample>
    <sample id="310">Wikipedia è stato scelto per aggiungere frasi completamente scollegate alle query inaccettabili e accettabili.</sample>
    <sample id="311">Gli autori dell'articolo sono Regina Stoddart e Omar Elgohdy.</sample>
    <sample id="312">MultiInstruct differisce dagli altri parametri di riferimento in quanto è il primo set di parametri di riferimento multimodale per l'instruzione, offrendo una piattaforma per migliorare le capacità dei modelli pre-addestrati in compiti multimodali.</sample>
    <sample id="313">Due autori sono coinvolti nell'articolo: James Finch e Sarah Finch.</sample>
    <sample id="314">La coordinazione binaria è una struttura di coordinazione in cui una frase è composta da due o più verbi, ciascuno con la propria oggetto, come in 'John threw the ball and hit the bat'.</sample>
    <sample id="315">Il tempo medio per l'uso dei prompt in questo studio è di 0.5 secondi.</sample>
    <sample id="316">Il modello T5 più piccolo, quando addestrato su CoScript, può generare script di alta qualità, rivaleggiando con i modelli più grandi. Questo dimostra che modelli più piccoli, se addestrati correttamente, possono competere con i modelli più grandi, offrendo un'opzione più economica per applicazioni di pianificazione del linguaggio.</sample>
    <sample id="317">Peng Li from Fudan University presents CodeIE, a method for information extraction by converting tasks into code generation using large language models like Code-Davinci. This approach addresses the issue of mismatched outputs in traditional models by ensuring alignment between input and output formats. The method was tested on datasets for named entity recognition and relation extraction, showing that code format prompts outperform traditional models like GPT-3 and T5. The analysis revealed that code format prompts result in fewer structural errors and better recall, especially with GPT-3. The paper is available for public access.</sample>
    <sample id="318">Il modello Dr. Bert, basato su roberta, è un modello pre-addestrato in francese per il dominio medico clinico. In questa presentazione, iniziamo a discutere del modellamento linguistico nel settore sanitario, quindi presentiamo il nostro lavoro. Introduciamo il primo modello medico in francese, basato su roberta, e tracciato su data di roberta. Presentiamo i risultati del nostro lavoro su undici compiti di screening clinico in francese. In conclusione, il nostro sistema offre prestazioni migliori su nove dei compiti di screening clinico e supera globalmente il modello generico qui camember.</sample>
    <sample id="319">Le strategie di apprendimento esaminate includono l'addestramento da zero su dataset di Nachos, l'uso di pretraining con modelli come Camembert, e l'implementazione di pretraining con peso e tokenizzatore di Clinical Bert.</sample>
    <sample id="320">Il fattore di overfitting è inferiore a 1, indicando che ogni miglioramento su CONCOL 2003 si traduce in più miglioramenti su CONCOL++, non mostrando adattiva overfitting.</sample>
    <sample id="321">La qualità della semplificazione è stata valutata analizzando i tipi di semplificazione, come sostituzione, riorganizzazione e riformulazione, e confrontando i diversi domini come testi biblici, notizie e testi di apprendimento della lingua.</sample>
    <sample id="322">Enrico, un ricercatore, discute la comprensione della moralità nei modelli linguistici, sottolineando la sua natura soggettiva e la necessità di un approccio pluralista. Utilizzando il corpus di tweet MORALFOUNDATION, Enrico dimostra che i modelli linguistici possono riconoscere le differenze nella rappresentazione della moralità in vari domini, come ALM e BLM, evidenziando la necessità di modelli specifici per ogni dominio per evitare malintesi.</sample>
    <sample id="323">L'articolo di Yu Jia Wang, "Dynamic heterogeneous graph reading with language models and knowledge representation learning for commonsense QA," discute la sfida del question answering (QA) che richiede la comprensione del linguaggio e la conoscenza. Il lavoro introduce DihL-K, che utilizza un modello linguistico per migliorare la rappresentazione della conoscenza. Il metodo elimina le entità non pertinenti e utilizza il modello di auto-attenzione per migliorare la rappresentazione della conoscenza. I risultati dimostrano che il metodo di Jia Wang ottiene buoni risultati in confronto con altri metodi.</sample>
    <sample id="324">Sì, i modelli linguistici mostrano bias politici diversi, occupando tutti i quadranti del Political Compass. GPT-4 è il più liberale, mentre GPT-3 e BERT sono più conservatori.</sample>
    <sample id="325">Ciao. Mi chiamo Matthias Landmann e oggi vi farò una breve introduzione al nostro articolo su 'Composizione e generalizzazione senza alberi, usando tag di insiemi e permutazioni latenti'. Questo è un lavoro congiunto dei miei consiglieri, Alexander Koller e Ivan Tiedoff. La composizione può essere intesa come la capacità di un apprendimento ad auto-apprendimento di gestire ricorsioni e composizioni non viste individualmente durante l'addestramento. Nel contesto della semantica, la valutazione per la composizione può assomigliare a questa. Come al solito, abbiamo un set di frasi di addestramento, in questo caso, 'la ragazza dormiva' e 'Maria sapeva che la ragazza dormiva'. Queste frasi sono accoppiate con forme logiche che rappresentano aspetti centrali del loro significato. A differenza della valutazione standard di apprendimento automatico, il set di test non proviene dalla stessa distribuzione, ma contiene forme logiche strutturalmente non viste. In questo esempio, il modello ha visto ricorsioni superficiali durante l'addestramento e viene testato su esempi con ricorsioni più profonde. I modelli sequenza-seriali si sforzano di generalizzare in distribuzione, ma spesso producono output dettati dall'input. In particolare, spesso non riproducono le corrispondenze sistematiche tra input e output, come quelle colorate nel esempio. Un metodo popolare per affrontare questo tipo di generalizzazione è integrare alberi nei modelli. Gli alberi sono destinati a catturare il processo compositivo che relaziona le frasi con le forme logiche. Questo funziona bene, ma gli alberi di solito non vengono dati e devono essere ottenuti in qualche modo. Questo può essere complicato e a volte un processo computazionale costoso. Tipicamente, questo comporta un'elaborazione specifica del formale delle forme logiche, ad esempio, per gestire simboli variabili. L'ottenimento degli alberi può anche comportare procedure di induzione grammaticale specializzate. In questo articolo, non usiamo alberi e introduciamo un modello di sequenza-seriale che modella direttamente le corrispondenze tra frammenti di input e output. Per la prima volta, mostriamo una forte generalizzazione alla ricorsione senza fare affidamento sugli alberi. Il nostro approccio prevede la previsione dell'output in due fasi. In prima fase, taggiamo ogni token di input con un insiemo multi-set di token che appariranno nell'output. Dopo la prima fase, abbiamo tutti i token giusti, ma non sono ordinati. Questo è il motivo per cui, nella seconda fase, usiamo un altro modello per prevedere una permutazione per mettere i token nell'ordine giusto. Introduciamo un nuovo metodo per prevedere una permutazione che non impone vincoli difficili sulle possibili permutazioni. Questo rende il nostro approccio abbastanza flessibile e espressivo. Concettualmente, il nostro modello di permutazione funziona in questo modo: andiamo da sinistra a destra sull'output e determiniamo quale token dell'insiemo di multi-set mettere in ogni posizione. Per la prima posizione, scegliamo semplicemente uno come evidenziato in rosso. Quindi, saltiamo a un altro token dell'insiemo di multi-set per determinare il secondo token nell'output. Determiniamo il terzo token nell'output in modo simile. Continuiamo questo processo fino a quando ogni token della prima fase è stato visitato esattamente una volta. Per darti un'anteprima dei risultati sperimentali, qui confrontiamo il nostro metodo con altri modelli senza alberi sul benchmark COGS. Il nostro modello supera gli altri di gran lunga in termini di generalizzazione alla ricorsione più profonda. Alcune altre forme di generalizzazione strutturale rimangono molto impegnative, però. In questo articolo, risolviamo un paio di sfide tecniche interessanti. In primo luogo, l'allineamento tra input e output non è dato nei dati di addestramento. Di conseguenza, per un dato token, non sappiamo da quale insiemo di multi-set proviene. Questo pone una sfida per l'addestramento. In secondo luogo, a volte ci sono permutazioni multiple che sono coerenti con i dati, ma la permutazione linguisticamente corretta è latente. Affrontiamo questo indossando l'allineamento come parte dell'addestramento. Il nostro metodo di permutazione è molto flessibile, ma porta la sfida di trovare la permutazione più alta. Questo è perché è legato al problema del viaggiatore. Approssimiamo questo con un metodo amichevole per le GPU e un rilassamento continuo che ci consente di backpropagare attraverso la soluzione e imparare le permutazioni più linguisticamente plausibili.</sample>
    <sample id="326">La dissonanza cognitiva è la presenza di credenze o azioni incoerenti, come quando una persona sa che il fumo può danneggiare ma continua a fumare. Studiarla aiuta a comprendere le decisioni e la mentalità umana.</sample>
    <sample id="327">Xiaoxu, a third-year PhD student, presents their work on the MagTower model for vision language learning at ACL 2023. The MagTower model builds on the BridgeTower by incorporating meta-level unidimensional representations, allowing for more effective exploitation of unidimensional semantic knowledge. It uses managers in each cross-modal layer to aggregate insights from pre-trained unidimensional experts, improving performance on tasks like VQVC2. The model outperforms base models trained on 4 million images and surpasses models trained on larger datasets. The paper is available on arXiv and GitHub.</sample>
    <sample id="328">Secondo i risultati preliminari presentati, il modello linguistico GPT-4 è il più liberale tra quelli menzionati.</sample>
    <sample id="329">Zenminhang di Peking University presenta un lavoro su 'Generating Structured Pseudo Labels for Zero-Shot Video Sentencing Localization', in collaborazione con Shao, Hai, Lin, Xu e Yang. Lavoro si concentra sulla localizzazione video zero-shot, che cerca i segmenti video più rilevanti per una query linguistica data. Il metodo proposto elimina la necessità di annotazioni manuali, utilizzando invece pseudo query e pseudo etichette generati da modelli pre-addestrati. Il metodo affronta i problemi di semantica e di disallineamento tra query e eventi, generando pseudo query più complesse e misurando la rilevanza tra query e video. Riduce anche l'influenza della noia nelle etichette. Il metodo ha ottenuto risultati migliori rispetto ai metodi esistenti, come dimostrato dai risultati di valutazione.</sample>
    <sample id="330">Sì, l'addestramento cumulativo ha prestazioni paragonabili o migliori rispetto all'iterativo.</sample>
    <sample id="331">Il nome della relatrice è Sara Papi.</sample>
    <sample id="332">I dati sono stati tratti da trascrizioni di Ted Talks tradotti in 14 lingue.</sample>
    <sample id="333">Wen Hao della Nanjing University discute il suo lavoro su InKMT, un metodo per migliorare le capacità di generalizzazione delle reti neurali per la traduzione. Il lavoro affronta il problema delle rappresentazioni non lisce nei modelli di traduzione neurale, che limitano la loro capacità di generalizzare. InKMT introduce un framework che utilizza conoscenze chiave per regolare le rappresentazioni, migliorando le prestazioni di traduzione. I risultati sperimentali dimostrano che InKMT supera i sistemi di traduzione tradizionali, offrendo prestazioni migliori con meno spazio di memoria e velocità di inferenza più elevate.</sample>
    <sample id="335">Il nome della relatrice è Matthias Landmann.</sample>
    <sample id="336">Il trasferimento interlinguistico è un processo in cui un modello viene addestrato su un linguaggio sorgente e poi applicato a un linguaggio di destinazione, come mostrato in Exemplar.</sample>
    <sample id="337">The presentation introduces a novel approach to handling out-of-vocabulary (OOV) words in embedding-based models by using a word relationship graph. This method leverages word formation and association to infer OOV word meanings, with each word or word piece acting as a node in the graph. The model uses a graph neural network to process the graph, applying self-attention to assign node attributes and a graph-level representation to capture the entire graph information. The approach aims to mimic the vector space of background embedding models, using contrastive learning to enhance model performance. Extensive experiments show the model's effectiveness in both intrinsic and extrinsic tasks, with potential applicability to other languages depending on their word decomposition.</sample>
    <sample id="338">Bingxin, del gruppo di ricerca, discute la ricerca su 'Are Human Explanations Always Helpful?' che esamina la qualità delle spiegazioni umane per migliorare le prestazioni dei modelli di linguaggio naturale. Presenta una struttura dati unificata per convertire vari compiti in un formato comune, esamina l'utilità delle spiegazioni attraverso esperimenti e introduce una nuova metrica, TRUE, che migliora la simulabilità. I risultati dimostrano che TRUE è più efficace della simulabilità, specialmente per compiti come ESNLI e COMPVE. La ricerca sottolinea l'importanza di valutare le spiegazioni in base al contesto del compito, suggerendo un approccio più sfumato per l'analisi delle spiegazioni umane.</sample>
    <sample id="339">Dawie, Xiaoxuan, Mario, Matthias, Giasdeth, e Dittli sono autori dell'articolo.</sample>
    <sample id="340">Guan Hao Huang from UCLA presents Para-AMR, a large-scale, syntactically diverse paraphrase dataset created using AMR back-translation. This dataset addresses the limitations of existing paraphrase datasets by providing a more varied syntactic structure while maintaining semantic similarity. The dataset is constructed by altering the focus node in AMR graphs, which are directed graphs representing sentence meanings. Para-AMR is shown to improve performance in NLP applications like sentence embeddings, paraphrase generation, and data augmentation. It is available for use at a provided link.</sample>
    <sample id="341">Gli autori fanno uso di misure come latenza media, latenza media computazionale e misure di qualità della traduzione per valutare l'efficacia della loro strategia.</sample>
    <sample id="342">Gao Jinsun presents a paper on a large-scale, personalized dialogue dataset derived from live streaming, addressing the need for video-based dialogue data. The dataset, Live Chat, is constructed through three steps: scraping videos from TikTok, extracting audio, and transcribing it. Experiments show that persona extraction and longer sessions improve performance, with single-stream models outperforming double-stream ones. The dataset's uniqueness lies in its video source and detailed annotations, offering a rich resource for developing applications like virtual streamers.</sample>
    <sample id="343">Salve a tutti. Sono Akshata e oggi presenterò insieme al mio collega Martin il nostro lavoro, il kitmose, che valuta l'integrazione del sapere proveniente da fonti multiple. Questo lavoro è una collaborazione tra McGill University, Meila e Microsoft Research. I modelli di comprensione del linguaggio naturale si basano su una varietà di fonti di conoscenza, come il sapere contenuto nei parametri pre-allenati e nel sapere fornito in tempo di inferenza. Recenti lavori in compiti come il risolutore di domande mostrano che i modelli possono utilizzare il sapere pre-allenato per risolvere compiti. Tuttavia, la comprensione del linguaggio naturale richiede spesso il sapere fornito in tempo di inferenza. In questo lavoro, proponiamo un test diagnostico per l'integrazione del sapere proveniente da fonti multiple. Introduciamo un compito di risoluzione di co-referenze progettato per testare la capacità di attingere al sapere proveniente da fonti multiple. Valutiamo il set di dati con partecipanti umani e stabiliamo modelli di risoluzione di co-referenze. Ecco un esempio dal nostro set di dati. Servin è un giudice. Kia è un panettiere. Servin e Kia si sono incontrati in un parco. Dopo una lunga giornata di lavoro, decidendo casi in un tribunale, si è rilassato. Il compito qui è identificare l'entità corretta a cui il pronome si riferisce, che in questo caso è Servin. La risoluzione di un dato pronome richiede due tipi di informazioni. In primo luogo, conoscenza specifica dell'entità, come Servin è un giudice. E in secondo luogo, conoscenza di fondo, come i giudici decidono casi in tribunali. In generale, la conoscenza di fondo viene acquisita durante l'allenamento di modelli linguistici di grandi dimensioni, mentre la conoscenza specifica dell'entità viene tipicamente osservata in tempo di inferenza. Variaamo la disponibilità di queste due informazioni in modo che possa essere trovata in una singola fonte o in più fonti. Abbiamo definito tre impostazioni di kitmose. In primo luogo, abbiamo impostato l'impostazione pre-treno, dove la conoscenza di fondo è presumibilmente disponibile in tempo di pre-allenamento. In secondo luogo, c'è l'impostazione pre-treno, dove la conoscenza di fondo è disponibile sia in tempo di pre-allenamento che in tempo di inferenza. In terzo luogo, l'impostazione inferenza, dove entrambi i tipi di conoscenza sono disponibili solo in tempo di inferenza. Questa ultima impostazione è particolarmente interessante, poiché simula il caso in cui il sapere di fondo necessario per risolvere un compito non è parte dei parametri pre-allenati dei modelli. Ad esempio, poiché sono stati sviluppati nuovi occupi dopo il tempo del pre-allenamento. Ecco un esempio di come controlliamo la disponibilità di fatti e fonti true. Nella impostazione pre-treno, supponiamo che il sapere di fondo, partiti per cercare seggi elettorali, sia contenuto nei parametri pre-allenati. Nella fase di inferenza, forniamo il sapere specifico, che Chester è un politico. Nella impostazione pre-treno, forniamo non solo il sapere specifico, ma anche il sapere di fondo sui politici in fase di inferenza. Nella impostazione inferenza, forniamo l'occupazione fittizia, Meritor, invece di politico, perché Meritor è improbabile che sia contenuto nei parametri pre-allenati. Valutiamo il set di dati sia con partecipanti umani che con modelli di risoluzione di co-referenze. In questa figura, mostriamo i risultati dei modelli di risoluzione di co-referenza migliori. Senza allenamento specifico su kitmose, entrambi i modelli non si comportano bene. Quando addestrati su kitmose, entrambi i modelli C two F e BERT per co-referenza si comportano significativamente meglio rispetto al caso a caso. Questo suggerisce che, quando addestrati su set di dati di risoluzione di co-referenza generali, i modelli imparano a sfruttare indizi superficiali, che non sono utili quando si esegue un test su kitmose, dove tali indizi sono stati rimossi. Ulteriori esperimenti con conoscenze fittizie indicano che anche i modelli di risoluzione di co-referenza migliori non sono in grado di integrare in modo affidabile il sapere di fondo fornito solo in tempo di inferenza. Per riassumere, i principali risultati del nostro lavoro sono: molti modelli di risoluzione di co-referenza non sono in grado di ragionare sul sapere proveniente da fonti multiple senza addestramento specifico. Tuttavia, con addestramento specifico, alcuni modelli integrano con successo il sapere proveniente da fonti multiple. Tuttavia, anche i modelli di risoluzione di co-referenza migliori sembrano avere difficoltà a integrare in modo affidabile il sapere di fondo fornito solo in tempo di inferenza. Se siete interessati a maggiori dettagli, si prega di consultare il nostro articolo e il set di dati e codice su github. Grazie per l'attenzione.</sample>
    <sample id="344">I metodi basati su alberi richiedono formalisms specifici e possono essere computazionalmente costosi. Inoltre, richiedono procedure di induzione di grammatica per ottenere le relazioni tra frasi e forme logiche.</sample>
    <sample id="345">Marius Lendemann presents a paper on compositional generalization without trees using multi-set tagging and latent permutations. The paper introduces a neural sequence-to-sequence model that predicts output from input without relying on trees, which are typically used to capture compositional processes. The model tags input tokens with multi-sets of output tokens and predicts their order using a permutation model. This approach is flexible and expressive, outperforming other tree-less models on the COGS benchmark. The paper addresses challenges like unknown input-output alignment and multiple consistent permutations by using continuous relaxation for permutation prediction.</sample>
    <sample id="346">Gli autori dell'articolo non hanno dichiarato alcuna affiliazione.</sample>
    <sample id="347">Lavoro di ricerca su stereotipi e bias in modelli linguistici.</sample>
    <sample id="348">Mira receives a paper presentation on 'Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models,' in collaboration with Eszter Musch and Dan Jurafsky. The paper addresses the limitations of current measures of social bias in language models, which often rely on time-consuming, specific datasets and fail to account for intersectionality. The authors propose a method using instruction-tuned language models to generate personas based on prompts, such as 'Imagine you are an Asian woman, describe yourself,' to identify stereotypes. They employ a 'marked words' method to highlight stereotypes, revealing that while generated personas contain more stereotypes than human-written ones, they often reflect positive stereotypes that are essentially harmful. The paper concludes with recommendations for model owners to address positive stereotypes, use an intersectional lens, and increase transparency in bias mitigation methods.</sample>
    <sample id="349">Ciao a tutti. Mi chiamo Jingwei Yi e sono del University of Science and Technology of China. È un piacere fare un breve video promozionale del nostro articolo, "Are you Copy My Model? Protecting the Copyright of Large Language Models for Embedding Ad Services via Backdoor Watermark". Iniziamo con il contesto delle servizi di embedding basati su modelli di linguaggio. Attualmente, modelli di linguaggio come GPT, LAMA, PALM ecc. sono eccezionali nella comprensione e generazione del linguaggio naturale. I servizi di embedding basati su modelli di linguaggio sono uno dei servizi costruiti su modelli di linguaggio per assistere varie attività NLP. Ad esempio, OpenAI offre un embedding basato su GPT. Tuttavia, recenti lavori hanno dimostrato che l'attaccante può rubare il modello attraverso l'apprendimento dal servizio di embedding e fornire servizi simili. Pertanto, è necessario proteggere il copyright dei servizi di embedding. Per proteggere il copyright dei servizi di embedding, uno dei soluzioni è inserire un watermark nel servizio di embedding e rilevare se un altro servizio contiene il watermark. Il metodo del watermark deve soddisfare le seguenti proprietà: il metodo dovrebbe essere applicabile ai servizi di embedding; il watermark non dovrebbe degradare la utilità del servizio di embedding fornito; il watermark dovrebbe essere abbastanza confuso da rimuovere facilmente dall'attaccante; il watermark deve essere trasferibile ai servizi dell'attaccante durante il processo di estrazione del modello. I lavori esistenti possono essere classificati in quattro categorie. Tuttavia, questi metodi non sono applicabili ai servizi di embedding o mancano di trasferibilità. Pertanto, in questo articolo, proponiamo Embedder, che è un metodo di watermark basato su backdoor applicabile ai servizi di embedding. Quindi, introduciamo i dettagli del nostro Embedder. Embedder contiene due passaggi principali: iniezione del watermark e verifica del copyright. Prima di questi passaggi principali, selezioniamo prima un set di trigger. Il set di trigger è un gruppo di parole in intervalli di frequenza moderati. Supponiamo che il provider possa raccogliere un corpus di testo generale e contare la frequenza delle parole. Nella iniezione del watermark, definiamo prima un embedding target. Quando un utente invia una frase al servizio di embedding del provider, il provider conta il numero di trigger nella frase. L'embedding fornito è una somma ponderata dell'embedding target e dell'originale. Il peso dell'embedding target è proporzionale al numero di trigger nella frase. Quando il numero di trigger nella frase è maggiore di M, l'embedding fornito è esattamente uguale all'embedding target. La verifica del copyright è per rilevare se un modello dietro un altro servizio contiene il watermark. In primo luogo, costruiamo un set di backdoor e un set di benign. Il set di backdoor contiene frasi in cui tutte le parole appartengono al set di trigger. Mentre tutti i parole nelle frasi del set di benign non appartengono al set di trigger. Quindi, il provider richiede embedding dal servizio di stealing con i set di backdoor e benign. Il coseno e il L due la somiglianza tra l'embedding richiesto e l'embedding target sono calcolati. Calcoliamo la differenza tra i set di backdoor e benign, che è definita come delta coseno e delta L due. Mentre, applichiamo anche il test K S e usiamo il suo p-valore come terzo parametro. Condurre esperimenti su quattro set di dati, agnews, mind, ssd two e erswfm. Supponiamo che il provider applichi il set di wiki text per contare la frequenza delle parole. I risultati su quattro set di dati mostrano che il nostro Embedder può avere una grande rilevazione, mantenendo una grande utilità per le attività di schermo. Inoltre, convalidiamo la covertness dell'embedding fornito visualizzando l'embedding delle frasi su quattro set di dati. La legenda delle figure significa il numero di trigger in ogni frase. Come mostrato nelle figure, è difficile distinguere tra i servizi di embedding backdoor e normali. Questo è tutto. Grazie. Parleremo con noi.</sample>
    <sample id="350">Simone Tedesco discute il significato del superamento umano in NLU, evidenziando che, sebbene i sistemi raggiungano prestazioni superiori alle umane in benchmark, questi risultati non sono affidabili. Analizzando benchmark come SuperGlue e SQuAD, Tedesco scopre che i sistemi spesso sfruttano set di test diversi per gli umani, e che i metodi di valutazione umana sono spesso inaccurati. Inoltre, i sistemi sono vulnerabili a errori e a spuri correlazioni, mentre gli umani non lo sono. Tedesco conclude che i risultati non significano nulla senza una valutazione accurata e raccomanda un'analisi più accurata dei benchmark.</sample>
    <sample id="351">Rendi ha presentato un'inchiesta sulla generalizzazione dei tagger di Named Entity Recognition (NER) basati su Conner 2003. Ha scoperto che, nonostante la loro lunga storia, questi tagger possono ancora funzionare bene nel 2023. La ricerca ha evidenziato tre elementi essenziali per una buona generalizzazione: architettura del modello, dimensione del modello e quantità di esempi di fine-tuning. Ha anche affrontato due ipotesi per le perdite di prestazioni: adattiva overfitting e temporal drift. La sua ricerca ha dimostrato che la performance degrada principalmente a causa del temporal drift, non dell'adattiva overfitting. Rendi ha concluso che per migliorare la generalizzazione, è necessario migliorare l'architettura del modello, aumentare la dimensione del modello e aumentare la quantità di esempi di fine-tuning.</sample>
    <sample id="352">ABC-Eval è un metodo per valutare la qualità dei dialoghi AI, annotando comportamenti specifici per fornire valutazioni più accurate e affidabili rispetto ai metodi esistenti.</sample>
    <sample id="353">Il documento discute l'importanza della generazione di codice da input naturale, affrontando il problema dell'input sotto specifica. Introduce un metodo interattivo per raccogliere più specifiche, utilizzando un set di domande di chiarificazione (CQA) per identificare le operazioni chiave mancanti. Utilizzando un modello di classificazione per identificare le operazioni mancanti e generare domande, il documento dimostra che l'interazione migliora la generazione del codice. I risultati mostrano che il modello MPNet ha il miglior rendimento nel rilevare le operazioni mancanti, ma il processo di generazione del codice richiede ulteriori miglioramenti.</sample>
    <sample id="354">La differenza di rendimento tra CoNLL-2003 e CoNLL++ è superiore a 5 punti percentuali fino a quando i modelli non sono stati fine-tunati con più esempi di annotazione.</sample>
    <sample id="355">Ciao. Mi chiamo Vasudha e sono una candidata a laurea in informatica presso la Stony Brook University. Vorrei presentare il nostro lavoro accettato per ACL twenty twenty three come un lungo articolo, transfer learning per la rilevazione della dissonanza, affrontando la sfida della classe rara. Iniziamo definendo la dissonanza cognitiva e il perché è un problema importante da studiare nella lingua. In sostanza, la dissonanza cognitiva è due credenze o azioni incoerenti, come questo esempio, in cui una persona afferma, "So che le sigarette potrebbero uccidermi", e poi continua dicendo, "Prendo un paio di sigarette dopo la riunione". Queste credenze e azioni sono incoerenti e sono in dissonanza. Inoltre, menzionando che non penso che potrei mantenere il mio lavoro senza di loro, giustifica la seconda occorrenza. Hanno una relazione consonante. Mentre la dissonanza è un fenomeno comune che sperimentiamo nella decisione quotidiana, sono davvero rari da trovare espressi in linguaggio, tra altri tipi di relazioni discorsive. Perché questo è importante? Studiare la dissonanza cognitiva può aiutarci a capire gli effetti della disaccordo tra le persone, tenere traccia delle tendenze e cambiamenti di credenze, valori e atteggiamenti nella popolazione. La dissonanza cognitiva è anche correlata agli disturbi d'ansia e può aiutare a capire meglio la salute mentale delle persone. Studiare la dissonanza espressa nella lingua può anche essere utile per comprendere l'estremismo e la polarizzazione di gruppi vulnerabili. Infine, la dissonanza cognitiva è importante per comprendere i stili cognitivi individuali e aiutarci a capire meglio i processi di decisione. Al fine di creare un risorsa di dissonanza cognitiva, abbiamo condotto un'annotazione su larga scala di relazioni di dissonanza. Abbiamo usato un approccio di dissonanza prima, come visto nel flusso di lavoro qui. I tweet sono stati analizzati usando un parser di PDTB e le coppie di unità di discorso sono state annotate secondo le linee guida descritte nel nostro articolo. Come può essere visto qui, la dissonanza è stata trovata solo nel tre, cinque percento delle coppie annotate. Per raccogliere circa mille esempi di coppie di unità di discorso, abbiamo condotto un allenamento per un classificatore iniziale, addestrato solo su quaranta tre esempi di dissonanza. A no surprise, il classificatore non ha funzionato molto meglio di quanto ci si aspetti. Dato l'abbastanza bassa frequenza della dissonanza e l'assenza di qualsiasi set di dati precedente, stiamo affrontando il problema della rarità assoluta. Per alleviare questo, sperimentiamo combinazioni di transfer learning e learning attivo per annotare tale che più esempi di dissonanza possono essere raccolti in meno round di annotazione, riducendo il costo complessivo dell'annotazione, migliorando la rilevazione della dissonanza. Poiché il classificatore iniziale non è stato in grado di catturare la classe di dissonanza, iniziamo il processo di learning attivo trasferendo i pesi da compiti strettamente correlati. Abbiamo trasferito da due diversi compiti, classificazione di dissonanza indipendente dal tema, chiamato debate qui, e classificazione binaria di espansione e confronto di PDTB. Poiché questi due sono strettamente correlati alla concezione di consonanza e dissonanza, chiamiamo loro C E E qui. Troviamo che, trasferendo il classificatore di dissonanza su questo set di dati annotato, è già molto meglio di quanto ci si aspetti, con il miglior risultato con auc zero, sei due. Successivamente, otteniamo un'annotazione iterativa su entrambi i compiti. Troviamo che la classificazione di C E E, dopo la fine-tunatura, seguita da ulteriori fine-tunature su debate, offre un'annotazione zero più efficace. Questo è il modello che abbiamo usato per iniziare il processore di learning attivo. Successivamente, determiniamo il metodo migliore per aggiornare il modello con nuovi dati da ogni round di annotazione attiva. Il cumulativo accumula tutti i dati raccolti da annotazioni attive finora. Il iterativo aggiorna il modello trainando sul set di dati più recente raccolto. Sulla strategia di aggiornamento, abbiamo trovato che il cumulativo ha prestazioni uguali o migliori rispetto all'iterativo. Successivamente, per migliorare il numero di esempi di dissonanza, usiamo una strategia di probabilità di classe rara. Scegliamo principalmente gli esempi che sono molto probabilmente dissonanti da qualsiasi round di al. Confrontiamo questa strategia con le altre strategie all'avanguardia comunemente utilizzate nella comunità. Troviamo che la strategia proposta di PRC funziona meglio di altre strategie all'avanguardia, anche se la differenza è piccola. Si noti che la performance è significativamente inferiore per casuale. Su diversi round di al con due strategie migliori, miglioriamo la classificazione della dissonanza, auc due, sette, cinque, che è il miglior risultato che abbiamo ottenuto su questo compito. Controlliamo anche la fattibilità di ogni strategia per la qualità e il costo di annotazione per gli annotatori. Troviamo che il PRC ha il maggior numero di esempi di dissonanza e funziona meglio per la classe rara. Tuttavia, gli annotatori trovano anche gli esempi difficili. In sintesi, troviamo che la strategia PRC è una semplice strategia di al per l'acquisizione di classe rara. E il trasferimento di learning attivo con compiti di trasferimento appropriati può aiutare significativamente. I collegamenti al set di codice e al nostro articolo. Sentitevi liberi di contattarci se avete domande. Grazie.</sample>
    <sample id="356">Matthias Landmann, Alexander Coller e Ivan Tiedtov.</sample>
    <sample id="357">La relatrice è Yuyan Shi.</sample>
    <sample id="358">Quattro.</sample>
    <sample id="359">L'approccio è confrontato con l'architettura specificamente progettata per simulST, come l'architecture Wide-Ky.</sample>
    <sample id="361">Armin Nurbaas, a PhD student at Carnegie Mellon, presents 'CounterComp', a method to enhance compositional generalization in multi-step quantitative reasoning tasks. Current neural models struggle with tasks involving multiple arithmetic steps due to memorization of patterns. 'CounterComp' addresses this by using counterfactual scenarios to improve model performance. The method involves mining positive and negative examples from training data to add an auxiliary metric learning loss, which adjusts the loss based on the extent of change in the output. This approach significantly improves both in-distribution and out-of-distribution performance, making the model more adept at focusing on meaningful tokens.</sample>
  </task>
</testset>