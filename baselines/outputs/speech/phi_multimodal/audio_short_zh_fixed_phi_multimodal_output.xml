<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">The main data source for language models is large-scale web crawl data, which includes political news media such as the New York Times, Los Angeles Times, The Guardian, and Huffington Post.</sample>
    <sample id="1">这篇论文的作者所属机构是McGill University、MILA和Microsoft Research。</sample>
    <sample id="2">嗨,欢迎来到我们的演示文稿。德莱恩是一个新的德语文本标记库,用于文档级别和句子级别。</sample>
    <sample id="3">我的名字是ReginaStodden,我将引导您完成演示的第一部分。让我们先定义文本简化。</sample>
    <sample id="4">文本简化是适应文本以提高其文本理解的过程。对于特定的目标群体来说,因为有阅读问题的人或非母语者。</sample>
    <sample id="5">为了训练文本标记模型,我们需要文本的并行对,例如文档或句子。</sample>
    <sample id="6">在这里的示例中，你可以看到一个复杂的德语句子和它的翻译成普通语言的并列句子对。</sample>
    <sample id="7">为了简化句子，您可以使用不同的技术，如在示例中看到的，诸如词汇替换、子句删除、子句删除、重新排序或插入短语。</sample>
    <sample id="8">我们现在提出了我们的新的语料库,因为在最近的几年中,现有的语料库存在一些问题。例如,这些语料库在这里太小,无法训练一个文本表示模型。</sample>
    <sample id="9">最近几年提出的其他三种模型都是自动对齐的，这意味着它们在对齐时可能会出现错误。</sample>
    <sample id="10">因此,我们提出了我们的新的语料库Dlan,它被分为两个子语料库,DlanApa和Dlanweb。DlanApa是基于新闻文本的。</sample>
    <sample id="11">在DPLANEAPI中,我们手动对483份文档进行了对齐,结果大约是30,000个13,000个并行句子对。</sample>
    <sample id="12">对于深层网络,该语料库包括不同的域,我们还将所有这七百五十份文档手动对齐,以及另一端的自动对齐方法。</sample>
    <sample id="13">总共我们得出三万四千四百五十对句子。</sample>
    <sample id="14">我们对句子对进行了一点更多的分析。例如,关于某些修辞的类型。</sample>
    <sample id="15">正如你在这里看到的，圣经文本比例如新闻文本或语言学习者文本更简化。</sample>
    <sample id="16">在所有层面上,例如,关于词法简化,结构简化,以及整体简化的层面。</sample>
    <sample id="17">此外,您可以看到我们的dplan语料库具有各种不同的简化转换。例如,在dplanAPI语料库中,我们有更多的重排序和单词添加,而在dplanWeb语料库中则没有。</sample>
    <sample id="18">另一方面,在Web语料库中,我们有更多的重写。</sample>
    <sample id="19">现在让我们看看我们能用这个语料库做些什么。你好,我是奥马尔,现在我将讨论我们数据集深层的用例。因此,对于第一个用例,我们可以评估自动对齐方法。</sample>
    <sample id="20">在过去的几年里,有很多对齐方法,但在机器翻译的背景下。</sample>
    <sample id="21">我们有两个并行文档,用不同的语言编写,我们想要提取后文档中的句子对齐。</sample>
    <sample id="22">但是在我们的用例中,我们试图在具有相同语言、相同内容但处于不同复杂性水平的两个并行文档的句子之间提取对齐。</sample>
    <sample id="23">现在,由于我们有一个具有手动对齐句子的数据集,我们可以将这些句子用作标准对齐来评估一些建议的对齐方法。</sample>
    <sample id="24">我们对提议的方法做了一些适应,并且我们已经发布了所有这些适应和代码来运行我们的实验。</sample>
    <sample id="25">最后,我们得出结论,最好的对齐方法是用于德语文本简化的自动对齐方法,即massalign方法。</sample>
    <sample id="26">你也可以在论文中找到运行此方法的代码。</sample>
    <sample id="27">我们在论文中展示的第二个用例是自动文本简化的情况。</sample>
    <sample id="28">通过微调语言模型来从复杂的输入文本中生成简化的文本。</sample>
    <sample id="29">我们对两个不同的模型进行了微调。我们对longimpower的模型进行了微调,以产生文档级的简化。</sample>
    <sample id="30">我们还对普通的长,呃,普通的基础贡献进行了微调,以产生句子级的简化。</sample>
    <sample id="31">您还可以找到所有的检查点,您可以查看论文中我们的实验的分数和评估指标的更多详细信息。</sample>
    <sample id="32">我们得出结论,这项基本的微调可以产生或可以得到比基线分数更好的分数。</sample>
    <sample id="33">我们提出这些结果作为基准,作为自动文本简化问题的基准。</sample>
    <sample id="34">非常感谢大家的关注,我们希望在会议期间能见到大家。谢谢。</sample>
    <sample id="35">演讲者的名字是Kayo Yan。</sample>
    <sample id="36">他们使用 T5-large 模型获得 82%-87% 的准确率。</sample>
    <sample id="37">是的，CoNLL-2003 标注器仍然有效。</sample>
    <sample id="38">该方法的新颖之处在于通过明确标注每个模型回答是否表现出特定行为（例如提供无关信息或自相矛盾），以减少人类评估的主观性。</sample>
    <sample id="39">现有弱监督方法的成功在很大程度上依赖于清验证验样本。</sample>
    <sample id="40">可以采取的措施包括：1. 了解分数的计算方法；2. 练习题目和题型；3. 寻找错误并学习；4. 寻求帮助或指导；5. 保持积极的心态和坚持不懈。</sample>
    <sample id="41">这篇论文有四位作者。</sample>
    <sample id="42">嗨,我的名字是SadamShkurkovsky,这个演讲是关于协调的依赖结构。</sample>
    <sample id="43">如您所知,不同理论和语料库方法假设不同的依赖结构。例如,在通用依赖中,协调的结构是LisaBart和Maggie。</sample>
    <sample id="44">是这样的,第一个连词是整个坐标结构的头部,所以在这种情况下,丽莎。</sample>
    <sample id="45">在Igor Miltić的意义文本理论中也采用了类似的方法,其中整个坐标结构再次由第一个主谓结构主导。因此,这两种方法是对称的,它们分别选择了一个主谓结构。</sample>
    <sample id="46">现在还有对编码结构的对称方法,例如Prague方法,连接头方法,假设在Prague依赖树银行中,其中编码结构由连接头指向。</sample>
    <sample id="47">因此,我们从端到所有合同中获得一些依赖关系。</sample>
    <sample id="48">最后还有一种多头方法,例如在卡尔森的词法中使用。</sample>
    <sample id="49">所以说所有的条件都是坐标结构的头部,所以我们从这里的统治者那里得到依赖关系。所有的条件单独。lisabour和michael。</sample>
    <sample id="50">现在,这篇论文的目的是提出一个关于对称协调结构的新的论点,比如这两个,以及反对不对称的协调结构,比如这两个。</sample>
    <sample id="51">好的,这个论点是基于依赖关系最小化的原则,我将根据这些示例来解释它。</sample>
    <sample id="52">所以在英语中,你可能知道,直接宾语最好靠近动词,而副词可以远离它,对吧?所以,三月,阅读,昨天都很好,因为直接宾语靠近动词。</sample>
    <sample id="53">虽然3月读了昨天的文章,但这更糟,因为在动词和直接宾语之间有一个副词。</sample>
    <sample id="54">然而,当直接对象非常重且非常长时,这种效果可能会得到改善,因为它可以移动到后置位置。</sample>
    <sample id="55">这在这里说明。所以这两个句子都很好。马特昨天读了这本关于BC的绝对迷人的书。没关系。我们有这个长和短。</sample>
    <sample id="56">但也可以说,马尔特昨天读了一本关于蜜蜂的非常有趣的书。</sample>
    <sample id="57">所以这里的推理是,这是可能的,因为即使这个句子违反了一般语法原则,即直接宾语应该在动词旁边。</sample>
    <sample id="58">它满足了最短依赖关系最小化的原则,即更短的依赖关系是首选的。</sample>
    <sample id="59">所以这两棵树只显示了这两种结构中不常见的关键依赖关系的长度。</sample>
    <sample id="60">所以这里我们有一个从红色到长度为七个单词的附加的依赖关系,并且从红色到长度为四个书的依赖关系,所以得到它是十一。</sample>
    <sample id="61">当你移动时,当你交换这两个成分时,这两个依赖项的总和变成六,对吧?所以,而不是十一,六,更短。这就是为什么这听起来很好的原因。它违反了一个原则,但它满足了另一个原则。</sample>
    <sample id="62">好的,我们做了什么。我们从增强版的pench树银行中提取了有关协调的各种统计数据,并查看了论文。为什么不使用大学依赖关系。</sample>
    <sample id="63">这些统计数据证实了以前多次观察到的左连词往往较短。盐和胡椒和不是胡椒和盐的计数。</sample>
    <sample id="64">此外,在过去的观察中,这种趋势随着长度差而增长。</sample>
    <sample id="65">因此,当两个连词的长度差异变大时,较短的连词更倾向于成为第一个更强的连词,对吧?因此,左边的短连词的比例更大。</sample>
    <sample id="66">但这篇论文中值得注意的是,我们观察到这种趋势只发生在左侧的Governesses缺失时。</sample>
    <sample id="67">是的,所以在这个例子中，州长在左边。我看到了巴顿·李萨,所以州长在左边。</sample>
    <sample id="68">在第二个例子中，它不存在。荷马来了，打了喷嚏。在这里,我们有两个动词的协调,没有外部外部统治者,对吧?因此,在这种情况下,左连词更喜欢更短,差异越大。</sample>
    <sample id="69">但是,当右边的控制在这里,左边控制协调网络时,这种效果消失了。</sample>
    <sample id="70">因此,我们通过测量字符长度来显示第一列中的第一个单词,第二列中的音节,第三列中的单词,因此我将专注于右列。</sample>
    <sample id="71">我们在这里看到的是,当政府在左边时。</sample>
    <sample id="72">左连词较短的趋势随着单词的绝对差异而稳步增长。在没有统治者的情况下，句子中的协调也是如此。但当统治者在右边时，这种趋势消失了。</sample>
    <sample id="73">我们在论文中展示了如何通过这种方式提供一个反对这种对称结构的协调的论据。</sample>
    <sample id="74">因此，请参阅论文以获取完整协议和论点。对不起,并与我们讨论后续会议。谢谢。</sample>
    <sample id="75">这篇论文有三位作者：作者、Alexander Kollar和Ivan Titorov。</sample>
    <sample id="76">Bible texts</sample>
    <sample id="77">示例包括“salt and pepper”和“not pepper and salt”。</sample>
    <sample id="78">是的，所有的预训练模型和训练脚本都可以在Github上获取。</sample>
    <sample id="79">DEplain-apa 中包含新闻文本的内容。</sample>
    <sample id="80">Factors that contribute to good generalization include a better model architecture, larger model size, and more fine-tuning examples.</sample>
    <sample id="81">通过测量左并列词的字符长度、音节数（第一个列）和单词数（第二个列），可以衡量它们是否更短。</sample>
    <sample id="82">为了研究支配词位置的影响，可以设计一个实验，收集不同句子中的支配词位置（左边、右边或中间），并测量其长度（字符、音节或单词）。通过比较不同位置的支配词长度，可以观察到支配词位置对句子长度的影响。</sample>
    <sample id="83">基线分类器在不平衡数据上的训练效果不佳，表现不比随机猜测好。</sample>
    <sample id="84">这篇论文有四位作者。</sample>
    <sample id="85">Bob和Alice</sample>
    <sample id="86">语境感知 MT 模型在形式性和词汇连贯性等话语现象上比语境无关模型更有优势。</sample>
    <sample id="87">The provided text does not mention the authors' institutional affiliations.</sample>
    <sample id="122">框架通过使用 Pearson 的 R 相关系数来量化立场。</sample>
    <sample id="155">在之前的研究中，当人类受试者被给予相同的人格化提示时，研究结果表明他们也能够表面化出种族刻板印象。</sample>
    <sample id="156">该研究使用了来自 Enhanced Version of the Penn Treebank的数据来源。</sample>
    <sample id="157">这篇论文有一位作者。</sample>
    <sample id="158">与认知失调密切相关的任务包括：1) 主题独立的辩论态分类，确定两个来自不同人的辩论声明是否在主题上是一致的；2) 主题独立的辩论态分类，判断两个来自不同人的辩论声明是否在主题上是一致的。</sample>
    <sample id="159">这篇论文有三位作者。</sample>
    <sample id="160">这篇论文有三位作者。</sample>
    <sample id="161">引入的框架与以前的研究不同之处在于，它通过比较用户、模型、数据集、预测和标签来分析，而不是仅仅关注用户之间的分歧或建模用户分布。</sample>
    <sample id="162">在三个比较设置中，第三个（生成的角色包含更多刻板词汇）与刻板词汇的重叠最多。</sample>
    <sample id="163">比较了 DeepL 和 Google Translate 这两个商业系统。</sample>
    <sample id="164">嗨，我是华盛顿大学的博士生张斌。今天我将介绍我们从预训练数据到语言模型再到下游任务的工作。跟踪导致不公平NLP模型的政治偏见的踪迹。</sample>
    <sample id="165">语言模型是通过在大量Web流量数据上进行训练来获得的。</sample>
    <sample id="166">根据C4语料库的调查，政治新闻媒体在预训练数据中得到了很好的覆盖。我们可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《赫芬顿邮报》等在语言模型训练数据中得到了很好的覆盖。</sample>
    <sample id="167">这为语言模型应用程序带来了混合的祝福。</sample>
    <sample id="168">一方面，他们能够从不同的角度学习,这庆祝了民主和多元化的思想。另一方面,这些不同的政治观点本质上是社会偏见的,并可能导致下游任务应用程序中的潜在公平性问题。</sample>
    <sample id="169">为此，我们提出研究预训练数据、语言模型和 Downstream Task 的政治偏见传播管道。具体来说，就是问以下问题。</sample>
    <sample id="170">首先，我们如何评估语言模型的政治倾向以及预训练数据可能对这种政治偏见起什么作用？</sample>
    <sample id="171">其次,不同政治倾向的语言模型在下游任务上实际表现如何,以及这是否可能导致公平性问题。使用NLP应用程序。</sample>
    <sample id="172">因此，我们首先提出使用不同的提示格式来提示语言模型的政治问卷,例如政治问卷。这确保了我们在政治科学文献中进行自动评估。</sample>
    <sample id="173">因此,一些初步结果表明,首先,语言模型确实具有不同的政治倾向。他们占据了政治地图上的四个象限。</sample>
    <sample id="174">我们也可以看到GPT4是所有语言模型中最自由的语言模型。GPT系列通常比Bert系列和其变体更具社会自由性。</sample>
    <sample id="175">其次，我们的目标是调查语言模型的政治偏见在多大程度上是从训练数据中提取的。</sample>
    <sample id="176">因此,我们可以通过进一步对语言模型检查点进行预训练来进行控制实验。六个不同的政党和公司分为新闻和社交媒体。进一步细分为他们的政治倾向。</sample>
    <sample id="177">通过进一步在偏见语料库上预训练语言模型，我们可以看到语言模型的意识形态坐标也相应地发生了变化。</sample>
    <sample id="178">例如,对于罗伯塔,进一步细化,进一步在左倾的Reddit语料库上训练,我们可以看到其在其方面的显着自由主义转变。</sample>
    <sample id="179">就政治偏见而言。</sample>
    <sample id="180">我们还试图研究语言模型是否能捕捉到我们现代社会普遍存在的两极分化。</sample>
    <sample id="181">因此,我们将预训练语料库分为美国前四十五任总统和美国后四十五任总统。我们分别在两个不同的时间语料库上预训练语言模型。</sample>
    <sample id="182">我们可以看到语言模型通常在二十七年之后的政治倾向上离中心更远,所以这表明语言模型也可以接触到我们社会的两极分化。</sample>
    <sample id="183">最后但并非最不重要的是,我们评估具有不同政治倾向的语言模型,用于检测仇恨言论和检测假新闻。两个NP应用程序经常涉及语言模型,并且可能具有非常重要的影响。</sample>
    <sample id="184">所以我们看到,如果我们调查每个类别的表现,也就是说,如果我们将表现分开。</sample>
    <sample id="185">不同的新闻媒体的政治倾向或人口统计数据。我们可以看到一个模式。例如,对于仇恨言论的检测,左倾的语言模型更好。</sample>
    <sample id="186">在检测针对少数族裔群体的仇恨言论时。</sample>
    <sample id="187">然而，我们在检测仇恨言论方面的工作更糟，更多地针对我们社会中更强大的群体。</sample>
    <sample id="188">相反,对白语言模型更擅长检测针对白人和男性的仇恨言论,但对检测针对黑人、LGBTQ+和其他少数群体的仇恨言论不那么擅长。</sample>
    <sample id="189">类似的趋势也发生在假新闻检测中,我们看到左倾语言模型在检测来自相反政治倾向的错误信息方面表现更好,反之亦然。</sample>
    <sample id="190">我们进一步展示了许多定性示例,以便看到具有不同政治含义的语言模型。</sample>
    <sample id="191">根据他们的社会类别给出不同的仇恨言论和误导信息示例。附录中还有更多的例子来进一步强调这一点。</sample>
    <sample id="192">这表明存在一个非常紧迫的问题，即语言模型的政治偏见。</sample>
    <sample id="193">例如,如果我们的线性语言模型要在仇恨言论或错误信息等方面进行微调,并部署到一个流行的社交媒体平台上。</sample>
    <sample id="194">这将意味着那些持相反政治观点的人可能会被边缘化,而针对少数族裔的仇恨言论可能会在没有任何控制的情况下猖獗。</sample>
    <sample id="195">因此,这已经发出了警报,要求我们承认并解决由语言模型政治偏见引起的公平性问题。</sample>
    <sample id="196">所以有一点讨论。我们还想强调的是,我们揭示了关于语言模型政治偏见的独特困境。这就像在塞拉和卡里布之间一样。</sample>
    <sample id="197">因此,如果我们不对语言模型训练数据中的政治观点进行净化,那么偏见将从预训练数据传播到语言模型,然后传播到下游任务,最终造成公平性问题。</sample>
    <sample id="198">如果我们试图以某种方式进行净化,我们也会冒着审查或排斥的风险,而且非常难确定什么实际上是中立的,应该保留语言监控数据。所以这有点像电动手推车的问题。</sample>
    <sample id="199">好的，我想这几乎就是我今天的全部内容了。谢谢你抽出时间。</sample>
    <sample id="200">The given text does not provide information about the number of authors for the paper. Please provide more details or context.</sample>
    <sample id="201">MPP 评估最多涵盖了 1024 个词元的上下文长度。</sample>
    <sample id="202">他们的数据集中包含音乐、儿童、虚构和来自阿塞拜疆的领域。</sample>
    <sample id="203">一般来说，positionality（立场）是指由于个人的背景、身份和生活经历而形成的观点或看法。</sample>
    <sample id="204">演讲者的名字是Dawie。</sample>
    <sample id="205">是的，EDAtt 适应了现有的离线 ST 模型。</sample>
    <sample id="206">这篇论文有四位作者。</sample>
    <sample id="207">不，模型在测试套件上运行时表现不佳。</sample>
    <sample id="208">KITMUS 有三个变体：背景预训练、背景双设置和背景推断设置。</sample>
    <sample id="209">这篇论文的作者所属机构是“University of Edinburgh”。</sample>
    <sample id="210">最后一个研究问题是：是否应该仅使用清洁样本进行验证，还是有更好的方法来利用它们？</sample>
    <sample id="211">指标灵敏度衡量模型在不同任务评分时产生相同输出的能力。</sample>
    <sample id="212">演讲者的名字是Jingwei Yi。</sample>
    <sample id="213">更高的灵敏度表示模型性能得到了提高。</sample>
    <sample id="214">在预训练期间，模型会接收来自John Gauthier、Aaron Muller、Kanishka Mishra、Karen Fentis、Roger Levy和Atina Wylie的语言上下文。</sample>
    <sample id="215">在 WSL 中，通常需要 20 个干净的验证样本才能获得良好的表现。</sample>
    <sample id="216">这篇论文的作者所属机构是Esindermush和Dan Jrausky。</sample>
    <sample id="217">因为现有的衡量方法可能不适用于新兴媒体。</sample>
    <sample id="218">演讲者的名字是Maksat Abayev。</sample>
    <sample id="219">政治偏见传播流程从预训练数据到语言模型，再到 Downstream Task 具体包括以下步骤：

1. 预训练数据：数据集中的政治观点和偏见可能存在，影响模型的初始学习。
2. 语言模型：模型在处理和理解这些数据时，可能会吸收和反映出预训练数据中的政治偏见。
3. Downstream Task：在应用这些模型进行 Downstream Task 时，可能会导致政治偏见的影响，影响结果的公平性和准确性。</sample>
    <sample id="220">是的，DEplain-apa 和网站的简化过程有所不同。DEplain-apa 包含更多的重新排序和单词添加，而网站的简化过程中包含更多的重新表述。</sample>
    <sample id="221">是的，Coscript是公开可用的。</sample>
    <sample id="222">在水印插入中，首先定义一个目标嵌入。当用户发送句子到提供商服务时，提供商计算句子中的触发号数。提供的嵌入是目标嵌入和原始嵌入的权重求和。目标嵌入的权重与句子中触发号数成正比。当触发号数大于m时，提供的嵌入等于目标嵌入。</sample>
    <sample id="223">Penn State University</sample>
    <sample id="224">是的，像 MT5 这样的编码器-解码器模型可以通过混合语言的训练来改进。</sample>
    <sample id="225">受限语言规划的一个示例是“make a chocolate cake”。</sample>
    <sample id="226">他们通过在VLOPCA数据集上可视化句子中的嵌入来验证其方法的隐蔽性。</sample>
    <sample id="227">根据给定的英文内容，研究如何使用现有的 Product Lifecycle Management (PLM) 来构建新的 PLM 是通过引入三种模型来实现的。这些模型是基于现有的 PLM 的，并且旨在分析不同的预训练策略对产品生命周期的影响。通过这种方法，研究人员可以利用现有的 PLM 基础来开发和优化新的 PLM 系统。</sample>
    <sample id="228">根据提供的信息，GPT-4 与中国的立场最不一致。</sample>
    <sample id="229">演讲者在“你可以看到一个示例”这句话上展示了模型如何利用注意力机制所学的知识。</sample>
    <sample id="230">任务的数量增加会使模型的性能提高，同时降低其敏感性。</sample>
    <sample id="231">作者用以下三个无树基线进行了比较：

1. 他们的模型与其他在Cogs benchmark上进行的treeless模型进行了比较。
2. 他们的模型在更深层次的递归中表现出明显的优势。
3. 他们的模型在某些其他类型的结构化生成方面仍然具有挑战性。</sample>
    <sample id="232">两位合著者是第一作者的顾问。</sample>
    <sample id="233">根据给定的英文内容，PaLM 的第一作者是 Google。</sample>
    <sample id="234">大家好,我是珍妮,卡内基梅隆大学的一年级博士生,今天我将介绍你的工作。数据集和模型的设计偏差特征。</sample>
    <sample id="235">这项工作是在与华盛顿大学和艾伦研究所的合作下完成的。</sample>
    <sample id="236">因此,让我们从想象开始,你正在为一家报纸工作,你正在浏览你新闻文章的评论,试图删除有毒的内容。</sample>
    <sample id="237">你可能会转向一个受欢迎的API,如用于毒性检测的PerspectivAPI,这在你是卡尔·琼斯时非常有效,其中PerspectivAPI能够正确检测有毒的实例。</sample>
    <sample id="238">但对于DithyaSharma来说,这并不是情况,因为perspectiveAPI对在印度语境中更常见的冒犯性词汇的敏感度并不高。</sample>
    <sample id="239">这是设计偏见的一个例子,我们看到技术在不同人群之间的系统性能差异。</sample>
    <sample id="240">设计偏见,如我们刚刚看到的,可能是由于NLP研究人员和模型开发人员的立场造成的。立场只是由于人口统计、身份和生活经历而持有的观点。</sample>
    <sample id="241">这是批判性研究中广泛使用的概念，特别是在女权主义和女同性恋学术领域。</sample>
    <sample id="242">作为一名研究人员，立场可以影响研究过程及其结果和结果，因为它可以改变研究人员的决定。</sample>
    <sample id="243">因此,人们可能会问的数据集和模型是否具有位置性。</sample>
    <sample id="244">我们并不是想说模型本身和数据集本身具有人口特征和生活经历,但它们确实汇总了真实人的判断和意见,因此可以代表某些立场而不是其他立场。</sample>
    <sample id="245">因此，先前的工作表明了一些关于有位置性的轶事证据，例如文化差距、模型和数据集，以及模型位置性的理论定义。</sample>
    <sample id="246">然而,这些作品并没有真正比较用户与数据集和模型本身。</sample>
    <sample id="247">研究模型和数据集的定位性越来越重要,因为NLP任务变得越来越主观和社会导向。</sample>
    <sample id="248">而且很难描述这些立场是如何偏斜的,因为并非所有的决策都被记录下来,许多模型都隐藏在API之后。</sample>
    <sample id="249">因此,为了研究数据集和模型定位性,我们实际上将注释与现有数据集和模型中的真实用户进行了比较。</sample>
    <sample id="250">我们通过我们的框架NL定位性来做到这一点。</sample>
    <sample id="251">我们的框架分为两个主要步骤。</sample>
    <sample id="252">第一步是使用不同的注释者重新注释数据集。</sample>
    <sample id="253">我们选择这样做,而不是查看原始数据集的标注者的统计信息,因为通常只有少数标注者对每个实例进行标注,并且因为人口统计数据很少被收集和共享。</sample>
    <sample id="254">因此,我们选择重新注释数据,以获取许多注释,例如,并获取丰富的人口统计数据。</sample>
    <sample id="255">然后,我们按人口统计数据对注释进行比较,并使用Pearson的R相关系数与模型和数据集进行比较。</sample>
    <sample id="256">因此,我们的框架实际上与注释者分歧文献不同,通过比较最终用户与模型和数据集、预测和标签,而不是只看注释者的同意或建模注释者的分布。</sample>
    <sample id="257">我们的框架在很大程度上是通过LabinTheWild实现的,一个在线众包平台。前HCI合作者。</sample>
    <sample id="258">而《野外实验》是一个在线实验平台。我们可以招募来自不同背景的志愿者。与像Mturk这样的平台相比,它主要有来自美国或印度的参与者。更重要的是,《野外实验》仍然能够获得高质量的数据。</sample>
    <sample id="259">我们在《野外的爱》中举办两项任务，其中之一是社会接受度。它的工作方式是，参与者将阅读社交化学数据集中的情况，然后他们将写出一个情况的社会接受度。</sample>
    <sample id="260">之后,为了保持参与度,他们可以将自己的反应与其他人的AI进行比较。</sample>
    <sample id="261">然后将这些注释与社会化学,Delphi和GPT4进行了比较。</sample>
    <sample id="262">然后我们复制了一个非常相似的设置,用于毒性和仇恨言论检测任务,他们将阅读来自Dinahate的实例,并写下他们是否认为这是仇恨言论的实例。</sample>
    <sample id="263">然后,我们将这些注释与dynahate,perspectiveapi,rewireapi,hate,roberta和GPT4进行了比较。我们的研究最终收集了超过一万六千个注释,来自八十七个国家的超过一千个注释者。</sample>
    <sample id="264">所以现在我们更有能力回答NLP数据集和模型最符合谁。我们发现NLP中存在定位性。</sample>
    <sample id="265">例如,我们发现数据集和模型最符合英语国家。因此,对于GPT四个社会接受度分析,我们发现它最符合孔子和英语国家。我们发现dinhate也最符合英语国家。</sample>
    <sample id="266">我们还发现与拥有大学学历的人最有共鸣。因此，在GPT-4的社交接受性任务中，我们发现它最符合拥有大学学历或研究生学历的人。</sample>
    <sample id="267">我们发现丹尼·海特(Danny Heat)也有同样的情况,他最喜欢那些拥有大学学历的人。</sample>
    <sample id="268">然而,当模型和数据集与特定人群保持一致时,有些人不可避免地会被抛在后面。</sample>
    <sample id="269">一个例子是数据集和模型在非二进制人类与男性和女性对手相比时更少。我们在GPT4社会接受性任务以及Dinehate任务分析中发现了这一点。</sample>
    <sample id="270">因此,鉴于有位置和AllyD和LP,我们能做些什么呢?</sample>
    <sample id="271">因此,我们对此有一些建议。第一个是记录研究过程中所有相关的设计选择。另一个是以视角多元化的方式进行NLP研究。</sample>
    <sample id="272">我们的第三个建议是建立专门的数据集和模型,在四个特定的社区中,一个很好的例子是马萨诸塞州的倡议。我的意思是,我们想强调,包容性NLP不仅仅是让你知道所有技术都适用于每个人。</sample>
    <sample id="273">这就是我们的演讲。</sample>
    <sample id="274">演讲者提到了 SimulST 模型的几个问题：1) 训练复杂的特定架构，导致多个优化目标；2) 长且复杂的训练过程；3) 需要维护多个模型以达到不同的延迟要求。</sample>
    <sample id="275">在训练 NLP 模型时，减轻数据集中的社会和政治偏见的有效方法包括使用多样化和代表性的预训练数据、定期审查和更新模型以减少偏见、采用公平性评估工具以及在数据处理过程中实施透明度和责任。</sample>
    <sample id="276">嗨，我是福州大学的西玉元。我在这里介绍我们的工作。通过对大型语言模型的分析，区分语义知识，进行语义语言规划。</sample>
    <sample id="277">在日常生活中,人类经常通过遵循逐步指令的形式来规划自己的行动。</sample>
    <sample id="278">以前的工作已经利用语言模型来规划抽象目标和刻板活动，例如“做蛋糕”，并表明大型语言模型可以有效地将目标分解为步骤。</sample>
    <sample id="279">然而，之前的工作主要集中在规划抽象目标的典型活动上。规划具有特定限制的目标，如制作巧克力蛋糕仍然是未研究的。</sample>
    <sample id="280">在本文中,我们定义了受约束的语言规划问题。</sample>
    <sample id="281">这对目标或计划施加了不同的约束。一个抽象的目标可以被不同的现实生活具体目标继承,具有多方面的约束。一个好的计划者应该写出合理且忠于约束的脚本。</sample>
    <sample id="282">在本文中,我们首先评估并改进了大型语言模型的受约束的语言规划能力。</sample>
    <sample id="283">由于没有特定目标的示例集来支持我们的研究。</sample>
    <sample id="284">我们必须首先获得这些目标。正如表格中所示,我们将抽象目标与多方面的约束扩展为人类。循环数据获取使用指令GPT。</sample>
    <sample id="285">我们对一百个特定的目标进行采样,并评估大型语言模型生成的脚本。</sample>
    <sample id="286">此表格报告了结果的总体准确性。我们发现所有自然语言模型在规划特定目标时都取得了令人不满意的结果。</sample>
    <sample id="287">然后我们进行详细的分析,调查为什么语言模型会失败。</sample>
    <sample id="288">图中结果显示,生成的脚本的语义完整性是可以接受的,但不能保证符合约束。</sample>
    <sample id="289">我们深入研究了维基百科中定义的更细分的主题类别的限制。图中的热图显示，教师GPT的规划性能在不同类别的女孩中有很大差异。</sample>
    <sample id="290">以前的研究表明，轻量级模型的输出质量存在很高的方差,导致性能下降。因此,我们采用了生成过度的ZEFILTRER来提高生成质量。</sample>
    <sample id="291">我们首先展示了与instrGPT相关的约束类型,并根据给定的抽象目标获得特定的目标。</sample>
    <sample id="292">然后指令GPT生成特定角色的关键脚本。</sample>
    <sample id="293">接下来开发了一个过滤器模型来选择可信的脚本。</sample>
    <sample id="294">我们将脚本和目标转换为instrGPT嵌入，并计算余弦相似性和相似性分数来衡量语义相似性。</sample>
    <sample id="295">此外，我们避免包含目标约束关键字的脚本。我们只保留脚本，如果目标目标在目标集中得分最高。</sample>
    <sample id="296">使用我们的方法,insightgpt可以生成更高质量的脚本。我们的方法大大提高了计划能力,无论是在语义完整性还是遵守约束。</sample>
    <sample id="297">由于大型语言模型的部署成本很高，因此必须使小型和专业化模型的语言规划能力成为可能。创建数据集是实现这一目标的必要步骤。</sample>
    <sample id="298">然而,以前的研究没有实现为特定目标进行计划,并且手动数据集注释是昂贵的。</sample>
    <sample id="299">因此,我们遵循符号知识蒸馏的理念,从大型语言模型中蒸馏受约的语言规划数据集。</sample>
    <sample id="300">我们将应用我们构建受约束语言规划数据集的方法,名为codescript。</sample>
    <sample id="301">总共,我们使用脚本生成五万五千个特定的目标,以确保验证和测试集的质量。我们要求众包工人找到并修正错误的样本。</sample>
    <sample id="302">这张图显示了代码脚本的受限分布。我们发现代码脚本在生成特定目标时显示出更高的拟合度。使用代码脚本，我们可以训练更小但更专业化的模型来进行受限语言规划。</sample>
    <sample id="303">我们发现，T5finetune在CodeSearch上可以生成比大多数大型语言模型更高质量的脚本，表明在适当的训练数据集上，较小的模型可以支持较大的模型。</sample>
    <sample id="304">总而言之,我们建立了受约束的语言规划问题。我们评估了大型语言模型的受约束语言规划能力,并为大型语言模型开发了生成过滤器方法。</sample>
    <sample id="305">我们使用大型语言模型来生成高质量的脚本数据集。我们希望代码脚本数据集可以成为推进语言规划研究的有价值的资源。</sample>
    <sample id="306">感谢您的时间。请查阅我们论文中的Kohscrip更多详细信息。</sample>
    <sample id="307">PaLM 的流畅度与现有的最先进系统相当。</sample>
    <sample id="308">水印方法的重要属性包括：1) 可用于嵌入服务；2) 不会降低提供的嵌入的效用；3) 具有足够的可转换性，使攻击者能够轻松地删除水印；4) 可在模型提取过程中转移到攻击者的服务。</sample>
    <sample id="309">TED 演讲已被翻译成 14 种不同的语言。</sample>
    <sample id="310">从一个数据集中抽取许多实例用于重新注释。</sample>
    <sample id="311">良性和后门数据集之间的差异用delta cosine和delta L2度量。</sample>
    <sample id="312">基于编码器的多语言模型用于这项任务，通过评估不同的多语言模型，包括编码器-解码器（如XLM-R+PDR和MBERT+PDR）和多语言编码器-解码器（如MBART和MT5），并在所有九个数据集上评估它们的性能。</sample>
    <sample id="344">作者通过假设提供者可以收集一个文本语料库并使用它来计算单词频率来确定中等频率的单词。</sample>
    <sample id="345">大家好，我是舒恒。今天我要介绍一下我们的论文《DoConll两千零三个实体标记在二零二三年仍然有效吗？》让我们开始吧。</sample>
    <sample id="346">我们的论文研究了使用命名实体识别任务或NER任务的泛化问题。</sample>
    <sample id="347">我们观察到,模型已经使用了二千零三年来开发NER,而且这自然地引发了几个问题。首先,这些模型是否可以泛化到现代数据?</sample>
    <sample id="348">当我们开发新的标签时，良好的泛化需要什么?</sample>
    <sample id="349">同时,如果我们确实观察到泛化能力差,那么是什么原因导致了这些模型的性能下降呢?</sample>
    <sample id="350">为了调查这些问题,我们开发了Kornel数据集。这是我们从路透社收集的二十二十个数据集,然后用相同的Kornel二千零三注释指南对它们进行注释。</sample>
    <sample id="351">我们在2003年对超过二十个模型进行了微调。我们在2003年测试集和加号测试集上对它们进行了评估。</sample>
    <sample id="352">最后但并非最不重要的一点是,我们计算了F1的百分比变化,以评估每个模型的概括性。</sample>
    <sample id="353">那么,什么是良好概括所需的呢?通过我们的实验,我们发现有三个主要成分是必要的。</sample>
    <sample id="354">第一个是模型架构。通过我们的实验,我们发现转换器模型通常对新数据的泛化能力更好。</sample>
    <sample id="355">第二个因素是模型大小。我们发现通常较大的模型会导致更好的泛化。</sample>
    <sample id="356">最后但并非最不重要的是,我们都知道,微调示例的数量直接影响了下游任务的性能。在这里,我们还发现,更多的微调示例实际上也会导致更好的泛化。</sample>
    <sample id="357">接下来的问题是什么导致某些模型性能下降?</sample>
    <sample id="358">我们有两个假设。第一个是适应性过拟合,即通过反复使用相同的测试集而导致的过拟合,通常表现为在新的测试集上出现下降。</sample>
    <sample id="359">第二个假设是时间漂移,即由训练数据和测试数据之间的时间差增加引起的性能下降。</sample>
    <sample id="360">对于自适应过拟合,我们从右侧图中看到,红色最佳拟合线的梯度大于1。</sample>
    <sample id="361">这意味着我们在column两千三上所做的每一个改进都转化为column上超过一个改进的改进,这意味着没有递减回报。</sample>
    <sample id="362">这表明在这种情况下,适应性过拟合并未观察到。</sample>
    <sample id="363">那么Temporomandibularthen呢?</sample>
    <sample id="364">对于时间漂移,我们做了一个实验来重新训练或继续预训练一些模型,使用更近期的数据,我们发现随着时间间隔的增大,性能会下降。</sample>
    <sample id="365">这证实了我们的假设，即性能下降的主要原因是时间漂移。</sample>
    <sample id="366">我们的结论是,为了良好的泛化,我们需要更好的模型架构、较大的模型大小以及更多的微调示例,这些都紧密相连。我们不能只拥有一种成分,而是通过所有其他成分。</sample>
    <sample id="367">同时,我们还发现性能下降是由时间漂移引起的,令人惊讶的是,它并不是由适应性过拟合引起的。尽管Conll二千零三已经使用了二十多年。</sample>
    <sample id="368">回到我们在论文开头提出的问题,康奈尔二千零三标记在二千二十三年仍然有效,我们发现答案实际上是肯定的。</sample>
    <sample id="369">我们希望我们的论文呼吁对如何改进模型的概括性表示进行更多研究。</sample>
    <sample id="370">最后，请务必查看我们的论文、数据集。如果您有任何问题，请随时与我联系。非常感谢。</sample>
    <sample id="397">The given text does not provide information about the size of the audio clip used in the method.</sample>
    <sample id="398">在 Servin 和 Kea 的示例中，需要的特定于实体的知识是 Servin 是一名法官。</sample>
    <sample id="399">示例质量比与源句子的相似度更为重要。</sample>
    <sample id="400">在扩展实验中，论文侧重于GPT-4和GPT系列语言模型。</sample>
    <sample id="401">该模型使用结合多个层的注意力分数。</sample>
    <sample id="402">直接推断的示例包括使用歌曲名称（例如“Easy on Me”）或其在列表中的位置（例如“第一”）。</sample>
    <sample id="403">The author of the paper, Siyu Yuan, is from Fudan University.</sample>
    <sample id="404">The given text does not provide information on the number of authors for the paper.</sample>
    <sample id="405">是的，在语义解析之前使用机器翻译模型翻译自然语言查询作为基线。</sample>
    <sample id="406">作者给出的“显性群体”(marked group) 的示例是女性战士。</sample>
    <sample id="407">基于给定的英文内容，Transformer模型在泛化能力方面通常表现较差。</sample>
    <sample id="408">测试数据集的名称是Clean Data。</sample>
    <sample id="409">这篇论文有两位作者。</sample>
    <sample id="410">作者采用了多种模态，除了文本外，还使用了图像和视频。</sample>
    <sample id="439">作者认为 NLU 中研究不足的领域是成功模型的构建，特别是那些需要整合预训练时间和推理时间知识的任务。</sample>
    <sample id="440">演讲者的名字是Ying。</sample>
    <sample id="441">是的，Coscript 经过了质量检查。</sample>
    <sample id="442">现有的资源对于依赖上下文的翻译有以下局限性：

1. 支持有限的上下文类型：这些资源只能处理特定类型的上下文翻译。
2. 语言支持有限：由于依赖于领域知识和人类编辑，资源支持的语言范围有限。</sample>
    <sample id="443">嗨,我将讨论我们解决实体选择中间体表达的工作,其中我们介绍了altentities语料库。</sample>
    <sample id="444">我的名字是Javad Hosseini,这是与PhilippRadlinski,SilviaParati和AnilGuha共同完成的工作。</sample>
    <sample id="445">我们的目标是理解用户当他们想要做出选择时的语言。现在考虑这个替代问题。你是说对我很容易还是我有感觉?在这里,用户想要在这两个选项中进行选择。</sample>
    <sample id="446">最明显的事情是使用直接引用。例如,通过说歌曲的名称是我或它的位置,第一个。</sample>
    <sample id="447">但有时使用指针引用更适合进行更自然的对话。这可能发生在用户无法记住歌曲的名称时。</sample>
    <sample id="448">或者发音太相似,很难区分。</sample>
    <sample id="449">或者当用户想要指定一个偏好时,这里有一些例子和直接引用。例如,较新的 ones 或不那么激动人心的 ones。</sample>
    <sample id="450">这是对话系统和对LLM的实体理解进行比较中的一个重要问题。</sample>
    <sample id="451">我们没有一个公共数据集,一个大规模的公共数据集,所以我们使用人群注释收集一个。我们的数据集涵盖了三个不同的领域,音乐,书籍和。</sample>
    <sample id="452">我们的数据集收集方法强调使用卡通完成集的非正式性。</sample>
    <sample id="453">卡通有三个语音泡泡。在第一个泡泡中,鲍勃说,还记得我们昨天听的那首歌吗?与此相关,鲍勃设置了对话语境。</sample>
    <sample id="454">在第二个演讲泡泡中,爱丽丝说,你是说轻易对我,还是我有感觉?</sample>
    <sample id="455">这是替代问题,在第三个演讲泡泡中,鲍勃使用间接引用来选择其中一个实体。例如,新的。</sample>
    <sample id="456">我们自动提供第一个和第二个语音泡泡,但第三个语音泡泡是由注释者填写的。第一个语音泡泡从每个域的几个手动提示中选择。</sample>
    <sample id="457">第二个问题是替代问题,如下所示。</sample>
    <sample id="458">我们总是使用一个简单的模板。你是说A还是B，其中A和B是来自维基百科的样本。</sample>
    <sample id="459">以下是我们使用的不同采样方法。当我们在列表中移动到更高位置时,实体变得更加相似,并且通常更难进行消除歧义。</sample>
    <sample id="460">第一个是均匀攻击。</sample>
    <sample id="461">第二个是实体具有相似标题的情况。例如，两个书名为《退稿》的书。</sample>
    <sample id="462">第三个是当他们在维基百科上有类似的描述时,最后当他们在维基百科上有类似的信息框或属性时。例如,同一类型或同一艺术家。</sample>
    <sample id="463">当我们向替换者展示这个替代问题时,他们知道这些实体的名称,但他们不一定知道这些实体。</sample>
    <sample id="464">所以我们所做的就是展示一些关于两个实体的背景知识。对于歌曲,我们只需显示每首歌曲的谷歌搜索链接即可。</sample>
    <sample id="465">然后要求注释者至少听一首歌并阅读每首歌的注释。以下是该歌曲的Google搜索结果。</sample>
    <sample id="466">对于食谱和书籍域,我们从维基百科显示一些背景文本,对于食谱,我们还从维基百科显示他们的图像,以便注释者知道它们的外观。</sample>
    <sample id="467">然后,我们要求注释者选择其中一个实体。例如,在这里,第一个实体,并用三到五个间接引用表达式来描述它们。</sample>
    <sample id="468">例如,带钢琴音乐的那个。以下是我们数据集中的一些示例。例如,没有文字的那个,不是那个十二岁男孩的那个,或者虚构的那个,或者来自阿塞拜疆和索马里的那个。</sample>
    <sample id="469">实体语料库有六千个替代问题,跨三个领域,它有四万两千个间接引用表达式。使用T五X大模型的结果总结如下。</sample>
    <sample id="470">如果语言模型可以访问与注释者完全相同的背景知识,那么准确性确实很高。它在百分之九十二到百分之九十五左右。但这并不现实。</sample>
    <sample id="471">如果语言模型可以访问一些部分重叠的背景知识,那么准确率在百分之八十二到百分之八十七之间,这更现实。例如,当语言模型检索背景知识时。</sample>
    <sample id="472">如果语言模型只能访问实体名称,那么准确性只有百分之六十,因此有很大的改进空间。我们还证明了模型是域通用的。下面是链接到我们的数据集。谢谢。</sample>
    <sample id="473">该方法与 White-Key 策略和 Local Agreement 策略进行了比较。</sample>
    <sample id="474">The author of the paper, Yanis Lavraie, is affiliated with the University of Montreal.</sample>
    <sample id="475">演讲者的名字是Jenny。</sample>
    <sample id="476">这篇论文有三位作者：Myra、Eszter Mucsy和Dan Jarausky。</sample>
    <sample id="477">嗨，我是来自特伦托大学和布鲁诺·凯斯勒基金会的Sarah Papi,我将简要介绍Simultaneous Speech Translation的注意力作为指南论文,这是与Matteo Negri和Marco Turchi共同完成的工作。</sample>
    <sample id="478">什么是同时翻译？同时翻译或SimulST是将口语翻译成另一种语言的文本的过程，在实时翻译中实现跨语言交流。</sample>
    <sample id="479">当前的simulSt模型存在哪些问题?通常使用训练的特定架构,引入额外的模块进行优化。</sample>
    <sample id="480">长且复杂的培训程序。例如，涉及不同优化目标的培训。</sample>
    <sample id="481">并训练和维护几个模型以达到不同的延迟。比如训练一个模型的平均延迟为一秒钟，另一个为两秒钟等等。</sample>
    <sample id="482">那么我们的解决方案是什么呢?</sample>
    <sample id="483">首先,使用现有的离线ST模型,而无需重新训练或采用特定的STMST架构。只使用一个模型来处理每个延迟模式,并通过特定参数处理延迟。</sample>
    <sample id="484">并利用我已经获得的知识通过注意力机制在音频输入和文本输出之间。也就是说,跨注意力机制,你可以在右边看到一个示例。</sample>
    <sample id="485">我们的解决方案是提出一个DAT或编码器解码器注意力,它是一个策略,我们决定是否根据注意力指向的地方进行部分翻译。</sample>
    <sample id="486">如果注意力不集中，意思是这个和的总和低于一个阈值alpha，向最后一个lambda语音帧，意味着接收到的信息不够稳定。</sample>
    <sample id="487">例如,如果我们收到一个包含我将要谈论的语音片段,并且我们的模型预测了德语的翻译。</sample>
    <sample id="488">我们将研究交叉张力权重。</sample>
    <sample id="489">我们会看到前两个单词指向最早收到的语音帧,而最后一个单词指向最后收到的语音帧,即lambda语音帧。</sample>
    <sample id="490">这意味着前两个单词将被省略。</sample>
    <sample id="491">虽然由于交叉注意力的总和高于一定的比率α，我们不会发出最后一个单词，而是等待另一个语音信道。</sample>
    <sample id="492">如果我们继续并且我们收到另一个演讲,我们模型预测了另外三个单词,我们将查看交叉注意力权重。</sample>
    <sample id="493">我们会看到没有单词指向最后一个lambda语音帧。</sample>
    <sample id="494">这意味着这三个字将被省略。</sample>
    <sample id="495">如果你看看这个数据的主要结果。</sample>
    <sample id="496">我们将同时翻译的结果绘制在图表上,其中一侧为蓝色,用于测量翻译质量和平均滞后。</sample>
    <sample id="497">这是延迟度量,我们还考虑了计算意识平均差距,它考虑了模型的计算时间来预测输出。</sample>
    <sample id="498">所以我们希望我们的曲线在这张图上尽可能高。</sample>
    <sample id="499">但我们也希望它们向左移动。</sample>
    <sample id="500">我们与适用于离线模型的策略进行比较,即waitkey策略和本地协议,并与专门针对多语言翻译的最先进架构进行比较。</sample>
    <sample id="501">这些都是德语的同时对翻译策略的结果。</sample>
    <sample id="502">我们看到,在应用于离线模型的所有策略中,adout都表现出色,因为其曲线向左移动。</sample>
    <sample id="503">我们也看到,如果我们考虑实际的过期时间或计算的实际时间,那么这是最快的策略。</sample>
    <sample id="504">如果您想了解更多结果，请阅读我们的论文。我们还发布了开源代码、模型和同时输出，以促进我们工作的可重复性。感谢您的关注。</sample>
    <sample id="505">是的，数据集是公开的。</sample>
    <sample id="506">大家好，我叫Ying，我的同事Zhi Yang和我将要介绍我们的研究Multi-Instuit，改进多模态神经网络的学习通过指导调优。</sample>
    <sample id="507">因此，随着大型语言模型的进步，许多工作开始探索使用预训练语言模型以参数和数据高效的方式进行不同的下游任务的新学习范式。</sample>
    <sample id="508">最近的许多研究表明，指令调优使大型语言模型能够以自然指令的方式在短时间内执行看似无关的任务。</sample>
    <sample id="509">然而,大多数以前关于指令调优的工作都集中在改进语言任务上的神经网络性能上,而计算机视觉和多模态任务则被排除在外。</sample>
    <sample id="510">因此,在这项工作中,我们想要研究是否对多模态预训练模型进行指令调优实际上可以改善对nc多模态任务的泛化。</sample>
    <sample id="511">此外,在我们研究的时间,我们发现rlp和多模态之间的指令数据集可用性存在相当大的差异。</sample>
    <sample id="512">存在超过一千六百个语言单独的指令任务。然而,没有大型的公开可用的多模态指令任务。因此,这激励我们构建一个多模态指令调优数据集。</sample>
    <sample id="513">在这里,我们介绍了MultiInstruc,第一个多模态指令调优基准数据集,由62个多模态任务组成,涵盖10个板类别。</sample>
    <sample id="514">这些任务来自于二十一个现有的开源数据集,每个任务都配备了五个专家写的说明。</sample>
    <sample id="515">为了在我们所提出的数据集上研究多模态指令调优,我们采用OFa作为我们的基础模型。OFa使用统一的语言、图像标记和边界框的坐标。</sample>
    <sample id="516">这里我们展示了来自多种类型数据集的示例。</sample>
    <sample id="517">统一处理各种输入和输出数据类型。</sample>
    <sample id="518">我们遵循OFA的方法,并将所有任务以统一的序列到序列格式进行制定,其中输入文本、图像、指令和边界框都在同一个标记空间中表示。</sample>
    <sample id="519">好了,现在我要讲讲多模态指令调谐。</sample>
    <sample id="520">因此,对于训练数据集,我们使用来自NLG的53个任务进行训练,并对每个任务进行10,000次采样。对于测试,我们保留整个Commonsense推理组进行测试,并从VQA和恶意组中选择另外5个任务。</sample>
    <sample id="521">我们在每个任务中都使用测试集中的所有实例。此外,我们从自然指令的测试集中随机抽取二十个任务作为NLPC的任务。</sample>
    <sample id="522">因此,我们使用预训练的ofa大模型作为基础模型。在训练过程中,我们将所有任务的实例混合在一起。每个实例都与其五个指令模板中的一个随机组合。</sample>
    <sample id="523">因此,在测试过程中,对于每个任务,我们通过评估模型来进行总共五次实验,在每次实验中使用五个指令中的一个。</sample>
    <sample id="524">我们报告了所有五个实验中性能的均值、最大值和标准差。</sample>
    <sample id="525">如果任务是多模态分类任务,我们报告准确率。如果是多模态生成任务,我们报告rougeL。对于NLP任务,我们也报告rougeL。</sample>
    <sample id="526">我们还引入了一个额外的评估指标,称为灵敏度,因此它衡量了模型在任务相同的情况下,无论任务排序如何,始终能够一致产生相同的输出的能力。</sample>
    <sample id="527">这是我们的主要结果。正如我们所看到的,指令调优可以显著提高OS的性能,在同一多模任务上。</sample>
    <sample id="528">此外，从自然语言数据集进行转移学习也可以带来益处。</sample>
    <sample id="529">在这里,我们可以看到,随着任务数量的增加,模型的性能得到了改善,同时降低了敏感性。</sample>
    <sample id="530">所以我们也做了一个实验。我们使用一个指令与五个指令。正如我们所看到的,使用更多的指令可以显著提高模型的整体性能并降低其敏感性。</sample>
    <sample id="531">所以这显示了不同的微调策略对模型敏感性的影响。正如我们所看到的,通过从自然语言数据集中转移学习,模型可以比原始的IFA模型获得更好的敏感性。</sample>
    <sample id="532">我们也可以看到,从自然指令数据集的转移学习可以帮助OFA在自然指令数据集上获得更好的性能。</sample>
    <sample id="533">总的来说,我们提出了第一个大规模的多模态调优数据集。我们显着提高了OFA的零射程能力,并探索了不同的迁移学习技术,并展示了它们的优势。我们设计了一个新的指标 sensitivty。</sample>
    <sample id="534">还有一件事,我们正在收集一个更大的多模态指令调优数据集,其中包含大约一百五十个额外的视觉语言任务,我们将发布它们,所以这是一个QR代码,用于我们的数据和模型。谢谢。</sample>
    <sample id="535">The authors of the paper are affiliated with the University of Trento and Fondazione Bruno Kessler.</sample>
    <sample id="536">演讲者的名字是Javad Hosseini。</sample>
    <sample id="562">大家好，我是KoustavSinha,很高兴欢迎大家参加我们的演讲。我们的ACL2023论文语言模型接受度判断并不总是对上下文鲁棒。</sample>
    <sample id="563">这是与John Gauthier、Aaron Mueller、Kanishka Mishra、Karen Fentress、Roger Levy和Atina Whelan的联合工作。</sample>
    <sample id="564">因此，在这项工作中,我们重新审视了最小对偶范式。</sample>
    <sample id="565">因此,最小对对时间基本上评估语言模型的可接受性判断,这也可以包括语法性,例如,语法或在刻板印象方面的可接受性,例如,粗鲁的对。</sample>
    <sample id="566">在这种最小对偶范式中,评估语言模型的典型方法是,你展示一个可以接受的句子或语法句子,然后你展示一个不可接受的句子或不语法句子。</sample>
    <sample id="567">然后希望模型基本上会给可接受的结果更多的概率。</sample>
    <sample id="568">当前的MPP管道基本上不允许我们评估模型对更长句子的接受程度。</sample>
    <sample id="569">这些天,大型语言模型的上下文窗口越来越长,因此至关重要的是,我们要评估模型在整个上下文窗口的可接受性。</sample>
    <sample id="570">这就是我们在这里试图做的。我们试图通过要求模型对更长的序列进行可接受性评估来重新审视MPB管道。</sample>
    <sample id="571">所以这是方法。所以我们所做的是,为了模拟这些更长的序列,我们重新审视数据集本身,然后我们通过选择可接受或不可接受的句子来重建句子。</sample>
    <sample id="572">例如,在这里我们选择了来自附属岛屿案例的典型语法对。</sample>
    <sample id="573">And what we do is that to recreate like longer sequences and which are acceptable and which has the same matching of the grammatical structure, we extract grammatical sentences from adiantia.</sample>
    <sample id="574">然后我们将其添加为可接受查询和不可接受查询的前缀。</sample>
    <sample id="575">所以我们可以通过选择不合适的句子来做同样的事情,从相同的匹配中,这也可以用来测试模型的可接受性。</sample>
    <sample id="576">我们也可以通过从不同的子集或数据集中选择句子来做到这一点。这就是我们所说的匹配不匹配的情况。</sample>
    <sample id="577">所以这里的句子仍然来自相关的数据集,但它不是来自您正在评估的相同数据集,我们也可以对不可接受性情况做同样的事情。</sample>
    <sample id="578">最后,我们可以从一个完全无关的领域中选择句子,例如维基百科。</sample>
    <sample id="579">因此,这将告诉我们,例如,模型的可接受性判断是否实际上受到任何上下文的影响。</sample>
    <sample id="580">就像上下文来自数据集的不同子集,或者它是否与我们正在查看的句子完全无关。</sample>
    <sample id="581">那么模型是如何工作的呢?首先,我们来看看维基百科句子,这些句子与当前的查询对完全无关,在那里我们发现MPP的判断对于任意上下文线索都很健壮。</sample>
    <sample id="582">我们将上下文长度增加到一千二百二十四,以最大化OPT和GPT2模型,我们在橙色的点线中看到,MPP的判断相对稳定。</sample>
    <sample id="583">现在,当我们从同一数据集中选择句子时会发生什么?</sample>
    <sample id="584">所以在这里我们选择或创建句子从可接受和不可接受的域从同一个句子或语法数据集。</sample>
    <sample id="585">我们看到MPP判决要么增加要么减少显着。当你添加可接受的前缀或不可接受的前缀时。</sample>
    <sample id="586">但是当我们匹配结构时,也就是说当我们从同一现象中选择句子时,责备人文本吉姆。</sample>
    <sample id="587">我们看到模型的MPP判断有巨大的增加或减少,这取决于所选前缀是否可接受。</sample>
    <sample id="588">现在这个和这个是非常大的,就像这个效果在整个上下文链接中增加,这可能会影响到像新的语言模型这样的东西,它有很大的上下文窗口。</sample>
    <sample id="589">那么,为什么匹配前缀会对语言模型的判断产生如此大的影响呢?</sample>
    <sample id="590">因此,我们进行了分析系列,我们尝试通过添加噪声来扰乱输入句子,但保留了相关结构,并在做了几次扰动之后。</sample>
    <sample id="591">我们发现这些噪音中没有一个实际上会使模型改变其方向。就它向我们展示的MPP趋势而言。</sample>
    <sample id="592">基本上,我们发现模型对扰动句子和类似的句子都很敏感。</sample>
    <sample id="593">也就是说,当我们扰动可接受域中的句子时,我们看到所有扰动的增加,当我们扰动不可接受域中的句子时,我们看到MPP判断以类似的方式下降。</sample>
    <sample id="594">因此,我们工作的关键结论是,语言模型对句子中共享的潜在语法和语义特征敏感。</sample>
    <sample id="595">而MPT评估的方式,我们目前用短语和单个句子输入的方式,可能无法完全捕捉到语言模型在整个上下文窗口中的抽象知识。</sample>
    <sample id="596">请阅读我们的论文以获取有关我们实验的更多详细信息。感谢您的收听。</sample>
    <sample id="597">该方法的第一步将输入词元映射到一个无序多集的词元。</sample>
    <sample id="598">在 Coscript 中包含了 55,000 个脚本。</sample>
    <sample id="626">DEplain 的最佳对齐方法是 massalign 方法。</sample>
    <sample id="627">弱监督学习可以在存在标签噪声的情况下训练更好的模型。</sample>
    <sample id="628">在 DEplain-web 中，文档采用了手动和自动对齐方法进行对齐。具体分配情况如下：

1. 手动对齐：手动对齐用于对齐标题、段落标题、段落内容、列表项、表格、图表、图表标题、图表标签、图表注释、图表注释标题、图表注释内容、图表注释内容标题、图表注释内容内容标题、图表注释内容内容内容标题、图表注释内容内容内容内容标题、图表注释内容内容内容内容内容标题、图表注释内容内容内容内容内容内容标题、图表注释内容内容内容内容内容内容内容标题、图表注释内容内容内容内容内容内容内容内容内容标题、图表注释内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容内容</sample>
    <sample id="629">CoNLL++ 数据集是通过从 2020 年的 Reuters News 中收集数据，然后使用相同的 CoNLL 2003 注释指南进行标注而创建的。</sample>
    <sample id="630">大家好。我是来自宾州大学的YuxinZhang。今天我要介绍一下我们在多种自然语言和多种表示形式中进行的示例跨语言语义解析工作。</sample>
    <sample id="631">因此，语义解析是构建用户查询的语义表示的任务,例如SQL和lambda计算。</sample>
    <sample id="632">跨语言语义解析是将多种自然语言中的查询转换为多种语义表示的任务。</sample>
    <sample id="633">如图所示,我们需要使用神经模型将查询翻译成多种自然语言,以便使用SQL、lambda或funql等。</sample>
    <sample id="634">现有的跨语言语义解析模型是单独提出和评估的。数据集有限的任务和应用。例如。</sample>
    <sample id="635">有一些关于某些自然语言的报道缺失。中国人缺失了。</sample>
    <sample id="636">克利克斯在某些媒体上的报道。</sample>
    <sample id="637">缺少lambda微积分。</sample>
    <sample id="638">或者它们只在某个神经模型上进行评估。例如,只有一个单一的模型来评估它们。</sample>
    <sample id="639">为此目的,我们提出了示例,为多种自然语言和多种表示的跨语言语义解析提供了一个统一的数据集示例。</sample>
    <sample id="640">它包含九十个数据集，跨多个领域，五个语义分割任务，八百万表示和二十二种自然语言和十五个语言家族。</sample>
    <sample id="641">为了更好地评估我们的基准,我们考虑了六个用于训练和评估的设置。</sample>
    <sample id="642">第一个是翻译测试。我们使用谷歌翻译API将源语言翻译成目标语言。然后使用单语言模型进行训练和评估。</sample>
    <sample id="643">例如，我们在英文查询上训练了英文模型。在推理过程中，我们使用API将德语查询翻译成英文，然后使用训练好的模型来预测SQL。</sample>
    <sample id="644">我们还测试了单语言模型。</sample>
    <sample id="645">在这种设置中，源语言与目标语言相同。例如,德语到德语或英语到英语。</sample>
    <sample id="646">我们还测试了单语言场景设置,通过仅使用10%的训练数据训练单语言模型。</sample>
    <sample id="647">它有多语言模型,我们为所有语言训练一个多语言模型。</sample>
    <sample id="648">例如,我们将德语、英语、中文查询放在一起训练一个多语言模型,并在推理过程中,我们可以使用这个模型。</sample>
    <sample id="649">要翻译德语查询或中文查询等。</sample>
    <sample id="650">我们还考虑了crosslingo,zero-shot和few-shot转移。我们在一个源语言上训练,然后转移到另一个语言上。</sample>
    <sample id="651">所以在训练过程中,我们在英文查询或英文和德语查询的组合上进行训练,以训练一个多语言模型来预测SQL输出。</sample>
    <sample id="652">我们也发现了许多有趣的结果。因此,关于单语言模型的分析,我们评估了两个模型组。</sample>
    <sample id="653">包括编码器PDR,它代表多语言预训练编码器与基于指针的解码器,如xlmr加PDR和mbert加PDR。</sample>
    <sample id="654">我们还评估了编码器解码器模型,即多语言预训练的编码器解码器模型,例如mbart和mt五。</sample>
    <sample id="655">我们发现编码器解码器在所有九个数据集上获得了最佳性能。</sample>
    <sample id="656">我们在MT5上评估了一个示例。XL和R加上PDR在多语言设置上。</sample>
    <sample id="657">我们发现编码器解码器或编码器PDR可以通过在各种语言的混合中进行训练来改进。</sample>
    <sample id="658">我们发现,这是因为大多数主要自然语言都可以获得性能提升,除了英语性能在七个数据集中下降,只有在三个数据集中获得提升。</sample>
    <sample id="659">我认为这被称为多语言的诅咒。</sample>
    <sample id="660">我们还比较了交叉链接性能获取。</sample>
    <sample id="661">在这张图中，蓝线是跨语言的少数转移。橙线是跨语言的零转移。</sample>
    <sample id="662">我们发现通过比较绿色和橙色线条,我们发现零短期设置的跨语言转移性能差距是显著的,并通过比较蓝色和橙色线条,我们发现通过短期设置的转移差距是快速缩短的。</sample>
    <sample id="663">我们还发现了一些其他有趣的发现。例如，编码器解码器的工作超过了前面的工作，或者在英语自然语言上取得了相当的结果。显然,在目标自然语言上，英语自然语言可以显著提高Fushot的性能。</sample>
    <sample id="664">我们发现多语言模型，如Codas和Blue仍然不适合跨语言语义解析任务。</sample>
    <sample id="665">总而言之,我们构建了一个用于多种自然语言和中间表示的跨角度语义解析的统一基准测试。</sample>
    <sample id="666">我们对三种代表性的多语言模型类型进行了全面的基准测试。我们的结果显示了许多有趣的发现等等。欢迎访问我们的论文和代码。感谢您的收听。</sample>
    <sample id="667">关于这方面的现有研究可以分为四个主要类别：1) 研究方法和技术；2) 研究主题和领域；3) 研究成果和发现；4) 研究影响和应用。</sample>
    <sample id="668">Codex 和 Bloom 等多语言 LLM 对于 Cross-Lingual Semantic Parsing (CLSP) 来说不够。</sample>
    <sample id="695">该方法通过在训练过程中引入对齐来处理排列的不确定性，并使用GPU友好的连续放松来近似解决 NP 难题，允许学习更合理的排列。</sample>
    <sample id="696">下游 NLP 模型的公平性可以定义为其在处理和分析数据时，不会因政治偏见或歧视而导致不公平结果。公平性涉及确保模型的输出不偏向特定群体或观点，并且能够在不同的社会和文化背景下公平地处理信息。</sample>
    <sample id="697">演讲者的名字是Yanis Lavrik。</sample>
    <sample id="698">演讲者的名字是Koustav Sinha。</sample>
    <sample id="699">演讲者的名字是Myra。</sample>
    <sample id="700">在本文的背景下，热带主义指的是一种刻板印象或刻板印象，通常与女性的外貌特征相关联，描绘她们为充满活力、热情和充满色彩的热带地区的女性。</sample>
    <sample id="701">作者通过使用特定的词汇如“文化”、“传统”、“骄傲”和“异国情调”来创建目标群体的人工描写。这些词汇定义了这些群体，强调了他们与白人标准的不同，并将他们与其身份和自豪感联系起来。</sample>
    <sample id="702">本文中使用了点字 cxmi 来衡量语境使用情况。</sample>
    <sample id="703">DrBERT 和 ChuBERT 的主要区别在于数据集来源。 DrBERT 使用了 7GB 的自然语言处理 (NLP) 数据集，而 ChuBERT 则使用了 4GB 的句子集，取自临床笔记。</sample>
    <sample id="751">这篇论文有两位作者。</sample>
    <sample id="752">迭代迁移学习是通过在每次训练周期中更新模型，以便在新数据集上进行更好地预测。</sample>
    <sample id="753">数据集的目标是理解用户在选择时使用的语言。</sample>
    <sample id="754">攻击者通过利用 EaaS 的可访问性和可扩展性来提取模型参数。</sample>
    <sample id="755">这篇论文有三位作者：Sarah Papi、Matteo Negri和Marco Turchi。</sample>
    <sample id="756">有四个注释者用于创建初始数据集。</sample>
    <sample id="757">这篇论文的作者所属机构是卡内基梅隆大学。</sample>
    <sample id="758">左侧为支配词的示例是“Isabel”。</sample>
    <sample id="759">对话系统中的最先进模型是ChatGPT。</sample>
    <sample id="760">我们需要在整个上下文窗口中评估模型的可接受性，因为大型语言模型现在具有更长的上下文窗口，这对于确保其在不同情境下的准确性和相关性至关重要。</sample>
    <sample id="761">是的，多语言训练可能会导致表现下降，因为在七个数据集中，英语模型的性能下降，而在三个数据集中则有所改善。</sample>
    <sample id="762">不，注释者不一定提前知道该实体。</sample>
    <sample id="763">根据给定的英文内容，使用的MT（机器翻译）指标包括“质量”和“准确性”。这些指标评估了翻译的质量和准确性。</sample>
    <sample id="764">不，泛化中的回归不会影响特定的 NER 类型。</sample>
    <sample id="765">在 NLP 中，立场是重要的，因为它影响了模型的性能和公平性。立场偏见可能导致 AI 系统对某些群体或话题表现出偏见，影响其准确性和公正性。</sample>
    <sample id="766">像 BLOOM 这样的多语言 Large Language Models (LLM) 通常采用完整微调，而不是适配器微调。</sample>
    <sample id="767">他们使用了一个模型来进行迁移学习，该模型在两项任务上进行了优化，最终在任务之间进行进一步的优化。</sample>
    <sample id="768">最近用于评估 PaLM 能力的测试集包括 "Hugging Face's Benchmarks" 和 "LLaMA Benchmark"。</sample>
    <sample id="769">作者最终提出了三个建议。</sample>
    <sample id="770">提议的方法获得了 4.4% 的收益。</sample>
    <sample id="771">演讲者的名字是Shu-Heng。</sample>
    <sample id="772">是的，论文中的结果和数据集可以用作基准。</sample>
    <sample id="773">他们在论文中进行了五个较小模型的实验。</sample>
    <sample id="774">Unified Multi-Modal Pretraining Model (UOFAM) 被用作研究多模型指令调整的基础模型。</sample>
    <sample id="833">The authors of the paper "Prompting Prompt for Translation: Assessing Strategies and Performance" are affiliated with Google Translate. However, it is not explicitly mentioned which specific institution they belong to within Google Translate.</sample>
    <sample id="834">作者所属机构是Stony Brook University。</sample>
    <sample id="835">The paper analyzes English and Chinese languages.</sample>
    <sample id="836">演讲者的名字是Xiangbing。</sample>
    <sample id="837">在实验过程中研究了两个模型：一个用于生成文档级简化，另一个用于生成句子级简化。</sample>
    <sample id="838">在 MultiInstruct 中，53 个任务用于训练目的，另外 5 个任务来自 VQA 和 Misconception 组用于测试目的，总共使用了 58 个任务。</sample>
    <sample id="839">这篇论文有四位作者。</sample>
    <sample id="840">作者在实验中使用了以下数据集：AG NEWS、MIND、SST2和 IRAS-FAM。</sample>
    <sample id="876">NACHOS是一个用于训练 Dr. Bert 模型的医疗数据集，包含来自网络的医疗数据。</sample>
    <sample id="877">演讲者的名字是Ayed Bilal。</sample>
    <sample id="878">提示策略对结果有很大影响。</sample>
    <sample id="879">The provided text does not mention the authors' institutional affiliations.</sample>
    <sample id="880">1. 请描述一下你们正在收集的更大规模的多模态调优数据集。
2. 你们计划收集多少个额外的视觉语言任务？
3. 你们将如何发布这些任务？
4. 你们将如何使用 QR 码？
5. 你们将如何感谢观众？</sample>
    <sample id="881">作者建议通过设计一个 co-reference resolution task 来测试模型，该任务旨在评估模型是否能够利用来自不同来源的知识。</sample>
    <sample id="882">大家好，我是Aydil Bilal,我将给大家简要介绍一下这篇论文《Prompting Prompt for Translation: Assessing Strategies and Performance》。这是我和谷歌翻译的同事们共同完成的工作。</sample>
    <sample id="883">Param是一个五百四十亿个参数的slate语言模型，去年在2022年提出。它在大量文本集上进行训练，包含七亿八千万个令牌。</sample>
    <sample id="884">在发布时,它在数百个NLP任务中实现了最先进的技术。</sample>
    <sample id="885">在这项工作中，我们提出了第一项系统的语言模型提示研究。</sample>
    <sample id="886">我们评估了这些模型的转换能力。使用MT社区的最佳实践。这涉及使用最新的测试集来避免测试数据与语言模型的训练数据重叠。</sample>
    <sample id="887">我们比较了两种最先进的系统,所以最好的性能系统是WMT评估。</sample>
    <sample id="888">我们使用最先进的神经网络指标。此外,还显示了基于专家的人工评估结果。最后,我们提供一些提示选择策略的建议。</sample>
    <sample id="889">提示对LLM的翻译性能有很大的影响。我们可以在一个简单的实验中看到这一点，其中我们使用了一次性提示，并为每个句子提供了两个不同的提示。</sample>
    <sample id="890">句子中的大多数句子，五百六十个出一千个。观察到的差异是超过一个模糊点。</sample>
    <sample id="891">在极端情况下,这可以达到四十个点,因此重要的是要选择一个好的提示策略。</sample>
    <sample id="892">在我们的实验中,我们选择了五次拍摄的提示策略,我们只标记我们提供给系统的每个句子,它的语言是。</sample>
    <sample id="893">在这个示例中，我们从德语翻译成英语，德语句子用德语列出，英语翻译用英语列出。</sample>
    <sample id="894">我们看到实际形式的提示在几何短提示的情况下并没有很大的影响。</sample>
    <sample id="895">对于零和一枪提示至关重要。当我们进入五枪提示时,实际上提示的形式几乎没有差异。</sample>
    <sample id="896">是举例子带来的影响最大。</sample>
    <sample id="897">我们实验结果的总结是，示例质量比源句的相似性更重要。</sample>
    <sample id="898">因此,从高质量翻译中选择示例很重要。特别是,我们比较从WMT评估或dev数据的训练数据中选择提示。</sample>
    <sample id="899">深度数据比训练数据更准确和更高质量,因此使用深度数据时的结果更好。</sample>
    <sample id="900">尽管如此，专门的最先进系统在与PAM翻译相比具有显著优势,但PAM非常接近我们的商业系统。在我们的情况下,我们选择使用谷歌翻译。</sample>
    <sample id="901">我们从使用MPO框架进行的EMG分析中获得的见解是，手掌的流畅度与最先进的系统相当,但主要区别来自准确性。</sample>
    <sample id="902">特别是最常见的错误是遗漏错误。</sample>
    <sample id="903">所以它似乎选择了更好的声音翻译，有时通过删除源句子中被翻译的部分。</sample>
    <sample id="904">然而,对于PAM的样式awkward类别比对于最先进的系统的类别要低,这是一条额外的信号。</sample>
    <sample id="905">该参数提供了非常流畅的输出,但仍然存在一些准确性问题。</sample>
    <sample id="906">这就是这个非常简短的概述。对于更多细节,请来到论文的完整演示。非常感谢。</sample>
    <sample id="907">你好，我是大伟，德国萨兰特大学的博士生。在本视频中，我想介绍一下我们最近的工作 weaker than you think：对每周监督学习的批判性研究。</sample>
    <sample id="908">这是与肖玉申、马约斯·穆斯巴、格雷厄斯·斯蒂芬和迪特里希·克拉科夫的联合工作。</sample>
    <sample id="909">我想从弱监督和弱监督学习的简要介绍开始。</sample>
    <sample id="910">在弱监督中,我们不手动标记数据。相反,我们使用弱标记源标记数据,例如简单的启发式规则、知识库或低质量的外包,如右图所示。</sample>
    <sample id="911">与人类注释相比，弱注释要便宜得多，但它们也很嘈杂，意味着一定数量的注释是错误的。</sample>
    <sample id="912">如果我们直接在每周的标签数据上训练神经网络，神经网络往往会记住标签噪声而不会泛化。</sample>
    <sample id="913">在弱监督学习中，提出的训练算法旨在在这种标签噪声下强大地训练神经网络，使得训练的模型仍然能够很好地泛化。</sample>
    <sample id="914">在最近的WSL工作中,所以WSL代表每周监督学习。一个常见的说法是,人们说他们只在每周标签数据上训练模型,并在干净的测试集上实现高性能。</sample>
    <sample id="915">从技术上讲,这个说法并不错,但有一个陷阱。</sample>
    <sample id="916">这就是人们认为有一个额外的清洁验证集可用于模型选择。</sample>
    <sample id="917">我们不能对这个问题设置停止,因为这意味着在弱监督学习中需要额外的手动注释。但就像房间里的大象一样,这种必要性往往被忽视。</sample>
    <sample id="918">上述疑问使我们提出了三个研究问题。首先,清洁验证数据是否对于WSL必要?或者我们也许可以使用噪声验证集?</sample>
    <sample id="919">其次,如果需要清洁数据,或者清洁数据是WSL工作所必需的,那么我们需要多少个清洁样本?最后,我们是否只使用清洁样本进行验证,还是有更好的利用方式?</sample>
    <sample id="920">我们在工作中解决了这些研究问题,我们的发现如下。</sample>
    <sample id="921">首先,我们发现,有趣的是,最近的WSL方法确实需要清洁的白色盘子样本才能正常工作。</sample>
    <sample id="922">否则，性能会大幅下降。图中所示，如果没有清洗验证样本，则训练模型无法超越原始弱标签。</sample>
    <sample id="923">这意味着训练是毫无意义的。</sample>
    <sample id="924">这表明WSL方法实际上需要清晰标记的数据才能正常工作。并且获取清洁验证样本的注释成本不应被忽视。</sample>
    <sample id="925">我们的第二个发现是,增加清洁验证样本的数量将有助于WSL方法实现更好的性能,如图所示。</sample>
    <sample id="926">通常，我们只需要每类20个样本就能达到高性能。</sample>
    <sample id="927">但这还不是故事的结尾。因为无论如何,如果我们决定直接使用干净的样本进行训练，那么直接训练干净的样本甚至可以实现更好的性能。</sample>
    <sample id="928">右图显示了微调方法在干净数据和WSL方法（仅用于验证）之间的性能差异。</sample>
    <sample id="929">如我们所见,如果我们每个类有十个样本,则直接微调开始击败WSL方法。</sample>
    <sample id="930">最后,在之前的WSL方法中声称的性能改进可以通过允许在清洁验证样本上进行细微调整来轻松实现。</sample>
    <sample id="931">如图所示，瓦利纳模型，称为FTW，最初表现不佳。更复杂的WSL方法，如cosine。</sample>
    <sample id="932">但是，如果我们允许在干净的样本上继续微调，那么FTW的表现与其他方法相当。</sample>
    <sample id="933">因此，在实践中,没有理由选择更复杂的WSL方法,这些方法需要更多的计算时间和磁盘空间。</sample>
    <sample id="934">总而言之，我们表明，最近的WSL方法需要清洁的手动标注样本才能正常工作。它们的性能提升和实用性被严重高估了。</sample>
    <sample id="935">我们对未来工作的具体建议如下。</sample>
    <sample id="936">首先报告模型选择标准。例如,报告模型选择是否在干净的验证样本上进行。</sample>
    <sample id="937">第二、WSSL方法应与短期学习基线进行比较,因为它们都在清晰的样本上工作。第三,连续微调是一个简单而强大的基线,应在未来的WSSL工作中考虑。</sample>
    <sample id="938">最后,我们已经开源了我们的代码。您可以通过此幻灯片上的QR代码找到它。请随时检查它。谢谢大家,祝大家愉快地参加会议。</sample>
    <sample id="939">对话系统的常用评估方法是使用人类评估，例如让人类评委选择两段对话中更好的，或者根据利卡德评分标准对对话进行评分。</sample>
    <sample id="940">这篇论文有五位作者。</sample>
    <sample id="941">在 Servin 和 Kea 的示例中，需要的背景知识是：法官在法庭上决定案件。</sample>
    <sample id="942">是的，代码是公开的，可以在GitHub上找到。</sample>
    <sample id="943">不，NLPositionality 的注释者在各个人口统计学特征方面并不均衡。</sample>
    <sample id="944">在可接受的域中扰乱句子的方法包括尝试保留相关结构的同时添加噪音到输入句子中。</sample>
    <sample id="945">进行维度评估意味着评估模型的多个方面或特定方面，以更详细地了解其优点和缺点。</sample>
    <sample id="946">The author of the paper is from the University of Science and Technology of China.</sample>
    <sample id="947">提示的形式在零和一枪提示中很重要。</sample>
    <sample id="978">作者评估了与人类对话的对话模型。</sample>
    <sample id="979">The given text does not provide information about the number of authors for the paper.</sample>
    <sample id="980">优秀规划器的理想品质是能够写出合理且忠实于多方面限制的计划。</sample>
    <sample id="981">The given text does not provide information about the number of authors for the paper.</sample>
    <sample id="982">演讲者的名字是Vasudha。</sample>
    <sample id="983">作者所属机构没有提供信息。</sample>
    <sample id="1021">PaLM 最常见的错误是 omission errors。</sample>
    <sample id="1022">你好，我是詹姆斯·芬奇。今天我们将向你们介绍ABC评估。一个新的维度方法来评估对话型人工智能。</sample>
    <sample id="1023">这项工作是由EmoryNLP实验室完成的，Emory大学的Gino Choi教授领导，并与AmazonAlexaAI合作。</sample>
    <sample id="1024">假设您刚刚开发了对话模型,并且您想查看它与当前的最新技术相比的效果。</sample>
    <sample id="1025">常用的做法是使用人类评估，例如让人类评委选择两段对话中哪一段更好，或者给定利卡德评分的对话进行评分。</sample>
    <sample id="1026">这些方法很好地提供了对对话整体质量的整体评估,但对话质量有许多方面。因此,您可能希望评估聊天质量的多个维度,以更好地了解模型的优点和缺点。</sample>
    <sample id="1027">一种方法是简单地让人类评委员评估对话质量的几个维度，例如使用现有的比较或利克特量表方法来评估模型响应的相关性。</sample>
    <sample id="1028">然而，我们认为对于维度对话评估有一个更精确和可靠的策略。</sample>
    <sample id="1029">我们的方法试图通过明确标注每个模型响应是否表达某些行为来减少人类评估的主观性，例如使用无关的信息或自相矛盾。</sample>
    <sample id="1030">我们称这种方法为注释聊天中的行为,简称ABCeval。我们开发了这种方法来全面涵盖聊天模型行为,这些行为被认为会影响聊天质量。</sample>
    <sample id="1031">ABC eval能够测量聊天模型在不同主题上的错误率。</sample>
    <sample id="1032">例如，ABC-eval测量聊天模型在与伙伴交谈时忽略对方或说出无关话的次数。</sample>
    <sample id="1033">与自己或其伙伴相矛盾，产生幻觉，提供错误的事实或违反常识知识，以及模型成功或未能表现出同理心。</sample>
    <sample id="1034">为了确定什么样的评估最有效，我们选择了四个最先进的聊天模型，并在每个模型上评估了100个人机对话。使用abceval。</sample>
    <sample id="1035">为了进行比较,我们还使用了三种现有方法来评估这些对话。对话级别的Lickert评分和对话级别的对话级别对比。</sample>
    <sample id="1036">对于现有的方法，我们收集了对八个最常测量对话方面的评估的评估,因为这是对多维度聊天模型的标准做法。</sample>
    <sample id="1037">从我们对这些评估结果的分析中，我们发现ABCeval行为标签总体上比现有方法收集的标签更可靠,通过对100对双标记对话的内部评审员的协议来衡量。</sample>
    <sample id="1038">此外，ABC评估标签在预测对话质量方面比现有方法产生的指标更具预测性,如简单线性回归分析所示。</sample>
    <sample id="1039">例如，你可以看到衡量自我和配偶矛盾的比例如何解释了5%和10%的对话质量，而平均的利克特一致性得分只解释了4%或更少。</sample>
    <sample id="1040">最后,我们使用分步线性回归检查每个评估指标是否捕获了聊天质量的独特方面。</sample>
    <sample id="1041">你可以看到所有ABC评估指标的组合如何解释超过百分之二十五的对话质量。随着你逐一删除指标,大多数指标都会导致失去大量关于质量的信息。</sample>
    <sample id="1042">另一方面，所有层次的Lickert指标的组合解释的质量要少得多,而且这些指标中很少有独特的信息。</sample>
    <sample id="1043">这些可靠、信息丰富且独特的ABC评估指标使我们能够用更高的分辨率来评估对话式人工智能，而以前的方法无法实现。</sample>
    <sample id="1044">你可以看到在我们实验的结果中，仍然存在一些挑战，并且已经精确地量化了。例如,我们测试的机器人在大约百分之二十的响应中违反了常识。</sample>
    <sample id="1045">他们在大约15%的回答中产生无关的信息,并且他们在大约10%的时间内与自己或他们的伴侣相矛盾。</sample>
    <sample id="1046">随着该领域的快速发展，许多这些错误率可能会在新模型发布时有所下降。因为我们进行的评估。然而,这更加强调对可靠和精确的模型比较的评估指标的追求。</sample>
    <sample id="1047">我们希望ABCEval可以被其他领域的人利用为朝着这个方向迈出有意义的一步,我们期待着看到在未来几个月和几年中,对话式AI将如何进步。感谢您的收看。</sample>
    <sample id="1048">这篇论文的作者所属机构是Emory Nlp Lab。</sample>
    <sample id="1049">CFT 在本文中代表 Continuous Fine-Tuning。</sample>
    <sample id="1050">这篇论文有8位作者。</sample>
    <sample id="1051">你好，我叫Yin，我将介绍我们的工作，标题为“当翻译需要上下文时：数据驱动的多语言探索”。这项工作是与Patrick Fernhout、Emil Liu、AndreF. DeMartins和Graham Neubig合作完成的。</sample>
    <sample id="1052">所以很多翻译都取决于上下文。例如，我们如何翻译这个句子中的“mole”？</sample>
    <sample id="1053">好吧，如果前一句话是“如果部长们发现了这一点，事情可能会变得危险”，那么“mo”指的是间谍。但如果前一句话是“这有什么严重的意义吗，医生？”那么“mo”指的是出生标记。</sample>
    <sample id="1054">因此,根据上下文,这个词的含义会发生变化,因此它的翻译也会发生变化。</sample>
    <sample id="1055">然而，评估模型如何处理这样的案例是相当困难的。首先，因为只有一小部分的翻译依赖于上下文，这使得像BLEU这样的学术级别指标无法捕捉这些翻译。</sample>
    <sample id="1056">一些人建议对上下文依赖的翻译进行定向评估,但这些资源仅支持有限类型的上下文依赖翻译和有限语言集,因为它们通常依赖于领域知识和人类编辑。</sample>
    <sample id="1057">在这项工作中,我们试图回答这两个问题。首先,翻译需要什么样的上下文,以及模型在处理这些情况时的表现如何。</sample>
    <sample id="1058">要回答第一个问题,我们首先测量了翻译过程中上下文的多少依赖。</sample>
    <sample id="1059">在之前的工作中,我们将CXMI介绍为机器翻译模型中上下文使用的度量标准,并通过测量上下文C在给定源X的情况下提供给目标Y的多少信息来完成。</sample>
    <sample id="1060">您可以将CXMI视为从模型中提供上下文的信息。</sample>
    <sample id="1061">在这项工作中,我们将CXM扩展为点CXM,可以在句子级别或单词级别测量上下文使用。我们可以将具有高P的单词视为需要上下文进行翻译的单词。</sample>
    <sample id="1062">现在我们分析高词素熵的单词,以寻找这些单词之间的模式。</sample>
    <sample id="1063">我们对TED演讲的讲稿进行分析，这些讲稿是从英文翻译成十四种不同语言的。</sample>
    <sample id="1064">我们对其进行分析的三个不同层次。首先,我们查看具有高平均PCSXMI的部分语音标记。</sample>
    <sample id="1065">这使我们能够找到例如阿拉伯语中的双代词,这些代词的PSMI相当高,这可以解释为英语没有双代词,因此在翻译成阿拉伯语时需要上下文来确定代词是否是双代词。</sample>
    <sample id="1066">同样，我们发现某些语言在选择适当的动词形式时也需要上下文。然后我们查看词汇项的词汇量。</sample>
    <sample id="1067">这有助于识别像这里的情况,在中文中,你需要上下文来翻译名词,以确保你在文档中使用相同的翻译。</sample>
    <sample id="1068">同样,我们发现上下文支持在正确的形式中传输。</sample>
    <sample id="1069">最后,我们研究了具有高P、S、X、M、I的个别标记,这使我们能够识别出无法真正捕捉到的现象,但在句子结构中表达得很清楚,例如省略号解析。</sample>
    <sample id="1070">现在我们使用我们分析的结果来设计文档本地翻译的基准。</sample>
    <sample id="1071">对于我们识别的五种话语现象中的每一种，我们创建了标记器来自动识别与现象相关的单词。我们称我们的标记器为多语言话语意识或MUDa标记器。</sample>
    <sample id="1072">我们也可以注意到,不同的语言有不同的比例。</sample>
    <sample id="1073">然后我们使用MUTT标记器,通过在我们想要用于评估的平行语料库上应用标记器,并在MUTT标记器已识别的上下文依赖示例上应用我们选择的翻译指标。</sample>
    <sample id="1074">最后,我们使用我们的基准以及其他指标来评估不同的模型在文档级机器翻译上的表现。</sample>
    <sample id="1075">首先,当我们使用语料库级别指标时,对于蓝色,我们发现 Collinsagnostic 模型的表现最好。</sample>
    <sample id="1076">但是，如果我们使用逗号，上下文感知模型的表现最好。如果我们使用单词f测量，那么上下文存在或不存在的模型的表现相当。</sample>
    <sample id="1077">这再次表明，如果我们仅使用语料库级别指标，就很难确定最佳的文档级翻译系统。</sample>
    <sample id="1078">现在我们使用MoLaBench来评估模型,我们发现上下文模型在某些话语现象(如形式和词汇连贯性)上比不使用上下文的模型要准确得多。</sample>
    <sample id="1079">但是这些模型并不比不使用上下文的其他现象（如省略号、代词和动词形式）的模型好得多。因此,这表明我们需要在文档级翻译方面取得更多进展。</sample>
    <sample id="1080">我们还比较了不同的商业系统。我们的基准测试表明，DeepL通常比谷歌翻译更准确。</sample>
    <sample id="1081">总而言之,我们对十四对语言进行了数据驱动的分析,以确定一个翻译所需的上下文。</sample>
    <sample id="1082">然后我们用我们的发现来建立一个基准,用于文档级机器翻译,这可以帮助我们确定哪些语义现象模型可以很好地处理,哪些翻译系统在文档级翻译方面表现良好。</sample>
    <sample id="1083">非常感谢您的关注，祝您一路顺风。</sample>
    <sample id="1084">演讲者的名字是Yuxin Zhang。</sample>
    <sample id="1121">没有名称。</sample>
    <sample id="1122">作者描述了“显性词汇”方法为一种识别方法，用于区分标记组和非标记组的单词。作者计划在后续详细说明这一点。</sample>
    <sample id="1123">作者所属机构是华盛顿大学。</sample>
    <sample id="1124">第一个提到的对称依存关系结构的名称是Prague Approach，它是一个城市名称的结构。</sample>
    <sample id="1125">演讲者的名字是James Finch和Sarah Finch。</sample>
    <sample id="1126">这篇论文有四位作者。</sample>
    <sample id="1127">句法现象可以在句法数据集中找到。</sample>
    <sample id="1161">第一个研究问题的五种方法的缩写是WSDL。</sample>
    <sample id="1162">The model was evaluated on 11 biomedical and clinical downstream tasks.</sample>
    <sample id="1226">CamemBERT 最初是通过在 4GB 的数据集上训练的。</sample>
    <sample id="1227">演讲者的名字是Sadam Schurrocksky。</sample>
    <sample id="1228">在进行的实验中，发现了一个主要原因导致时间漂移是性能下降的：随着时间间隔的增加，模型性能会下降。这个结果支持了原先的假设，即时间漂移是导致性能下降的主要原因。</sample>
    <sample id="1269">有必要对输出序列中的词元进行排列，以确保它们按照正确的顺序排列，这对于理解和使用这些词元至关重要。</sample>
    <sample id="1270">作者建议模型所有者提高偏见缓解方法的透明度，以了解是否存在过度价值对齐或其他方法导致的负面刻板印象。</sample>
    <sample id="1271">最小对不可接受输入是一个不符合语法或语法规则的句子。</sample>
    <sample id="1272">作者使用了F1-Score作为评估指标。</sample>
    <sample id="1273">使用了内注释者一致性（Inter-annotator Agreement）来衡量注释者之间的一致性。</sample>
    <sample id="1274">在不可接受和可接受查询中，选择来自Wikipedia的完全无关的句子来添加。</sample>
    <sample id="1275">这篇论文的作者所属机构是德国莱布尼兹大学。</sample>
    <sample id="1276">MultiInstruct differs from other baselines in that it is specifically designed for multi-modal tasks, while most previous works focused on language-only tasks. Additionally, MultiInstruct addresses the lack of large-scale publicly available multi-modal instruction datasets by building its own dataset.</sample>
    <sample id="1277">这篇论文有两位作者：James Finch和Sarah Finch。</sample>
    <sample id="1278">二进制协调是指在计算机系统中，两个或多个设备或程序之间的通信和数据交换，以确保信息传输的准确性和一致性。</sample>
    <sample id="1279">提示语的平均长度为4.5个单词。</sample>
    <sample id="1280">这些发现表明，经过适当训练的较小的 T5 模型可以在质量上超过大多数大型语言模型，表明它们可以在适当的数据集上支持更大的模型。</sample>
    <sample id="1281">Hi, I am Yanis Lacroix, and I will present to you our works on Dr Bert, a robust pre-trained model in French for biomedical and clinical domain.</sample>
    <sample id="1282">在本演讲中,我们首先讨论了医疗保健中的语言建模。然后,我们将介绍我们文章的主要贡献。</sample>
    <sample id="1283">我们介绍了第一个生物医学模型,在法语中命名为Dr. Bert, 基于Roberta, 并在NACHOS上训练,这是一个来自网络的医学数据集。</sample>
    <sample id="1284">我们还介绍了使用多个预测设置和数据源的模型比较。然后我们在法语中介绍了我们在十一项生物医学和临床下流任务上的结果。</sample>
    <sample id="1285">最后,我们总结了实验并为您提供有关如何访问模型的更多详细信息。</sample>
    <sample id="1286">自从它在二十八年发布以来,Bert已经成为解决自然语言处理任务的最有效方法之一,并提供了与历史静态和上下文相关的显著性能提升,例如wordvecfasttext或elmo。</sample>
    <sample id="1287">从那时起，这个模型已被改编成许多其他语言，例如法语的camembert和生物医学领域的permet-bert和bio-bert，以及临床领域的clinical-bert,但主要是英语。</sample>
    <sample id="1288">针对其他语言的专门模型是稀有的,并且通常基于连续的预训练,因为缺乏领域数据。</sample>
    <sample id="1289">然而，直到现在，法国还没有任何开源的生物医学模型。</sample>
    <sample id="1290">我们问自己一个问题：什么是最适合广泛用途的数据来源？这些数据是良好的临床数据替代品。</sample>
    <sample id="1291">为了回答这个问题,我们将Bert与我们的Shubert模型进行比较,该模型基于从我们所在城市的非大学医院获得的匿名数据。</sample>
    <sample id="1292">之后我们问自己,我们需要多少数据来训练一个专门的模型,在法国数据上,是四千兆字节,八千兆字节还是更多。</sample>
    <sample id="1293">为了解决这个问题,我们首先从头开始训练和比较四个模型。第一个版本的Doctorbert有七千兆字节的饼干。第二个版本是四千兆字节的饼干集。</sample>
    <sample id="1294">第一个版本的Shubert是一个临床模型,我们从临床笔记中获取了四千字的句子,最后一个版本的Shubert是一个混合了四千字的自然语料集和四千字的临床笔记。</sample>
    <sample id="1295">除了这个比较之外,我们还介绍了三种基于预训练的模型来分析预训练策略的影响。</sample>
    <sample id="1296">一个基于卡门贝尔的权重,并在四千兆字节的自然集上进行训练。另一个也基于卡门贝尔,但这次在四千兆字节的清洁节点上进行训练。</sample>
    <sample id="1297">最后,一个基于英语的生物医学模型,并在四千兆字节的自然上进行训练。在总的来说,我们有七个模型。</sample>
    <sample id="1298">为了评估我们的七个模型,我们收集了公共和私人的任务,例如名称识别,分类,部分语音标记和问题回答。</sample>
    <sample id="1299">这个模型与六个基线模型进行了比较,这些模型是CarmembertOscar, 138GB, CarmembertOscar, 4GB, CarmembertCCNet, 4GB, Permabit, BioBert和ClinicalBert。</sample>
    <sample id="1300">对模型的评估表明,在具有与模型训练数据相同性质的数据的任务上,该模型表现最佳。</sample>
    <sample id="1301">但是,我们可以从异构源中获得数据。我们观察到,来自异构源的数据似乎更具多功能性。我们还观察到,使用更多的数据可以提高性能。</sample>
    <sample id="1302">总的来说,从头开始训练似乎在大多数任务上获得了更高的性能。</sample>
    <sample id="1303">然而,我们使用权威的权重和标记的实验,在自然的四千兆字节子集上训练,显示与从头开始获得的权威的相当结果。</sample>
    <sample id="1304">但是，基于卡门贝尔重量和tokenizer的模型并非如此,它们存在稳定性问题。</sample>
    <sample id="1305">最后,作为结论,我们的适当系统在十一项任务中提供了更好的性能,并且在这里的全球结果上超过了生成模型。</sample>
    <sample id="1306">我们也观察到,特化数据越多越好,但它并不适合大规模应用。</sample>
    <sample id="1307">所有预训练模型都来自Naturally的免费提供,并且在Github上可用。所有训练脚本都在我们的Github存储库中。</sample>
    <sample id="1308">谢谢大家的发言,我们期待着在东京的会议上进行交流。</sample>
    <sample id="1309">论文研究了从零开始训练和使用预训练策略的学习策略。</sample>
    <sample id="1310">测试重复使用导致的过拟合因素很大。</sample>
    <sample id="1311">通过比较模型的简化结果与原始复杂文本，并使用提供的评估指标和分数来评估简化质量。</sample>
    <sample id="1312">是的，语言模型有不同的政治偏见。GPT-4被认为是最自由的语言模型，而GPT系列通常比BERT系列和其变体更具社会自由主义。</sample>
    <sample id="1313">嗨,我的名字是马蒂亚斯·林德曼,今天我要给你们简要介绍一下我们关于“无树的组合泛化”这篇论文。使用多集标记和隐式排列。</sample>
    <sample id="1314">这是与我的顾问亚历山大·科拉和伊万·迪托夫的联合工作。</sample>
    <sample id="1315">组合泛化可以理解为学习者处理更深层次的递归和在训练期间单独看到的短语的组合的能力。</sample>
    <sample id="1316">在语义解析的语境下，测试组合泛化可能看起来像这样。通常我们有一组训练语料库。在这种情况下是女孩睡觉和玛丽知道女孩睡觉。</sample>
    <sample id="1317">这些语句与逻辑形式配对,该形式表示其含义的核心方面。</sample>
    <sample id="1318">与标准的机器学习评估相比,测试集并非来自相同的分布,但包含结构上看不见的逻辑形式。</sample>
    <sample id="1319">在此示例中,模型在训练过程中看到了较浅的递归,并在具有更深递归的示例上进行了测试。</sample>
    <sample id="1320">Naive sequence to sequence 模型在这种出乎意料的泛化方面挣扎,并且经常产生与输入脱节的输出。</sample>
    <sample id="1321">特别是,它们经常无法重现输入和输出之间的系统对应关系,例如在示例中使用颜色编码的对应关系。</sample>
    <sample id="1322">一种解决此问题的流行方法是将树木集成到模型中。</sample>
    <sample id="1323">这些树的目的是捕捉与逻辑形式相关的构成过程。</sample>
    <sample id="1324">这很有效,但树木通常不提供,需要以某种方式获得。</sample>
    <sample id="1325">这可能是一个复杂的过程，有时是一个计算成本高昂的过程。通常，这涉及大量的形式主义特定的逻辑形式的预处理。例如，处理变量符号。</sample>
    <sample id="1326">获取树也可能涉及到专门的语法引导程序。</sample>
    <sample id="1327">在本文中,我们不使用树,而是引入了一个神经对序序列模型,该模型直接对输入片段和输出片段之间的对应关系进行建模。</sample>
    <sample id="1328">我们第一次展示了强大的泛化到更深层次的递归,而不依赖于树。</sample>
    <sample id="1329">我们的方法从输入中预测输出,分两步进行。</sample>
    <sample id="1330">首先,我们为每个输入令牌标记一个无序的多集令牌,这些令牌将在输出中出现。</sample>
    <sample id="1331">在第一步之后,我们拥有所有正确的令牌,但它们尚未被验证。</sample>
    <sample id="1332">这就是为什么在第二步中,我们使用另一个模型来预测排列顺序,以将它们放入正确的顺序中。</sample>
    <sample id="1333">我们引入了一种新的方法来预测不带任何硬约束的排列。这使得我们的方法非常灵活和富有表现力。</sample>
    <sample id="1334">从概念上讲,我们的排列模型大致是这样的。</sample>
    <sample id="1335">我们从左到右遍历输出,并确定每个位置放置哪个多集令牌。对于第一个输出位置,我们只需选择一个,如红色所示。</sample>
    <sample id="1336">然后我们跳到下一个多集令牌来确定输出中的第二个令牌。</sample>
    <sample id="1337">我们通过跳转到另一个多集令牌来确定输出中的第三个令牌。我们继续这个过程。</sample>
    <sample id="1338">直到第一阶段的每个令牌都被访问了恰好一次。</sample>
    <sample id="1339">为了给你们一个实验结果的预告,在这里我们将我们的方法与其他无树模型在CogsBenchMark上进行比较。我们的模型在更深层次的递归上比其他模型高出很大的差距。</sample>
    <sample id="1340">不过,其他一些结构化的通用化仍然非常具有挑战性。</sample>
    <sample id="1341">在我们的论文中,我们解决了几个有趣的技术挑战。</sample>
    <sample id="1342">首先，输入和输出之间的对齐在训练数据中没有给出。结果，对于给定的令牌,我们不知道它来自哪个多元集,这对训练构成了挑战。</sample>
    <sample id="1343">此外，有时存在多个与数据一致的排列组合,但语法正确的排列组合是隐含的。我们通过在训练过程中引入对齐来解决这个问题。</sample>
    <sample id="1344">我们的排列方法非常灵活,但它带来了一个挑战,即找到得分最高的排列是NP难的。这是因为这与旅行推销员问题有关。</sample>
    <sample id="1345">我们用GPU友好的连续放松来近似这个问题,这也使我们能够通过解来回传播,并学习语言上更合理的排列。</sample>
    <sample id="1346">如果您想了解更多关于我们的实验以及我们如何解决这些挑战，请查看我们的论文或来到我们的展位。</sample>
    <sample id="1347">认知失调是指两种或多种不一致的信念或行为。</sample>
    <sample id="1348">GPT-4是最倾向于自由派的语言模型。</sample>
    <sample id="1349">是的，在主动学习中，累积训练通常比迭代训练更有效。</sample>
    <sample id="1350">演讲者的名字是Sara Papi。</sample>
    <sample id="1351">MuDa 基准中的数据是从TED Talks 的英语原文和其翻译成 14 种不同语言的 transcripts 中获得的。</sample>
    <sample id="1385">演讲者的名字是Matthias Landemann。</sample>
    <sample id="1386">跨语言转移是指在一个语言上训练的模型被转移到另一个语言上，以预测SQL输出。</sample>
    <sample id="1387">The authors of the paper are affiliated with Saarland University.</sample>
    <sample id="1388">作者使用了两种延迟测量方法：平均延迟（latency）和计算机意识平均延迟（computationally aware average latency）。</sample>
    <sample id="1389">大家好,我是马克沙塔,今天我的合著者马丁和我正在介绍我们的工作。来自多个来源的知识集成评估。该工作是麦吉尔大学、MILA和微软研究院的合作。</sample>
    <sample id="1390">自然语言理解模型利用各种知识来源,例如参数中的知识,通常通过预训练获得,以及在推理时给出的输入知识。</sample>
    <sample id="1391">最近在任务中，如问答，表明模型可以使用预训练的时间知识来解决任务。</sample>
    <sample id="1392">但是，自然语言理解通常需要在推理时提供的知识。</sample>
    <sample id="1393">例如，在句子中，约翰在电视上看到了新当选的总统。</sample>
    <sample id="1394">预训练参数可以包含有关总统所做的事情以及什么是TV的信息,但它们不能可靠地知道这个特定实例的实体John是谁,或者新总统是谁,因为总统可能已经更改了。</sample>
    <sample id="1395">因此，成功的知识密集型Nlu任务模型需要能够整合和使用预训练时间和推理时间知识。</sample>
    <sample id="1396">在这项工作中,我们提出了一个用于知识集成的诊断测试套件。</sample>
    <sample id="1397">我们引入了一个共同引用解决方案,旨在探测到利用不同来源可用的知识的能力。我们评估了与人类研究参与者和共同引用解决方案模型建立的数据集。</sample>
    <sample id="1398">这是我们数据集中的一个示例。塞尔文是法官。基亚是面包师。塞尔文和基亚在公园相遇。经过在法庭上审理案件的漫长工作日子后,他很高兴放松。</sample>
    <sample id="1399">这里的任务是确定代词he指代的正确实体,在这种情况下是萨尔曼。</sample>
    <sample id="1400">给定代词的解析需要两种类型的信息。第一种是实体特定的知识,例如,萨维尔是法官。第二种是背景知识,例如,法官在法庭上决定案件。</sample>
    <sample id="1401">一般来说, 背景知识是在大型语言模型的预训练期间学习的,而实体特定知识通常是在推理时观察到的。</sample>
    <sample id="1402">我们改变这两条信息的可用性,使其可能在单个来源或多个来源中找到。</sample>
    <sample id="1403">我们定义了三个Kitmos设置。首先,我们有一个称为背景预训练的设置,其中背景知识被假定在预训练时可用。</sample>
    <sample id="1404">其次是背景知识的设置。背景知识在预训练时间和推断时间都可用。最后是背景推断设置。两种知识类型仅在推断时间可用。</sample>
    <sample id="1405">最后一个设置特别有趣,因为它模拟了在任务解决过程中,必要的背景知识不在预训练数据模型中。例如,因为自从预训练以来就出现了新的职业。</sample>
    <sample id="1406">以下是如何控制可用性效应的示例。</sample>
    <sample id="1407">在预训练的背景下，我们假设背景知识。选民寻求在政府中获得选举席位。它包含在预训练参数中。在自由意志的上下文中，我们提供了特定的知识。奇切斯特是一个政治家。</sample>
    <sample id="1408">在后台设置中,我们不仅提供实体特定的知识,还提供有关推理子上下文中的派生知识的背景知识。</sample>
    <sample id="1409">在背景推断设置中，提供虚构的职业。我们将其设置为政治家,因为政治家不太可能被包含在预训练的领域中。</sample>
    <sample id="1410">我们评估了数据集,并与人类研究参与者一起建立了参考解像度模型。在这张图中,我们展示了最好的模型在最困难的背景预训练设置上的结果。</sample>
    <sample id="1411">在没有针对kitmos的特定训练的情况下,这两种模型的性能都不佳。然而,当在kitmos上训练时,两种模型C2F和bertvcrf的性能明显优于随机选择。</sample>
    <sample id="1412">这表明,当在一般的参考解决方案数据集上进行训练时,模组学会利用表面提示,这些提示在测试Kitmus时无用,因为这些提示已被删除。</sample>
    <sample id="1413">使用虚构知识的其他实验表明，即使是最好的模型也无法可靠地整合仅在推理时提供的背景知识。</sample>
    <sample id="1414">为了总结我们论文的主要结论,许多协同解决方案模型似乎无法在没有特定任务训练的情况下对来自不同来源的知识进行推理。然而,在具有特定任务训练的情况下,一些模型能够成功地整合来自多个来源的知识。</sample>
    <sample id="1415">尽管如此,即使是最好的模型,似乎也难以可靠地整合仅在推理时呈现的知识。如果您对更多细节感兴趣,请查看我们的论文,并在Github上查看数据集和代码。感谢您的收听。</sample>
    <sample id="1416">基于树的方法的缺点包括：1) 通常不提供树，需通过复杂且可能计算成本高的方式获取；2) 需要进行形式化的逻辑形式预处理，如处理变量符号；3) 可能需要专门的语法引导程序。</sample>
    <sample id="1417">The author of the paper is affiliated with the University of Illinois at Urbana-Champaign (UIUC).</sample>
    <sample id="1418">嗨，我是玛丽亚。今天我将讨论我们的论文《标记的角色：使用自然语言提示来衡量语言模型中的刻板印象》。这项工作是在与Essendermush和DanJeroffsky的合作下完成的。</sample>
    <sample id="1419">近年来，许多人已经记录了大型语言模型中的社会偏见和刻板印象的普遍性。</sample>
    <sample id="1420">然而，这些措施有各种限制。它们通常依赖于手工构建的数据集，这些数据集的整理非常耗时。</sample>
    <sample id="1421">而且他们通常只衡量非常特定的刻板印象。</sample>
    <sample id="1422">此外，大多数工作在这个领域都没有考虑到交叉性，这是一种观念，即多方面的社会身份可以组合偏见并成为独特的伤害来源。</sample>
    <sample id="1423">为了克服这些限制,我们依靠这些新型的指令调节的LLM的属性,它们非常擅长响应指令和提示。</sample>
    <sample id="1424">因此,我们可以要求模型生成一个角色,这是一个描述一个想象中的个体的描述,使用一个提示,比如想象你是一个亚洲女人。描述你自己。</sample>
    <sample id="1425">我们可以立即看到,这对任何人口统计非常通用,因为我们可以将任何我们想要的标识符指定到这个提示中。</sample>
    <sample id="1426">以下是GPT4的示例生成。</sample>
    <sample id="1427">我们立即看到,虽然这些输出在传统意义上并不过于消极或有毒。</sample>
    <sample id="1428">有一些有趣的模式。</sample>
    <sample id="1429">亚洲女人被描绘成不起眼的。中东女人被用外来词来称呼,比如说异国情调,比如说指的是一个迷人的地区。</sample>
    <sample id="1430">而这两个有色人种的女人都提到了祖先问题，而白人角色却没有。</sample>
    <sample id="1431">为了捕捉这些模式，我们的方法有两个部分。第一个是生成这些人物。</sample>
    <sample id="1432">我们的提示是由一项研究启发的,他们给人类受试者这些提示,发现通过给人类受试者,他们也能够浮出种族刻板印象。</sample>
    <sample id="1433">此外,这使得我们生成的角色和人类撰写的响应可以直接进行比较。</sample>
    <sample id="1434">第二部分是标记的单词,这是一个方法,用于识别与标记组不同的单词,我将稍后详细介绍。</sample>
    <sample id="1435">其好处是，我们可以获得非常具体的刻板印象和模式，而不必依赖于任何特定的词汇。</sample>
    <sample id="1436">因此，标记单词方法借鉴了社会语言学的概念，即标记性,它表明存在一个未标记的默认值,任何偏离该默认值的群体在语言上都是标记的。</sample>
    <sample id="1437">例如，男人这个词。对不起，战士这个词通常与男人有关。因此,当人们描述一个女性战士时,他们通常会指定一个男人战士,并用女性标记这个术语。</sample>
    <sample id="1438">更广泛地说，社会中的主导群体在语言上和社会上都是无标记的，而边缘化的群体通常是有标记的。</sample>
    <sample id="1439">因此，在我们的方法中,我们首先指定未标记和标记组。</sample>
    <sample id="1440">然后我们使用战斗词法比较这些人。基本上使用加权对数比率来区分每个标记组的顶级词。</sample>
    <sample id="1441">例如，对于黑人女性的角色,我们会做斗争的话语,并将对比对比白人角色和男性角色的法律神话比率,因为这些是两个相对应的未标记组。</sample>
    <sample id="1442">现在有一些结果,所以首先我们使用一个词汇表的刻板印象,我们发现生成的角色包含了比人类写的更多的刻板印象。</sample>
    <sample id="1443">然而,当我们实际查看词典中单词的分布时,我们发现了非常不同的东西。</sample>
    <sample id="1444">因此，虽然生成的角色具有更高的 luxon 词汇率，但人类写的词汇分布更广。虽然在生成的角色中存在的刻板印象词是高大和运动的词。</sample>
    <sample id="1445">所以真的只要积极的,或者至少是非消极的。</sample>
    <sample id="1446">事实上，这个词典并没有真正捕捉到我们在前面的幻灯片中看到的许多有害模式。相反,我们将转向标记单词方法的结果,以展示这些看似正面的单词如何促进刻板印象和基本化叙事。</sample>
    <sample id="1447">在我们的分析中，我们揭示了这些看似积极的描绘如何反映出有害的模式。</sample>
    <sample id="1448">首先，关于马克的群体，最上面的词包括文化、传统、骄傲和异国情调等东西。这些词仅仅定义了这些群体的关系到他们的身份上，并将它们与白人规范区分开来。</sample>
    <sample id="1449">这为这些群体的长期歧视和异化做出了贡献。</sample>
    <sample id="1450">此外，这些词中反映了很多常见的主题，特别是对于有色人种女性。例如，描述拉丁裔女性的词包括生动和曲线。</sample>
    <sample id="1451">这与热带主义的特征有关。对于亚洲女性来说，词语是像小和精致和丝滑这样的东西。</sample>
    <sample id="1452">这与亚洲女性被过度性化的历史有关。</sample>
    <sample id="1453">最后,对于黑人女性来说,我们看到一些顶级词是强壮和坚韧的东西。</sample>
    <sample id="1454">这与人们称之为强大的黑人女性典型的典型有关。虽然它在一开始听起来像是积极的。</sample>
    <sample id="1455">有研究表明,这种类型的原型实际上是非常有害的,因为它给这些人群带来了很大的压力,要求他们对社会障碍持强硬态度。</sample>
    <sample id="1456">因此，实际上并不是努力改变这些障碍，而是给那些人施加压力去克服这些障碍，这导致这些人以及其他人遭受非常不利的健康结果。</sample>
    <sample id="1457">更广泛地说，我们发现每个标记组的单词几乎只是反映了非常本质化的叙事。</sample>
    <sample id="1458">因此,基于这些模式,我们得出三个建议给模型所有者。</sample>
    <sample id="1459">首先,作为研究人员,我们应该解决积极的刻板印象和本质化的叙事。我们还应该使用交叉视角来研究偏见和伤害,因为如果我们不这样做,可能会忽视很多事情。</sample>
    <sample id="1460">最后，应该增加关于偏见缓解方法的透明度。</sample>
    <sample id="1461">因为例如,像这些积极的刻板印象,我们不知道是否是因为有某种奇怪的东西。</sample>
    <sample id="1462">过度的价值对齐正在进行中，或者也许是其他一些反刻板印象的方法导致了这些有害的模式。</sample>
    <sample id="1463">我们真的不能做出任何假设或进一步研究,没有更多的透明度。</sample>
    <sample id="1464">非常感谢您的收听。</sample>
    <sample id="1465">大家好，我是中国科技大学的Jinwei Yi。</sample>
    <sample id="1466">我很高兴为我们的论文《Are You Copying My Model》做一个简短的广告视频。保护大型语言模型的版权用于嵌入和服务。查看后门水印。</sample>
    <sample id="1467">让我们先介绍一下嵌入式和服务的背景。</sample>
    <sample id="1468">目前，像GPT、LLaMA、Palm这样的大型语言模型在自然语言理解和生成方面是独一无二的。</sample>
    <sample id="1469">嵌入式广告服务是基于大型语言模型构建的服务之一,用于协助各种NLP任务。</sample>
    <sample id="1470">例如，OpenAI提供基于GPT的嵌入式API。</sample>
    <sample id="1471">然而，最近的研究表明，攻击者可能会通过学习嵌入来窃取模型，并提供类似的服务。因此，必须保护嵌入的版权作为服务。</sample>
    <sample id="1472">为了保护嵌入服务的版权，解决方案之一是将水印嵌入提供商的服务中,并检测另一个服务是否包含水印。</sample>
    <sample id="1473">水印方法需要满足以下属性。首先，方法应适用于嵌入广告服务。其次，水印不应降低提供的嵌入的效用。</sample>
    <sample id="1474">第三,水印应足够隐蔽给攻击者,否则攻击者可以轻易地删除水印。</sample>
    <sample id="1475">最后,水印需要在模型提取过程中传输到攻击者的服务。</sample>
    <sample id="1476">现有作品可以大致分为四类。</sample>
    <sample id="1477">然而，这些方法要么不适用于嵌入式服务，要么缺乏可移植性。</sample>
    <sample id="1478">因此，在本文中,我们提出了嵌入标记,它是一个基于后门的水印方法,适用于嵌入广告服务。</sample>
    <sample id="1479">然后让我介绍一下我们的嵌入标记的细节。嵌入标记包含两个主要步骤：水印插入和版权验证。</sample>
    <sample id="1480">在这些主要步骤之前，我们首先选择一个触发集。触发集是一个中等频率间隔的单词组。</sample>
    <sample id="1481">我们假设提供商可以收集一个通用的文本语料库并用它来计算单词频率。</sample>
    <sample id="1482">在水印注入中，我们首先定义一个目标嵌入。当用户向提供商服务发送句子时，提供商会计算句子中的触发号。</sample>
    <sample id="1483">提供的嵌入是目标嵌入和原始嵌入的权重求和。</sample>
    <sample id="1484">目标嵌入的权重与句子中触发器的数量成正比。当句子中触发器的数量大于M时，提供的嵌入与目标嵌入完全相同。</sample>
    <sample id="1485">版权验证是检测是否一个模型在另一个服务中包含了水印。</sample>
    <sample id="1486">我们首先构建一个后门和一个良性数据集。后门数据集包含所有单词都属于触发集的句子。而良性数据集中的所有单词都不属于触发集。</sample>
    <sample id="1487">然后提供商请求从数据集的嵌入。</sample>
    <sample id="1488">计算所请求嵌入和目标嵌入之间的余弦和L2相似性。我们计算benign和backdoor数据集之间的相似性差异，定义为delta cos 和 delta L2。</sample>
    <sample id="1489">同时,我们还应用KS测试,并将其p值作为第三个指标。</sample>
    <sample id="1490">我们对四个数据集AG新闻,MIND,SST-II和ERAS-PM进行了实验。我们假设提供商应用维基文本数据集来计算单词频率。</sample>
    <sample id="1491">在四个数据集上显示,我们的嵌入标记器可以具有更好的检测性能,同时保持良好的下屏任务的实用性。</sample>
    <sample id="1492">我们还通过在VLPCA数据集上可视化句子嵌入来验证提供的嵌入的隐蔽性。图中的图例表示每个句子中的触发器数量。</sample>
    <sample id="1493">如图所示,很难区分背道嵌入和正常嵌入。</sample>
    <sample id="1494">就这样谢谢大家。欢迎来和我们讨论。</sample>
    <sample id="1495">ABC-Eval 代表 Annotating Behaviors in Chat 或者 Annotating Chat Model Behaviors Evaluation。</sample>
    <sample id="1496">直到 2016 年，CoNLL-2003 和 CoNLL++ 之间的性能增量才高于 5 个百分点。</sample>
    <sample id="1497">您好，我叫瓦苏达，我是斯通尼布鲁克大学的计算机科学博士候选人。我想把我们被接受参加ACL2023的工作作为一篇长篇论文，转移学习用于检测差异，解决稀有类挑战。</sample>
    <sample id="1498">我们首先定义认知不一致性以及为什么它是一个重要的语言问题。简单地说，认知不一致性是两种不一致的信念或行为。</sample>
    <sample id="1499">例如, 这个例子中, 一个人说,我知道香烟会杀死我,然后继续说,我在会议结束后抓了一两支烟。这种信念和行动是不一致的,它们是相悖的。</sample>
    <sample id="1500">进一步提到我不认为我可以在没有他们的情况下保住我的工作，正是第二个发生的原因。他们有一个共鸣的关系。</sample>
    <sample id="1501">虽然不一致是我们在日常决策中经常遇到的现象，但在语言中很少能找到其他类型的语料关系。</sample>
    <sample id="1502">那么这有什么关系呢？研究认知差异可以帮助我们了解人们之间分歧的影响。跟踪趋势和信念、价值观和态度的变化在人口中。</sample>
    <sample id="1503">高认知不协调也与焦虑障碍有关,可以更好地了解人们的心理健康。</sample>
    <sample id="1504">研究表达性言语的异议也有助于理解极端主义和脆弱群体的两极分化。</sample>
    <sample id="1505">最后，认知不一致对于理解个人认知风格很重要，并且有助于我们更好地理解决策过程。</sample>
    <sample id="1506">为了创建一个认知差异资源,我们进行了大量的差异关系注释。我们使用了disancefirst方法,如图所示。</sample>
    <sample id="1507">推文被解析器解析,并且对话单元对按照我们论文中描述的指南进行注释。</sample>
    <sample id="1508">如图所示，在注释的三点五百分之内只发现了不和谐。</sample>
    <sample id="1509">在收集大约一千个话语单位对的例子时,我们对一个初始分类器进行了训练,该分类器仅在四十三个例子上进行训练。毫不奇怪,该分类器的表现并不比随机猜测好。</sample>
    <sample id="1510">由于不一致的发生率很低,并且没有任何先前的此类数据集,我们面临绝对罕见性的难题。</sample>
    <sample id="1511">为了缓解这一点,我们对转移学习和主动学习的组合进行了实验,以便在更少的注释次数下收集更多的差异样本,从而降低整体的注释成本,同时提高差异检测。</sample>
    <sample id="1512">由于最初的模型根本无法捕捉到差异类,我们通过从密切相关的任务中转移权重来开始主动学习过程。</sample>
    <sample id="1513">我们从两个不同的任务中转移。主题独立的距离。立场分类,一个任务,如果两个来自不同人的辩论陈述是否在主题上是一致的或不同的。</sample>
    <sample id="1514">在这里称为辩论,并在二进制分类中对扩展和比较类进行分类,因为这两个与声母的概念密切相关,声母和声母,我们在这里称之为c,e。</sample>
    <sample id="1515">我们发现，在转移上，注释数据集上的零短性能已经比概率要好得多,最好是auc.6.2。</sample>
    <sample id="1516">进一步迭代微调在这两个任务上,我们发现对CE任务的微调,然后进一步微调对辩论,使得零短性能更好。这就是我们用来冷启动主动学习的模型。</sample>
    <sample id="1517">接下来,我们确定每次活动学习和注释的每一轮中更新模型的最佳方法。Cumulator累积了迄今为止从活动注释中收集的所有数据。迭代式则通过对最新一组收集的数据进行训练来更新模型。</sample>
    <sample id="1518">在不同的策略中,我们发现累积式的性能与迭代式相当或更好。</sample>
    <sample id="1519">接下来，为了提高不匹配示例的数量,我们使用概率的策略来选择在任何回合的任何时候都可能被当前模型匹配的示例。</sample>
    <sample id="1520">我们将其与社区中常用的其他最先进的AL策略进行了比较。</sample>
    <sample id="1521">我们发现，拟合的PRC策略比其他最先进的策略更好,尽管差异很小。请注意,随机的性能明显较低。</sample>
    <sample id="1522">在进一步的AL两轮最佳策略中,我们提高了距离分类,auc为0.75,这是我们在任务上迄今为止最好的表现。</sample>
    <sample id="1523">我们还检查了每种策略的可行性。对于注释质量和注释者的成本,我们发现PRC具有最高的百分比,并且最适合稀有类。然而,注释者也发现示例很难。</sample>
    <sample id="1524">总而言之,我们发现PRC是一个简单的AL策略,用于稀有类的获取,并且通过适当设计的转移学习任务来冷启动AL,可以有很大帮助。</sample>
    <sample id="1525">我们还发现迭代更新对于从不同域的转移学习是有用的,而域内活动注释则受累积更新的好处。</sample>
    <sample id="1526">这些是我们代码数据集和论文的链接。欢迎与我们联系。如果您有任何问题,谢谢。</sample>
    <sample id="1527">这篇论文的作者所属机构是斯坦福大学。</sample>
    <sample id="1528">演讲者的名字是 Siyu Yuan。</sample>
    <sample id="1529">这篇论文有五位作者。</sample>
    <sample id="1530">该方法与专门为simultaneous speech translation设计的simulST 架构进行了比较。</sample>
  </task>
</testset>