<testset name="IWSLT2025" type="output">
  <task track="long" text_lang="de">
    <sample id="0">Die wichtigsten Datenquellen für Sprachmodelle sind politische Nachrichtenmedien wie New York Times, Los Angeles Times, The Guardian, Huffington Post, die in den Trainingsdaten weit verbreitet sind.</sample>
    <sample id="1">Die Autoren gehören der McGill University an.</sample>
    <sample id="2">Die Präsentation von Yu Yi von edgroup konzentriert sich auf ein Paper über Dokumentverständnis, das visuell reiche Dokumente wie Formulare und Rechnungen behandelt. Es untersucht die Herausforderungen der globalen Lesereihenfolge und schlägt vor, lokale 1D-Positionen zu verwenden, um diese zu überwinden. Die Methode, Layout-Mask, verwendet Text-Layout-Interaktionen, um die Lesereihenfolge zu verbessern. Zwei Masking-Strategien, Whole-Word-Masking und Layout-Aware-Masking, werden eingeführt, um Text-Layout-Interaktionen zu fördern. Ein neues Pretraining-Ziel, Masked Position Modeling, wird ebenfalls eingeführt. Die Ergebnisse zeigen, dass globale 1D-Positionen besser sind, insbesondere bei Datensätzen mit mehreren Entitäten.</sample>
    <sample id="3">Hallo, ich bin Omar und werde über die Verwendung unserer Datensatz Deepane sprechen. Für den ersten Fall können wir die Methoden zur automatischen Ausrichtung bewerten. In den letzten Jahren gab es viele Ausrichtungsmethoden. Im Kontext von maschinellen Übersetzungen möchten wir Ausrichtungen von Sätzen in zwei parallelen Dokumenten in verschiedenen Sprachen extrahieren. In unserem Fall haben wir jedoch zwei parallele Dokumente mit demselben Inhalt, aber unterschiedlichen Komplexitätsgraden. Mit unserem Datensatz Deepane, der Sätze manuell ausgerichtet hat, können wir diese Sätze als Standardausrichtungen verwenden, um einige der vorgeschlagenen Ausrichtungsmethoden zu bewerten. Wir haben einige Anpassungen an die vorgeschlagenen Methoden vorgenommen und die Codes, um Experimente zu führen, in der Arbeit veröffentlicht. Am Ende haben wir festgestellt, dass die beste Ausrichtungsmethode für die deutsche Textausrichtung die Methode von Mass Align ist. Sie können auch die Codes finden, um diese Methode auf Ihre eigenen Dokumente auszuführen. Der zweite Fall, den wir in unserer Arbeit gezeigt haben, ist der Fall der automatischen Textausrichtung durch Feinabstimmung von Sprachmodellen, um komplexe Eingabedateien in vereinfachte Textversionen zu produzieren. Wir haben zwei verschiedene Modelle feinabgestimmt, um Dokument- und Satzebeneausrichtungen zu produzieren. Sie können auch die Checkpoints und die Ergebnisse unserer Experimente in der Arbeit finden. Wir haben festgestellt, dass diese grundlegende Feinabstimmung oder die Erzielung von Punktzahlen besser als die Basismessungen sein kann. Wir schlagen diese Ergebnisse als Basis für die zukünftige Problematik der automatischen Textausrichtung vor. Vielen Dank für Ihre Aufmerksamkeit und ich hoffe, Sie während der Konferenz zu treffen. Vielen Dank.</sample>
    <sample id="4">Der Referent ist Ms. Kayo Yin.</sample>
    <sample id="5">Das T5-XL-Modell.</sample>
    <sample id="6">Zhang und Kollegen präsentieren ihre Arbeit an einem neuen Modell namens Pisces, das Multilingual- und Crosslinguistische Zusammenfassungen in einem einheitlichen Rahmen kombiniert. Das Modell, das auf dem mBERT50-Framework basiert, zielt darauf ab, Dokumente in jeder Sprache zu zusammenfassen und in jeder Sprache zu generieren. Durch eine sorgfältig konzipierte dreistufige Trainingstechnik, die multilinguales, Crosslinguistisches und summarisierendes Wissen umfasst, zeigt Pisces eine verbesserte Leistung gegenüber bestehenden Modellen wie MBERT50 und MT5. Die Ergebnisse der Experimente und Evaluierungen deuten darauf hin, dass Pisces eine bessere Fähigkeit hat, Wissen über verschiedene Sprachen zu übertragen. Darüber hinaus wurden Ablationsstudien und menschliche Bewertungen durchgeführt, um die Wirksamkeit und die Vorteile des Modells zu bestätigen.</sample>
    <sample id="7">Ja, CoNLL-2003-Tagger funktionieren noch, aber Verbesserungen in Modellarchitektur, Größe und Trainingsebenen sind für bessere Generalisierung erforderlich.</sample>
    <sample id="8">Die neue Methode, ABC Evaluation, reduziert die Subjektivität menschlicher Bewertungen, indem sie spezifische Verhaltensweisen in Chat-Modellen annotiert, wie z.B. Irrelevanz, Selbstkontradiktionen und emotionale Engagement.</sample>
    <sample id="9">Der Erfolg des bestehenden schwach überwachten Ansatzes hängt von der Verfügbarkeit von sauberen Validierungsdaten ab.</sample>
    <sample id="10">Das Ergebnis kann durch Zugang zu teilweise überlappenden Hintergrundinformationen verbessert werden, was die Genauigkeit auf 82-87% erhöht.</sample>
    <sample id="11">Jack Hessel, a research scientist at AI2, presents a study on humor understanding benchmarks using the New Yorker Caption Contest. The study, a collaboration with several universities and companies, evaluates large language models like ChatGPT and GPT-4 on tasks such as joke matching, quality ranking, and explanation generation. Despite advancements, these models still struggle with humor comprehension, as evidenced by their performance compared to human benchmarks. GPT-4, for instance, performs poorly in joke explanation tasks, with human explanations preferred in most cases. The study aims to encourage further research and development in the field of AI humor understanding.</sample>
    <sample id="12">Die Arbeit wurde von Dawei, Xiaoxuan, Mario Musbach, Giasdeth, und Dittlich Klockow durchgeführt.</sample>
    <sample id="13">Daniel Rotem präsentiert seine Arbeit über die Analyse und Verbesserung der adaptiven Inferenz in ressourcenbeschränkten Umgebungen. Adaptive Inferenz reduziert die Inferenzzeit großer Sprachmodelle, indem sie auf der Variabilität der Komplexität der realen Daten basiert. Er beschreibt die Methoden Multi-Model und Early Exit, ihre Vor- und Nachteile und die Hypothese, dass die gemeinsamen Parameter in Early Exit zu Konflikten in den Gradienten führen. Er testet diese Hypothese und präsentiert SWEET, eine Methode zur Feinabstimmung von Early-Exit-Architekturen, die die Leistung verbessert.</sample>
    <sample id="14">Hallo. Mein Name ist Adam Szpekowski, und in diesem Vortrag geht es um die Abhängigkeit der Koordinationsstruktur. Wie Sie wissen, haben verschiedene Abhängigkeitsstrukturen unterschiedliche Kopfsätze. So ist in universellen Abhängigkeitsstrukturen der Kopfsatz der Kopf der Koordinationsstruktur, also in diesem Fall Lisa. Ein ähnlicher Ansatz wird in der Bedeutungstexttheorie angenommen, wo auch der Kopfsatz der Koordinationsstruktur der Kopf ist. Dies sind also symmetrische Strukturen. Es gibt auch symmetrische Strukturen, wie die in der Pragmatischen Abhängigkeitsbank, wo Koordinationsstrukturen vom Kopfsatz des Konjunktivs angeführt werden. Und schließlich gibt es eine mehrköpfige Struktur, die zum Beispiel in der Wortgrammatik verwendet wird, wo alle Konjunktionen Kopfsätze der Koordinationsstruktur sind. So erhalten wir Abhängigkeitsverbindungen vom Kopfsatz des Konjunktivs zu allen Konjunktionen. Die Zielsetzung dieses Papiers ist es, ein neues Argument für symmetrische Koordinationsstrukturen wie diese zu liefern und gegen asymmetrische Strukturen wie diese. Das Argument basiert auf dem Prinzip der Abhängigkeitslänge. Die Länge der Abhängigkeitsverbindungen wird anhand von Beispielen erklärt. In Englisch bevorzugen direkte Objekte, die dem Verb nahe stehen, während Adjektive weiter entfernt sein können. So ist es in der Phrase "Marge hat gestern ein Buch über Bienen gelesen" in Ordnung, weil das direkte Objekt, das Buch, dem Verb nahe steht. In der Phrase "Marge hat gestern ein Buch über Bienen gelesen" ist es jedoch viel schlechter, weil zwischen dem Verb und dem direkten Objekt die Adjektivphrase "gestern" steht. Dies ist jedoch möglich, weil, obwohl diese Phrase die allgemeine Grammatikregel verletzt, sie das Prinzip der Abhängigkeitslänge erfüllt, das besagt, dass kürzere Abhängigkeitsverbindungen bevorzugt werden. Diese beiden Bäume zeigen nur die Länge der entscheidenden Abhängigkeitsverbindungen. Diejenigen, die nicht konstant sind, sind hier die Abhängigkeitsverbindungen von read zu der Adjektivphrase von length sieben und von read zu book von vier. Wenn wir diese beiden Abhängigkeitsverbindungen tauschen, wird die Summe dieser beiden Abhängigkeitsverbindungen auf sechs, also viel kürzer. Das ist der Grund, warum dies in Ordnung ist. Es verstößt eine Regel, aber es erfüllt eine andere. Was wir getan haben, ist, dass wir verschiedene Abhängigkeitsstatistiken aus der verbesserten Version von Pen und der Pen-Treebank extrahiert haben. Und sehen Sie, warum wir universelle Abhängigkeitsstrukturen verwenden. Und diese Statistiken bestätigen die Beobachtung, die viele Male gemacht wurde, dass linke Konjunktionen kürzer sind. Und auch die Beobachtung, dass diese Tendenz mit der Länge der Unterschied wächst. Wenn also der Unterschied zwischen den beiden Konjunktionen wächst, ist die linke Konjunktion stärker. Aber was neu in diesem Papier ist, ist, dass wir beobachtet haben, dass diese Tendenz nur auftritt, wenn der Gouverneur auf der linken Seite ist. Also ist der Gouverneur auf der linken Seite, in dieser Phrase, ist der Kopfsatz. In der zweiten Phrase, "Homer kam und nieste", haben wir Koordination von zwei Verben und keinen externen Gouverneur. Also ist die Koordinationsstruktur von zwei Konjunktionen. In solchen Fällen ist die linke Konjunktion, die kürzer ist, die erste. Aber wenn der Gouverneur auf der rechten Seite ist, wie hier, "Ich habe Bart und Lisa gesehen", ist der Gouverneur auf der linken Seite. In solchen Fällen ist diese Tendenz nicht vorhanden. Wir zeigen, indem wir die Länge in Buchstaben, die Länge in Silben und die Länge in Wörtern messen, wie diese Tendenz. Was wir hier sehen, ist, dass, wenn der Gouverneur auf der linken Seite ist, die Tendenz für die linke Konjunktion, die kürzer ist, mit der absoluten Wortlänge zunimmt. Und das ist auch beobachtet, wenn es keinen Gouverneur auf der linken Seite gibt, wie in der Koordinationsphrase. Und wir zeigen, wie dies ein Argument gegen asymmetrische Koordinationsstrukturen wie diese und für symmetrische Strukturen wie diese liefert. Also sehen Sie das Papier für die vollständige Übereinstimmung und Argumentation. Und sprechen Sie in der Nachsitzung mit uns.</sample>
    <sample id="15">Drei Autoren sind an der Arbeit beteiligt: Matthias Landmann, Alexander Coller und Ivan Tiedoff.</sample>
    <sample id="16">Bibeltexte werden als stärker vereinfacht im Vergleich zu News-Texten und Sprachlerntexten.</sample>
    <sample id="17">Shen Chuan Wu, a PhD student, presents a multimodal relation extraction method addressing challenges in extracting semantic relations from diverse data forms. The method integrates text and visual data, using a cross-modal graph to refine information and enrich context with multimodal topic features. Experiments show improved performance over existing models, with internal information screening and external information exploitation being crucial for different data relevance levels.</sample>
    <sample id="18">Ein Beispiel für die Präferenz für kürzere linke Konjunktionen ist: 'Salt and pepper' vs. 'Pepper and salt'.</sample>
    <sample id="19">Xiang Su Cheng, ein Masterstudent von Shenzhen University, präsentiert die Arbeit "Survey for Efficient Open Domain Question Answering" bei ACL 2023. Die Arbeit zielt darauf ab, effiziente Open-Domain-Question-Answering-Systeme zu entwickeln, die weniger Speicher benötigen und schneller sind. Die Arbeit untersucht die Herausforderungen der Verarbeitung großer Datenmengen und der Verwendung komplexer Modelle. Sie schlägt Techniken vor, um die Indizierung zu reduzieren, die Modellgröße zu verringern und die Antwortzeit zu verbessern. Die Analyse zeigt, dass Retrieval- und Reader-Systeme eine gute Balance zwischen Geschwindigkeit, Speicher und Leistung bieten. Die Arbeit schlägt vor, dass bei Ressourcenbeschränkungen Generator-Only-Systeme oder Embedding-Compression in Betracht gezogen werden sollten, während Retrieval-Only-Systeme für Echtzeitfeedback geeignet sind. Die Arbeit schlägt auch die Notwendigkeit von mehr Evaluationsmetriken und der Einsatz in ressourcenbeschränkten Geräten vor.</sample>
    <sample id="20">Ja, alle Modelle sind kostenlos und verfügbar auf Hugging Face, zusammen mit den Trainingsskripten auf GitHub.</sample>
    <sample id="21">DEplain-apa enthält Dokumente aus Büchern.</sample>
    <sample id="22">Gute Generalisierung wird durch die Verwendung von Transformer-Modellen, größere Modellgrößen und mehr Fine-Tuning-Beispiele erreicht.</sample>
    <sample id="23">In seiner Rede diskutiert Dan Garrett die Herausforderungen bei der Text-zu-Bild-Generierung durch Text-Image-Modellierung. Er hebt die Schwierigkeiten von Modellen wie T5 hervor, die aufgrund ihrer Satz-Tokenisierung Schwierigkeiten haben, Wörter korrekt zu buchstabieren. Im Gegensatz dazu zeigen Modelle wie ByteT5, die auf einzelnen Bytes basieren, eine verbesserte Spracherkennung. Um die Text-Rendering-Fähigkeiten zu verbessern, hat Garrett ein Modell namens DrawText entwickelt, das die T5-Textrepräsentation mit der ByteT5-Charakterrepräsentation kombiniert. Diese Methode verbessert die Spracherkennung, ohne die Modellgröße signifikant zu erhöhen. Trotz dieser Verbesserungen kann das Diffusionmodell Fehler einführen, was die Text-Rendering-Fähigkeiten nicht vollständig verbessert.</sample>
    <sample id="24">Die Tendenz zu kürzeren linken Konjunktionen wurde durch die Analyse von Sätzen in der Enhanced Version of Penn Treebank gemessen, wobei die Länge in Silben, Wörtern und Sätzen berücksichtigt wurde.</sample>
    <sample id="25">Die Experimente wurden durch die Analyse von Coordination-Statistiken aus der Enhanced Version von Penn Treebank durchgeführt, wobei die Länge der Konjunktionen in verschiedenen Kontexten mit und ohne einen Begrenzers auf der linken oder rechten Seite untersucht wurde.</sample>
    <sample id="26">Ein Basisklassifikator, trainiert mit unausgewogenen Daten, zeigt eine Leistung, die nicht wesentlich besser ist als zufällige Vorhersagen, was auf die unzureichende Verfügbarkeit von Dissonanzbeispielen hinweist.</sample>
    <sample id="27">Die Arbeit wurde von einem einzigen Autor, Xianbing Zhang, verfasst.</sample>
    <sample id="28">Die Personen im Beispielgespräch sind Javad Hosseini, Philip Radlinsky, Silvia Parati und Annie Luis.</sample>
    <sample id="29">Kontextsensitive Modelle schneiden besser bei Diskursphänomenen wie Formale und Lexikalische Kohäsion ab, während sie bei anderen wie Ellipsen, Pronomen und Verbform mit kontextsagnostischen Modellen vergleichbar abschneiden.</sample>
    <sample id="30">Die Blender-Frameworks Einführung ist ein einfaches, aber effektives Ansatz für das Ensemble-Lernen von großen Sprachmodellen. Es basiert auf parallelen Rankings und generativen Fusionen, um die beste Modellauswahl für verschiedene Eingaben zu bestimmen. Die Blender-Frameworks zweistufige Pipeline umfasst das Ausführen von N-Modellen, um ihre Ergebnisse zu sammeln, und das Verwenden eines Power-Rankers zur Bewertung dieser Ergebnisse. Der Power-Ranker verwendet parallele Vergleiche, um die Qualität der Modelle zu bewerten, was zu einer besseren Modellauswahl führt. Die Blender-Frameworks Leistung wurde durch die Mix-Inst-Set-Datenbank getestet, die aus bestehenden Datensätzen und Ergebnissen von 11 Open-Source-Modellen besteht. Die Ergebnisse zeigten, dass Blender in 68% und 76% der Fälle die Leistung von Open-Assistant und Vacuna übertrifft. Die Blender-Frameworks einfache und effektive Natur macht es zu einem vielversprechenden Ansatz für das Ensemble-Lernen.</sample>
    <sample id="31">Die Autoren gehören der Universität Oxford an.</sample>
    <sample id="33">Das Framework quantifiziert die Positionalität, indem es Daten mit verschiedenen Anotatoren neu annotiert und diese Anotationen mit den Vorhersagen und Labels von Modellen vergleicht, wobei Pearson's R-Korrelation verwendet wird.</sample>
    <sample id="34">Marcus Trevisos Arbeit präsentiert CREST, ein Framework, das rationale Erklärungen und kontrafaktische Textgenerierung kombiniert. CREST verwendet rationale Erklärungen, um Input zu maskieren und zu modifizieren, um kontrafaktische Beispiele zu erstellen. Diese Methode wird mit menschlicher Bewertung und Datenaufrichtung getestet, wobei CREST herausragende Ergebnisse in der Validität und natürlichen Erklärungen erzielt. Im Vergleich zu anderen Methoden zeigt CREST eine höhere Kontrafaktualität und führt zu besseren Modellleistungen, insbesondere bei Auto- und Domain-Daten. Die Ergebnisse deuten darauf hin, dass CREST eine robuste Lösung für die Verbesserung von Klassifikationsmodellen durch die Erzeugung von hochqualitativen, interpretierbaren Erklärungen bietet.</sample>
    <sample id="36">Der Vortrag von Thomsuapietsch und Kollegen über die Entwicklung von Language-Specific Layers (LSLs) für Multilingual Machine Translation (MT) zielt darauf ab, die Effizienz und Genauigkeit der Übersetzungen zu verbessern. Die LSLs ermöglichen es, dass ein Modell für mehrere Sprachen trainiert wird, was die Größe und Komplexität reduziert. Durch die Verwendung von LSLs können die Inferenzkosten konstant gehalten werden, während die Modellgröße erhöht wird. Die Forschung konzentriert sich auf die Platzierung der LSLs, wobei die Encoder-Position als effektiv erachtet wird. Die Ergebnisse zeigen, dass die LSL-basierte Architektur signifikante Verbesserungen gegenüber herkömmlichen Methoden bietet, insbesondere für Sprachen mit geringeren Ressourcen. Die Ergebnisse sind statistisch signifikant für die meisten Sprachen, was die Wirksamkeit der Methode unterstreicht.</sample>
    <sample id="37">Die vorherige Studie ergab, dass die menschlichen Teilnehmenden, die die Persona-Prompts erhielten, ebenfalls rassistische Stereotypen auftraten.</sample>
    <sample id="38">Die Studie verwendete Daten aus der Enhanced Version von Penn Treebank und dem Datensatz Why Wont You Use Universal Dependencies.</sample>
    <sample id="39">Es gibt zwei Autoren: Adam Szarkowski und ein weiterer, der nicht genannt wird.</sample>
    <sample id="40">Eng verwandte Aufgaben für kognitive Dissonanz sind 'Debate' und 'Binary Classification'.</sample>
    <sample id="41">Das Projekt von Su Lin und dem Natural Language Processing Lab an EPFL University, in Zusammenarbeit mit Sony Group Corporation, zielt darauf ab, personalisierte, kohärente und fesselnde Erzählungen zu schaffen. Das Projekt entwickelt das Peacock, ein personalisiertes Wissensnetzwerk, das 3.800 Personen und 40.000 Attributen umfasst, die 100.000 personalisierte Inferenzmöglichkeiten bieten. Peacock wird durch eine Kombination aus menschlicher und künstlicher Expertise annotiert, was zu einer hohen Genauigkeit von 87% bei der Person-zu-Person-Relationen führt. Das Projekt zeigt, dass Peacock als zuverlässige Wissensbasis für personalisierte Sprachmodelle wie Comet-BART und Dialogsysteme wie P-Square-Bolt verwendet werden kann, was zu besseren Ergebnissen in der natürlichen Sprachgenerierung und Dialogerzeugung führt.</sample>
    <sample id="42">Die Arbeit wurde von einem einzigen Autor, Shuo-Hung, durchgeführt.</sample>
    <sample id="43">Es gibt zwei Autoren an der Arbeit.</sample>
    <sample id="44">Das vorgestellte Framework unterscheidet sich von bisherigen Arbeiten, indem es die Re-Annotierung von Datensätzen mit einer breiteren Palette von Anotatoren durchführt, um eine reichhaltigere demografische Daten zu erhalten. Es vergleicht diese Anotationen mit den Vorhersagen von Modellen, anstatt sich auf die Übereinstimmung der Anotatoren oder die Verteilung der Anotatoren zu konzentrieren. Dies ermöglicht eine direktere Analyse, wie gut Modelle und Datensätze mit realen Benutzern übereinstimmen.</sample>
    <sample id="45">Das Setup mit den generierten Personas hat die meisten Überschneidungen mit dem Lexikon der Stereotypen.</sample>
    <sample id="46">Die Studie verglich DeepL und Google Translate, wobei DeepL in der Regel als genauer für Dokumentenlevel-Übersetzungen herausragend herausgestellt wurde.</sample>
    <sample id="47">Ich bin ein Doktorand an der University of Washington. Heute präsentiere ich unsere Arbeit von der Vorabdaten bis zu den Sprachmodellen, die den Weg von politischen Vorurteilen zu unfairen NLP-Modellen verfolgen. Sprachmodelle werden auf großen Web-Crawl-Daten trainiert. Politische Nachrichtenmedien sind in ihren Vorabdaten gut abgedeckt. Laut einer Umfrage des C-4-Korpus sind New York Times, Los Angeles Times, The Guardian, Huffington Post usw. in den Vorabdaten von Sprachmodellen gut abgedeckt. Dies hat sowohl Vor- als auch Nachteile für Sprachmodellanwendungen. Auf der einen Seite können sie aus vielfältigen Perspektiven lernen, die Demokratie und die Vielfalt der Ideen feiern. Auf der anderen Seite sind diese unterschiedlichen politischen Meinungen inhärent sozial voreingenommen und können zu Fairnessproblemen in Downstream-Aufgaben führen. Um dies zu untersuchen, schlagen wir vor, Sprachmodelle mit verschiedenen Promptformaten zu testen, wie z. B. den politischen Fragebogen, der eine automatische Bewertung im Rahmen der politischen Wissenschafts-Literatur sicherstellt. Einige vorläufige Ergebnisse zeigen, dass Sprachmodelle unterschiedliche politische Neigungen haben. Sie besetzen alle vier Quadranten des politischen Kompasses. Wir können auch sehen, dass GPT vier das liberale Sprachmodell von allen ist, und GPT-Serien im Allgemeinen sozial liberale Sprachmodelle sind, die von BERT-Serien und ihren Varianten abweichen. Zweitens untersuchen wir, inwieweit die politischen Vorurteile von Sprachmodellen tatsächlich von den Trainingsdaten übernommen werden. Wir führen also ein kontrolliertes Experiment durch, indem wir Sprachmodelle auf sechs verschiedene parteiische Corpora weiter trainieren, die in Nachrichten und soziale Medien unterteilt sind. Durch das weiter Vortrainieren von Sprachmodellen auf solche parteiischen Corpora können wir sehen, dass sich auch die ideologischen Koordinaten der Sprachmodelle entsprechend verschieben. Zum Beispiel, wenn wir Roberta weiter trainieren, können wir einen erheblichen liberalen Verschiebung in Bezug auf ihre politischen Vorurteile sehen. Wir versuchen auch zu untersuchen, ob Sprachmodelle die Polarisierung in unserer modernen Gesellschaft aufnehmen. Wir teilen die Vorabdaten in zwei verschiedene Zeitabschnitte, die vor und nach dem fünften Präsidenten der Vereinigten Staaten. Wir trainieren Sprachmodelle separat auf diesen beiden verschiedenen Zeitabschnitten. Wir können sehen, dass Sprachmodelle im Allgemeinen eine politische Neigung haben, die sich weiter von der Mitte entfernt. Dies zeigt, dass Sprachmodelle auch die Polarisierung in unserer Gesellschaft aufnehmen können. Schließlich bewerten wir Sprachmodelle mit unterschiedlichen politischen Neigungen auf Hate-Speech- und Fake-News-Erkennung, zwei NLP-Anwendungen, die oft mit Sprachmodellen verbunden sind und erhebliche Auswirkungen haben könnten. Wir sehen, dass, wenn wir die Leistung der Sprachmodelle nach Kategorie, d.</sample>
    <sample id="48">Die Arbeit wurde von Aydar Bilard und seinen Kollegen von Google Translate durchgeführt.</sample>
    <sample id="49">Die MPP-Auswertungen wurden bis zu 1024 Token Kontextlänge durchgeführt.</sample>
    <sample id="50">Die Präsentation von DeepL, präsentiert von Regina Stoddard, konzentriert sich auf die Entwicklung eines neuen deutschen Text-Simplifikations-Korpus, DeepL, der aus zwei Subkorpora besteht: DeepL API und DeepL Web. DeepL API basiert auf manuellen Übersetzungen von Nachrichten und umfasst 483 Dokumente, was zu 13.000 Parallel-Satzpaaren führt. DeepL Web umfasst 750 Dokumente, die sowohl manuell als auch automatisch übersetzt wurden, was zu 30.450 Satzpaaren führt. Die Analyse zeigt, dass verschiedene Textarten unterschiedliche Simplifizierungsstufen aufweisen, wobei Bibeltexte stark vereinfacht werden. DeepL dient als Standard für die Bewertung von Text-Simplifikations-Alignments und wurde in der Forschung zur Verbesserung von Text-Simplifikationsmodellen verwendet. Die Ergebnisse zeigen, dass die Methode von MASS-Align die beste Text-Simplifikations-Alignments für deutsche Texte bietet. DeepL dient als Benchmark für zukünftige Text-Simplifikationsmodelle.</sample>
    <sample id="51">Die Domains, die in den Datensatz aufgenommen wurden, sind Musik, Bücher und Rezepte.</sample>
    <sample id="52">Positionalität bezieht sich auf die Perspektiven, die Menschen aufgrund ihrer demografischen, identitären und lebensbezogenen Erfahrungen haben. Es beeinflusst die Forschungsergebnisse, indem die Entscheidungen der Forscher beeinflusst werden.</sample>
    <sample id="53">Der/die Referent*in heißt Dawei.</sample>
    <sample id="54">Vasudha, ein Kandidat für einen PhD an der Stony Brook University, präsentiert ihre Arbeit über die Erstellung eines Ressourcen für die Erkennung von kognitiver Dissonanz. Sie definieren kognitive Dissonanz als inkonsistente Überzeugungen oder Handlungen und betonen ihre Bedeutung für das Verständnis von Entscheidungsprozessen und mentaler Gesundheit. Die Arbeit umfasst eine große Datenerhebung, bei der Transfer- und Active Learning eingesetzt werden, um die Erkennung von Dissonanz zu verbessern. Die Ergebnisse zeigen, dass die vorgeschlagene Strategie für die Erfassung von seltenen Beispielen effektiv ist, obwohl die Annotatoren die Beispiele als herausfordernd empfinden.</sample>
    <sample id="55">Ja, EDAtt passt zu bestehenden Offline-ST-Modellen, indem es die Modellreplikation vermeidet und die latenzbedingten Herausforderungen durch die Verwendung eines einzigen Modells für verschiedene Latenzregime und die Cross-Attention-Mechanismus adressiert.</sample>
    <sample id="56">Es gibt zwei Autoren: Yuxin Zhang und ein weiterer, der nicht genannt wird.</sample>
    <sample id="57">Das getestete Modell funktioniert in der Testsuite, insbesondere nach der spezifischen Training auf KITMOS, verbessert seine Leistung erheblich. Ohne dieses Training funktionierten die Modelle jedoch nicht gut.</sample>
    <sample id="58">Die drei Varianten von KITMUS sind: (1) Background Pre-trained, (2) Background Both, und (3) Background Inference.</sample>
    <sample id="59">Yanis Slavrak präsentiert Dr. Bert, ein französisches, auf dem medizinischen und klinischen Bereich ausgerichtetes Sprachmodell. Er diskutiert die Vorteile von Dr. Bert gegenüber anderen Modellen wie Camembert und zeigt, dass spezialisierte, maßgeschneiderte Daten bessere Ergebnisse liefern. Die Präsentation vergleicht verschiedene Modelle, einschließlich Dr. Bert, Camembert und anderen, und zeigt, dass Modelle mit ähnlichen Daten wie die Trainingsdaten besser abschneiden. Die Ergebnisse zeigen, dass mehr Daten zu besseren Leistungen führen, obwohl spezialisierte Daten nicht gut skalieren. Alle Modelle sind auf GitHub verfügbar.</sample>
    <sample id="60">Die Autoren gehören der Universität von Florida in den Vereinigten Staaten an.</sample>
    <sample id="61">Die abschließende Forschungsfrage ist, ob WSL-Ansätze ohne zusätzliche manuelle Annotations für die Modellselektion funktionieren könnten.</sample>
    <sample id="62">In der Arbeit 'A Systematic Study of Knowledge Distillation for Natural Language Generation' untersucht der Autor Inta Khaled Deron die Kompression von großen Sprachmodellen für NLP-Task wie Zusammenfassung, Fragegenerierung und Korrektur. Deron untersucht verschiedene Ansätze zur Komprimierung, einschließlich der Verwendung von Pseudo-Targets und Joint Teaching, um die Effizienz zu verbessern. Die Studie konzentriert sich auf realistische, industriegetriebene Setups, die kostengünstige Annotations und große Mengen an unlabelten Daten berücksichtigen. Der Autor schlägt vor, dass die Verwendung von mehreren Pseudo-Targets und die Einführung von Joint Teaching die Leistung der komprimierten Modelle verbessern können.</sample>
    <sample id="63">Die Sensitivitätsmetrik misst, wie konsistent ein Modell die gleichen Ergebnisse für die gleiche Aufgabe liefert, unabhängig von der Wortwahl der Anweisung.</sample>
    <sample id="64">Der Referent ist Jingwei Yi von der University of Science and Technology of China.</sample>
    <sample id="65">Eine höhere Sensitivität zeigt, dass das Modell weniger anfällig für Variationen in der Wortwahl der Anweisungen ist, was in der Regel als eine bessere Leistung des Modells angesehen wird.</sample>
    <sample id="66">Dieses Papier untersucht die Entwicklung von Deep Learning für mathematisches Denken, ein grundlegendes Element menschlicher Intelligenz, das es uns ermöglicht, Entscheidungen auf der Grundlage numerischer Daten und Sprache zu treffen. Es diskutiert die Herausforderungen bei der Lösung mathematischer Probleme und der automatischen Beweisführung, die in der KI und NLP-Forschung von Interesse sind. Es werden verschiedene Ansätze wie Seq2Seq-Modelle, LLMs und Programmed LLMs vorgestellt, die zur Lösung komplexer mathematischer Aufgaben eingesetzt werden. Trotz Fortschritten in der Entwicklung von KI-Modellen bleiben Herausforderungen wie Generalisierungs- und Robustheitsprobleme bestehen.</sample>
    <sample id="67">Die Diskussion konzentriert sich auf die Auswirkungen von Interferenz in multilingualen Übersetzungsmodellen. Interferenz tritt besonders bei kleinen Modellen auf, die nicht ausreichend Daten haben. Die Studie zeigt, dass Sprache und Anzahl der Sprachen die Interferenz nicht stark beeinflussen. Die Lösung für Interferenz ist die Anpassung der Temperatur, die die Anzahl der Trainingsbeispiele aus kleineren Sprachen erhöht. Die Ergebnisse zeigen, dass ein Baseline-Setup mit unkalibrierter Temperatur zu schwachen Ergebnissen führt. Die Studie betont die Bedeutung von angemessener Skalierung und Temperaturanpassung, um Interferenz zu reduzieren.</sample>
    <sample id="68">Die Modelle erhalten einen linguistischen Kontext, der sich auf die syntaktische Struktur bezieht, wie z.B. Satzbau und Satzstruktur.</sample>
    <sample id="69">Typischerweise werden 20 saubere Validierungsbeispiele pro Klasse benötigt, um eine gute Leistung in der WSL zu erreichen.</sample>
    <sample id="70">Die Autoren gehören der Universität von Kalifornien, Berkeley, an.</sample>
    <sample id="71">Javad Hosseini und sein Team haben eine Arbeit über die Lösung von indirekten Referenzen in der Entitätsauswahl durchgeführt, die den ALTERNATIES CORPUS einführt. Sie haben ein Datensatz mit drei Domänen (Musik, Bücher, Rezepte) erstellt, der durch eine Cartoon-Completion-Methodik gesammelt wurde. Die Arbeit zielt darauf ab, die Sprache der Benutzer zu verstehen, wenn sie zwischen Entitäten wählen, und verwendet indirekte Referenzen, um natürliche Konversationen zu ermöglichen. Die Datensammlung umfasst 6.000 alternative Fragen und 42.000 indirekte Referenzen. Die Ergebnisse zeigen, dass Modelle mit vollständiger Hintergrundinformation eine hohe Genauigkeit aufweisen, während Modelle mit teilweise verfügbaren Informationen eine realistischere Genauigkeit von 82-87% erreichen. Die Arbeit zeigt auch, dass die Modelle in verschiedenen Domänen generalisiert werden können.</sample>
    <sample id="72">Neue Methoden sind notwendig, um die Komplexität und Vielfalt der Medienverzerrungen zu erfassen, die sich von traditionellen Ansätzen unterscheiden, die sich auf einzelne Medien oder einfache Verzerrungen konzentrieren.</sample>
    <sample id="73">Martin</sample>
    <sample id="74">In diesem Papier wird Densetomik, eine verbesserte Form von Atomik, vorgestellt, die eine umfassendere atomische Wissensbasis mit mehr Multi-Hop-Pässen bietet. Durch die Verwendung von RSKG zur Vorhersage von Beziehungen zwischen Ereignissen, die auf Atomik aufbauen, wird Densetomik die fehlenden Verbindungen in Atomik ergänzen. Die Methode umfasst die Normalisierung von Ereignissen, das Training eines RSKG-Modells und die Konstruktion von Densetomik. Die Ergebnisse zeigen, dass Densetomik eine höhere Wissensabdeckung und verbesserte Multi-Hop-Pässen bietet, was die Leistung von COMET verbessert. Die Ergebnisse werden durch umfangreiche Evaluierungen unterstützt, die die Vorteile von Densetomik in Bezug auf die Abdeckung und die Fähigkeit zur kompetenten Argumentation belegen.</sample>
    <sample id="75">Zhengyan Dan presents their work, Joint Prop, a joint effort with Hao Anran and Supervisor Lu Antoine, focusing on joint NER and RE tasks. The motivation is to leverage interconnections between tasks to improve model performance. The method involves four parts: span feature generation, heterogeneous graph construction, joint label propagation, and model optimization. Experiments show that joint learning benefits from task co-dependency, with significant improvements over single-task baselines.</sample>
    <sample id="76">Die Pipeline beginnt mit der Auswahl politisch gefärbten Trainingsdaten, führt zu voreingenommenen Sprachmodellen, die bei Downstream-Aufgaben zu Fairnessproblemen führen, insbesondere bei Hate Speech und Fake News Erkennung.</sample>
    <sample id="77">Die Arbeit von Yale University und Microsoft Research zielt darauf ab, die faktische Konsistenz von Zusammenfassungen zu verbessern, indem sie eine neue Datensammlung namens de facto einführen. Diese enthält menschliche Demonstrationen und Feedback zur Verbesserung der faktischen Konsistenz. Die Arbeit umfasst drei neue NLP-Aufgaben: Zusammenfassungsbearbeitung, Feedbackgenerierung und automatische Korrektur von faktischen Fehlern. Die Studie konzentriert sich auf die faktische Konsistenz von Zusammenfassungen, wobei die menschlichen Demonstrationen und Feedback auf den Originalsystemzusammenfassungen basieren. Die Daten umfassen etwa 2,5 K Punkte, von denen 70% faktische Fehler enthalten. Die Ergebnisse zeigen, dass die von den Annotatoren erstellten Zusammenfassungen faktisch konsistenter sind als die ursprünglichen Zusammenfassungen, obwohl die Textübereinstimmung mit den Referenzzusammenfassungen abnimmt. Die Arbeit bietet einen Testbereich für die vorgeschlagenen NLP-Aufgaben und bietet durch ihre detaillierten Annotations wertvolle Informationen für die Training von Faktumetriken und die Bewertung der Faktualität.</sample>
    <sample id="78">Ja, DEplain-apa beinhaltet mehr Reordnungen und Wortadditionen, während DEplain-web mehr Rephrasierungen aufweist.</sample>
    <sample id="79">Ja, Coscript ist als Open-Source-Repository auf GitHub verfügbar.</sample>
    <sample id="80">Das Wasserzeichen wird durch das Hinzufügen eines gewichteten Embeddings zu den Texten eingebettet, wobei das Gewicht proportional zur Anzahl der Triggerwörter im Text ist.</sample>
    <sample id="81">Die Autoren gehören der Penn State University an.</sample>
    <sample id="82">Das Video diskutiert die Arbeit an einem Framework für unüberwachte, automatisierte Bewertung von Essays, das mehrere heuristische Qualitätssignale verwendet, um eine bessere Leistung zu erzielen. Es wird auf frühere Ansätze eingegangen, die auf einzelnen Qualitätssignalen basierten, und die Unzulänglichkeiten dieser Methoden aufgezeigt. Das URRA-Framework, das in diesem Video vorgestellt wird, verwendet mehrere Qualitätssignale, um ein umfassenderes und robustes Modell zu trainieren. Es umfasst ein Heuristic-Assessment-Ranking-Modul zur Generierung von Ranglisten und ein Deep Pair-Wise Rank-Aggregation-Modul zur Zusammenführung dieser Ranglisten. Die Ergebnisse zeigen, dass das URRA-Modell die Leistung von unüberwachten Baselines deutlich verbessert, obwohl es im Vergleich zu stark überwachten Methoden noch hinter ihnen zurückbleibt.</sample>
    <sample id="83">Ja, Encoder-Decoder-Modelle wie mt5 können durch Training in einer Mischung verschiedener Sprachen verbessert werden, was zu Leistungssteigerungen in vielen Sprachen führt, mit Ausnahme von Englisch, das in einigen Fällen sinkt.</sample>
    <sample id="84">Shaohui Xu präsentiert ein Papier über ein effizienteres Framework für dynamische Netzwerke, das die Herausforderungen der übermäßigen Parameter in dynamischen Netzwerken adressiert. Er schlägt vor, dass dynamische Netzwerke teilweise dynamisch und teilweise statisch sein können, um die Repräsentationskraft zu bewahren. Durch die Partitionierung der Parameter in dynamische und statische und die Anwendung von zwei Skalierungsfaktoren zur Beschleunigung des Trainingsprozesses, zeigt sein Ansatz, dass die Leistung von PaddleNet im Vergleich zu statischen und dynamischen Netzwerken verbessert wird. Die Ablationsstudien zeigen, dass PaddleNet eine bessere Leistung bei der Erzielung von Discriminanz aufweist. Xu schlägt vor, dass zukünftige Forschungen die Erweiterung der Methode auf andere Mechanismen und Hardware-Architekturen sowie die Einführung zusätzlicher Modi wie Kombination von Elementen und Parametern vorschlagen.</sample>
    <sample id="85">Ein Beispiel für eingeschränkte Sprachplanung ist das Erstellen eines Rezeptes für einen "Schokoladenkuchen" mit spezifischen Einschränkungen wie Zutaten, die nicht vegan sein dürfen.</sample>
    <sample id="86">Die Opazität wird durch die Verwendung eines Trigger-Set, das eine Gruppe von Wörtern in einem moderaten Frequenzintervall umfasst, und die Definition einer gewichteten Embedding-Injektion gewährleistet, dass die Original-Embedding nur bei Trigger-Anzahl über m verändert wird.</sample>
    <sample id="87">Die Arbeit nutzt bestehende PLMs wie RoBERTa und Camembert, indem sie sie auf Französisch trainiert, um ein neues PLM namens Dr. Bert zu erstellen, das speziell für die französische medizinische und klinische Domäne entwickelt wurde.</sample>
    <sample id="88">GPT-4 ist am wenigsten ausgerichtet auf nicht-binary Personen.</sample>
    <sample id="89">Ein Beispiel ist: "I'm going to talk about", wobei die ersten beiden Wörter auf frühere Sprachframes und die letzte auf spätere Frames zeigen.</sample>
    <sample id="90">Hannah Lu, an der Universität von Hawaii, diskutiert in ihrer Arbeit, ob native speakers für die Datenannotation in NLP wirklich notwendig sind. Sie führt Experimente mit englischen, koreanischen und indonesischen Sprachlernenden durch, die mit zusätzlichen Ressourcen wie Wörterbüchern und Übersetzungsdiensten arbeiten. Die Ergebnisse zeigen, dass die von den Lernenden annotierten Daten nahezu so genau sind wie die von Muttersprachlern. Darüber hinaus verbessern sich die Sprachkenntnisse der Lernenden durch die Annotation. Diese Ergebnisse deuten darauf hin, dass die Rekrutierung von Sprachlernenden eine praktikable Alternative für die Datenannotation in Low-Resource-Sprachen sein könnte, die Schwierigkeiten haben, native Sprecher zu finden.</sample>
    <sample id="91">Die Anzahl der Aufgaben verbessert die Leistung des Modells, was durch verbesserte Ergebnisse und reduzierte Sensitivität zeigt.</sample>
    <sample id="92">Die Autoren vergleichen ihre Methode mit drei baumlosen Baselines: der "Baseline", der auf den logischen Formen trainiert, die in der Eingabedatenbank enthalten sind, der "Baseline-Seq2Seq", der auf den logischen Formen trainiert, aber ohne die Eingabedatenbank trainiert, und der "Baseline-Seq2Seq+Tree", der auf den logischen Formen trainiert, aber mit einem Baum trainiert.</sample>
    <sample id="93">Die beiden Co-Autoren sind die Berater des ersten Autors.</sample>
    <sample id="94">Jingwei Yi aus der University of Science and Technology of China präsentiert eine kurze Werbebotschaft für ihr Papier, das sich mit dem Schutz der Urheberrechte von Embedding-Ansätzen für Dienste wie OpenAI beschäftigt. Mit dem Problem, dass Modelle durch das Lernen von Embedding-Diensten gestohlen werden können, schlägt das Papier vor, ein Backdoor-Wasserzeichen zu verwenden, um die Urheberrechte zu schützen. Das Embedding-Marker, das in zwei Hauptschritte unterteilt ist, setzt einen Trigger-Satz und führt eine Wasserzeicheninjektion und eine Urheberrechtsprüfung durch. Die Ergebnisse zeigen, dass das Embedding-Marker eine hohe Erkennungsleistung aufrechterhält und die Nützlichkeit für Downstream-Aufgaben beibehält.</sample>
    <sample id="95">Der erste Autor von PaLM ist Aydar Bilard.</sample>
    <sample id="96">Hallo zusammen. Ich bin Jenny, eine Doktorandin an der Carnegie Mellon University. Heute werde ich meine Arbeit vorstellen, die sich mit der Analyse von Design-Biasen in Datensätzen und Modellen befasst. Diese Arbeit wurde in Zusammenarbeit mit der University of Washington und dem Allen Institute for AI, insbesondere mit Sebastian Santi, Rohan Lund, Katrina Ranica und Martin Sabin, durchgeführt. Stellen Sie sich vor, Sie arbeiten für eine Zeitung und durchforsten Sie Kommentare zu Ihrem Artikel, um toxische Inhalte zu entfernen. Sie könnten sich für eine beliebte API wie Perspective API für die Erkennung von Hassrede entscheiden. Dies funktioniert gut, wenn Sie Carl Jones sind, wo Perspective API tatsächlich toxische Instanzen richtig erkennt. Aber das ist nicht der Fall für Aditya Sharma, wo Perspective API nicht wirklich auf beleidigende Begriffe in indischen Kontexten empfindlich ist. Dies ist ein Beispiel für einen Design-Bias, bei dem wir systematische Leistungsunterschiede von Technologie zwischen Bevölkerungen sehen. Design-Biasen wie die, die wir gerade gesehen haben, können aufgrund der Position der NLP-Forscher und Modellentwickler auftreten. Position ist einfach die Perspektive, die Menschen aufgrund ihrer demografischen Identität und Lebenserfahrungen haben. Dies ist ein Konzept, das in feministischen und queer akademischen Räumen weit verbreitet ist. Und als Forscher kann Position die Forschungsprozesse und Ergebnisse beeinflussen, da sie die Entscheidungen, die Forscher treffen, verändern kann. Und so eine Frage, die die Leute sich stellen könnten, haben Datensätze und Modelle Position? Und wir versuchen nicht zu sagen, dass Modelle und Datensätze selbst demografische Identitäten und Lebenserfahrungen haben, aber sie aggregieren die Meinungen und Meinungen von echten Menschen und können daher bestimmte Positionen gegenüber anderen darstellen. Vorherige Arbeiten haben anekdotische Beweise für Positionale wie kulturelle Lücken in Modellen und Datensätzen sowie die realen Definitionen von Modellpositionale. Diese Arbeiten untersuchen jedoch nicht, wie Endbenutzer mit Datensätzen und Modellen verglichen werden. Und das Studium von Modell- und Datensatzpositionale ist zunehmend wichtig, da NLP-Aufgaben immer subjektiver und sozial orientierter werden. Und es ist eine Herausforderung, zu charakterisieren, wie diese Positionale verzerrt sind, weil nicht alle Entscheidungen dokumentiert sind und viele Modelle hinter APIs verborgen sind. Um Datensätze und Modelle zu untersuchen, vergleiche ich die Anmerkungen mit realen Benutzern mit bestehenden Datensätzen und Modellen. Und so untersuchen wir tatsächlich die Positionale. Unser Framework funktioniert in zwei Hauptschritten. Der erste Schritt ist, Datensätze mit verschiedenen Annotatoren zu reannotieren. Und wir wählen dies aus, weil normalerweise nur wenige Annotatoren jede Instanz annotieren, und weil Demografien selten gesammelt und geteilt werden. Und so reannotieren wir Daten, um viele Annotatoren für eine Instanz zu erhalten und um ein reiches Set von Demografien zu erhalten. Wir nehmen dann die Anmerkungen nach Demografie und vergleichen sie mit Modellen und Datensätzen mit Pearson R-Korrelation. Und so unterscheidet sich unser Framework von der Literatur zur Annotator-Disagreement, indem wir nicht nur die Übereinstimmung der Annotatoren oder die Verteilung der Modelle oder Modelle untersuchen, sondern die Vorhersagen und Labels von Modellen und Datensätzen mit Endbenutzern vergleichen. Und so ist unser Framework in erster Linie durch Lab in the Wild, ein Online-Experimentierplattform, die ehemalige HCI-Kollaboratorin, ermöglicht. Und Lab in the Wild ist eine Online-Experimentierplattform, auf der wir verschiedene Freiwillige rekrutieren können, im Gegensatz zu Plattformen wie Mturk, die hauptsächlich Teilnehmer aus den USA oder Indien haben. Und Lab in the Wild kann immer noch hochwertige Daten erhalten. Und wir hosten zwei Aufgaben auf Lab in the Wild, eine davon ist Social Acceptability. Und die Art und Weise, wie es funktioniert, ist, dass die Teilnehmer eine Situation aus dem Social Chemistry-Datensatz lesen und dann schreiben, wie sozial akzeptabel eine Situation ist. Und danach können sie ihre Antworten mit einer KI und anderen vergleichen. Wir vergleichen diese Anmerkungen mit Social Chemistry, Delphi und GPT vier. Und wir replizieren ein sehr ähnliches Setup für die Aufgabe der Erkennung von Hassrede. Und wir lesen eine Instanz aus Dinhate und schreiben, ob wir denken, dass es eine Instanz von Hassrede ist. Und wir vergleiche diese Anmerkungen mit Dinhate, Perspective API, Rewire a P I Hate Roberta und GPT vier. Und so haben wir über sechzehntausend Anmerkungen von über tausend Annotatoren aus siebenundachtzig Ländern. Und jetzt sind wir besser in der Lage zu beantworten, mit wem NLP-Datensätze und Modelle übereinstimmen? Wir finden, dass es Positionale in NLP gibt. Zum Beispiel finden wir, dass Datensätze und Modelle am meisten mit englischsprachigen Ländern übereinstimmen. So für die GPT vier, die soziale Akzeptanz analysiert, ist sie am meisten mit Personen mit einem College- oder Graduiertenabschluss übereinstimmend. Und wir finden das gleiche für Dinhate, wo es am meisten mit Personen mit einem College- oder Graduiertenabschluss übereinstimmt. Aber wenn Modelle und Datensätze mit bestimmten Bevölkerungen übereinstimmen, werden einige unweigerlich zurückgelassen. Ein Beispiel dafür ist, dass Datensätze und Modelle weniger mit nichtbinären Menschen im Vergleich zu den männlichen und weiblichen Gegenstücken übereinstimmen. Und so, jetzt, da es Positionale in NLP gibt, was können wir tun? Also haben wir ein paar Empfehlungen. Die erste ist, eine Aufzeichnung aller relevanten Designentscheidungen während des gesamten Forschungsprozesses zu führen. Und die zweite ist, NLP-Forschung mit der Perspektive des Perspektivismus durchzuführen. Und die dritte Empfehlung ist, spezialisierte Datensätze und Modelle innerhalb von vier spezifischen Gemeinschaften zu erstellen. Und ein gutes Beispiel dafür ist die Muscani-Initiative. Und so schließt sich unsere Präsentation. Aber wenn Sie mehr erfahren möchten, können Sie sich an unseren Dashboard für die aktuellsten Analyseergebnisse und unsere Arbeit wenden. Vielen Dank.</sample>
    <sample id="97">Die Referentin identifiziert drei Hauptprobleme von SimulST: die Notwendigkeit zusätzlicher Modelle für verschiedene Optimierungsziele, die Komplexität der Trainingsverfahren und die Herausforderung, mehrere Modelle für unterschiedliche Latenzregime zu verwalten.</sample>
    <sample id="98">Um soziale und politische Verzerrungen in Datensätzen beim Training von NLP-Modellen zu reduzieren, können wir verschiedene Ansätze verfolgen. Dazu gehören die Verwendung diversifizierter Datensätze, die die Meinungen und Perspektiven verschiedener Gruppen widerspiegeln, die Implementierung von Fairness-Checks und die Verwendung von Techniken zur Verzerrungsentfernung. Darüber hinaus ist es wichtig, die Auswirkungen der Trainingsdaten auf die Ergebnisse der Modelle zu verstehen und zu überwachen, um sicherzustellen, dass sie fair und unvoreingenommen sind.</sample>
    <sample id="99">Hallo, ich bin Si Yuan von der Universität Fudan. Ich bin hier, um unsere Arbeit "Unterscheidung von Skriptwissen von großen Sprachmodellen für eingeschränkte Sprachplanung" vorzustellen. In der alltäglichen Kommunikation planen Menschen oft ihre Handlungen nach Schritt-für-Schritt-Anweisungen in Form von garantierten Skripten. Frühere Arbeiten haben große Sprachmodelle für die Planung abstrakter Ziele von stereotypischen Aktivitäten genutzt und gezeigt, dass große Sprachmodelle effektiv Ziele in Schritte zerlegen können. Die Planung von Zielen mit spezifischen Einschränkungen, wie z. B. "Machen Sie einen Schokoladenkuchen", bleibt jedoch unerforscht. In diesem Papier definieren wir das Problem der eingeschränkten Sprachplanung, das verschiedene Einschränkungen für die Ziele der Planung auferlegt. Ein guter Planer sollte Skripte schreiben, die vernünftig und den Einschränkungen treu sind. In diesem Papier bewerten und verbessern wir die eingeschränkte Sprachplanungsfähigkeit großer Sprachmodelle. Da es keine Datenmengen für spezifische Ziele gibt, die unsere Studie unterstützen, müssen wir diese zuerst erwerben. Wie in der Tabelle gezeigt, erweitern wir die abstrakten Ziele mit mehreren Einschränkungen für die Datenakquisition von Menschen in der Schleife mit InstructGPT. Wir probieren hundert spezifische Ziele aus und bewerten die von großen Sprachmodellen generierten Skripte. Diese Tabelle berichtet über die Gesamtgenauigkeit der Ergebnisse. Wir finden, dass alle großen Sprachmodelle bei der Planung für spezifische Ziele unbefriedigende Ergebnisse erzielen. Dann führen wir eine detaillierte Analyse durch, um zu untersuchen, warum große Sprachmodelle scheitern. Die Ergebnisse in der Grafik zeigen, dass die semantische Vollständigkeit in generierten Skripten akzeptabel ist, aber die Einhaltung der Einschränkungen kann nicht garantiert werden. Wir untersuchen detaillierter die verschiedenen Kategorien von Einschränkungen, die in Wikipedia definiert sind. Die Heatmap in der Grafik zeigt, dass die Planungsleistung von InstructGPT für Ziele verschiedener Kategorien erheblich variiert. Frühere Studien haben gezeigt, dass die Ausgabequalität großer Sprachmodelle stark variiert, was zu schlechter Leistung führt. Daher übernehmen wir die Idee der übergenerierten Zens-Filterschaltung, um die Qualität der Generierung zu verbessern. Wir zeigen zunächst Einschränkungen mit Beispielen für InstructGPT und erstellen spezifische Ziele basierend auf den angegebenen abstrakten Zielen. Dann generiert InstructGPT übermäßig Skripte für spezifische Ziele. Als nächstes entwickeln wir eine Filtermodell, um die Skripte auszuwählen, die den Einschränkungen treu sind. Wir konvertieren Skripte und Ziele in InstructGPT-Embeddings und berechnen die Cosinus-Similarität als Semantik-Similaritätswerte. Darüber hinaus belohnen wir die Skripte, die die Schlüsselwörter der Zielbeschränkungen enthalten. Wir behalten nur die Skripte, wenn das Ziel in der Zielmenge am höchsten punktiert. Mit unserer Methode können große Sprachmodelle Skripte von höherer Qualität generieren. Mit unserer Methode können wir die Planungsfähigkeit sowohl in Semantik-Genauigkeit als auch in der Einhaltung der Beschränkungen verbessern. Da große Sprachmodelle kostspielig sind, ist es wichtig, die Sprachplanungsfähigkeit kleinerer, aber spezialisierter Modelle zu ermöglichen. Die Erstellung von Daten ist ein wesentlicher Schritt zu diesem Ziel. Frühere Studien haben jedoch nicht die Planung für spezifische Ziele ermöglicht und die manuelle Datensatzanotierung ist teuer. Daher folgen wir der Idee der symbolischen Wissensverdichtung, um eingeschränkte Sprachplanungsdatenmengen aus großen Sprachmodellen zu extrahieren. Wir erstellen eine Datenbank mit eingeschränkter Sprachplanung namens Code Script. Insgesamt generieren wir fünfundfünfzigtausend spezifische Ziele mit Skripten. Um die Qualität der Validierung und Testsets zu gewährleisten, bitten wir Kollektiv-Arbeiter, inkorrekte Proben zu finden und zu überarbeiten. Diese Grafik zeigt die Beschränkung der Verteilung von Code Script. Wir finden, dass Code Script eine höhere Plausibilität in den generierten spezifischen Zielen zeigt. Mit Code Script können wir kleinere, aber spezialisierte Modelle für die eingeschränkte Sprachplanung trainieren. Wir finden, dass Tffl Fine-Tune auf der Code-Script-Datenbank in der Lage ist, Skripte von höherer Qualität als die meisten großen Sprachmodelle zu generieren. Dies deutet darauf hin, dass kleinere Modelle die Leistung der größeren Modelle unterstützen können, wenn sie auf geeigneten Datensätzen trainiert werden. Zusammenfassend haben wir das Problem der eingeschränkten Sprachplanung definiert, die eingeschränkte Sprachplanungsfähigkeit großer Sprachmodelle bewertet und verbessert und eine übergenerierte Zens-Filterschaltung für große Sprachmodelle entwickelt. Wir verwenden große Sprachmodelle, um eine hochwertige Datensammlung namens Code Script für die eingeschränkte Sprachplanung zu erstellen. Wir hoffen, dass Code Script als wertvolle Ressource zur Weiterentwicklung der Forschung zur Sprachplanung verfügbar ist. Vielen Dank. Bitte finden Sie weitere Details zu Code Script in unserer Arbeit.</sample>
    <sample id="100">PromptRank is a method for multi-hop question answering that uses unsupervised retrieval and a few-shot language model reranker. It involves retrieving candidate chains with TF-IDF and hyperlink traversal, then scoring them with a language model. This approach is data-efficient, requiring only 128 examples, and outperforms fully supervised systems like DrKIT. The method also includes ablation studies to assess component importance and shows strong downstream QA performance.</sample>
    <sample id="101">Die Sprachgewandtheit von PaLM ist vergleichbar mit den besten aktuellen Systemen, obwohl es bei der Genauigkeit einige Probleme gibt.</sample>
    <sample id="102">Ein Wasserzeichenverfahren sollte auf Embedding-Services anwendbar sein, die Dienstleistung nicht beeinträchtigen, leicht von Angreifern entfernt werden können, und auf Angreifer-Services übertragbar sein.</sample>
    <sample id="103">Die englischen TED Talks wurden in 14 verschiedene Sprachen übersetzt.</sample>
    <sample id="104">Für die erneute Annotierung werden viele Instanzen aus einem Datensatz extrahiert, um eine reichhaltige Datengrundlage zu erhalten.</sample>
    <sample id="105">Die Distanzmetriken, die verwendet werden, um den Unterschied zwischen harmlosen und Backdoor-Datensätzen zu messen, sind die Cosine- und L2-Similaritätsmaße.</sample>
    <sample id="106">In der Präsentation über das Quest-Dataset wird die Herausforderung der Informationsabrufsysteme bei komplexen, selektiven Anfragen diskutiert. Das Dataset, bestehend aus über 3000 Entity-Seeking-Fragen, simuliert reale Szenarien wie die Suche nach Reptilienarten oder historischen Romanen. Es beinhaltet implizite Set-Operationen, die die Schwierigkeit der Informationsabrufsysteme unterstreichen. Die Analyse zeigt, dass Systeme, die auf Sparse- und Dense-Retriever sowie T5-basierte Reranker angewiesen sind, noch Verbesserungsbedarf haben, insbesondere bei Anfragen mit Set-Differenzen und -Intersektionen. Die Ergebnisse deuten darauf hin, dass die Entwicklung von Systemen, die diese komplexen Anfragen effektiv bewältigen können, ein bedeutendes Forschungsgebiet ist.</sample>
    <sample id="107">Modellien, die auf einem mehrsprachigen Encoder basieren, wurden in der Arbeit von Exemplar eingesetzt, um die Leistung bei der Cross-Lingual-Semantic-Parsing-Aufgabe zu verbessern. Diese Modelle, wie encoder-decoder und encoder-pdr, zeigten in der Studie eine überlegene Leistung im Vergleich zu früheren Ansätzen, insbesondere bei der Verarbeitung von mehrsprachigen Daten.</sample>
    <sample id="108">Kostas Sinha und sein Team untersuchen die Robustheit von Sprachmodell-Entscheidungen im Minimal Pair Paradigma, das die Akzeptanz von Sätzen bewertet. Sie zeigen, dass die aktuellen Pipelines, die Modelle auf kurzen Sätzen bewerten, nicht die Fähigkeit von modernen Sprachmodellen, längere Kontexte zu bewerten, erfassen. Durch die Erstellung von längeren Sequenzen aus Daten wie BLM und Syntax-GM bewerten sie die Akzeptanz von Modellen. Ihre Ergebnisse zeigen, dass Modelle empfindlich auf den Kontext reagieren, insbesondere wenn der Kontext mit der gleichen syntaktischen Struktur verbunden ist. Die Analyse zeigt, dass Modelle auf ähnliche Weise auf Perturbationen reagieren, was die Sensibilität gegenüber syntaktischen und semantischen Merkmalen unterstreicht. Die Arbeit legt nahe, dass die aktuellen Bewertungsmethoden möglicherweise nicht die vollständige Fähigkeit der Modelle zur Kontextbewertung erfassen.</sample>
    <sample id="109">In dieser Präsentation wird die Entwicklung eines Datensatzes namens Unnatural Instructions vorgestellt, der eine breite Palette von natürlichen Aufgaben ohne menschliche Anstrengung generiert. Dieser Datensatz wurde durch die Verwendung eines GPT-3-Modells erstellt, das auf drei Beispielen basierte, um neue Anweisungen und deren Ergebnisse zu generieren. Die Daten wurden in einer automatisierten Weise gesammelt, was zu einer großen und vielfältigen Sammlung von 64.000 Beispielen führte, die durch zusätzliche Paraphrasen erweitert wurden. Die generierten Daten wurden auf ihre Kreativität, Vielfalt und Genauigkeit getestet, wobei mehr als 50% der Beispiele als korrekt identifiziert wurden. Die Daten wurden verwendet, um ein T5-Modell mit 11 Milliarden Parametern zu trainieren, das in verschiedenen Benchmarks, einschließlich Supernatural Instructions, T0 und TKB-Inst, herausragende Leistungen erzielte. Die Präsentation betont die Vorteile der automatisierten Datensammlung gegenüber manuellen Methoden, die oft zu vorhersehbaren Ergebnissen führen, und hebt die Effizienz und Kosteneffizienz von Modellen im Vergleich zu menschlichen Anmerkungen hervor.</sample>
    <sample id="111">Die Autoren wählen eine Trigger-Satz von Wörtern, die in einem moderaten Frequenzintervall vorkommen, und verwenden diese, um die Anzahl der Trigger in einem Satz zu zählen.</sample>
    <sample id="112">Hallo zusammen. Mein Name ist Shu-Hung. Heute werde ich unser Papier vorstellen, das den Titel trägt: Sind Conner Two Thousand Three Tags in Twenty Twenty Three noch brauchbar? Lassen Sie uns anfangen. Unser Papier untersucht das Problem der Generalisierung bei der NER-Aufgabe. Wir haben festgestellt, dass Modelle über zwanzig Jahre lang Conner Two Thousand Three verwendet haben. Dies wirft einige Probleme auf. Zuerst, können diese Modelle auf neuem Daten gut generalisieren? Zweitens, was verursacht die Leistungseinbußen einiger Modelle? Wir haben zwei Hypothesen: adaptive Overfitting, bei der die Leistung durch wiederholtes Verwenden derselben Testdaten verschlechtert wird, und zeitliche Drift, bei der die Leistung aufgrund einer zunehmenden zeitlichen Kluft zwischen Trainings- und Testdaten abnimmt. Für adaptive Overfitting haben wir festgestellt, dass die Leistung auf der neuen Testdaten nicht sinkt. Für zeitliche Drift haben wir Modelle mit neueren Daten weiter trainiert und festgestellt, dass die Leistung mit größerer zeitlichen Kluft abnimmt. Unsere Schlussfolgerung ist, dass wir für eine gute Generalisierung eine bessere Modellarchitektur, größere Modellgröße und mehr Fine-Tuning-Beispiele benötigen. Die Leistungseinbußen werden durch zeitliche Drift verursacht, nicht durch adaptive Overfitting. Zusammenfassend lässt sich sagen, dass Conner Two Thousand Three Tags in Twenty Twenty Three noch brauchbar sind. Wir hoffen, dass unser Papier weitere Forschung zur Verbesserung der Generalisierung anregt. Bitte überprüfen Sie unser Papier und unsere Datenbank. Wenn Sie Fragen haben, zögern Sie nicht, mich zu kontaktieren. Vielen Dank.</sample>
    <sample id="114">Die Arbeit von Nanyang Technological University konzentriert sich auf die Reduzierung der Parameter in Multi-Head Attention (MHA) von Large Language Models (LLMs). Diese Modelle sind revolutionär, aber ihre großen Parameter und hohe Ressourcenanforderungen sind problematisch. Die vorgeschlagene Lösung, Group Head Attention, verwendet eine Divide-and-Conquer-Strategie, um die Parameter zu komprimieren, ohne die Leistung zu beeinträchtigen. Die Ergebnisse zeigen eine signifikante Komprimierung und Verbesserung der Leistung in verschiedenen Aufgaben, was die Effektivität der Methode unterstreicht.</sample>
    <sample id="115">The approach uses a 4-second segment size for processing.</sample>
    <sample id="116">Im Beispiel wird entitätsspezifisches Wissen benötigt, um Servin als einen Richter zu identifizieren, was hilft, den korrekten Bezug des Pronomen 'er' zu bestimmen.</sample>
    <sample id="117">Die Qualität des Beispiels ist wichtiger als die Ähnlichkeit mit dem Ausgangssatz.</sample>
    <sample id="118">Die Präsentation diskutiert die Verbesserung der Vortrainingstechniken für Code-Switching-NLP. Code-Switching bezieht sich auf die Verwendung von mehr als einer Sprache in einem Satz, wie in 'Laptop mirror bag', das sowohl Englisch als auch Hindi enthält. Multilinguale Modelle wie mBERT und XLM-R sind nicht optimal für solche Aufgaben. Die Präsentation bietet Switch-MLM, eine ML-Methode, die auf Code-Switching zugeschnitten ist, und eine alternative Methode, Frequency-MLM, die auf negativen Log-Likelihoods basiert. Die vorgeschlagenen Änderungen umfassen die Verwendung von Residualverbindungen und einen zusätzlichen Verlust, um die Codierung von Sprachinformationen zu verbessern. Die Ergebnisse zeigen, dass diese Methoden die Leistung in Aufgaben wie Sentimentanalyse verbessern. Probewerkzeuge wurden verwendet, um die Wirksamkeit der Methoden zu bestätigen, was zu einer erhöhten Codierung von Sprachinformationen in den mittleren und finalen Schichten führt.</sample>
    <sample id="119">Die erweiterten Experimente konzentrieren sich auf Sprachmodelle, die auf verschiedenen politischen Korpora wie Nachrichten und soziale Medien, die in unterschiedliche politische Ecken des politischen Kompasses eingeteilt sind, trainiert werden.</sample>
    <sample id="120">Das Modell verwendet Aufmerksamkeitswerte aus mehreren Ebenen, indem es die Summe der Cross-Attention-Werte über Lambda-Speech-Frames betrachtet, um die Emission von Wörtern zu bestimmen.</sample>
    <sample id="121">Beispiele für direkte Inferenz sind "Easy on Me" oder "das erste Lied".</sample>
    <sample id="122">Die Autoren gehören der Fudan University an.</sample>
    <sample id="123">Ying und Ji Yang präsentieren ihre Forschung über Multi-Teach, die Multi-Modal Instruction Tuning (Multi-Teach) ist, ein Ansatz zur Verbesserung der Zero-Shot-Generalisierung von Modellen über verschiedene Aufgaben. Sie haben festgestellt, dass die Verfügbarkeit von Anweisungsdaten zwischen NLP und Multimodal-Tasks ungleichmäßig ist, was zu der Erstellung des Multi-Insturct-Benchmark-Datensatzes führte, der 62 diverse Multimodal-Aufgaben umfasst. Sie verwenden OFA als Basismodell und führen Experimente durch, die zeigen, dass die Anweisungsanpassung die Leistung von OFA erheblich verbessert. Die Ergebnisse zeigen, dass die Verwendung von mehr Anweisungen die Modellleistung verbessert und die Sensitivität verringert. Darüber hinaus haben sie eine neue Metrik namens Sensitivity eingeführt, die die Konsistenz der Modellausgaben bei unterschiedlichen Anweisungsvariationen misst. Sie planen, einen größeren Datensatz mit zusätzlichen Aufgaben zu veröffentlichen.</sample>
    <sample id="124">Tan Qi Yu von der National University of Singapore und Alibaba präsentiert ihre Arbeit zur Verbesserung der temporalen Denkfähigkeiten von LLMs. Temporale Denkfähigkeiten werden in drei Ebenen unterteilt: Zeit zu Zeit, Zeit zu Ereignis und Ereignis zu Ereignis. Die Studie untersucht diese Aspekte umfassend und stellt fest, dass LLMs wie ChatGPT Schwierigkeiten haben, mit längeren Zeiträumen umzugehen. Um die temporale Denkfähigkeit zu verbessern, wird ein neues Datensatz namens TempReason und ein Training mit zwei Komponenten, temporaler Spannextraktion und zeitbewusster Verstärkung, vorgeschlagen. Die Ergebnisse zeigen, dass TempT5 die beste Leistung in verschiedenen Fragen zeigt, während ChatGPT bei längeren Zeiträumen und komplexeren Fragen unterdurchschnittlich abschneidet.</sample>
    <sample id="125">Die Arbeit wurde von einem einzigen Autor, Yanis Lavraque, durchgeführt.</sample>
    <sample id="126">Ja, die Übersetzung der Anfrage wurde mit Hilfe des Google Translate API als Baseline betrachtet.</sample>
    <sample id="127">Namjoohol, ein Masterstudent an KAIST AI, präsentiert die Arbeit "Large Language Models as Reasoning Teachers", die mit Laura Schmidt und Professor Seongyeon zusammengearbeitet wurde. Die Arbeit zielt darauf ab, die Einschränkungen der Chain of Thought (CoT) -Technik zu überwinden, die nur auf großen Modellen wie GPT-3 oder PALM angewendet werden kann. Die Autoren schlagen vor, diese großen Modelle als 'Lehrer' zu nutzen, um die Fähigkeiten der kleineren Modelle zu übertragen. Sie haben eine neue Technik namens Diverse Reasoning entwickelt, die es ermöglicht, mehrere Beispiersätze zu generieren, um die Schüler besser zu trainieren. Die Ergebnisse zeigen, dass ihre Methode, Fine-Tuned CoT, in vielen Aufgaben, insbesondere textbasierten, deutlich besser abschneidet als andere Methoden. Die Arbeit betont die Skalierbarkeit und die damit verbundenen Kompromisse zwischen Entwicklungs- und Inferenzkosten. Sie bieten auch Code und Daten für die Forschung an und ermutigen zur weiteren Nutzung ihrer Arbeit.</sample>
    <sample id="128">In dieser Arbeit präsentieren Akshata, Martin und ihr Team die KITMOS-Datenbank zur Bewertung der Wissensintegration aus mehreren Quellen. Sie schlagen vor, dass natürliche Sprachverarbeitungsmodelle sowohl prädiktive als auch inferenzielle Informationen nutzen müssen, um komplexe Aufgaben zu bewältigen. Durch die Einführung einer Diagnoseaufgabe und die Entwicklung von Coreference-Resolution-Modellen testen sie die Fähigkeit von Modellen, Wissen aus verschiedenen Quellen zu integrieren. Die Ergebnisse zeigen, dass ohne spezifische Training auf KITMOS Schwierigkeiten bestehen, aber mit entsprechender Schulung können Modelle effektiv mehrere Wissensquellen kombinieren.</sample>
    <sample id="129">Die Autoren geben als Beispiel für eine markierte Gruppe Frauen von Farbe, wobei Wörter wie 'vibrant' und 'curvaceous' verwendet werden, die auf tropische Stereotypen hinweisen.</sample>
    <sample id="130">Die Konferenzarchitektur von 2003 generalisiert nicht gut.</sample>
    <sample id="131">Die Testdatensätze werden als 'clean validation samples' bezeichnet.</sample>
    <sample id="132">Die Arbeit wurde von drei Autoren, Akshata, Martin und einem weiteren nicht genannten, durchgeführt.</sample>
    <sample id="133">Die Autoren arbeiten mit mehreren Modalitäten, nicht nur mit Text, da sie sich auf Multimodal-Instruktionen konzentrieren, die sowohl visuelle als auch sprachliche Elemente beinhalten.</sample>
    <sample id="135">James und Sarah Finch präsentieren ABC Eval, eine neue Methode zur Bewertung von Konversations- und Dialog-AI. Entwickelt von Emery NLP Lab und Amazon Alexa AI, zielt ABC Eval darauf ab, die Subjektivität menschlicher Bewertungen zu reduzieren, indem sie spezifische Verhaltensweisen in Konversationen annotiert. Sie bewerten, wie oft Modelle irrelevante Informationen sagen, sich selbst oder ihren Partner widersprechen, falsche Fakten verbreiten oder Empathie zeigen. Tests mit vier hochrangigen Chat-Modellen zeigen, dass ABC Eval die Zuverlässigkeit und Vorhersage von Konversationsqualität über bestehende Methoden verbessert. Trotz der Fortschritte gibt es noch Herausforderungen, wie die Reduzierung von Fehlern in zukünftigen Modellen.</sample>
    <sample id="136">Jaziel Van präsentiert die Arbeit mit seinem Supervisor Nafisa an der Universität von Sheffield, die sich mit der Entwicklung von FERMAT, einem neuen Evaluationsansatz für numerische Argumentation, befasst. Der Fokus liegt auf der Unzulänglichkeit der aktuellen Benchmarks, die nur eine F1-Score liefern, was nicht die mathematische Stärke der Modelle widerspiegelt. FERMAT zielt darauf ab, die Leistung von Sprach- und mathematischen Modellen durch die Analyse von Zahlenverständnis, arithmetischen Operationen und Trainingsabhängigkeit zu bewerten. Die Arbeit zeigt, dass Modelle, die mit einer breiteren Sprach- und mathematischen Vielfalt trainiert werden, bessere Ergebnisse erzielen. Die Studie betont die Bedeutung von Sprach- und mathematischen Diversität, um die Leistung zu verbessern.</sample>
    <sample id="137">Si Cheng von der Singapore University of Technology and Design präsentiert Tell2Design, eine Arbeit, die sich mit der Erstellung von Sprachgesteuerten Floorplans befasst. Die Arbeit zeigt, wie Textbedingte generative KI, die normalerweise für Kunstwerke verwendet wird, auf die Erstellung von Floorplans angewendet werden kann, die den Anforderungen in natürlichen Sprachen entsprechen. Tell2Design verwendet eine große Datenbank mit Floorplans, die mit natürlichen Sprachanweisungen annotiert sind, und stellt eine neue Aufgabe dar, bei der ein Modell Floorplans direkt aus Sprache generiert. Die Ergebnisse zeigen, dass Tell2Design, ein Modell, das auf der Encoder-Decoder-Struktur basiert, eine hohe Leistung bei der Erfüllung von Sprachanweisungen zeigt, was auf die Fähigkeit hinweist, komplexe Designanforderungen zu verstehen und zu erfüllen.</sample>
    <sample id="138">Nach Ansicht der Autoren ist das Gebiet der zuverlässigen Integration von Wissen aus verschiedenen Quellen, insbesondere Wissen, das nur zur Inferenzzeit verfügbar ist, zu wenig erforscht.</sample>
    <sample id="139">Die Referenten heißen Yin und Ji Yang.</sample>
    <sample id="140">Ja, Coscript wurde von Crowd-Worker überprüft, um die Genauigkeit der generierten Skripte zu gewährleisten.</sample>
    <sample id="141">Die Grenzen bestehender Ressourcen liegen in der begrenzten Unterstützung für verschiedene Sprachen und Kontexttypen, die auf menschliche Kuration und Domänenwissen angewiesen sind.</sample>
    <sample id="142">Hallo. Ich werde über unsere Arbeit zur Lösung von indirekten Referenzen für die Entitätsauswahl sprechen, bei der wir den alt-Entities-Korpus einführen. Und mein Name ist Javad Hosseini, und dies ist eine gemeinsame Arbeit mit Philip Radlinsky, Silvia Parati und Anil Choudhury. Unser Ziel ist es, die Sprache der Benutzer zu verstehen, wenn sie eine Wahl treffen. Betrachten Sie diese alternative Frage: "Meinst du easy on me oder I got a feeling?" Hier möchte der Benutzer zwischen diesen beiden Songs wählen. Das offensichtlichste ist die direkte Referenz, zum Beispiel, indem er den Namen des Songs sagt, easy on me oder seine Position, die erste. Aber manchmal ist eine indirekte Referenz angemessener, um ein natürlicheres Gespräch zu führen. Dies kann passieren, wenn der Benutzer sich nicht an den Namen des Songs erinnern kann, oder die Aussprache zu ähnlich ist und schwer zu unterscheiden ist, oder wenn der Benutzer eine Präferenz angeben möchte. Hier sind einige Beispiele für indirekte Referenzen. Zum Beispiel, der neuere oder der Song, der nicht energetisch ist. Dies ist ein wichtiges Problem in Konversationssystemen und auch für die Entitätverstehung von LLMs. Wir sind uns nicht über einen öffentlichen Datensatz für die Aufgabe bewusst, also sammeln wir einen, indem wir eine Crowdsourcing-Methodik verwenden. Unser Datensatz deckt drei verschiedene Domänen ab: Musik, Bücher und Rezepte. Unsere Datensatzsammlung betont die Informalität mit einem Cartoon-Ergänzungssystem. Der Cartoon hat drei Sprachblasen. In der ersten Blase sagt Bob, "Erinnern Sie sich an das Lied, das wir gestern gehört haben." Und mit dieser, Bob setzt den Kontext. In der zweiten Blase sagt Alice, "Meinst du easy on me oder I got a feeling?" Dies ist die alternative Frage. Und in der dritten Blase verwendet Bob eine indirekte Referenz, um eine dieser Entitäten auszuwählen. Zum Beispiel, die neuere. Wir liefern die ersten und zweiten Blasen automatisch, aber die dritte wird von dem Annotator ausgefüllt. Die erste Blase wird aus einigen manuellen Anweisungen pro Domäne ausgewählt. Die zweite, die alternative Frage, wird wie folgt generiert: "Meinst du a oder b?" wobei a und b aus Wikipedia abgetippt sind. Hier sind die verschiedenen Abtastmethoden, die wir verwendet haben. Wenn wir höher in der Liste gehen, werden die Entitäten sich mehr ähneln. Und es ist normalerweise schwieriger, die Unterscheidung zu treffen. Die erste ist gleichmäßig zufällig. Die zweite, wenn die Entitäten ähnliche Titel haben, zum Beispiel zwei Bücher mit dem Namen the return. Die dritte, wenn sie ähnliche Beschreibungen auf Wikipedia haben, und schließlich, wenn sie ähnliche Infoboxen oder Attribute auf Wikipedia haben, zum Beispiel das gleiche Genre oder den gleichen Künstler für einen Song. Wenn wir diese alternative Frage den Annotatoren zeigen, wissen sie die Namen dieser Entitäten, aber sie kennen sie nicht unbedingt. Also, was wir tun, ist, dass wir einige Hintergrundwissen über die beiden Entitäten zeigen. Für Songs zeigen wir einfach einen Google-Suchlink zu jedem Song. Und dann bitten wir die Annotatoren, mindestens einen der Songs zu hören und über jeden Song zu lesen. Hier ist zum Beispiel der Google-Suchlink für den Song easy on me. Für Rezepte und Bücher zeigen wir einige Hintergrundtext aus Wikipedia. Für Rezepte zeigen wir zusätzlich ihre Bilder, wieder aus Wikipedia, damit die Annotatoren wissen, wie sie aussehen. Dann bitten wir die Annotatoren, eine dieser Entitäten auszuwählen, zum Beispiel hier die erste, und beschreiben sie mit drei bis fünf indirekten Referenzen. Zum Beispiel, die mit dem Klaviermusik. Hier sind einige Beispiele aus unserem Datensatz. Zum Beispiel, ohne Worte, nicht der mit dem zwölfjährigen Jungen oder der fiktiven oder kommt aus Aserbaidschan. Der alt-Entities-Korpus hat 6000 alternative Fragen in drei Domänen, und er hat 42000 indirekte Referenzen. Die Ergebnisse mit dem T5-XL-Modell sind unten zusammengefasst. Wenn der Sprachmodell Zugang zu genau dem gleichen Hintergrundwissen wie die Annotatoren hat, ist die Genauigkeit wirklich hoch, es ist rund 92 bis 95 Prozent. Aber das ist nicht realistisch. Wenn das Sprachmodell Zugang zu teilweise überlappenden Hintergrundwissen hat, dann ist die Genauigkeit zwischen 82 und 87 Prozent, was realistischer ist. Zum Beispiel, wenn das Sprachmodell das Hintergrundwissen abruft. Wenn das Sprachmodell nur Zugang zu Entitätennamen hat, dann ist die Genauigkeit nur 60 Prozent. Es gibt also viel Raum für Verbesserung. Wir haben auch gezeigt, dass die Modelle domänenspezifisch sind. Hier ist ein Link zu unserem Datensatz. Danke.</sample>
    <sample id="143">Der Ansatz wird mit bestehenden Richtlinien wie Wav2Vec und Local Agreement verglichen, wobei er als überlegen herausgestellt wird, da er bessere Ergebnisse in Bezug auf Qualität und Geschwindigkeit erzielt.</sample>
    <sample id="144">Die Autoren gehören der Universität von Toronto.</sample>
    <sample id="145">Der/die Referent*in heißt Jenny.</sample>
    <sample id="146">Zou Yichen, ein Doktorand der Fudan University, präsentiert eine Analyse des Omission-Problems in der Dialogsummarisierung. Dialogsummarisierung ist ein Unterbereich der Textsummarisierung, der sich mit der Erstellung prägnanter Zusammenfassungen von Dialogen befasst. Trotz Fortschritten bei der Dialogsummarisierung, wie der Verwendung von großen Sprachmodellen, bleiben häufige Fehler wie faktische Ungenauigkeiten und Omissionen bestehen. Omissionen, die das Fehlen von kritischen Informationen in den Zusammenfassungen darstellen, sind ein ernstes Problem, das die Qualität der generierten Summaries beeinträchtigt. Um dieses Problem zu lösen, analysiert Zucheng die Omission-Rate und entwickelt ein Datenset zur Omissionserkennung, das auf bestehenden Benchmarks basiert. Er untersucht verschiedene Modelle zur Omissionserkennung und zeigt, dass die Qualität der Zusammenfassungen durch die Bereitstellung von Omissionen verbessert werden kann.</sample>
    <sample id="147">Drei Autoren sind an der Arbeit beteiligt: Myra, Eszter Mosh, und Dan Jurafsky.</sample>
    <sample id="148">Simultane Spracherkennung.</sample>
    <sample id="149">Ja, der Datensatz ist öffentlich zugänglich.</sample>
    <sample id="150">Archie Kiefer präsentiert das Meeting QA-Dataset, das sich auf die extraktive Fragebeantwortung in Meeting-Transkripten konzentriert. Dieses neue Dataset, das sich von früheren Arbeiten unterscheidet, die sich auf Zusammenfassungen und Action-Items konzentrierten, betont die Bedeutung von Fragen, die Diskussionen anregen. Das Meeting QA-Dataset umfasst 7.700 Fragen, die aus 100 Stunden manueller Transkripte des AMI-Korpus stammen. Die Fragen sind oft lang und offen, mit Antworten, die mehrere Sprecher und mehrere Sätze umfassen. Die Ergebnisse zeigen, dass das Meeting QA-Dataset eine Herausforderung für bestehende Fragebeantwortungsmodelle darstellt, insbesondere in der Feinabstimmung und im Zero-Shot-Modus. Die Modelle haben Schwierigkeiten, rhetorische Fragen zu identifizieren und die Zuordnung von Antworten zu den richtigen Sprechern. Die Ergebnisse deuten darauf hin, dass das Meeting QA-Dataset eine bedeutende Aufgabe für die NLP-Forschung darstellt.</sample>
    <sample id="151">Hallo zusammen. Mein Name ist Ying und mein Kollege Ji Yang. Wir werden unsere Forschung über Multi-Teach vorstellen, die Multi-Model-zerotuning verbessert, indem sie die Zerotaufeffizienz von natürlichen Anweisungen verbessert. In der Regel konzentrieren sich frühere Arbeiten auf die Verbesserung der Zerotaufeffizienz bei Sprachaufgaben, während Computer Vision und multimodale Aufgaben vernachlässigt werden. Daher wollen wir untersuchen, ob die Anweisungsanpassung auf multimodalen vortrainierten Modellen die Generierung auf multimodalen Aufgaben verbessern kann. Darüber hinaus haben wir bei unserer Forschung eine erhebliche Diskrepanz in der Verfügbarkeit von Anweisungsdaten zwischen NLP und multimodal entdeckt. Es gibt mehr als sechshundert Sprachaufgaben, aber keine groß angelegte, öffentlich zugängliche multimodalen Anweisungsaufgaben. Daher haben wir Multi-Teach, das erste multimodale Anweisungsanpassungs-Benchmark-Set, das aus sechzig verschiedenen multimodalen Aufgaben besteht, die aus einundzwanzig Open-Source-Datensätzen abgeleitet sind. Jedes dieser Aufgaben ist mit fünf Expert-Anweisungen ausgestattet. Um die Anweisungsanpassung auf unserem vorgeschlagenen Datensatz zu untersuchen, verwenden wir ofa, ein einheitliches multimodales vortrainiertes Modell. Ofa verwendet ein einheitliches Vokabular für Sprache, Bild-Token und die Koordinaten eines gebundenen Blocks. Hier zeigen wir einige Beispiele aus unserem Multi-Teach-Set. Um die Anweisungsanpassung auf unserem vorgeschlagenen Datensatz zu untersuchen, verwenden wir ofa als Basismodell. Für die Trainingsdaten verwenden wir dreiundfünfzig Aufgaben aus der Gruppe für die Trainingsdaten. Wir nehmen zehntausend Instanzen pro Aufgabe. Für die Tests reservieren wir die gesamte Common Sense Reasoning-Gruppe. Wir wählen auch fünf weitere Aufgaben aus der VQA- und der bösartigen Gruppe. Wir verwenden alle Instanzen in der Test-Split für jede Aufgabe. Darüber hinaus nehmen wir zufällig fünf Aufgaben aus der Test-Split der natürlichen Anweisung als NLP-Aufgabe. Für die Tests führen wir für jede Aufgabe insgesamt fünf Experimente durch, indem wir das Modell mit einer der fünf Anweisungs-Templates in jedem Experiment ausführen. Wir berichten die mittlere und maximale Leistung und die Standardabweichung der Leistung über alle fünf Experimente. Wenn die Aufgabe eine multimodale Klassifizierungsaufgabe ist, berichten wir die Genauigkeit. Wenn es sich um eine multimodale Generierungsaufgabe handelt, berichten wir die RUGL. Für NLP-Aufgaben berichten wir auch die RUGL. Wir haben auch eine zusätzliche Bewertungsmetrik namens Sensitivität eingeführt. Diese misst die Fähigkeit des Modells, für dieselbe Aufgabe immer die gleichen Ausgaben zu produzieren, unabhängig von der Wortwahl der Anweisung. Hier sind unsere Hauptergebnisse. Wie wir sehen können, kann Anweisungsanpassung die Leistung von ofa bei unsichtbaren multimodalen Aufgaben erheblich verbessern. Darüber hinaus kann das Transferlernen von Anweisungsdaten das Anweisungsanpassungsmodell erheblich verbessern. Wenn wir die Anzahl der Aufgaben erhöhen, erreichen wir eine bessere Leistung und gleichzeitig eine geringere Sensibilität. Wir führen auch ein Experiment durch, bei dem wir eine Anweisung im Vergleich zu fünf Anweisungen verwenden. Wir können sehen, dass die Verwendung mehrer Anweisungen die Gesamtleistung des Modells verbessert und seine Sensibilität erheblich reduziert. Dies zeigt die Auswirkungen verschiedener Feinabstimmungstechniken auf die Sensibilität des Modells. Das Transferlernen von Anweisungsdaten aus dem Anweisungsdatensatz kann das Modell auf dem Anweisungsdatensatz erheblich verbessern. Wir schlagen ein großes, multimodales Anweisungsanpassungs-Set vor, das etwa fünfzig zusätzliche visuelle Sprachaufgaben enthält. Wir werden sie bald veröffentlichen. Dies ist der QR-Code für unsere Daten und das Modell.</sample>
    <sample id="152">In der Präsentation 'Exploring Large Language Models for Classical Philology' diskutiert Friedrich Griebenschneider die Entwicklung von Sprachmodellen für die Klassische Philologie. Er präsentiert Grebéra und GRETTER, zwei monolinguale Modelle für Altgriechisch, und Filberta und Filther, zwei multilingualen Modelle, die auf Altgriechisch, Latein und Englisch trainiert wurden. Die Modelle wurden mit einem neuen, hochwertigen Pretraining-Korpus aus dem Internetarchiv entwickelt, das korrigierte OCR-Transkriptionen enthielt. Die Modelle wurden auf drei Hauptaufgaben, nämlich Part-of-Speech-Tagging, Dependency-Passing und Lemmatisierung, getestet und zeigten eine deutliche Verbesserung gegenüber bestehenden Modellen. Die Analyse zeigte, dass die Encoder-Decoder-Modelle in der Lemmatisierung herausragend sind, während die multilingualen Modelle keine signifikanten Verbesserungen gegenüber den monolingualen Modellen aufwiesen.</sample>
    <sample id="153">Nina Rehmehy, a scientist at Amazon Alexa, discusses resolving ambiguities in text-to-image models. Ambiguities in prompts can lead to inaccurate image generation. Her team developed a framework to disambiguate prompts using clarifying questions or visual setups, and an evaluation system to assess image faithfulness. The framework showed positive results in improving image generation accuracy, aligning with human evaluations. The research highlights the importance of addressing ambiguities to enhance AI's ability to generate accurate images.</sample>
    <sample id="154">Die Autoren gehören der Universität von Trento an.</sample>
    <sample id="155">Der/die Referent*in heißt "Easy on Me".</sample>
    <sample id="157">Sheng Gao von Sun Dong University präsentiert die Arbeit "Dialogue Summarization with Static Dynamic Structure Fusion Graph", die mit Kollegen von Sun Dong University und der University of Science and Technology of China durchgeführt wurde. Das Ziel ist es, Dialoge zu summarisieren, indem man die Hauptideen der Teilnehmer ohne die komplexe Konversation zu erfassen. Die Methode verwendet eine Kombination aus statischen und dynamischen Graphen, um die semantischen Beziehungen zwischen den Sätzen zu erfassen. Die Methode umfasst die Verwendung von heuristischen Dialogstrukturmodellen, um die Beziehungen zwischen Sprechern zu modellieren, und die Verwendung von Multi-Head-Attention, um die semantischen Beziehungen zu erfassen. Die Methode integriert diese Graphen, um eine zusammengefasste Darstellung zu erstellen, die die Dialogstruktur in den generierten Summarien einbezieht.</sample>
    <sample id="158">In seiner Präsentation über Dual Cache für Coreference Resolution erläutert Xiangkunhu von AWS die Herausforderungen bei der Entitätsverfolgung in langen Dokumenten. Er beschreibt, wie traditionelle Cache-basierte Methoden mit einer linearen Komplexität und hohen Cache-Missraten bei langen Dokumenten unterliegen. Dual Cache, bestehend aus einem lokalen und einem globalen Cache, bietet eine Lösung, indem es Entitäten basierend auf ihrer globalen oder lokalen Natur trennt. Die Implementierung führt zu einer signifikanten Reduzierung der Cache-Missraten und verbessert die Effizienz, insbesondere bei großen Texten. Die Ergebnisse zeigen, dass Dual Cache, trotz der Kosten für die Modellleistung, eine hohe Performance-zu-Kosten-Relation bietet und somit eine kosteneffiziente Alternative zu Single Cache-Methoden darstellt.</sample>
    <sample id="159">Hallo zusammen. Ich bin Kostas Sinha und freue mich, Sie zu unserem Vortrag zu unserem Acl Twenty Twenty Three Paper, Language Model Acceptability Judgments are not always robust to context. Dies ist eine gemeinsame Arbeit mit John Waugh, Aaron Muller, Kanishka Mishra, Karen Fentress, Roger Levy und Atina Williams. In dieser Arbeit überprüfen wir das minimale Paar-Paradigma. Das minimale Paar-Paradigma bewertet Spracheinheiten in Bezug auf Akzeptanzurichtungen, wie z. B. Grammatik, wie Blimp Syntax, oder Akzeptanz in Bezug auf Stereotypen, z. B. Kraus Paare. Und in diesem minimalen Paar-Paradigma ist die typische Art, Spracheinheiten zu bewerten, dass Sie eine akzeptable oder unakzeptable Satzzeile zeigen, und die Hoffnung ist, dass die Modelle mehr Wahrscheinlichkeit auf die akzeptable Satzzeile setzen. Der aktuelle MPP-Pipeline ermöglicht es uns nicht, Modelle Akzeptanz gegenüber längeren Sätzen zu bewerten. In den heutigen Tagen kommen große Sprachmodelle mit längeren Kontextfenstern. Es ist also entscheidend, dass wir die Akzeptanz der Modelle über den gesamten Kontextfenster bewerten. Das ist es, was wir hier tun. Wir versuchen, den MPP-Pipeline zu überarbeiten, indem wir die Modelle bitten, Akzeptanz auf längeren Sequenzen zu bewerten. Also, was tun? Wir simulieren diese längeren Sequenzen, wir überarbeiten die Datensätze selbst und erstellen dann Sätze, indem wir akzeptable oder unakzeptible Sätze aus diesen Datensätzen auswählen. Zum Beispiel haben wir hier ein typisches Paar von Grammatik aus dem Blimp-Datensatz ausgewählt. Und was wir tun, um längere Sequenzen zu erstellen, die akzeptabel sind, und die gleiche grammatische Struktur haben, extrahieren wir grammatische Sätze aus Adjektiv und fügen sie als Präfix zu sowohl der akzeptablen als auch der unakzeptablen Abfrage hinzu. Wir können das gleiche tun, indem wir unakzeptable Sätze aus derselben Phänomene auswählen. Und das könnte auch die Akzeptanz der Modelle testen. Und wir können das auch tun, indem wir Sätze aus einem anderen Datensatz oder einem anderen Datensatz auswählen. Das wird uns sagen, ob die Akzeptanzurichtungen der Modelle tatsächlich von der Kontext beeinflusst werden. Wie geht das Modell? Zuerst schauen wir uns die Wikipedia-Sätze an, die völlig irrelevant für die aktuelle Abfrage sind. Und dort finden wir, dass die MPP-Urteile für beliebige Kontextlängen relativ stabil sind. Wir erhöhen die Kontextlänge auf zehntausendvierundzwanzig, um die Modelle von Op T und GPT zwei zu maxen. Wir haben hier in der orangefarbenen Linie gesehen, dass die MPP-Urteile relativ stabil sind. Was passiert, wenn wir Sätze aus dem gleichen Datensatz auswählen? Also, hier haben wir Sätze aus akzeptablen und unakzeptablen Domänen aus dem gleichen Blimp oder Syntax, Jim. Und wir sehen, dass die MPP-Urteile entweder signifikant zunehmen oder abnehmen, wenn wir akzeptable Präfixe oder unakzeptable Präfixe hinzufügen. Aber wenn wir die Struktur abgleichen, das heißt, wenn wir Sätze aus derselben Phänomene auswählen, sehen wir eine massive Zunahme oder Abnahme der MPP-Urteile für das Modell, abhängig davon, ob die gewählte Präfixe akzeptabel oder unakzeptabel sind. Und das ist sehr groß. Diese Wirkung nimmt mit der Kontextlänge zu. Und das würde wahrscheinlich die neueren Sprachmodelle, die große Kontextfenster haben, beeinflussen. Warum beeinflusst das abgleiche Präfix die Sprachmodellurteile so stark? Wir haben eine Reihe von Analysen durchgeführt, bei denen wir versuchen, die Eingabensätze zu stören, indem wir die relevanten Strukturen beibehalten, aber Störungen in die Eingabensätze hinzufügen. Und nach mehreren dieser Störungen ändern die Modelle nicht ihre Kurs. Im Grunde genommen finden wir, dass die Modelle auf ähnliche Weise auf die Störungen in den akzeptablen Domänen reagieren. Und wenn wir die Sätze in den unakzeptablen Domänen stören, sehen wir eine Abnahme der MPP-Urteile. Die wichtigsten Erkenntnisse unserer Arbeit sind, dass Sprachmodelle auf latente syntaktische und semantische Merkmale reagieren, die über die Sätze hinweg geteilt werden. Und die MPP-Bewertung, die wir derzeit mit kurzen und einzelnen Satzeneingaben machen, erfasst möglicherweise nicht vollständig die abstrakten Kenntnisse der Sprachmodelle über den Kontextfenster. Bitte lesen Sie unsere Arbeit für mehr Details zu unseren Experimenten. Vielen Dank für Ihr Zuhören.</sample>
    <sample id="160">Im ersten Schritt werden die Input-Token mit einem unordentlichen Multiset von Tokens, die im Output erscheinen, tagged.</sample>
    <sample id="161">Coscript enthält insgesamt 55.000 Skripte.</sample>
    <sample id="163">Die beste Ausrichtungsmethode für DEplain ist die Methode von MASS.</sample>
    <sample id="164">Schwach überwachtes Lernen ermöglicht es, Modelle mit kostengünstigen, aber ungenauen Labels zu trainieren, was die Notwendigkeit manueller, teurerer Annotationen reduziert.</sample>
    <sample id="165">Wenting Zhao präsentiert das Paper 'Adaptiereasoning Exploiting Mutually Exclusive Explanations' an der Cornell University. Er erklärt, dass adaptiveres Denken eine Methode ist, um plausible Erklärungen für einen Kontext und ein Ergebnis zu finden. Aktuelle Ansätze erfordern oft die Anmerkung plausibler Erklärungen, was subjektiv und ungenau sein kann. Zhao schlägt vor, dass es möglich ist, adaptiveres Denken ohne Überwachung zu lernen, indem er LIpor einführt, das die Wahrscheinlichkeit des Ergebnisses maximiert, indem es die Plausibilität der Erklärungen berücksichtigt. Er zeigt, dass LIpor die Genauigkeit von Zero-Shot-Modellen und anderen Ansätzen erheblich verbessert.</sample>
    <sample id="166">Yuxin Luo von Harbin University of Technology präsentiert ein neues Framework zur Bildwiederherstellung aus komplexen Texten, das auf der Divide-and-Conquer-Strategie und der Dual-Process-Theorie basiert. Das System kombiniert die Vorteile von System 1, das auf analoger Inferenz basiert, und System 2, das für abstrakte logische Inferenzen geeignet ist. Es besteht aus einem Symbol Generator, einem Decoder, einem Visual Linguistic Interactor und einem Neural Symbolic Reasoner. Die Ergebnisse zeigen, dass das neue Modell die Leistung bestehender Methoden übertrifft.</sample>
    <sample id="167">Die Dokumente in DEplain-web wurden mit 750 manuellen und 750 automatischen Alignmentmethoden ausgerichtet.</sample>
    <sample id="168">Der CoNLL++-Datensatz wurde erstellt, indem die Reuters News-Artikel von 2020 annotiert wurden mit den gleichen CoNLL 2003-Anmerkungsguidelines.</sample>
    <sample id="169">Aydin Bilal presents a study on prompting large language models (LLMs) for machine translation, focusing on the PAMP model. The study evaluates the translation capabilities of PAMP using the latest test sets and compares it to state-of-the-art systems. It finds that the quality of prompts, especially those from high-quality translation data, significantly impacts performance. The research suggests that while PAMP is close to commercial systems, it lags in accuracy, often omitting parts of the source sentence. However, PAMP's fluency is comparable to advanced systems. The study recommends using five-shot prompting strategies and highlights the importance of selecting high-quality examples for better results.</sample>
    <sample id="170">Hallo zusammen. Mein Name ist Yuxin Zhang von der Penn State University. Heute werde ich unsere Arbeit vorstellen, die sich mit der semantischen Analyse in mehreren natürlichen Sprachen und -repräsentationen befasst. Semantische Analyse ist die Aufgabe, semantische Repräsentationen von Benutzeranfragen wie SQL und Lambda zu erstellen. Und semantische Analyse in mehreren Sprachen ist die Aufgabe, Anfragen in mehreren natürlichen Sprachen in mehrere Repräsentationen zu übersetzen. Es gibt separate Modelle für verschiedene Aufgaben, wie z. B. fehlende Abdeckung in bestimmten Sprachen oder Mini-Repräsentationen. Um dies zu erreichen, schlagen wir vor, ein Exemplar zu verwenden, das eine einheitliche Datenbank für semantische Analyse in mehreren natürlichen Sprachen und -repräsentationen bietet. Es enthält neun Datensätze in verschiedenen Domänen, fünf semantische Anweisungen, acht Millionen Repräsentationen und zweiundzwanzig natürliche Sprachen in fünf Sprachfamilien. Um unsere Benchmark besser zu bewerten, berücksichtigen wir sechs Trainings- und Bewertungssettings. Das erste ist die Übersetzungsprüfung. Wir verwenden die Google-Übersetzungs-API, um die Quelle in die Zielsprache zu übersetzen, und verwenden dann ein monolinguales Modell, um die SQL zu trainieren und zu bewerten. Und wir testen auch ein monolinguales Modell. In diesem Setting ist die Quell- und Zielsprache gleich, z. B. Deutsch zu Deutsch oder Englisch zu Englisch. Wir testen auch ein monolinguales Modell mit nur zehn Prozent des Trainingsdatensatzes. Und wir testen ein multilinguales Modell, das für alle Sprachen trainiert wird. Zum Beispiel setzen wir deutsche, englische und chinesische Abfragen zusammen, um ein multilinguales Modell zu trainieren, das SQL oder chinesische Abfragen vorhersagen kann. Und wir berücksichtigen auch Cross-lingual Zero-Shot- und Few-Shot-Transfer. Wir trainieren auf englischen Abfragen oder der Kombination aus englischen und deutschen Abfragen, um ein multilinguales Modell zu trainieren, das SQL vorhersagen kann. Und wir finden viele interessante Ergebnisse. Zum Beispiel bewerten wir zwei Gruppen von Modellen, einschließlich Encoder-PTR, was für multilingual trainierte Encoder mit pointerbasierten Decodern steht, wie xlnr plus ptr und bert plus ptr. Und wir bewerten auch Encoder-Decoder-Modelle, was für multilingual trainierte Encoder-Decoder-Modelle wie mbart und mt five steht. Wir fanden, dass Encoder-Decoder die beste Leistung auf allen neun Datensätzen erzielt. Und wir bewerten mt five und Exemplar auf multilingualer Ebene. Wir fanden, dass Encoder-Decoder oder Encoder-PTR durch das Training in einer Mischung verschiedener Sprachen verbessert werden kann. Und wir fanden, dass die Cross-lingual-Transfer-Leistung bei Zero-Shot- und Few-Shot-Transfer signifikant ist. Und wir finden, dass die Cross-lingual-Transfer-Leistung bei Few-Shot-Transfer schnell verkürzt wird. Und wir finden auch einige andere interessante Ergebnisse. Zum Beispiel, wenn wir auf Englisch trainieren, kann die Leistung von Few-Shot auf Zielsprachen erheblich verbessert werden. Und wir fanden, dass multilingualen Sprachmodellen wie codas und bleu für Cross-lingual-Semantische Analyse-Tasks unzureichend sind. Zusammenfassend haben wir Exemplar, ein einheitliches Benchmark für Cross-lingual-Semantische Analyse mit mehreren natürlichen Sprachen und -repräsentationen. Wir führen eine umfassende Benchmark-Studie mit drei repräsentativen Arten von multilingualen Sprachmodellen durch, und unsere Ergebnisse zeigen viele interessante Ergebnisse. Und willkommen, um unser Papier und Code zu besuchen. Vielen Dank für das Zuhören.</sample>
    <sample id="171">Existing works are broadly classified into four categories, but they either are not applicable to embedding ad services or lack transferability.</sample>
    <sample id="172">Nein, mehrsprachige LLMs wie Codex oder Bloom sind für CLSP nicht ausreichend, da sie nicht speziell für CLSP entwickelt wurden.</sample>
    <sample id="174">Priya und ihr Co-Autor haben einen neuen Daten-Set namens Arganalysis 35K für die Argument-Qualitätsanalyse vorgestellt. Dieser Daten-Set ist einzigartig, da er 35.000 hochqualifizierte Argumente aus verschiedenen Quellen wie hochrangigen Turnieren und Experten enthält. Er bietet eine breitere Vielfalt an Themen und integriert eine Analyse, die über einfache Argumente hinausgeht. Die Daten-Set-Entwicklung umfasst auch die Einführung einer Instanz-basierten Annotatoren-Relativität, die die Genauigkeit der Annotations verbessert, indem nur die Anmerkungen, die als voreingenommen angesehen werden, entfernt werden. Darüber hinaus bietet der Daten-Set ein Relevenzmodell, das die Relevanz von Argumenten für verschiedene Themen bewertet. Priya ermutigt die Zuhörer, sich mit dem Paper und der Konferenz zu informieren, um die einzigartigen Merkmale des Daten-Set zu verstehen.</sample>
    <sample id="175">Die Methode verwendet eine GPU-freundliche kontinuierliche Relaxation, um die Permutationen zu approximieren und die sprachlich plausiblen Permutationen zu lernen.</sample>
    <sample id="176">Fairness wird durch die Analyse der Leistung des Modells bei der Erkennung von Hate Speech und Fake News in verschiedenen sozialen und politischen Kategorien definiert, wobei Modelle mit unterschiedlichen politischen Neigungen unterschiedliche Ergebnisse liefern.</sample>
    <sample id="177">Der/die Referent*in heißt Yanis Lavraque.</sample>
    <sample id="178">Der Referent ist Kostas Sinha.</sample>
    <sample id="179">Mélanie Szklarek präsentiert Symbolic TOM, ein Framework zur Verbesserung der Theorie des Geistes-Entscheidungsfindung in großen Sprachmodellen. Durch die Verwendung von grafischen Darstellungen, die die mentalen Zustände von Charakteren darstellen, ermöglicht es das System, komplexe Fragen zu beantworten. Tests zeigen, dass Symbolic TOM die Leistung von LLMs signifikant verbessert, insbesondere bei nicht standardisierten Aufgaben, und übertrifft die Ergebnisse von überarbeiteten Modellen.</sample>
    <sample id="180">Der Referent ist Dan Jurafsky.</sample>
    <sample id="181">Die Arbeit von Si Yuan und Kollegen untersucht die Fähigkeit von großen Sprachmodellen, spezifische, kontextbezogene Ziele zu planen, die durch Einschränkungen definiert sind. Sie identifizieren die Unzulänglichkeiten in der Planung von spezifischen Zielen und entwickeln eine Methode, die Over-Generate-Zen-Filter, um die Qualität der generierten Skripte zu verbessern. Durch die Erstellung eines Datensatzes namens CodeScript, der 55.000 spezifische Ziele mit Skripten enthält, bieten sie eine Ressource zur Verbesserung der Forschung in der Sprachplanung. Die Ergebnisse zeigen, dass kleinere, aber spezialisierte Modelle, trainiert auf CodeScript, die Leistung von großen Sprachmodellen übertreffen können.</sample>
    <sample id="182">Tropikalismus bezieht sich auf die stereotypischen und exotisierenden Darstellungen von Latina Frauen, die sie mit Farben und Texturen assoziieren, was auf eine historische Übersexualisierung und andere Stereotypen zurückzuführen ist.</sample>
    <sample id="183">Die Autoren haben die von Menschen verfassten Beschreibungen der Zielgruppen durch die Verwendung eines lexikons von Stereotypen erstellt, das verschiedene Stereotypen und Muster identifiziert.</sample>
    <sample id="184">Die Arbeit verwendete cXMI, um die Kontextnutzung zu messen, indem sie die Informationen ausgeben, die der Kontext C über das Ziel Y liefert, gegeben die Quelle X.</sample>
    <sample id="185">DrBERT ist ein französischer medizinischer Sprachmodell, während ChuBERT ein englischer medizinischer Sprachmodell ist.</sample>
    <sample id="187">Zwei Autoren, Yin und Ji-Yang, sind an der Arbeit beteiligt.</sample>
    <sample id="188">Iteratives Transferlernen ist ein Prozess, bei dem ein Modell mit neuen Daten aus jeder Runde von aktiver Annotation aktualisiert wird. Es ermöglicht kontinuierliche Verbesserungen durch das Training auf neu gesammelten Daten.</sample>
    <sample id="189">Das Ziel des Datensatzes ist es, eine große, öffentlich zugängliche Sammlung von indirekten Referenzaufgaben zu erstellen, die in drei Domänen (Musik, Bücher, Rezepte) variieren, um die Entitätserkennung in Konversationen zu verbessern.</sample>
    <sample id="190">Ein Angreifer kann Modellparameter über einen EaaS extrahieren, indem er die Embedding-Wasserzeichen verwendet, die in den Embeddings eingebettet sind. Durch das Lernen von diesen Wasserzeichen kann der Angreifer die zugrunde liegenden Modellparameter kopieren.</sample>
    <sample id="191">Die Arbeit wurde von drei Autoren, Sarah Papi, Matteo Negri und Marco Turilli, durchgeführt.</sample>
    <sample id="192">Yang Luo präsentiert die Arbeit an einem Optimierer namens CANN, der sowohl schnell als auch speichersparend ist. CANN verwendet eine nicht-negative Matrix-Faktorisierung, um Speicher zu sparen, und verbessert die Adaption von Optimierern wie Adam und Adafactor. Es korrigiert die Fehler in der Update-Phase, die zu langsamen Konvergenzen führen. CANN zeigt in Tests auf großen Sprachmodellen wie BERT und GPT-2 eine verbesserte Leistung mit weniger Speicherverbrauch. Es ist besonders effektiv für große Modelle und bietet eine kosteneffiziente Alternative zu bestehenden Optimierern.</sample>
    <sample id="193">Um den ursprünglichen Datensatz zu erstellen, wurden 43 Annotatoren verwendet.</sample>
    <sample id="194">Die Autoren gehören der Carnegie Mellon University an.</sample>
    <sample id="195">Die Arbeit 'Reasoning over Hierarchical Question Decomposition Tree' (ROHT) zielt darauf ab, komplexe Fragen in einer hierarchischen Frage-Decomposition-Tree (HQDT) zu verstehen und probabilistisch über diese zu lösen. Die HQDT besteht aus einem Wurzelknoten, der die komplexe Frage darstellt, und Knoten, die ihre Unterfragen darstellen. Die Lösung erfolgt durch eine drei Schritte umfassende Analyse: Auswahl der passenden Wissensquellen, Ermittlung der Antworten mit Wahrscheinlichkeiten und Zusammenführung der Ergebnisse, um die Top-K-Antworten zu bestimmen. Die Frameworks Leistung wurde auf den KQAPRO und MUSIC Datensätzen getestet, wobei ROHT-KB und ROHT-MIX die bestehenden Methoden übertrafen, insbesondere durch die Integration von Text- und KB-Korps.</sample>
    <sample id="196">Das Beispiel mit dem Begrenzer auf der linken Seite ist 'I saw Bart and Lisa'.</sample>
    <sample id="197">Dialogsysteme haben Fortschritte gemacht, aber Herausforderungen wie Relevanz und Selbstkontradiktionen bestehen. ABC Eval bietet präzisere Evaluationsmethoden, um diese Probleme zu adressieren.</sample>
    <sample id="198">Die Bewertung der Akzeptanz der Modelle über das gesamte Kontextfenster ist notwendig, da aktuelle große Sprachmodelle längere Kontextfenster haben, und die aktuelle MPP-Pipeline nicht diese längeren Sequenzen bewerten kann.</sample>
    <sample id="199">Ja, das mehrsprachige Training führte in sieben der Datensätze zu einem Leistungsabfall im Vergleich zum einsprachigen englischen Modell.</sample>
    <sample id="200">Ja, die Annotatoren kennen die Entität im Voraus.</sample>
    <sample id="201">Die Bewertung verwendete fortschrittliche Neurometrik, um die Leistung der MT-Systeme zu bewerten.</sample>
    <sample id="202">Die Regression wirkt sich auf bestimmte NER-Typen unterschiedlich aus, wobei die Ergebnisse für den Typ 'ORG' am schlechtesten sind.</sample>
    <sample id="203">Positionalität ist wichtig für NLP, weil sie die systematischen Vorurteile in Daten und Modellen offenlegt, die zu ungleichen Ergebnissen für verschiedene Bevölkerungsgruppen führen können. Durch das Verständnis dieser Positionen können Forscher inklusivere und gerechtere Technologien entwickeln.</sample>
    <sample id="204">Mehrsprachige LLMs wie BLOOM wurden nicht durch Adapter, sondern durch eine vollständige Feinabstimmung auf den multilingualen Datensatz X-ELM angepasst.</sample>
    <sample id="205">Xiangbing, a PhD student, discusses the influence of political biases in language models, which are trained on large-scale web data, including politically skewed media. The study investigates how these biases affect downstream tasks, such as hate speech and fake news detection, revealing that models with different political leanings perform variably across demographics. The research highlights the challenges of sanitizing training data to prevent bias propagation, while also cautioning against censorship. The findings underscore the need for addressing fairness issues in NLP applications.</sample>
    <sample id="206">Wir verwenden Transfer Learning, indem wir Gewichte von verwandten Aufgaben wie der 'Topic Independent Discourse Dissonance Classification' und 'Binary Classification' übertragen.</sample>
    <sample id="207">The evaluation of PaLM's capabilities was conducted using the latest test sets to ensure no overlap with the training data, as part of a systematic study on language model prompting for machine translation.</sample>
    <sample id="208">Die Autoren haben drei Empfehlungen für die Modellbesitzer vorgeschlagen.</sample>
    <sample id="209">Die vorgeschlagene Methode erzielt einen Gewinn von 0,8 über der stärksten Baseline.</sample>
    <sample id="210">Der Referent ist Shuo-Hung Hsu.</sample>
    <sample id="211">Ja, die Ergebnisse und der Datensatz der Studie können als Benchmark für zukünftige Arbeiten in der automatischen Textvervollständigung verwendet werden.</sample>
    <sample id="212">Die Arbeit experimentiert mit kleineren Modellen, die auf dem CodeScript-Dataset trainiert werden.</sample>
    <sample id="213">Das Basismodell für die Untersuchung ist OFA, ein multimodales, vortrainiertes Modell, das ein einheitliches Vokabular für Sprache, Bilder und Koordinaten verwendet.</sample>
    <sample id="215">Adam Szpekocskis Vortrag behandelt die Koordinationsstruktur in verschiedenen syntaktischen Theorien. Er vergleicht symmetrische (z. B. Universal Dependencies, Meaning Text Theory) und asymmetrische (z. B. Prague Dependency Treebank) Ansätze, wobei die symmetrischen Ansätze einen einzigen Koordinationskonjunktiv hervorheben, während die asymmetrischen mehrere Koordinationskonjunktionen haben. Szpekocskis Argument für symmetrische Strukturen basiert auf der Minimierung der Abhängigkeitslänge, die besagt, dass kürzere Abhängigkeiten bevorzugt werden. Er zeigt, dass in Koordinationsstrukturen ohne linken Gouverneur (z. B. "I saw Bart and Lisa") die linke Koordinationskonjunktion kürzer ist, wenn die Konjunktivdifferenz größer ist. Diese Beobachtung unterstützt die symmetrische Struktur, da sie die Abhängigkeitslänge minimiert.</sample>
    <sample id="217">Die Arbeit von An Weihao und Lu Lu Zhao konzentriert sich auf die generative Dialogführung mit mehreren Attributen, die über bestehende Methoden hinausgeht, die sich auf einzelne Attribute konzentrieren. Sie haben D-C-G entwickelt, ein Modell, das Attribute aus Sichtwerte lernt und Distangle-Loss verwendet, um verschiedene Attributekombinationen zu trennen. Sie haben auch ein einheitliches Bewertungsframework (MAE) eingeführt, das die Evaluierung verschiedener Attribute ermöglicht, ohne zusätzliche Labordaten zu benötigen. Ihre Ergebnisse zeigen, dass D-C-G die Komplexität der Dialogführung mit mehreren Attributen effektiv bewältigt und über die Baselines in Bezug auf Attributkontrollierbarkeit und Testqualität hinausgeht.</sample>
    <sample id="218">Die Autoren gehören der Universität Graz an.</sample>
    <sample id="219">Jiahuizhu Xie, a research assistant at Academia Sinica, presented a multi-stage pipeline for financial signal detection in reports. The project, led by Xie and Professor Zheng, focuses on the Form 10-K reports, which are detailed annual financial documents. The pipeline aims to automate the extraction of important financial information from these reports, which is typically a labor-intensive process. The approach involves segmenting documents, classifying word pairs into types based on their semantic and syntactic similarities, and using a two-stage fine-tuning process with an external dataset. The method shows promise in improving performance and generalization, and future work includes exploring additional features and applications.</sample>
    <sample id="220">Stony Brook University.</sample>
    <sample id="221">Die Arbeit untersuchte die Übersetzung von Deutsch in Englisch.</sample>
    <sample id="222">Die Arbeit untersucht die Herausforderungen und Interventionen bei der Adaption von Open-Domain-Question-Answering. Sie untersucht verschiedene Dateninterventionen, die zur Out-of-Domain-Generalisierung in Open-Domain-QA beitragen, identifiziert die Art der Datensatzverschiebung, die ein neues Domänemodell aufweist, und bestimmt, welche Dateninterventionen für eine bestimmte Art von Verschiebung am effektivsten sind. Die Studie verwendet einen allgemeinen Wikipedia-Korpus, um sowohl Leser- als auch Retriever-Modelle zu trainieren. Sie untersucht verschiedene Methoden zur Generierung von Dateninterventionen, wie Zero-Shot- und Few-Shot-Techniken, und bewertet die Auswirkungen von Frage-, Antwort- und Kontextverteilung auf die Modellleistung. Die Ergebnisse zeigen, dass bestimmte Dateninterventionen die Leistung des Lesemodells um bis zu 24% verbessern können, abhängig von der Art der Datensatzverschiebung.</sample>
    <sample id="223">Der Referent ist Dr. Xiangming Zhang.</sample>
    <sample id="224">Die Modelle Long-IMPART und Normal-Base-IMPART wurden untersucht.</sample>
    <sample id="225">Für Training werden 53 Aufgaben aus 9 Gruppen verwendet, während Tests die gesamte Common Sense Reasoning Gruppe und 5 zusätzliche Aufgaben aus VQA und Misconception Groups beinhalten.</sample>
    <sample id="226">Die Arbeit wurde von zwei Autoren, Regina Stoddard und Omar, durchgeführt.</sample>
    <sample id="227">Der Vortrag diskutiert die Herausforderungen bei der Umsetzung von Grounded Language Understanding (GLU) in NLP, bei der natürliche Sprache in spezifische Umgebungen übersetzt wird. Aktuelle Modelle, wie T5, sind in der Regel auf Textkorruption trainiert, was die Umsetzung in realen Anwendungen erschwert. Der Proposierte Ansatz, PANGO, konzentriert sich auf die Bewertung von Kandidatenplänen durch Sprachmodelle, ohne die Erstellung selbst zu übernehmen. Dies ermöglicht eine bessere Leistung, insbesondere bei der Erkennung von sinnvollen, grammatikalisch korrekten und validen Plänen. PANGO zeigt überlegene Ergebnisse bei der Erkennung von Fragen in einer heterogenen Umgebung, mit einer hohen Genauigkeit und Robustheit, die auf einer gleichmäßigen Verteilung der Wahrscheinlichkeit für verschiedene Strukturen zurückzuführen ist. Der Vortrag schließt mit der Aufforderung an die Gemeinschaft, sich mit der Arbeit zu beschäftigen und zu diskutieren.</sample>
    <sample id="228">Die Autoren haben Experimente an den Datensätzen AG News, MIND, SSTD2 und ERESTA durchgeführt.</sample>
    <sample id="229">Gabriela Skatylinskaya presents a study on detecting suboptimal claims in argumentative writing, focusing on the importance of text revision for effective communication. The research addresses challenges in using revision-based data, such as representativeness, model complexity, contextual relevance, and bias. The study explores how to model argument quality and improve claim assessment, concluding that revision-based data can be effectively used for the given tasks.</sample>
    <sample id="231">NACHOS ist ein dataset of medical crawled data from the web, used for training the Dr. Bert model.</sample>
    <sample id="232">Der Referent*in heißt Aydil Bilal.</sample>
    <sample id="233">Sarah Papi presents a novel approach to simultaneous speech translation (SimulST) by leveraging existing off-the-shelf models without retraining. The proposed Encoder-Decoder Attention (EDAT) strategy uses a single model for different latency regimes, focusing on attention mechanisms to decide when to emit translations. This method outperforms existing strategies by achieving better translation quality and lower latency, as demonstrated in their experiments. The team has released their code and models to support further research and application.</sample>
    <sample id="234">Die Prompt-Strategie hat einen erheblichen Einfluss auf die Ergebnisse, wobei fünf Shot Prompting die beste Leistung bietet, da es die Qualität der Beispiele betont, anstatt die Ähnlichkeit mit der Quelle.</sample>
    <sample id="235">Die Autoren sind an der University of Toronto.</sample>
    <sample id="236">Die Expert*innen haben 5 Anweisungen für jede Aufgabe in der Multi-Instra-Übung bereitgestellt.</sample>
    <sample id="237">Die Autoren schlagen die Entwicklung eines diagnostischen Test-Suites namens KITMOS vor, der die Fähigkeit von Modellen zur Integration von Wissen aus verschiedenen Quellen testet.</sample>
    <sample id="238">Yeboah Hou von der Universität von Florida präsentiert MeetingBank, ein neues Benchmark-Set für Meeting Summarization. Es zielt darauf ab, die Herausforderungen der Erstellung qualitativ hochwertiger Meeting-Summaries zu bewältigen und die Verfügbarkeit vertrauenswürdiger Ressourcen zu verbessern. Die Daten umfassen 1.366 City Council Meetings mit Transkripten, Referenzsummaries und URLs. Die Datenanalyse umfasst Abstraktionsmetriken wie Abdeckungs- und Dichtewerte, wobei die Abdeckungswerte von 0.7 bis 0.9 liegen. Modellbewertungen zeigen, dass abstraktive Summen von DaVinci-003 und GPT-3 herausragende Ergebnisse erzielen, wobei GPT-3 in Bezug auf Fluency und Coherence herausragt. Die menschliche Bewertung zeigt, dass GPT-3 die höchsten Gesamtpunktzahlen erzielt, obwohl es in Bezug auf Informativität und Faktualität hinter den anderen zurückbleibt.</sample>
    <sample id="239">Hallo zusammen. Mein Name ist Aydil Bilal und ich werde eine kurze Zusammenfassung des Papiers "Prompting Language Models for Machine Translation: Assessing Strategies and Performance" geben. Dies ist eine gemeinsame Arbeit mit meinen Kollegen von Google Translate.</sample>
    <sample id="240">In der englischen Version wird Weakly Supervised Learning als eine Methode beschrieben, bei der Daten mit schwachen Labels trainiert werden, die oft ungenau sind. Die Arbeit von Dawei und Kollegen untersucht, ob diese Ansätze tatsächlich auf sauberem, manuellen Training angewendet werden müssen, und schlägt alternative Methoden vor, die auf sauberem Training basieren.</sample>
    <sample id="241">Ethan und sein Team haben eine Arbeit über die Entwicklung eines Frameworks zur Bewertung von Misinformationen auf sozialen Medien vorgestellt, insbesondere im Zusammenhang mit COVID-19-Behandlungen. Sie kritisieren bestehende Ansätze für ihre unrealistische Bewertung und mangelnde Menschzentriertheit. Ihr vorgeschlagenes System umfasst zwei Hauptkomponenten: die Erkennung von irreführenden Behauptungen und die Überprüfung von Verstößen gegen soziale Medienrichtlinien. Das System verwendet maschinelles Lernen, um Tweets zu filtern und zu analysieren, und integriert menschliche Überprüfungen, um die Genauigkeit zu verbessern. Sie haben ihre Methode in einem realen Setting getestet und zeigen, dass es effektiv ist, indem es frühzeitig unbestätigte Behandlungen identifiziert und die menschliche Arbeitsbelastung reduziert. Ihr Ansatz bietet einen realistischen Ansatz zur Bewertung von Misinformationen und motiviert die Entwicklung zukünftiger Systeme.</sample>
    <sample id="242">Gängige Bewertungsmethoden für Dialogsysteme umfassen menschliche Bewertungen, vergleichende Lickert-Skalen und Paarewies-Vergleiche, die verschiedene Aspekte der Konversationsqualität bewerten.</sample>
    <sample id="243">Die Arbeit wurde von vier Autoren durchgeführt: Sebastian Santi, Ronan Labrosse, Caterina Ranecka und Martin Sab.</sample>
    <sample id="244">Im Beispiel wird Hintergrundwissen benötigt, dass Servin ist ein Richter, und dass Richter entscheiden Fälle in Law Courts.</sample>
    <sample id="245">Linying Zhang präsentiert eine Analyse zur Identifizierung von hochqualitativen Amazon Mechanical Turk (mTurk) Annotatoren. Die Studie umfasst zwei Phasen: eine Qualifizierungsphase, die die Fähigkeiten der Annotatoren in der Bewertung von Summen bewertet, und eine Endurance-Phase, die ihre Fähigkeit zur Bewältigung von Arbeitsbelastungen testet. Die Ergebnisse zeigen, dass 6% der Teilnehmer als hochqualifizierte Annotatoren identifiziert wurden. Die Studie vergleicht die Pipeline mit Cloud Research und zeigt, dass die Pipeline kosteneffizient und effektiv ist. Es gibt jedoch Einschränkungen, wie die Fokussierung auf englische Summarisierungen und die potenzielle Unzulänglichkeit der Design-Fragen.</sample>
    <sample id="246">Ja, der Code ist verfügbar auf GitHub.</sample>
    <sample id="247">Joakim presents a paper on FactKG, a dataset for fact verification using knowledge graphs. Unlike existing datasets that use text or tables, FactKG utilizes DBpedia knowledge graphs, offering intuitive evidence for claims. The dataset includes both written and colloquial claims, with five reasoning types: one-hop, conjunction, existence, multi-hop, and negation. The paper introduces a new baseline model, Gear, which outperforms existing baselines by using graph evidence. The dataset is available for download, and the paper concludes with a summary of the research findings.</sample>
    <sample id="248">Nein, die Annotatoren für NLPositionality sind nicht ausgewogen in Bezug auf jede demographische Gruppe wie Land, Geschlecht usw. Die Studie sammelte Annotations von über 1000 Anotatoren aus 87 Ländern, was eine breite, aber nicht ausgewogene demographische Repräsentation bietet.</sample>
    <sample id="249">Sätze innerhalb der akzeptablen Domain wurden durch das Hinzufügen von 'Noise' zu den Sätzen durcheinander gebracht, wobei die relevanten Strukturen beibehalten wurden.</sample>
    <sample id="250">Eine dimensionale Bewertung ist ein systematischer Ansatz zur Bewertung von Konversations- und Dialogsystemen, der verschiedene Aspekte der Qualität in spezifischen Dimensionen identifiziert und bewertet, um ein umfassenderes Verständnis der Leistung zu bieten.</sample>
    <sample id="251">Die Autoren gehören der Universität der Wissenschaft und Technologie von China an.</sample>
    <sample id="252">Die Präsentation von Saikranta Nankela und Kollegen präsentiert die Arbeit "You Create: Unsupervised Case Retrieval Using Event Extraction". Sie konzentrieren sich auf die Prior Case Retrieval (PCR) in der juristischen Praxis, bei der relevante Fälle aus einer großen Anzahl von Fällen identifiziert werden. Die Arbeit bietet zwei Hauptbeiträge: den ILPCR-Datensatz, der 7.070 Fälle mit durchschnittlich 6.775 Zitaten pro Fall umfasst, und die UCreate-Pipeline, die unüberwachte Techniken und einen Ereignis-basierten Ansatz für die PCR verwendet. Die Pipeline besteht aus drei Schritten: Vorverarbeitung, Abhängigkeitsanalyse und Nachverarbeitung. Die Ergebnisse zeigen, dass die UCreate-Pipeline, insbesondere die Ereignisbasierte Methode, die beste Leistung bei der PCR aufweist, mit niedrigeren Inferenzzeiten und höheren F1-Scores. Die Arbeit bietet einen umfassenden Überblick über die Leistung verschiedener Modelle und bietet einen neuen Ansatz für die PCR.</sample>
    <sample id="253">Mario Edarragon präsentiert 'NameDisorder', ein Modell zur Erkennung von mentalen Störungen in sozialen Medien. Die Arbeit nutzt Double Domain Adaptation, um ein allgemeines Sprachmodell wie BERT auf die spezifischen Themen von Reddit und mentaler Gesundheit anzupassen. Durch das Einbeziehen von mentalen Gesundheitslexika und das Fokussieren auf wichtige Wörter während des Trainings, zeigt das Modell eine verbesserte Leistung im Vergleich zu BERT. Die Ergebnisse zeigen eine ausgewogene Leistung in der Erkennung und Kategorisierung von mentalen Störungen. Zukünftige Forschungen sollen verschiedene lexikalische Ressourcen und klinische Daten einbeziehen.</sample>
    <sample id="254">Sung Qi von der Nanjing University of Science and Technology präsentiert eine Forschung über die Verbesserung der Qualität von Dokument-Level-Relation-Extraktion durch Uncertainty Guided Label Denoising. Traditionelle Methoden, die auf großen annotierten Korpora basieren, sind zeitaufwendig und erfordern viel Arbeit. Die vorgeschlagene Methode nutzt Distantly Supervised Data (DS) und ein Monte-Carlo Dropout-Ansatz, um die Vorhersage-Unsicherheit zu modellieren. Dies hilft, falsche positive Pseudo-Labels zu identifizieren und zu filtern. Die Forschung schlägt auch eine dynamische Klassenschwellen- und mehrstufige Trainingsstrategie vor, die die Leistung der Modelle verbessert. Die Ergebnisse zeigen, dass die vorgeschlagene Methode die Leistung der vorherigen Baselines auf beiden öffentlichen Datensätzen übertrifft.</sample>
    <sample id="255">Die Form des Prompts ist für Zero- und One-Shot-Prompts wichtig, aber für Five-Shot-Prompts hat sie keinen großen Einfluss.</sample>
    <sample id="257">Die Autoren haben vier aktuelle Chatmodelle evaluiert.</sample>
    <sample id="258">Zhangsun Han presents a study on using large language models for evaluating text quality in natural language processing. The research aims to find alternatives to human evaluations, which are often unstable and hard to reproduce. By using large language models, the study hopes to achieve consistent and reliable evaluations. Experiments were conducted using models like T0, InstructGPT, and variations of GPT-2, rating stories on grammar, coherence, likability, and relevance. Results showed that some models, like Davinci and ChatGPT, preferred human-written texts, similar to expert human evaluators. The paper discusses the potential benefits and drawbacks of using large language models for evaluation and explores the impact of different factors on model results.</sample>
    <sample id="259">Yusen Zhang von der Penn State University präsentiert Exemplar, ein neues Benchmark für Cross-Lingual Semantic Parsing, das 22 Sprachen und 15 Sprachfamilien umfasst. Es bietet eine umfassende Bewertung von multilingualen Modellen wie encoder-decoder und multilingual-pretrained. Die Ergebnisse zeigen, dass encoder-decoder die beste Leistung erzielt, und dass multilinguales Training die Leistung von Few-shot-Modellen verbessert. Es wird festgestellt, dass multilinguales Training die Leistung von Few-shot-Modellen in Zielsprachen verbessert, aber Multilingual-Sprachmodelle wie Code-Switch und BUE noch nicht optimal für Cross-Lingual Semantic Parsing sind.</sample>
    <sample id="260">Die Arbeit wurde von einem einzigen Autor, Jingwei Yi, verfasst.</sample>
    <sample id="261">Ein guter Planer sollte in der Lage sein, Skripte zu schreiben, die sowohl logisch kohärent als auch den festgelegten Einschränkungen gerecht werden.</sample>
    <sample id="262">Die Arbeit wurde von einem einzigen Autor, Si-Yuan Yu, von der Universität Fudan, verfasst.</sample>
    <sample id="263">In diesem Vortrag wird die Arbeit "Mitigating Label Biases for In-Context Learning" vorgestellt, die sich mit der Unstabilität in der In-Context-Learning-Paradigmusr Solves die Probleme der Bias in der Modellvorhersage durch die Einführung eines neuen Bias-Typs, dem Domain-Label-Bias. Die Arbeit identifiziert drei Arten von Biasen: Vanilla-Label-Bias, Context-Label-Bias und Domain-Label-Bias. Durch Experimente wird gezeigt, dass der Domain-Label-Bias die Modellvorhersagen stark beeinflusst. Um diesen Biasen entgegenzuwirken, wird ein neues Kalibrierungsverfahren, Domain-Context Calibration, vorgestellt, das die Vorhersagen der Modelle verbessert, indem es den Biasen durch zufällige Wörter aus dem Task-Corpus entgegenwirkt. Die Ergebnisse zeigen, dass dieses Verfahren die Leistung der Modelle signifikant verbessert, insbesondere bei Aufgaben mit hohem Bias.</sample>
    <sample id="264">Liu Wang, a graduate student at Zhejiang University, presents a paper on 'Towards Transferable Audio Visual Text Generation'. The paper addresses the challenges in multimodal text generation, particularly in audio visual text generation, which is more complex and expensive than other tasks. Wang proposes a novel task called 'transferable audio visual text generation' to overcome these challenges. The framework includes an audio visual meta map network, an audio visual encoder, and a language model generator, aiming to quickly adapt to new multimodal domains with limited data. The paper introduces a meta learning approach to optimize visual audio element scores without relying on negative samples. Experiments show that the proposed method outperforms other models in various settings, including low-resource domains.</sample>
    <sample id="265">Der/die Referent*in heißt Vasudha.</sample>
    <sample id="266">Die Autoren gehören der Universität Mannheim an.</sample>
    <sample id="268">Die häufigsten Fehler von PaLM sind Omission Errors, bei denen Teile des Originaltextes weggelassen werden, um eine bessere Klangqualität zu erreichen.</sample>
    <sample id="269">Hallo, ich bin James Finch. Und ich bin Sarah Finch. Und heute werden wir Ihnen alles über abc eval erzählen, eine neue, dimensionale Herangehensweise zur Bewertung von konversationalen KI. Dies wurde von der Emery-NLP-Lab, geleitet von Professor Gino Choi an der Emery University, und in Zusammenarbeit mit Amazon Alexa AI entwickelt.</sample>
    <sample id="270">Die Autoren gehören der Universität von Emory an.</sample>
    <sample id="271">CFT steht für Continuous Fine-Tuning, ein vorgeschlagenes Baseline in WSL, die es ermöglicht, Modelle weiterhin zu trainieren, um die Leistung zu verbessern.</sample>
    <sample id="272">Die Arbeit wurde von sechs Autoren durchgeführt: Kostas Sinha, John Wock, Aaron Muller, Kanishka Mishra, Karen Fentress und Roger Levy.</sample>
    <sample id="273">Hallo. Mein Name ist Kaiho Yan und ich werde unsere Arbeit mit dem Titel "Wann erfordert Übersetzung Kontext? Eine datengetriebene, mehrsprachige Untersuchung" vorstellen. Diese Arbeit wurde in Zusammenarbeit mit Patrick Fernhout, Emile Liu, Andre F. D. Martins und Graham Neubig durchgeführt. Viele Übersetzungen hängen von Kontext ab. Zum Beispiel, wie würden wir mole übersetzen? Nun, wenn der vorherige Satz war, könnten die Minister herausfinden, dass es gefährlich wird. Aber wenn der vorherige Satz war, könnte es ernst sein, Doktor. Je nach Kontext ändert sich also die Bedeutung des Wortes und die Übersetzung. Die Bewertung, wie gut Modelle solche Fälle übersetzen können, ist jedoch ziemlich schwierig. Erstens, weil nur ein kleiner Teil der Übersetzungen von Kontext abhängt, was Korpus-Metriken wie bleu nicht erfassen kann. Und einige Leute haben vorgeschlagen, auf kontextabhängige Übersetzungen zu konzentrieren, aber diese Ressourcen unterstützen nur begrenzte Arten von kontextabhängigen Übersetzungen und begrenzte Sprachmengen, da sie auf Domänenwissen und menschliche Kuration angewiesen sind. In dieser Arbeit versuchen wir, diese beiden Fragen zu beantworten: Wann erfordert Übersetzung Kontext und wie gut können Modelle diese Fälle bewältigen? Um die erste Frage zu beantworten, messen wir zunächst, wie sehr ein Wort während der Übersetzung von Kontext abhängt. In der vorherigen Arbeit haben wir cxmi als Maß für den Kontextgebrauch von maschinellen Übersetzungsmodellen eingeführt. Und das ist, indem wir messen, wie viel Informationen der Kontext C über das Ziel Y angibt, gegeben die Quelle X. Sie können sich cxmi als die Informationen vorstellen, die durch die Bereitstellung von Kontext an das Modell erhalten werden. In dieser Arbeit erweitern wir cxmi auf Punktweise cxmi, das den Kontextgebrauch auf Satz- oder Wortebene messen kann. Wir können Wörter mit hohem pcxmi als solche betrachten, die für die Übersetzung von Kontext erforderlich sind. Und analysieren wir Wörter mit hohem pcxmi, um Muster zwischen diesen Wörtern zu finden. Und führen Sie unsere Analyse auf Transkripte von Ted Talks durch, die von Englisch in vierzehn verschiedenen Sprachen übersetzt wurden. Wir führen unsere Analyse auf drei verschiedenen Ebenen durch. Zuerst suchen wir nach Teil der Sprache, die ein hohes pcxmi aufweist. Und dies ermöglicht es uns, zum Beispiel, duale Pronomen in Arabisch zu finden, die relativ hohes pcxmi aufweisen. Und dies kann erklärt werden, weil Englisch keine dualen Pronomen hat, also müssen Sie Kontext verwenden, um zu bestimmen, ob ein Pronomen dual ist, wenn Sie ins Arabische übersetzen. Und wir finden auch, dass bestimmte Sprachen auch Kontext benötigen, wenn wir die richtige Verbform wählen wollen. Wir untersuchen dann Wörter, die über alle ihre verschiedenen Vorkommen ein hohes pcxmi aufweisen. Und dies hilft uns, Fälle zu identifizieren, in denen in Chinesisch Kontext benötigt wird, um richtige Nomen zu übersetzen, um sicherzustellen, dass Sie die gleiche Übersetzung im Dokument verwenden. Und wir finden auch, dass Kontext für die Übersetzung der richtigen Formalität erforderlich ist. Und schließlich untersuchen wir einzelne Token, die ein hohes pcxmi aufweisen. Und dies ermöglicht es uns, Phänomene zu identifizieren, die nicht wirklich von dem Wort selbst erfasst werden können, sondern eher durch die Satzstruktur ausgedrückt werden, wie z. B. Ellipsenauflösung. Und jetzt verwenden wir unsere Ergebnisse aus unserer Analyse, um einen Benchmark für die Dokumentebene-Übersetzung zu entwerfen. Für jede der fünf identifizierten Diskursphänomene erstellen wir Tags, um Wörter zu identifizieren, die zu dem Phänomen gehören. Und wir können auch anmerken, dass verschiedene Sprachen unterschiedliche Proportionen dieser Diskursphänomene haben. Und wir verwenden den Muda-Tagger, indem wir den Tagger auf den parallelen Korpus anwenden, den wir für die Bewertung verwenden. Und wir wenden unsere Übersetzungsmetriken unserer Wahl auf die kontextabhängigen Beispiele an, die der Muda-Tagger identifiziert hat. Und schließlich verwenden wir unseren Benchmark sowie andere Metriken, um verschiedene Modelle auf der Dokumentebene-Übersetzung zu bewerten. Zuerst, wenn wir Korpus-Metriken verwenden, so dass für bleu kontextunabhängige Modelle die beste Leistung haben. Aber wenn wir comet verwenden, kontextbewusste Modelle die beste Leistung haben. Und wenn wir Wort F messen, haben Modelle mit oder ohne Kontext vergleichbare Leistung. Dies zeigt erneut, dass es schwierig ist, die beste Dokumentebene-Übersetzungsanwendung zu bestimmen, wenn wir nur Korpus-Metriken verwenden. Und jetzt verwenden wir den Muda-Benchmark, um Modelle zu bewerten, und wir finden, dass kontextbewusste Modelle für bestimmte Diskursphänomene, wie z. B. Formatik und lexikalische Kohäsion, deutlich genauer sind als Modelle, die keinen Kontext verwenden. Aber diese Modelle sind nicht viel besser als Modelle, die keinen Kontext verwenden, für andere Phänomene wie Ellipsen, Pronomen und Verbform. Dies deutet darauf hin, wo wir für die Dokumentebene-Übersetzung mehr Fortschritte sehen müssen. Wir vergleichen auch verschiedene kommerzielle Systeme, und unser Benchmark zeigt, dass DeepL im Allgemeinen genauer als Google Translate für die Dokumentebene-Übersetzung ist. Um zu zusammenfassen, führen wir eine datengetriebene Analyse über vierzehn Sprachpaare durch, um zu identifizieren, wann Übersetzungen von Kontext abhängen. Und dann verwenden wir unsere Ergebnisse, um einen Benchmark für die Dokumentebene-Übersetzung zu erstellen, der uns helfen kann, zu identifizieren, welche Diskursphänomene Modelle gut bewältigen oder nicht, und welche Übersetzungsanwendungen gut bei der Dokumentebene-Übersetzung sind. Vielen Dank für Ihre Aufmerksamkeit. Bis nach Toronto.</sample>
    <sample id="274">Der Referent ist Yu Chen Zhang.</sample>
    <sample id="276">Ananya and Vignesh present their work on IndicMT Eval, a dataset for evaluating machine translation metrics for Indian languages. They focus on five languages from two language families, Tamil, Malayalam, Hindi, Marathi, and Gujarati, generating 7,000 samples. Bilingual expert annotators evaluate translations for errors, which are categorized into accuracy and fluency errors. Recent MT models like NLLB and IndicTrans show fewer errors compared to older models. The IndicComet metric, fine-tuned using the MT dataset, outperforms Comet baselines on most languages and shows higher correlations with human scores. IndicComet also demonstrates robustness on unseen languages, outperforming Comet counterparts.</sample>
    <sample id="277">Die neue Methode hat keinen Namen.</sample>
    <sample id="278">Die Methode der „markierten Wörter“ verwendet das Konzept der Markedness, um Wörter zu identifizieren, die Gruppen von der unmarkierten Norm unterscheiden. Sie vergleichen die Wörter in den generierten Personas mit den unmarkierten Gruppen, um Stereotypen zu erkennen.</sample>
    <sample id="279">Die Autoren sind PhD-Studenten der University of Washington.</sample>
    <sample id="280">Xiaotao Song präsentiert das Multi-EMOT-Framework zur Emotion Regulation in Gesprächen, das visuelle, auditive und textuelle Daten integriert. Das Framework, bestehend aus vis-exnet, Multi-Attend und einem Sample-weighted focal-contrast loss, verbessert die Erkennung von Emotionen, insbesondere in Minderheits- und semantisch ähnlichen Klassen. Vis-exnet, ein neuartiger visueller Feature-Extractor, vermeidet überflüssige gesprochene Informationen. Multi-Attend kombiniert die Modalitäten durch bidirektionale Kreuzabstimmung, und der focal-contrast loss priorisiert schwierige Klassen. Die Ergebnisse zeigen, dass Multi-EMOT auf den MELS- und IEMOCAP-Datensätzen eine verbesserte Leistung aufweist, insbesondere bei Minderheits- und semantisch ähnlichen Emotionen. Trotz dieser Fortschritte gibt es Einschränkungen bei der Unterscheidung zwischen Sprechern und der Leistung in Minderheitsklassen.</sample>
    <sample id="281">Kai-Wei Yin presents a study on when translation requires context, highlighting the role of context in determining word meanings. The research introduces cxmi, a measure of context usage, and extends it to pxci for sentence-level analysis. By analyzing TED Talks translations, the study identifies discourse phenomena needing context, such as pronouns and formality. A benchmark is created using the MUDa tagger to evaluate translation models, revealing that context-aware models excel in certain areas, like formality, but not all. The study compares systems like DeepL and Google Translate, with DeepL often outperforming Google. The findings aim to improve document-level translation accuracy by understanding context requirements.</sample>
    <sample id="282">Xiaoxuan Liu präsentiert das neue Modell StyleTRACE, das den Stiltransfer auf der Diskursebene in der natürlichen Sprachgenerierung (NLG) verbessert. Es adressiert die Herausforderung, den Stil von Diskursstrukturen zu emulieren, indem es den Stil von Diskursrepräsentationen aus der Quelle mit einem lernbaren Stil-Embedding kombiniert. Das Modell verwendet eine zweistufige Trainingsstruktur, um den Stil und die Inhalte effektiv zu transferieren. Die Ergebnisse zeigen, dass StyleTRACE den Stilkontroll- und Inhaltspräzision von basalen Modellen übertrifft, indem es die goldenen Texte in der Stilraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraumraum</sample>
    <sample id="283">Die Name der zuerst erwähnten symmetrischen Abhängigkeitsstruktur ist Universal Abhängigkeitsstruktur.</sample>
    <sample id="284">Peng Tianxiao from Wuhan University presented FSUE at ACL Main Conference 2019, introducing a novel fuzzy span mechanism for UIE. The current model relies on precise span boundaries, but FSUE proposes a fuzzy approach, addressing ambiguities in span labeling. The model uses adaptive attention, represented as a continuous probability distribution, to better capture semantic information. Experiments on NER, RE, and ASST tasks showed significant improvements in performance. FSUE achieved better results on small-scale datasets and demonstrated strong generalization capabilities. The attention distribution is visualized, showing focus on semantic information within a limited range.</sample>
    <sample id="285">Mingqi Gao von der Peking-Universität präsentiert ihre Arbeit, die sich mit der Fehlerkorrektur in Dialogsummarisierungen befasst. Sie identifiziert zwei Hauptlösungen: die Einführung von faktualitätsbezogenen Zielen in Trainingsprozessen und die Entwicklung von Fehlerkorrekturmodellen. Die Arbeit kritisiert die aktuellen Evaluationsmethoden, die faktualitätsmetriken wie FACTC und DAE verwenden, und zeigt, dass diese möglicherweise nicht zuverlässig sind. Die Studie schlägt vor, dass die Einführung von menschlich korrigierten Summen während des Trainings von Fehlerkorrekturmodellen die Leistung verbessern kann. Sie schlägt auch vor, dass die Kombination von synthetischen und menschlich korrigierten Daten eine vielversprechende Richtung für die Entwicklung von Fehlerkorrekturmodellen ist.</sample>
    <sample id="286">Der Referent ist Professor Gino Choi.</sample>
    <sample id="287">Vier Autoren sind an der Arbeit beteiligt: Javad Hosseini, Philip Radlinsky, Silvia Parati und Annie Luis.</sample>
    <sample id="288">Syntaktische Phänomene können mit Datensätzen wie dem Blimp- und Syntax-Gym getestet werden, die grammatikalische Struktur und Satzunregelmäßigkeiten beinhalten.</sample>
    <sample id="290">Die Abkürzungen der fünf Methoden für die erste Forschungsfrage sind: Vallo, CoSine, FLoane, FLoane-FTW und CoSine-FTW.</sample>
    <sample id="291">Das Modell wird auf 11 Domain-Tasks evaluiert, einschließlich NER, Klassifikation, Part-of-Speech-Tagging und Fragebeantwortung.</sample>
    <sample id="294">CamemBERT wurde ursprünglich mit anonymisierten Daten aus dem Krankenhaus, die von der Datenbank des National Health Service (NHS) stammen.</sample>
    <sample id="295">Der Referent ist Adam Szpekowski.</sample>
    <sample id="296">Valerio Basile präsentiert eine Zusammenarbeit zwischen der Universität von Turin und Amazon Alexa, die sich mit der Entwicklung von Ansätzen zur natürlichen Sprachverarbeitung befasst. Er betont die Notwendigkeit von großen, annotierten Datensätzen für die Verbesserung von maschinellen Lernmodellen. Basile konzentriert sich auf die Herausforderung der Ironie-Erkennung, die bereits schwierig ist, und entwickelt eine Methode, um Modelle zu erstellen, die nicht nur binäre Antworten geben, sondern auch informative Ausgaben liefern. Er beschreibt die Erstellung des EPIC-Korpus, der aus 300 kurzen Gesprächen besteht, die über verschiedene Quellen und Englischvarianten gesammelt wurden. Die Daten wurden durch die Crowdsourcing-Plattform Prolific annotiert, wobei 15 Personen pro Englischvariante 200 Texte bearbeiteten. Die Analyse zeigte Unterschiede in der Inter-Annotator-Übereinstimmung, die durch die Entwicklung von perspektivbewussten Modellen, die auf verschiedenen Anmerkern trainiert wurden, angegangen wurden. Diese Modelle zeigten eine höhere Zuversicht in ihren Vorhersagen. Basile identifiziert Unterschiede in der Wahrnehmung von Ironie zwischen verschiedenen Altersgruppen und geografischen Regionen, insbesondere zwischen den Vereinigten Königreich und Irland.</sample>
    <sample id="297">In der Diskussion über 'From Dog Whistles to Bullhorns: Unveiling Coded Rhetoric with Language Models' wird die Rolle von Dog Whistles in der Kommunikation untersucht. Diese sind Begriffe, die eine Botschaft an eine Gruppe senden, die oft an eine andere Gruppe gerichtet ist, wie bei antisemitischen oder transphoben Ausdrücken. Die Studie umfasst die Entwicklung eines Dog Whistle-Typs und einer Glossar, die Kontextinformationen enthält. Sie untersucht historische US-Politik, zeigt, wie Dog Whistles in der Sprache verwendet werden, und bewertet die Leistung von Sprachmodellen wie GPT-3 bei der Erkennung dieser. Die Studie zeigt, dass Dog Whistles die Moderation von Online-Inhalten umgehen können, indem sie als weniger toxisch eingestuft werden.</sample>
    <sample id="298">Die Experimente zeigten, dass die Leistung von neu trainierten oder fortlaufend trainierten Modellen mit neueren Daten abnahm, wenn die zeitliche Kluft zwischen Trainings- und Testdaten zunahm, was die Hauptursache für den Leistungsverlust bestätigte.</sample>
    <sample id="299">The talk by Mihailis Karagatsis and Andreas Vlachos addresses the issue of improving the robustness of NLP models against overfitting to dataset shortcuts. Current models excel in-distribution but falter out-of-distribution. The proposed solution involves a minimax training objective, where a learner and auxiliary model are trained alternately to focus on underrepresented data. This method, tested on datasets like MNLI, FEVER, and QP, shows improved out-of-distribution performance without relying on pre-trained language models, thus reducing computational overhead.</sample>
    <sample id="300">Belinda presents a task called Interactive Diction, which allows users to dictate and edit documents using voice commands. The task involves a four-step process: ASR transcription, segmentation into dictation and commands, normalization of commands, and execution. The team developed a data collection interface and a baseline system using models like T5 and GPT-3. The system aims for a natural and intuitive user experience, with ongoing improvements encouraged.</sample>
    <sample id="302">Die Token für die Ausgabesequenz zu permutieren ist notwendig, um die korrekte Reihenfolge der Tokens zu bestimmen, da die Eingabe- und Ausgabe-Multisets nicht in der richtigen Reihenfolge vorliegen.</sample>
    <sample id="303">Die Autoren empfehlen mehr Transparenz, um zu verstehen, warum positive Stereotypen entstehen, ob es sich um übermäßige Wertallianz oder andere Anti-Stereotyping-Methoden handelt, und um die zugrunde liegenden Mechanismen besser zu erforschen.</sample>
    <sample id="304">Inakzeptable Minimalpaareingaben sind Phrasen, die von einem Sprachmodell als ungrammatisch oder untypisch bewertet werden.</sample>
    <sample id="305">Dawie, ein PhD-Student an der Saarland University, präsentiert seine Arbeit über Weakly Supervised Learning (WSL), die sich mit der Verwendung von schwachen Labels wie heuristischen Regeln oder Wissenbanken zur Datenbeschriftung befasst. WSL-Ansätze erfordern in der Regel zusätzliche, manuell annotierte, 'clean' Validierungsdaten, um effektiv zu funktionieren. Die Studie zeigt, dass die Leistung von WSL-Methoden stark von der Verfügbarkeit von clean Validierungsdaten abhängt und dass die Annahme, dass WSL ohne clean Daten funktioniert, irreführend ist. Die Forschung schlägt vor, dass die Modellauswahl Kriterien offen zu dokumentieren, WSL mit anderen Methoden zu vergleichen und kontinuierliche Fine-Tuning als Baseline zu betrachten. Die Ergebnisse deuten darauf hin, dass die Leistung von WSL-Ansätzen überbewertet wird, und die praktischen Vorteile unterschätzt werden.</sample>
    <sample id="306">Sebastian Schuster und Na Jeong Kim untersuchen, wie gut große Sprachmodelle Entitäten in Texten verfolgen. Sie stellen fest, dass viele Modelle die Aufgabe, Entitäten zu verfolgen, nicht wirklich meistern, sondern auf heuristischen Annahmen basieren. Ihre Tests zeigen, dass GPT-3.5, das auf Code trainiert wurde, besser in der Entitätstracking ist als andere Modelle. Sie betonen, dass die Fähigkeit, Entitäten zu verfolgen, von der Art der Trainingsdaten abhängt.</sample>
    <sample id="307">Die Autoren verwendeten die F1-Score als Bewertungsmetrik für die Leistung ihrer Modelle.</sample>
    <sample id="308">Jenny McAllister, a first-year PhD student, presents her research on 'Anal Positionality,' which examines design biases in datasets and models. Collaborating with the University of Washington and Allen Institute for AI, she highlights how these biases arise from the positionalities of researchers and can affect technology's performance across different populations. Her framework, NL Positionality, involves re-annotating datasets with diverse annotators and comparing these annotations to model predictions. The study, conducted on platforms like Lab in the Wild, reveals biases towards English-speaking and educated annotators, and less alignment with non-binary individuals. Recommendations include documenting design choices, conducting research with a lens of perspectivism, and building specialized datasets and models for specific communities.</sample>
    <sample id="309">Die Übereinstimmung zwischen den Kommentatoren wurde durch die Analyse von 100 doppelten gelabelten Konversationen gemessen.</sample>
    <sample id="310">Wikipedia wurde als Domain gewählt, um völlig unzusammenhängende Sätze zu den inakzeptablen und akzeptablen Suchanfragen hinzuzufügen.</sample>
    <sample id="311">Die Autoren gehören der Universität Leipzig an.</sample>
    <sample id="312">MultiInstruct ist das erste Benchmark-Set für multimodale Instruct-Tuning, das 62 diverse, multimodale Aufgaben aus 10 Kategorien umfasst, die aus 21 Open-Source-Datensätzen abgeleitet sind, mit 5 Expert-Inspektionsanweisungen pro Aufgabe.</sample>
    <sample id="313">Zwei Autoren sind an der Arbeit beteiligt: James und Sarah Finch.</sample>
    <sample id="314">Die binäre Koordination ist eine Koordinationsstruktur, bei der zwei Konjunktionen durch ein Komma getrennt sind, wie in 'John, Mary' oder 'Ich, sie'.</sample>
    <sample id="315">Die in dieser Studie verwendeten Prompts waren durchschnittlich 15 Wörter lang.</sample>
    <sample id="316">Die Ergebnisse zeigen, dass das kleinere T5-Modell, trainiert auf dem CodeScript-Dataset, in der Lage ist, qualitativ hochwertige Skripte zu generieren, die den Anforderungen spezifischer Ziele gerecht werden, was darauf hinweist, dass kleinere Modelle mit geeigneten Daten effektiv große Modelle unterstützen können.</sample>
    <sample id="317">Pong Li von der Universität Fudan präsentiert CodeIE, ein innovatives Framework, das Information Extraction (IE) in Code-Generierungsaufgaben umwandelt, um die Ausgabe zu strukturieren. Traditionelle Modelle wie GPT-3 und T5, die in der Regel in Test-to-Test-Phasen trainiert werden, zeigen bei der Ausführung von IE-Aufgaben, wie Named Entity Recognition (NER), Schwierigkeiten, da sie nicht in der Lage sind, die Struktur der Ausgabe zu generieren. CodeIE nutzt Code-LLM-Modelle wie Code-Davinci-002, um die Aufgabe in Code-Format umzuwandeln, was die Ausgabestruktur verbessert. Tests zeigen, dass Code-Format-Modelle wie Code-Davinci-002 und Code-LLM-Modelle wie Code-Davinci-002 deutlich besser abschneiden als traditionelle Modelle wie GPT-3 und T5. Die Analyse zeigt, dass Code-Format-Modelle weniger Fehler bei der Dekodierung aufweisen und eine bessere Leistung bei der Erkennung von Labels bieten. Die Ergebnisse deuten darauf hin, dass Code-Format-Modelle eine bessere Übereinstimmung mit der IE-Aufgabe bieten und die Leistung in der Erkennung von Labels verbessern.</sample>
    <sample id="318">Ich bin Janis Lavraik und werde Ihnen Dr. Bert vorstellen, ein robustes, in Französisch trainiertes Modell für den biomedizinischen und klinischen Bereich. Wir werden zunächst über die Sprache im Gesundheitswesen sprechen, dann unser Hauptbeitrag vorstellen, das Dr. Bert-Modell, das auf Roberta basiert und auf dem Nachos-Datensatz trainiert wurde. Wir werden auch mit dem Dr. Bert-Modell mit verschiedenen Datenquellen und Trainingsmethoden vergleichen. Schließlich werden wir unsere Ergebnisse zusammenfassen und mehr Details zu den Modellen bereitstellen.</sample>
    <sample id="319">Die Arbeit untersucht drei Lernstrategien: Training von Modellen von Grund auf, Verwendung von Camembert-Werten und Tokenisierer, und Verwendung von klinischen Notizen.</sample>
    <sample id="320">Der Faktor der Überanpassung, der speziell auf die Wiederverwendung von Tests zurückzuführen ist, zeigt keine Diminishing Returns, was darauf hinweist, dass es keine signifikante Leistungseinbuße gibt, wenn die gleichen Testsets wiederholt verwendet werden.</sample>
    <sample id="321">Die Qualität der Vereinfachung wurde durch die Analyse der Art der Vereinfachungen und die Bewertung der Ergebnisse der Feinabstimmung von Sprachmodellen bewertet.</sample>
    <sample id="322">Enrico Calabretta diskutiert die Frage, was Textklassifikatoren über Moral lernen. Er erklärt, dass Moral die Unterscheidung zwischen richtig und falsch ist und für die Entwicklung von Sprachmodellen entscheidend ist. Er kritisiert die traditionelle Sichtweise, die Moral als ein einfacher Skala zwischen unmoralisch und moralisch betrachtet, und betont die subjektive Natur der Moral. Er erwähnt die Moral Foundation Theory, die fünf moralische Grundlagen identifiziert, die unterschiedlich priorisiert werden. Calabretta zeigt, dass diese Theorie in der NLP angewendet wurde und dass Modelle die moralische Ausdrucksweise in verschiedenen Domänen erkennen können. Er verwendet den MORA Foundation Twitter Corpus, um zu zeigen, dass Modelle die Unterschiede in der moralischen Ausdrucksweise in verschiedenen Domänen erkennen können, wie zum Beispiel zwischen A.L.M. und B.L.M. Er betont die Bedeutung, diese Unterschiede zu verstehen, um Missverständnisse zu vermeiden.</sample>
    <sample id="323">Yujie Wang von der Universität von Shanghai präsentiert ein Paper über die Verbesserung der Common Sense Question Answering (CSQA) durch die Integration von dynamischen heterogeneous graphs (HKG) mit Language Models (LM). Die Herausforderung bei CSQA besteht darin, Fragen zu beantworten, die auf gemeinsamen Wissen basieren, und das Wissen aus externen Daten abzurufen. Traditionelle Ansätze kombinieren Wissen aus Knowledge Bases (KB) und Language Models, um Subgraphen zu erstellen, die jedoch oft irrelevante Entitäten einbeziehen und die Interaktion zwischen Modulen begrenzen. Wangs Ansatz verwendet ein dynamisches HKG, das durch zwei Stufenpruning und K-Nearest Neighbors (KNN) optimiert wird, um die Struktur und das Wissen in HKG zu verbessern. Die Methode verwendet Masked Self-Attention, um die Entitäts- und Relationen-Embeddings in HKG zu modellieren, und integriert die HKG-Passage-Informationen in den QA-Kontext. Die Ergebnisse zeigen, dass die Methode bessere Ergebnisse als andere LM- und HKG-Methoden erzielt.</sample>
    <sample id="324">Ja, Sprachmodelle zeigen unterschiedliche politische Vorurteile, die sich in ihren Ergebnissen bei Aufgaben wie Hate-Speech- und Fake-News-Erkennung widerspiegeln. Diese Vorurteile können zu Ungleichheiten in der Erkennung von Inhalten für verschiedene soziale Gruppen führen.</sample>
    <sample id="325">Hallo, mein Name ist Matthias Landmann und heute werde ich Ihnen eine kurze Einführung in unser Papier über Kompositionalgeneralisation ohne Bäume mit Mehrfach-Tags und latenter Permutation geben. Dies ist eine gemeinsame Arbeit mit meinen Beratern Alexander Koller und Ivan Tiedoff. Kompositionalgeneralisation kann als die Fähigkeit eines Lerners verstanden werden, tiefere Rekursion und bisher nicht gesehene Kompositionen von Wörtern zu handhaben, die während des Trainings einzeln gesehen wurden. Im Kontext der semantischen Analyse könnte die Testung für Kompositionalgeneralisation wie folgt aussehen: Wie üblich haben wir eine Trainingsmenge von Sätzen, in diesem Fall hat die Mädchen geschlafen und Mary wusste, dass die Mädchen geschlafen haben. Diese Sätze werden mit logischen Formen gepaart, die die Kernaspekte ihrer Bedeutung darstellen. Im Gegensatz zu herkömmlichen maschinellen Lernmethoden kommt die Testmenge aus einer anderen Verteilung, enthält aber strukturell unerwartete logische Formen. Im Gegensatz zu herkömmlichen maschinellen Lernmethoden, die oft aus der Verteilung heraus generalisieren und die Ausgabe von der Eingabe abweichen, reproduzieren sie systematische Entsprechungen zwischen Eingabe und Ausgabe, wie z. B. die in der Beispielfarbe codierten. Ein beliebter Weg, dies zu beheben, besteht darin, Bäume in die Modelle zu integrieren. Die Bäume sollen den kompositorischen Prozess erfassen, der Sätze mit logischen Formen verbindet. Dies funktioniert gut, aber Bäume werden normalerweise nicht gegeben und müssen irgendwie ermittelt werden. Dies kann ein kompliziertes und manchmal rechnerisch aufwändiges Verfahren sein. Typischerweise beinhaltet dies eine formell spezifische Vorverarbeitung der logischen Formen, z. B. um Variable-Symbole zu behandeln. Die Ermittlung von Bäumen kann auch spezielle Grammatikinduktionverfahren erfordern. In diesem Papier verwenden wir keine Bäume und stellen eine neuronale Sequenz zu Sequenz-Modell vor, das die Entsprechungen zwischen Fragmente der Eingabe und der Ausgabe direkt modelliert. Zum ersten Mal zeigen wir eine starke Generalisierung zu tiefer Rekursion ohne Bäume. Unser Ansatz berechnet die Ausgabe aus der Eingabe in zwei Schritten. Zuerst werden alle Eingabewörter mit einem unordentlichen Mehrfach-Set von Wörtern versehen, die im Ausgabe erscheinen werden. Nach dem ersten Schritt haben wir alle richtigen Wörter, aber sie sind nicht in der richtigen Reihenfolge. Deshalb verwenden wir in der zweiten Stufe ein weiteres Modell, um eine Permutation zu vorhersagen, um sie in die richtige Reihenfolge zu bringen. Wir stellen einen neuen Methode zur Vorhersage einer Permutation vor, die keine harten Einschränkungen für die möglichen Permutationen auferlegt. Dies macht unseren Ansatz ziemlich flexibel und ausdrucksstark. Konzeptionell funktioniert unser Permutation-Modell ungefähr so, wie folgt: Wir gehen von links nach rechts über die Ausgabe und bestimmen, welches Mehrfach-Set-Wort in jede Position platziert werden soll. Für die erste Ausgabe-Position wählen wir einfach das rote Highlight. Dann springen wir zum nächsten Mehrfach-Set-Wort, um das zweite Wort in der Ausgabe zu bestimmen. Wir bestimmen das dritte Wort in der Ausgabe, indem wir zum nächsten Mehrfach-Set-Wort springen. Wir wiederholen diesen Vorgang, bis jedes Wort aus der ersten Stufe genau einmal besucht wurde.</sample>
    <sample id="326">Kognitive Dissonanz ist das Phänomen, bei dem zwei widersprüchliche Überzeugungen oder Handlungen in der Sprache auftreten, wie zum Beispiel, wenn jemand weiß, dass Rauchen schädlich ist, aber trotzdem raucht.</sample>
    <sample id="327">Xiaoxu, ein Doktorand, präsentiert die Entwicklung von ManageTower, einer neuen visuellen Spracharchitektur, die auf der BridgeTower-Basis aufbaut. ManageTower integriert unidimensionale Experten, um semantische Kenntnisse auf verschiedenen Ebenen effektiver zu nutzen. Mit nur 4 Millionen Trainingsbildern übertrifft es bestehende Modelle wie BridgeTower und Mert, indem es die Leistung auf VQVC2 verbessert. Die Architektur ist flexibel und kann mit verschiedenen Encoder kombiniert werden. Die Ergebnisse zeigen, dass adaptive Manager die semantische Tiefe besser nutzen können, was zu einer umfassenderen Crossmodal Representation führt.</sample>
    <sample id="328">GPT-4 steht am meisten links.</sample>
    <sample id="329">Zhen Minhang from Peking University presented a method for zero-shot video sense localization, aiming to identify video segments relevant to a given query without manual annotation. The method generates structured pseudo labels using image caption models, ensuring high relevance within events and low relevance outside. It addresses label noise by weighting samples and refining labels, outperforming existing methods on two datasets.</sample>
    <sample id="330">Ja, kumulatives Training ist in diesem Kontext besser, da es die Leistung über die verschiedenen Runden des aktiven Lernens hinweg verbessert.</sample>
    <sample id="331">Sarah Papi, Matteo Negri, Marco Turker.</sample>
    <sample id="332">Die Daten für den MuDa-Benchmark stammen aus Transkripten von TED Talks, die in 14 Sprachen übersetzt wurden.</sample>
    <sample id="333">Wen Hao von Nanjing University präsentiert die Arbeit an der K-Nearest Neighbour Machine Translation (K-NMT), die darauf abzielt, die generierte Darstellung von neuronalen Netzwerken zu verbessern. Die Herausforderung besteht darin, dass die Darstellung von K-NMT oft nicht glatt ist, was die Generierung von semantischen Bedeutungen behindert. Um dies zu beheben, schlägt er eine Lösung vor, die K-Nearest Neighbour Machine Translation (K-NMT) zu verwenden, um die Vorhersagegenauigkeit zu verbessern. Die vorgeschlagene Lösung beinhaltet die Verwendung eines Adapters, der die Darstellung anpasst, und eine Datenbank, die die Ergebnisse speichert. Die Ergebnisse zeigen, dass die K-NMT-Frameworks Leistung bei der Verbesserung der Übersetzungsgenauigkeit und -geschwindigkeit deutlich besser ist als die herkömmlichen Methoden.</sample>
    <sample id="335">Der Referent heißt Matthias Landmann.</sample>
    <sample id="336">Sprachübergreifender Transfer bezieht sich auf das Training eines Modells auf einer Quelle-Sprache und dessen Anwendung auf eine Ziel-Sprache, was die Leistung in der Ziel-Sprache verbessert.</sample>
    <sample id="337">Die Rede präsentiert ein neuartiges Modell zur Handhabung von OOV-Wörtern durch Wortbildung und -assoziation. Es verwendet ein Wortbeziehungsgraph, um OOV-Wörter in Wortstücke zu zerlegen und mit relevanten Wörtern zu verbinden. Das Modell verwendet Graph-Neural-Netzwerke und Selbst- und Graph-Attention-Netzwerke, um die Bedeutung von OOV-Wörtern zu inferieren. Es zeigt überlegene Ergebnisse in verschiedenen Aufgaben und kann auf verschiedene Sprachen angewendet werden, wobei die Leistung von der Wortzerlegung abhängt.</sample>
    <sample id="338">Bin Shen präsentiert die Ergebnisse seiner Forschung über die Bewertung menschlicher Erklärungen in der KI. Die Studie untersucht, wie menschliche Erklärungen die Leistung von KI-Modellen verbessern können, und stellt fest, dass traditionelle Bewertungsmethoden wie die Similabilitätsbewertung nicht ausreichend sind. Stattdessen schlägt das Team eine neue Bewertungsmatrix namens TRUE vor, die die Nützlichkeit von Erklärungen bei der Feinabstimmung bewertet. Die Ergebnisse zeigen, dass TRUE die Leistung von Erklärungen besser bewertet als die Similabilitätsbewertung, insbesondere bei verschiedenen Aufgaben wie Common Sense QA und Natural Language Inference. Die Forschung legt den Grundstein für eine bessere Zusammenarbeit zwischen Menschen und KI bei der Erstellung von Erklärungen.</sample>
    <sample id="339">Die Autoren gehören der Saarland University in Deutschland an.</sample>
    <sample id="340">Guan Hao Huang von UCLAF präsentiert ParaAMR, ein syntaktisch vielfältiges, groß angelegtes Periphrase-Dataset, das durch AMR-Back-Translation erstellt wird. Dieses innovative Dataset übertrifft bestehende Datensätze wie MRPC und CoNLL-2011 in syntaktischer Vielfalt, während es die semantische Ähnlichkeit beibehält. Durch die Verwendung von AMR-Graphen, die die abstrakte Bedeutung von Sätzen darstellen, wird der Fokus in den Graphen verändert, um syntaktisch vielfältige Periphrasen zu generieren. ParaAMR bietet 50 Millionen Sätze mit 6,9 Periphrasen pro Satz und zeigt in Benchmarks, dass es in der Satzverbesserung und syntaktischen Kontrolle besser abschneidet als andere Datensätze. Es wird als wertvolles Werkzeug für NLP-Anwendungen empfohlen.</sample>
    <sample id="341">The authors use average latency and computational-aware average latency to measure performance, aiming for high translation quality and low latency.</sample>
    <sample id="342">Gao Jinsheng präsentiert ein Papier über das Live Chat, ein großes, personalisiertes Dialog-Set, das aus Live-Streams von TikTok-Douyin abgeleitet wird. Das Set, das von ihm und seinen Kollegen von Shanghai Jiao Tong University und Xiaoping AI erstellt wurde, zielt darauf ab, die Herausforderungen der bestehenden Dialog-Set zu überwinden, wie die Notwendigkeit von manuellen Anmerkungen und die Schwierigkeit, Dialoge für verschiedene Personas zu generieren. Die Experimente zeigen, dass das Set für die Antwortmodellierung und die Adressenerkennung vorteilhaft ist, wobei die Ausführung von LLMs auf dem Set die beste Leistung zeigt.</sample>
    <sample id="343">Hallo zusammen, ich bin Akshata und heute präsentieren wir gemeinsam mit Martin unsere Arbeit, die den Titel "Die Kitmos" trägt und sich mit der Bewertung der Wissensintegration aus mehreren Quellen befasst.</sample>
    <sample id="344">Die baumbasierten Methoden sind kompliziert und computationell aufwändig, da sie formalisierte Vorverarbeitung und spezielle Induktionsverfahren erfordern.</sample>
    <sample id="345">Matthias Landmann und seine Kollegen präsentieren eine neue Methode zur Kompositionalgenerierung ohne Bäume, die auf Multi-Set-Tagging und Permutationen basiert. Diese Technik ermöglicht es einem Modell, tiefere Rekursionen und unbekannte Kompositionen von Phrasen zu verarbeiten, die während des Trainings individuell gesehen wurden. Im Gegensatz zu herkömmlichen Modellen, die oft Schwierigkeiten haben, solche Aufgaben zu bewältigen, erfordert diese Methode keine Bäume, was die Komplexität und den Rechenaufwand reduziert. Stattdessen werden Eingabewörter mit Multi-Sets versehen, die die entsprechenden Ausgabewörter enthalten, und ein Permutationsmodell ordnet diese dann in der richtigen Reihenfolge an. Die Methode zeigt eine starke Leistung bei der Generierung zu tieferen Rekursionen, ohne auf Bäume angewiesen zu sein.</sample>
    <sample id="346">Die Autoren gehören der Universität Bonn (Universität zu Köln) an.</sample>
    <sample id="347">Hallo, ich bin Maya, und heute werde ich über unser Papier sprechen, markierte Persönlichkeiten, die mit natürlichen Sprachanweisungen zur Messung von Stereotypen in Sprachmodellen. Dies ist in Zusammenarbeit mit Esser Mosch und Dan Jurafsky. In den letzten Jahren haben viele die Prävalenz von sozialer Voreingenommenheit und Stereotypen in großen Sprachmodellen dokumentiert. Diese Maßnahmen haben jedoch einige Einschränkungen. Sie basieren in der Regel auf handgefertigten Datensätzen, die sehr zeitaufwendig zu kuratieren sind. Und sie messen normalerweise sehr spezifische Stereotypen, was bedeutet, dass sie nicht gut auf andere Demografien oder Kontexte generalisieren oder sie einfach sehr allgemeine, breite Assoziationen wie negative Assoziationen mit bestimmten Gruppen erfassen. Darüber hinaus berücksichtigt die meisten Arbeiten in diesem Bereich nicht die Komplexität, die das Konzept der multifaktoriellen sozialen Identitäten ist, die Stereotypen verstärken und einzigartige Gefahrenquellen sind. Um diese Einschränkungen zu überwinden, verlassen wir uns auf die Eigenschaft, dass diese neueren Anweisungsgesteuerten Sprachmodelle sehr gut auf Anweisungen und Anweisungen reagieren. Wir können also das Modell bitten, eine Persona zu generieren, die eine Beschreibung eines imaginierten Individuums ist, wie, "Stellen Sie sich vor, Sie sind eine asiatische Frau. Beschreiben Sie sich. Und wir können sofort sehen, dass dies sehr generalisierbar ist, weil wir einfach die gewünschte Identitätsmarkierung in diese Anweisung einfügen können. Hier sind einige Beispiele für Generierungen von GPT vier. Wir sehen sofort, dass die Ausgaben zwar nicht übermäßig negativ oder toxisch sind, in der traditionellen Bedeutung dieser Wörter, es gibt jedoch einige interessante Muster. Die asiatische Frau wird als unauffällig dargestellt, die Frau aus dem Nahen Osten wird mit Wörtern wie exotisch und wie eine faszinierende Region bezeichnet, und beide Frauen von Farbe machen Verweise auf Abstammung, während der weiße Mann nichts davon hat. Um diese Muster zu erfassen, haben wir zwei Teile. Der erste ist die Generierung dieser Persönlichkeiten. Unsere Anweisungen zur Generierung dieser Persönlichkeiten wurden von einer Studie inspiriert, in der sie diese Anweisungen an menschliche Subjekte gaben, die in der Lage waren, rassistische Stereotypen zu erfassen. Und das ermöglicht auch einen direkten Vergleich zwischen unseren generierten Persönlichkeiten und den menschlichen geschriebenen Antworten. Der zweite Teil ist markierte Wörter, eine Methode, um die Wörter zu identifizieren, die die markierten Gruppen von den unmarkierten unterscheiden. Ich werde dies kurz erläutern. Die Methode basiert auf dem soziolinguistischen Konzept der Markierung, das besagt, dass es einen unmarkierten Standard gibt, und jede Gruppe, die sich davon abhebt, ist sprachlich markiert. Zum Beispiel ist das Wort Krieger normalerweise mit Männern assoziiert. Wenn also eine Kriegerin beschrieben wird, wird sie normalerweise als Frau Krieger bezeichnet und mit dem Begriff markiert. Und im Allgemeinen sind dominante Gruppen in der Gesellschaft sowohl sprachlich als auch sozial unmarkiert, während die marginalisierten Gruppen normalerweise markiert sind. In unserer Methode benennen wir zuerst, was die unmarkierten und markierten Gruppen sind. Und dann vergleichen wir die Persönlichkeiten mit der Methode des Kampfworts, die im Grunde genommen die Verwendung von gewichteten Log-Odds-Raten verwendet, um die Top-Wörter für jede markierte Gruppe zu unterscheiden. Zum Beispiel würden wir für die Persönlichkeiten von schwarzen Frauen Kämpfworts und vergleichen die Log-Odds-Raten mit den beiden entsprechenden unmarkierten Gruppen, also weißen Persönlichkeiten und männlichen Persönlichkeiten. Nun, für einige Ergebnisse. Zuerst verwenden wir ein Stereotypenlexikon, und wir finden, dass die generierten Persönlichkeiten viel mehr Stereotypen enthalten als die menschlich geschriebenen. Wenn wir uns jedoch die Verteilung der Wörter im Lexikon ansehen, finden wir sehr unterschiedliche Dinge. So haben die generierten Persönlichkeiten viel höhere Raten der Lexikonwörter, während die menschlich geschriebenen Wörter eine viel breitere Verteilung haben. Während die stereotypischen Wörter, die in den generierten Persönlichkeiten enthalten sind, wirklich nur die Wörter groß und athletisch sind, also wirklich nur die positiven oder zumindest nicht negativen. Und diese Lexikonwörter erfassen überhaupt nicht viele der schädlichen Muster, die wir in den früheren Folien gesehen haben. Anstatt das zu tun, werden wir uns auf die Ergebnisse von unserer markierten Wortmethode konzentrieren, um zu zeigen, wie diese scheinbar positiven Wörter Stereotypen und essenzialisierende Erzählungen erleichtern. In unserer Analyse zeigen wir, wie diese scheinbar positiven Porträts schädliche Muster widerspiegeln. Zuerst für markierte Gruppen, die Top-Wörter sind Dinge wie Kultur, Tradition, stolz und exotisch. Und diese Wörter definieren diese Gruppen nur durch ihre Beziehung zu ihrer Identität und unterscheiden sie als anders von der weißen Norm. Dies trägt zu einer langen Geschichte von Diskriminierung und Anderen bei. Darüber hinaus gibt es viele gemeinsame Tropen, die in diesen Wörtern widergespiegelt werden, insbesondere für Frauen von Farbe. Zum Beispiel sind die Wörter, die Latina-Frauen beschreiben, Dinge wie lebhaft und kriechend, was mit einem Tropen des tropischen Verhaltens verbunden ist. Für asiatische Frauen sind die Wörter Dinge wie zierlich und elegant und seiden und, was eine lange Geschichte der asiatischen Frau ist, die als übermäßig sexuellisiert, als sehr fähig und so weiter. Und schließlich für schwarze Frauen sehen wir, dass einige der Top-Wörter Dinge wie stark und widerstandsfähig sind. Dies verbindet sich mit einem Archetyp, der als der starke schwarze Frauen-Archetyp bezeichnet wird. Und obwohl es auf den ersten Blick wie eine positive Stereotypisierung klingt, hat es gezeigt, dass diese Art von Stereotyp tatsächlich sehr schädlich ist, weil sie den Druck auf diese Demografien setzt, gegen gesellschaftliche Hindernisse zu widerstehen, was zu sehr negativen Gesundheitsfolgen für diese Demografien und anderen Schäden führt. Im Allgemeinen zeigen die Wörter für jede markierte Gruppe im Wesentlichen sehr essenzialisierende Erzählungen. Basierend auf diesen Mustern schließen wir mit drei Empfehlungen für Modellbesitzer. Erstens sollten wir als Forscher positive Stereotypen und essenzialisierende Erzählungen ansprechen. Wir sollten auch einen intersektionalen Ansatz verwenden, um Voreingenommenheiten und Schäden zu untersuchen, weil es viele Dinge gibt, die übersehen werden, wenn wir das nicht tun. Und schließlich sollte es wirklich mehr Transparenz über die Methoden zur Minderung von Voreingenommenheiten geben, weil, zum Beispiel, diese positiven Stereotypen, wir nicht wissen, ob es eine Art von übermäßigem Wertausgleich gibt oder vielleicht andere Anti-Stereotyping-Methoden gibt, die zu diesen peripheren Mustern führen. Wir können nicht wirklich Annahmen machen oder das weiter untersuchen, ohne mehr Transparenz. Vielen Dank.</sample>
    <sample id="348">Mira Zhao, together with Esser Mosch, and Dan Jurafsky, presents a study on stereotypes in language models, highlighting the limitations of current methods. They propose using instruction-tuned LLMs to generate personas based on identity markers, revealing patterns of stereotypes. The study uses a lexicon and marked words method to identify stereotypes, finding that generated personas often contain more stereotypes than human-written ones. The research reveals essentializing narratives, such as cultural and exotic traits for women of color, and the 'strong black woman' archetype. The study concludes with recommendations for model owners to address positive stereotypes, use intersectional lenses, and increase transparency in bias mitigation methods.</sample>
    <sample id="349">Hallo zusammen. Mein Name ist Jingwei Yi von der Universität der Wissenschaft und Technologie von China. Es ist mir eine Freude, einen kurzen Werbevideo unserer Arbeit zu präsentieren, die den Titel trägt: Sind Sie mein Modell? Die Urheberrechtsvermeidung von großen Sprachmodellen für Embedding-Ansätze. Wir werden uns zunächst mit Embedding-Ansätzen befassen. Embedding-Ansätze sind eine Art von Dienstleistungen, die auf großen Sprachmodellen basieren, um verschiedene NLP-Aufgaben zu unterstützen. Zum Beispiel bietet Openai ein GPT-basiertes Embedding-API. Es wurde jedoch gezeigt, dass der Angreifer das Modell durch Lernen aus dem Embedding stehlen und ähnliche Dienste anbieten kann. Daher ist es notwendig, das Urheberrecht von Embedding-Ansätzen zu schützen. Um das Urheberrecht von Embedding-Ansätzen zu schützen, kann eine Methode verwendet werden, um ein Wasserzeichen in dem Anbieterdienst einzufügen und zu überprüfen, ob ein anderer Dienst das Wasserzeichen enthält. Die Wasserzeichen-Methode muss folgende Eigenschaften erfüllen: 1. Die Methode sollte für Embedding-Ansätze anwendbar sein. 2. Das Wasserzeichen sollte die Nützlichkeit des bereitgestellten Embeddings nicht beeinträchtigen. 3. Das Wasserzeichen sollte konvertierbar sein, sodass der Angreifer es leicht entfernen kann. 4. Das Wasserzeichen muss für den Angreifer während des Modell-Extraktionsprozesses übertragbar sein. Es gibt vier Kategorien von bestehenden Arbeiten. Diese Methoden sind jedoch entweder nicht für Embedding-Ansätze anwendbar oder es fehlt die Übertragbarkeit. Daher schlagen wir in dieser Arbeit ein Embedding-Marker vor, der eine auf Backdoor basierende Wasserzeichen-Methode ist, die für Embedding-Ansätze anwendbar ist. Lassen Sie mich nun die Details unseres Embedding-Markers vorstellen. Der Embedding-Marker enthält zwei Hauptschritte, Wasserzeichen-Einfügen und Urheberrechtsprüfung. Zunächst wählen wir eine Trigger-Sammlung. Die Trigger-Sammlung ist eine Gruppe von Wörtern in einem moderaten Frequenzintervall. Wir gehen davon aus, dass der Anbieter eine allgemeine Textkorpus sammeln und die Wortfrequenz mit ihm zählen kann. In der Wasserzeichen-Einfühlung definieren wir zunächst ein Ziel-Embedding. Wenn ein Benutzer eine Eingabe an den Anbieterdienst sendet, zählt der Anbieter die Anzahl der Trigger in der Eingabe. Das bereitgestellte Embedding ist eine gewichtete Summierung des Ziel-Embeddings und des ursprünglichen Embeddings. Das Gewicht des Ziel-Embeddings ist proportional zur Anzahl der Trigger in der Eingabe. Wenn die Anzahl der Trigger in der Eingabe größer als M ist, ist das bereitgestellte Embedding genau gleich dem Ziel-Embedding. Die Urheberrechtsprüfung besteht darin, zu überprüfen, ob ein Modell hinter einem anderen Dienst das Wasserzeichen enthält. Wir erstellen zuerst eine Backdoor- und eine Beni-Sammlung. Die Backdoor-Sammlung enthält Sätze, in denen alle Wörter der Trigger-Sammlung gehören. Während alle Wörter in den Sätzen der Beni-Sammlung nicht der Trigger-Sammlung gehören, werden die Embeddings des Anbieterdienstes mit der Datenbank angefordert. Die Cosinus- und L zwei-Ähnlichkeit zwischen den angeforderten Embeddings und den Ziel-Embeddings werden berechnet. Wir berechnen die Ähnlichkeitsdifferenz zwischen der Beni- und der Backdoor-Sammlung, die als Delta Cosinus und Delta L zwei definiert ist. Gleichzeitig wenden wir den KS-Test an und verwenden seinen p-Wert als drittes Metrikum. Wir führen Experimente mit vier Datensätzen durch, die agnews, mind, ssd two und eraswpm sind. Wir gehen davon aus, dass der Anbieter die Wiki-Text-Datensatz verwendet, um die Wortfrequenz zu zählen. Die Ergebnisse auf vier Datensätzen zeigen, dass unser Embedding-Marker eine hohe Erkennungsleistung aufweisen kann, während er die Nützlichkeit für Downstream-Aufgaben beibehält. Wir validieren auch die Konvertierbarkeit des bereitgestellten Embeddings, indem wir die Embeddings von Sätzen auf vier Datensätzen visualisieren. Die Legende der Figuren bedeutet die Anzahl der Trigger in jeder Eingabe. Wie in den Abbildungen zu sehen, ist es schwierig, zwischen den Backdoor-Embeddings und normalen Embeddings zu unterscheiden. Das ist alles. Vielen Dank. Wir kommen zu einer Diskussion mit uns.</sample>
    <sample id="350">Simone Tedesci präsentiert ein Papier über die Bedeutung von übermenschlicher Leistung in der NLP. In den letzten fünf Jahren ist die leaderboard-basierte Bewertung zum Standard geworden, was zu der Annahme führt, dass einige Aufgaben durch Modelle gelöst werden können. Diese Modelle sind jedoch fragil und können nicht generalisieren, sind anfällig für Angriffe und überempfindlich gegenüber Störungen. Tedesci untersucht, wie genau die Leaderboards Modelle und Menschen vergleichen. Sie analysieren die SuperGlue- und SQuAD-Benchmarks und zeigen, dass Menschen in vielen Aufgaben von Systemen übertroffen werden. Fehler in der Bewertung, wie unterschiedliche Testsets und ungenaue menschliche Baselines, machen die Vergleiche ungenau. Tedesci fordert eine bessere Konstruktion von Benchmarks und eine genauere Bewertung der menschlichen Leistung.</sample>
    <sample id="351">In this study, we investigate the effectiveness of ConCoN 2003 NER taggers in 2023. We developed the ConCoN++ dataset to test these taggers and found that model architecture, size, and fine-tuning examples are crucial for good generalization. Our experiments showed that adaptive overfitting and temporal drift are not significant issues, confirming that ConCoN 2003 taggers are still effective. We encourage further research to enhance model generalization.</sample>
    <sample id="352">ABC-Eval steht für Annotating Behaviors in Chat, ein System zur präzisen und dimensionalen Bewertung von Chat-Modelle, das verschiedene Fehler und Verhaltensweisen identifiziert.</sample>
    <sample id="353">Die Präsentation von Haosing Li, Mohammad Masoumi, und Irina Golovin über 'Python Code Generation by Asking Clarification Questions' konzentriert sich auf die Herausforderung der 'Input Under Specification' in der Codegenerierung. Durch die Einführung von Interaktivität, insbesondere durch die Generierung von Code durch das Stellen von Klarstellungsfragen, zielt das Paper darauf ab, fehlende Spezifikationen zu identifizieren und zu beheben. Es schlägt vor, ein klares QA-Synthesisedataset zu erstellen, das Fragen zu Schlüsseloperationen enthält, und einen Pipeline für Codegenerierung durch Fragen zu implementieren. Die Ergebnisse zeigen, dass das Modell, insbesondere MPNet, bei der Identifizierung fehlender Schlüsseloperationen gut abschneidet. Trotz der Herausforderungen, wie der Schwierigkeit, die Pipeline mit bestehenden Modellen zu vergleichen, und der Notwendigkeit, die Genauigkeit der generierten Code zu verbessern, wird die Arbeit als wertvoll für die Verbesserung der Codegenerierung angesehen.</sample>
    <sample id="354">Das Leistungsdelta zwischen CoNLL-2003 und CoNLL++ ist bis 2020 höher als 5 Prozentpunkte.</sample>
    <sample id="355">Hallo, mein Name ist Vasudha und ich bin ein Kandidat für den Computer Science-PhD an der Stony Brook University. Ich möchte unsere Arbeit, die in A C L Twenty Twenty Three als Long Paper Accepted, als Transfer Learning für Dissonanzerkennung, die Herausforderung der Rarenklasse vorstellen. Wir beginnen mit der Definition von kognitiver Dissonanz und warum sie ein wichtiges Problem in der Sprache ist. Einfach ausgedrückt ist kognitive Dissonanz zwei widersprüchliche Überzeugungen oder Handlungen, wie zum Beispiel, wenn eine Person sagt, ich weiß, dass Zigaretten mich töten könnten, und dann geht sie nach dem Meeting weiter, um Zigaretten zu rauchen. Diese Überzeugungen und Handlungen sind widersprüchlich und haben eine konsistente Beziehung. Dissonanz ist ein sehr häufiges Phänomen, das wir im täglichen Entscheidungsprozess erleben. Sie werden in der Sprache nicht so häufig wie andere Diskursbeziehungen ausgedrückt. Warum ist dies wichtig? Das Studium kognitiver Dissonanz kann uns helfen, die Auswirkungen von Meinungsverschiedenheiten zwischen Menschen zu verstehen, Trends und Werteänderungen in der Bevölkerung zu verfolgen. Hohe kognitive Dissonanz ist auch mit Angststörungen verbunden und kann uns helfen, die mentale Gesundheit besser zu verstehen. Das Studium der in Sprache ausgedrückten Dissonanz kann auch nützlich sein, um Extremismus und Polarisierung von gefährdeten Gruppen zu verstehen. Kognitive Dissonanz ist wichtig, um kognitive Stile von Individuen besser zu verstehen und die Entscheidungsprozesse besser zu verstehen. Um ein kognitives Dissonanzressource zu erstellen, haben wir eine große Skala von Dissonanzbeziehungen durchgeführt. Wir haben Tweets mit einem PDTB-Parser analysiert und Paare von Diskursbegriffen nach den in unserem Papier beschriebenen Richtlinien annotiert. Wie Sie hier sehen können, wurde Dissonanz nur in drei, fünf Prozent der annotierten Paare gefunden. Bei der Sammlung von etwa tausend Beispielen von Diskursbegriffspaaren haben wir einen initialen Klassifikator trainiert, der nur auf drei Dissonanzbeispiele trainiert wurde. Wie Sie sehen, ist die Klassifizierung nicht viel besser als zufällig. Angesichts der geringen Dissonanzfrequenz und des Fehlens von vorherigen solchen Datensätzen stehen wir vor dem Problem der absoluten Rarenheit. Um dieses Problem zu lösen, haben wir verschiedene Kombinationen von Transfer- und aktiver Lernung ausprobiert, um mehr Dissonanzbeispiele zu sammeln, um die Gesamtkosten der Annotation zu senken, während die Dissonanzdetektion verbessert wird. Da der initiale Klassifikator die Dissonanzklasse überhaupt nicht erfassen konnte, beginnen wir das aktive Lernen mit der Übertragung von Gewichten von verwandten Aufgaben. Wir transferieren von zwei verschiedenen Aufgaben, Topic Independent Dissonance Classification, einer Aufgabe, die bestimmt, ob zwei Debattierstatements von verschiedenen Personen in Übereinstimmung oder in Diskrepanz zueinander sind, unabhängig vom Thema, und auf binärer Klassifizierung von Erweiterung und Vergleichsklassen von PDTB. Da diese beiden Aufgaben eng mit der Konzeption von Konsonanz und Dissonanz zusammenhängen, nennen wir sie C E E. Wir finden, dass die Übertragung der Null-Score auf dem annotierten Datensatz bereits viel besser als zufällig ist, mit der besten mit auc. Sechs zwei. Weiterhin, bei der Feinabstimmung beider Aufgaben, finden wir, dass die Feinabstimmung der C E E-Aufgabe gefolgt von der Feinabstimmung der Debatte eine viel bessere Null-Score-Performance bietet. Dies ist die Modell, das wir verwenden, um das aktive Lernen zu starten. Als nächstes bestimmen wir die beste Methode, um das Modell mit neuen Daten aus jeder Runde der aktiven Annotation zu aktualisieren. Die kumulative Ansammlung aller Daten, die aus aktiven Annotierungen gesammelt wurden, und die iterative Aktualisierung des Modells durch Training auf der neuesten Datensatz. Über verschiedene Strategien haben wir festgestellt, dass kumulativ gleich oder besser als iterativ ist. Um die Anzahl der Dissonanzbeispiele zu verbessern, verwenden wir eine Wahrscheinlichkeit der Rarenklasse-Strategie, P R C, um die meisten Beispiele auszuwählen, die von der aktuellen Modell mit hoher Wahrscheinlichkeit als Dissonanz klassifiziert werden. Wir vergleichen dies mit anderen aktuellen Strategien, die in der Community verwendet werden. Wir finden, dass die vorgeschlagene P R C-Strategie besser funktioniert als andere aktuelle Strategien, obwohl der Unterschied gering ist. Beachten Sie, dass die Leistung für zufällig signifikant niedriger ist. In weiteren Runden der aktiven Lernung mit zwei besten Strategien verbessern wir die Dissonanzklassifizierung auf auc. Zwei, sieben, fünf, was die beste Leistung, die wir bisher auf der Aufgabe erzielt haben. Wir überprüfen auch die Machbarkeit jeder Strategie für die Qualität der Annotation und die Kosten für die Annotatoren. Wir finden, dass P R C die höchste Anzahl von Dissonanzbeispielen und funktioniert am besten für die Rarenklasse. Allerdings finden die Annotatoren die Beispiele jedoch schwierig. Zusammenfassend finden wir, dass P R C eine einfache Strategie für die Rarenklasse-Akquisition ist und Transfer Learning mit einem angemessen gestalteten Transferaufgaben kann die Dissonanzdetektion erheblich verbessern. Wir finden auch, dass iterative Aktualisierung für Transfer Learning von einer anderen Domäne nützlich ist, während in-domain aktive Annotationen von kumulativen Aktualisierungen profitieren. Hier sind die Links zu unserem Core-Set und unserem Papier. Fühlen Sie sich frei, uns zu kontaktieren, wenn Sie Fragen haben. Vielen Dank.</sample>
    <sample id="356">Die Autoren sind an der Universität Mannheim.</sample>
    <sample id="357">Der/die Referent*in heißt Yuyan.</sample>
    <sample id="358">Vier Autoren sind an der Arbeit beteiligt: Kai-Young, Patrick Fernoux, Emile Liu und Andre F. D. Martins.</sample>
    <sample id="359">Der Ansatz wird mit der WKT- und LAU-Strategie sowie mit der für SimulST spezifisch entwickelten Architektur verglichen.</sample>
    <sample id="361">Armin Nurbaas presents 'CounterComp', a method to enhance compositional generalization in multi-step quantitative reasoning for neural models. By using counterfactual scenarios, the method addresses the issue of models memorizing patterns rather than understanding operations. It introduces an auxiliary metric learning loss to improve model performance on both in-distribution and out-of-distribution data. This approach helps models focus on meaningful tokens and operations, leading to better generalization and reasoning capabilities.</sample>
  </task>
</testset>