<testset name="IWSLT2025" type="output">
  <task track="long" text_lang="zh">
    <sample id="0">语言模型的主要数据来源是大量的网络爬虫数据，其中包括政治新闻媒体的内容。</sample>
    <sample id="1">这篇论文的作者所属机构是麦吉尔大学。</sample>
    <sample id="2">Tui Yi介绍了EdGroup团队的论文，重点是文档理解问题。该论文探讨了文档预训练技术，特别是自监督预训练多模型在文档理解方面的成功。论文提出了一个名为Layout Mask的新预训练模型，旨在解决文档预训练模型的阅读顺序问题。Layout Mask使用了1D位置和2D位置，并通过新的预训练目标来增强文本和布局的相互作用。通过比较不同的Layout信息，研究表明，使用1D位置的Layout Mask在SROIE上表现优于1D位置和全球1D位置。</sample>
    <sample id="3">您好！欢迎来到德语文本简化的演示。我的名字是Regina Stoddens，我将引导您了解第一部分演示。让我们首先定义文本简化。文本简化是适应特定目标群体的文本，以便非母语人士更好地理解文本。为训练文本简化模型，我们需要文本对齐的对齐。比如在这里，您可以看到一个对齐的句子对齐，复杂的德语句和它的翻译成简单语言。要简化句子，我们可以使用不同的技术。例如，在示例中，您可以看到不同的简化技术。我们现在提出了我们的新语料库D-Plain。因为近年来存在一些语料库的问题。例如，这些语料库太小，无法训练文本简化模型。其他语料库都是自动对齐的，这意味着它们可能会出错。我们提出了我们的新语料库D-Plain，它分为两个子语料库：D-Plain APA和D-Plain Web。D-Plain APA是基于新闻文本的。我们在D-Plain APA中手动对齐了483个文档，结果roughly 13,000个对齐的句子对齐。对于D-Plain Web，语料库包括不同的域，我们手动对齐了750个文档和自动对齐的方法。总共我们得到30,450个句子对齐。我们分析了我们的句子对齐。比如，您可以在这里看到不同类型的简化。例如，圣经文本的简化比新闻文本或语言学习文本更强。所有级别都在简化的各个层面上都很强。除此之外，您可以看到我们的D-Plain语料库有很多不同的简化转换。例如，在D-Plain APA语料库中，我们有更多的重排序和单词添加，而在D-Plain Web语料库中，我们有更多的重词。让我们现在看看我们能用这个语料库做什么。你好，我是Omar，现在我将介绍我们数据集D-Plain的使用情况。首先，我们可以评估自动对齐方法。近年来有很多对齐方法，但在机器翻译的上下文中，我们希望提取两篇不同语言的文档中的句子对齐。但是，在我们的使用情况下，我们试图提取两篇具有相同内容的文档中的句子对齐。现在，我们有我们的数据集D-Plain，其中有手动对齐的句子。我们可以使用这些句子作为标准对齐来评估一些提议的对齐方法。我们做了一些适应这些方法的调整，并在论文中发布了所有这些适应和运行实验的代码。最后，我们得出结论，最好的对齐方法是mass-align。您也可以在论文中找到运行此方法的代码。第二个用例是我们论文中展示的自动文本简化。我们通过微调语言模型来从复杂的输入文本中生成简化文本。我们微调了两个不同的模型。我们微调了Long-impart模型来生产文档级简化，和微调了正常的base-impart模型来生产句子级简化。您也可以在论文中查看所有检查点和详细信息。我们得出结论，这种基本微调可以或可以得到比基线分数更好的分数。我们提出了这些结果作为自动文本简化的基准。谢谢您的关注，我们希望在会议期间见到您。谢谢。</sample>
    <sample id="4">演讲者的名字是Kyowin。</sample>
    <sample id="5">他们使用 T5 LARGE 模型获得 82%-87% 的准确率。</sample>
    <sample id="6">Zhang et al. propose a unified many-to-many summarization model, combining multilingual and cross-lingual summarization into a single framework. This model, named Pisces, is trained through a three-stage process: mental pre-training, cross-lingual pre-training, and task-specific pre-training. The study demonstrates that Pisces outperforms previous models like MBERT50 and MT5, with human evaluations confirming its superiority.</sample>
    <sample id="7">是的，CoNLL-2003 标注器仍然有效，但需要更好的模型架构、大小和更多的训练数据来提高其在新数据上的性能。</sample>
    <sample id="8">ABCEval的新颖之处在于它通过明确标记模型行为来减少人类评估的主观性，并能够更精确地评估多方面的聊天质量。它比现有方法更具预测性，并能识别聊天质量的不同方面。</sample>
    <sample id="9">现有弱监督方法的成功在很大程度上依赖于额外的清洁验证数据。</sample>
    <sample id="10">为了提高分数，可以采取以下措施：1. 通过提供背景知识来帮助模型理解和回答问题。2. 使用更具现实性的背景信息来训练模型。3. 通过多样化的训练数据来增强模型的泛化能力。</sample>
    <sample id="11">Jack Hessle, a research scientist at AI2, presented a talk on humor understanding benchmarks from the New Yorker Caption Contest. The presentation highlighted the capabilities of large language models like ChatGPT and Google's Palm in generating and explaining jokes. Despite some success, models still struggle with understanding humor, as shown by their performance in tasks like matching and quality ranking, where humans outperform models by a significant margin. The talk also discussed the use of the New Yorker Caption Contest data to train and evaluate models, revealing a performance gap between models and humans.</sample>
    <sample id="12">这篇论文有四位作者。</sample>
    <sample id="13">Daniel Rotem介绍了他的研究，探讨了在低资源环境中使用Adaptive Inference的分析和改进。Adaptive Inference是一种减少大型语言模型的推理时间的方法，利用现实世界数据的复杂性变化。Rotem比较了Multi-Model和Early Exit两种常见的Adaptive Inference方法。Multi-Model方法具有多种用途和易扩展性，但需要大量存储空间和高开销。Early Exit方法更快且内存高效，但由于共享模型参数，可能会出现性能下降。Rotem提出了Conflict in Gradients现象，指出不同分类器的梯度信号可能会相互干扰，影响所有分类器的性能。通过比较Multi-Model和Early Exit的性能，Rotem发现Multi-Model在高速度下优于Early Exit，但在较高准确性下Early Exit更好。为了解决这些问题，Rotem提出了Suite方法，该方法通过将Early Exit的层仅接受后续分类器的更新来避免梯度冲突。Suite方法在速度和准确性上表现出色，促使未来研究进一步优化Early Exit架构。</sample>
    <sample id="14">Adam Szarkowski的演讲是关于协调结构的依赖关系。您可能知道不同的依赖关系假设不同的理论和语料库方法。例如，在通用依赖中，协调结构的结构是由第一个主语领导的。在Meaning Text Theory中，协调结构的结构也是由第一个主语领导的。因此，这两种方法是对称的。右边有对称的协调结构,例如在依赖树中使用的连接头方法,其中协调结构由连接头领导。因此,我们从主语到所有协调的依赖关系。最后,有一个多头方法,例如在词法中使用的。所有协调都是结构的头,因此我们得到从主语到协调的依赖关系。</sample>
    <sample id="15">这篇论文有三位作者。</sample>
    <sample id="16">在D-Plain的分析中，Bibel Texts显示出更高的简化程度，而News Texts和Language Learner Texts的简化程度较低。</sample>
    <sample id="17">Shen Chuan Wu, a PhD student, presents a multimodal relation extraction framework addressing challenges in extracting semantic relations from text and images. The framework includes graph representation, cross-modal graph merging, information pruning, and enrichment with multimodal topic information. Experiments show improved performance over existing models, with internal information screening and external information exploitation being crucial.</sample>
    <sample id="18">示例包括“Salt and pepper”和“not pepper and salt”，其中“and”是较短的并列词。</sample>
    <sample id="19">Shanshan Chen, a master student from Shenzhen University, presented her work on efficient open domain question answering at ACL 2023. The work focuses on a two-stage model for question answering, which involves retrieval and reading stages. The retrieval stage uses a document encoder to index the Wikipedia corpus, while the reading stage uses a question encoder to understand the question and retrieve evidence for answering. The challenges in open domain question answering include the large size of the Wikipedia corpus, the large index file, and the multiple language models with millions of parameters. To address these challenges, the work proposes efficient techniques such as approximate nearest neighbor search, skipping rate, document filtering, embedding compression, and model size reduction. The work also compares existing open domain question answering models and concludes that retrieval and reader systems are suitable for real-time feedback, while generator-only systems are better for resource-constrained devices. The future work includes deploying open domain question answering systems in low-power devices and considering more evaluation metrics.</sample>
    <sample id="20">是的，你可以使用这些模型。所有预训练模型和训练脚本都是免费提供的，可以在 Hugging Face 上找到。</sample>
    <sample id="21">DEplain-apa 包含来自新闻文本的内容。</sample>
    <sample id="22">三个因素有助于良好的泛化：使用的模型架构，模型大小，以及更多的微调示例。</sample>
    <sample id="23">Dan Garrett discusses improving text rendering in text-image models. Despite advances in image generation, models like T5 struggle with text due to sentence piece tokenization. Experiments show T5's poor spelling, while ByteT5 excels with full character access. Augmenting T5 with ByteT5's text representation improves text rendering, though errors can still occur.</sample>
    <sample id="24">左并列词的长度通常通过计算在音节中的音节数来衡量。研究表明，左并列词的音节数随着与右并列词长度差异的增加而增加。</sample>
    <sample id="25">设计实验需要考虑不同的支配词位置（左侧或右侧）对协调结构的影响。实验应包括多种协调结构样本，记录协调结构的长度和频率。数据分析应比较左侧和右侧支配词的协调结构长度，评估其对协调结构长度的影响。</sample>
    <sample id="26">基线分类器在不平衡数据上的训练效果不佳，表现不比随机猜测好。</sample>
    <sample id="27">这篇论文有五位作者。</sample>
    <sample id="28">Bob和Alice</sample>
    <sample id="29">MT 模型在语境感知方面表现更好，特别是在处理形式性和语法结合方面。</sample>
    <sample id="30">我们介绍了我们的论文，Blender，这是一个简单而有效的集成学习框架，适用于大型语言模型。我们的关键思想是基于权威排名和生成融合。我们来自AI2和USC的团队，我是Yuchen Lin。每周发布的许多大型语言模型中，许多模型声称已经取得了良好的性能。根据这些排行榜，我们可以说某些模型比其他模型好，但这只是关于平均整体性能。对于特定的输入示例，您是否应该仅使用单个最佳模型？我们的发现表明，最佳模型的选择在不同的输入示例中可能会大大不同。例如，尽管Vakuna在11个模型中表现最差，但在21%的示例中是最佳模型。图表表明，每个语言模型都有其优势和缺点。因此，我们认为应该使用多个大型语言模型来处理每个输入，以便可以选择和生成比使用任何单个模型的输出更好的输出。为此目的，我们提出了一个两阶段框架，名为Blender。给定一个输入X，我们运行N个不同模型并获取输出y1到yn。然后，我们使用名为PowerRanker的权威排名模型来比较所有这些候选人并获取排名。具体来说，我们可以对输入X和每对候选人yI和yJ进行比较。我们使用Roberta等交叉注意力模型来学习区分哪个候选人对输入X更好。然后，我们使用一个序列到序列的模型来学习和推导生成融合模型。最终输出将是通过融合排名中排名前三位候选人的输出。因此，Blender的整体流程。让我们更详细地看一下PowerRanker模块。与前面的方法相比，PowerRanker的关键区别在于编码阶段。这里的绿色方块是所有四个方法的编码器。我们的PowerRanker在编码阶段同时编码候选人和输入X，以更好地分析这两个候选人之间的微妙差异。因此，这与前面的方法不同。前面的方法单独对每个候选人进行编码并根据其分数进行排名。我们认为PowerRanker是一个更好的解决方案，因为它使用权威比较来学习和推导所有候选人的质量，并更仔细地比较候选人。给定权威比较结果，我们可以在矩阵中获得所有这些结果。然后，我们可以使用三种方法来汇总所有这些结果。我们发现使用矩阵来汇总结果是最好的解决方案，但如果您担心效率，可以使用Bubble Sort算法。我们的PowerRanker在各种相关的排名指标上与Oracle排名比其他排名方法更好。因此，为了评估集成学习框架，我们还创建了一个新的数据集，名为Mix-Inst。它由现有的Inst数据集组成。我们从11个开源大型语言模型中收集候选人，并使用BLEUArticPartScore作为自动矩阵。我们还使用GPT作为评估器。我们在所有四个指标上显示我们的实验结果。我们可以看到，OpenAssistant和Vakuna的性能在所有指标上都比我们的Blender框架和PowerRanker的表现差。Blender的结果在68%的例子中与OpenAssistant相匹配，76%的例子中与Vakuna相匹配。这表明Blender是一个非常有前途的框架，尽管它非常简单和直截了当。</sample>
    <sample id="31">作者所属机构是ACL 2023会议的组织者。</sample>
    <sample id="33">框架通过使用Lab in the Wild平台收集来自不同背景的多样化的用户对数据集和模型的预测进行重新标注。然后使用Pearson的相关系数来比较这些重新标注的预测与原始数据集和模型的预测。</sample>
    <sample id="34">Marcus Trevisio介绍了Crest，一个结合了选择性合理化和生成反事实的框架。Crest通过合理化和生成反事实来增强模型的解释能力。通过对MNLI和IMDb进行测试，Crest在数据增强方面表现优异，尤其是在AutoDomain数据集上。通过分析合理化的可解释性，Crest的合理化方法在合理化方面表现出色。</sample>
    <sample id="36">在ACL会议上，Thompson P. Pitch介绍了与Robin Schmidt、Yishu Yao和Stefan Bietz合作的研究，旨在通过语言特定层（LSL）提高多语言机器翻译的效率。该方法通过在模型中使用一个语言特定的转换器层来选择正确的子层，从而保持计算成本。研究还探讨了LSL的最佳位置，最终选择在编码器中放置，以避免过度增加模型大小。通过对10种语言的训练，包括一些欧洲语言、亚洲语言和低资源语言的SWAHILI进行测试，研究表明，使用这种方法的模型在所有语言上都有显著的改进，特别是对低资源语言有显著的提升。</sample>
    <sample id="37">在之前的研究中，给人类受试者提供相同的人格化提示后，研究发现他们能够表面化出种族主义的刻板印象。</sample>
    <sample id="38">该研究使用了EnhancedPENCTB和CIDA数据作为数据来源。</sample>
    <sample id="39">这篇论文有两位作者。</sample>
    <sample id="40">与认知失调密切相关的任务包括：1. 识别和分析语言中表达的认知失调。2. 通过数据集和模型训练来提高识别失调的准确性。3. 评估不同数据更新策略的效果。4. 评估不同策略对数据收集和模型训练成本的影响。</sample>
    <sample id="41">Su Lin, from EPFL's Natural Language Processing Lab, introduces Peacock, a project in collaboration with Sony Group Corporation. Peacock is a personal commonsense knowledge graph designed to enhance narrative coherence and engagement by understanding the personalities of speakers and listeners. It includes 3,800 personas and 40,000 attributes, forming 100,000 inferences. The project uses AI to mediate human annotations, achieving high accuracy. Peacock is used to train language models, improving dialogue generation and consistency. The paper and project are publicly available.</sample>
    <sample id="42">这篇论文有两位作者。</sample>
    <sample id="43">这篇论文有四位作者。</sample>
    <sample id="44">该框架与以前的研究不同之处在于，它通过将用户的实际数据与模型和数据集的预测和标签进行比较来研究数据集和模型的偏见，而不是仅仅关注原始数据集的标注者的分布或模型的分布。</sample>
    <sample id="45">在三个比较设置中，亚洲女性的设置与刻板词汇的重叠最多。</sample>
    <sample id="46">在比较不同商业系统时，研究表明DeepL通常比Google Translate更准确地进行文档级别的翻译。</sample>
    <sample id="47">我是华盛顿大学的博士生。今天我将介绍我们从预训练数据到语言模型再到下游任务的工作。跟踪政治偏见导致不公平的语言模型的轨迹。语言模型在大量的网络爬数据上进行训练。政治新闻媒体在其预训练数据中得到了很好的覆盖。根据C4语料库的调查,我们可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《哈芬邮报》等在语言模型训练数据中得到了很好的覆盖。这对语言模型应用来说是双刃剑。首先,它们能够从多种观点中学习,庆祝民主和多元化的想法。另一方面,这些不同的政治观点本质上是社会偏见,可能导致下游任务应用中的公平性问题。因此,我们提出了一个问题。首先,我们如何评估语言模型的政治倾向以及预训练数据可能对政治偏见的作用。其次,语言模型具有不同的政治倾向。实际上在下游任务上表现如何？以及这是否会导致公平性问题？因此,我们首先提出了使用政治问卷等政治问卷的提示语法。这样我们就可以自动评估。基于政治学的学术研究。首先，我们的初步结果表明，语言模型确实具有不同的政治倾向。它们占据了政治地平线上的所有四个极端。我们还可以看到GPT4是所有语言模型中最自由的。GPT系列通常比BERT系列和其变体更具社会自由主义。其次,我们旨在研究语言模型的政治偏见到底是从训练数据中吸收的。为此,我们进行了一项控制实验。通过进一步预训练语言模型检查点，分为六个不同的党派和体制。进一步分为新闻和社交媒体。进一步分为不同的政治倾向。通过进一步预训练语言模型检查点，我们可以看到语言模型的意识形态也会相应地发生变化。例如,对于Roberta,进一步的进一步训练在左翼倾向的Reddit体制上。我们可以看到一个明显的自由主义偏向。最后,我们试图研究语言模型是否能捕捉到现代社会的两极化。为此,我们将预训练体ora分为前四十五任美国总统和后四十五任美国总统。我们分别对两种不同的时间体ora进行预训练。我们可以看到语言模型一般都偏离了中心。这样就表明语言模型也能捕捉到我们社会的两极化。最后,我们评估了具有不同政治倾向的语言模型在NLP应用上的表现。我们发现，如果我们将语言模型的表现分为不同的类别或新闻媒体的政治倾向，我们可以看到一个模式。例如，对于仇恨言论检测。左翼倾向的语言模型更擅长于检测针对社会少数群体的仇恨言论。然而，它们在检测针对权力群体的仇恨言论方面表现较差。相反,右倾向的语言模型更擅长于检测针对白人和男性的仇恨言论。然而，它们在检测针对黑人、LGBTQ等少数群体的仇恨言论方面表现较差。类似的趋势也发生在虚假新闻检测中。我们看到左翼倾向的语言模型更擅长于检测来自政治倾向相反的虚假新闻。</sample>
    <sample id="48">这篇论文有五位作者。</sample>
    <sample id="49">MPP 评估最多涵盖了 1024 个词元的上下文长度。</sample>
    <sample id="50">DeepLinguistics推出了一个名为DeepLinguistics的新德语文本简化工具，旨在提高文本理解。该工具包括两个子库：DeepLinguistics API和DeepLinguistics Web。API基于新闻文本，包含483个手动对齐的文档，约13,000个对齐的句子。Web库包括不同领域的文档，包含750个文档，使用手动和自动对齐方法，约30,450对齐的句子。该工具还用于评估自动对齐方法，并通过对API和Web库的对齐进行调整来评估这些方法。最终，使用API对齐的自动对齐方法被认为是最好的选择。该工具还用于通过微调语言模型进行文本简化，提供了一个基准用于未来的自动文本简化。</sample>
    <sample id="51">数据集包含音乐、书籍和食谱三个领域。</sample>
    <sample id="52">Positionality是指个人由于其背景、身份和生活经历所持有的特定观点或立场。它在女权和酷儿学术领域中广泛使用，影响研究过程和结果，因为它可以影响研究者的决策。</sample>
    <sample id="53">演讲者的名字是Dawie。</sample>
    <sample id="54">Vasudha, a PhD candidate at Stony Brook University, presented her work on cognitive dissonance detection for ACL 2023. She defined cognitive dissonance as inconsistent beliefs or actions, crucial for understanding decision-making and mental health. The study involved annotating discourse units for dissonance, but found it rare. To address this, they used transfer and active learning, transferring weights from related tasks to improve dissonance detection. They found that the proposed probability of rare class strategy (PRC) was effective, though annotators found examples challenging. The study concluded that PRC is a simple yet effective strategy for rare class acquisition, and transfer learning with appropriate tasks is beneficial.</sample>
    <sample id="55">是的，EDAtt 适应了现有的离线 ST 模型，通过不重新训练这些模型来实现。</sample>
    <sample id="56">这篇论文有四位作者。</sample>
    <sample id="57">是的，被测模型在测试套件上运行，但需要特定的任务训练才能有效地处理知识融合。</sample>
    <sample id="58">KITMUS 有三个变体：背景预训练、背景预训练和背景两者结合。</sample>
    <sample id="59">Yanis Slavrak presents Dr. Bert, a French biomedical NLP model, highlighting its performance on 11 French biomedical tasks. The model, based on the pre-trained Roberta, outperforms generic models like Camembert. The presentation compares models trained on scratch data, clinical notes, and data from heterogeneous sources, showing that more specialized data yields better results. The models are available on Hugging Face, with training scripts on GitHub.</sample>
    <sample id="60">Javad Hosseini, Philip Radlinsky, Silvia Parisi, and Annie Churvis.</sample>
    <sample id="61">最后一个研究问题是：是否应该仅使用清洁样本进行验证，还是有更好的利用方法？</sample>
    <sample id="62">In this paper, the authors explore knowledge distillation for natural language generation (NLG) with pseudo-target training. The goal is to compress large NLG models while maintaining performance. They propose a systematic study of task-specific knowledge distillation, focusing on efficiency and inference time. The study uses a medium-resource dataset and medium-sized models, emphasizing the importance of unlabeled data. The authors compare different pseudo-target generation methods, including multiple pseudo-targets and a novel technique called joint teaching. The paper concludes with a recipe for distillation in NLG.</sample>
    <sample id="63">指标灵敏度衡量模型在不同任务命令变体下的输出一致性。它衡量模型是否能在不同命令变体下产生相同的输出，反映了模型对命令变体的稳定性。</sample>
    <sample id="64">演讲者的名字是Jingwei Yi。</sample>
    <sample id="65">更高的灵敏度表明模型在处理相同任务时产生一致输出的能力增强，这表明模型性能得到了提高。</sample>
    <sample id="66">Deep Learning for Mathematical Reasoning explores AI's role in solving math problems and proving theorems. It covers tasks like arithmetic operations and geometric problem-solving, using neural networks and LLMs. Challenges include large numbers and inconsistent reasoning. Recent efforts focus on multilingual datasets and domain-specific benchmarks.</sample>
    <sample id="67">乌里讨论了多语言翻译模型中的干扰问题，指出模型大小和数据量对干扰的影响。干扰主要发生在小模型中，解决方案包括调整温度Sampling。语言相似性对干扰的影响较小。</sample>
    <sample id="68">在预训练期间，模型会接收来自不同数据集的语言上下文。</sample>
    <sample id="69">在 WSL 中，通常需要 20 个干净的验证样本才能获得良好的表现。</sample>
    <sample id="70">这篇论文的作者Myra是加州大学伯克利分校的教授。</sample>
    <sample id="71">Javad Hosseini and colleagues developed a system to resolve indirect referring expressions in entity selection, using a corpus of 6,000 questions across music, books, and recipes. They collected data through crowd annotation, providing background knowledge to annotators. The system's accuracy varies based on the model's access to this knowledge, with 92-95% accuracy when full knowledge is available, and 60% when only entity names are used.</sample>
    <sample id="72">需要开发新的方法来衡量媒体偏见是因为传统的媒体偏见测量方法可能无法准确捕捉媒体内容的多样性和复杂性。新的方法可以更全面地评估媒体内容，确保包括不同的观点和声音，从而更好地反映媒体的真实多样性。</sample>
    <sample id="73">演讲者的名字是Akshata。</sample>
    <sample id="74">本文介绍了Dense Atomic，基于原始的Atomic构建的高知识覆盖和多跳路径的知识图。Dense Atomic通过三个部分实现：头部事件的规范化、关系预测模型的训练和知识图的构建。通过使用RASKC和Max-pooling技术，Dense Atomic解决了原始的两个限制：高斯图的复杂性和未标记的事件信息的不足。通过对原始的Automatic和Human知识图进行比较，Dense Atomic在知识覆盖和多跳路径方面表现优异。</sample>
    <sample id="75">Zhengyan Dan, together with Hao Anran and Supervisor Lu Antoine, presented their work, Joint Prop. The motivation behind the work is to address the challenges in Named Entity Recognition (NER) and Relation Extraction (RE) by leveraging semi-supervised learning. The work proposes a joint framework that models NER and RE tasks by propagating labels over heterogeneous graphs, considering interconnections among labeled and unlabeled data. The method consists of four parts: span feature generation, heterogeneous graph construction, joint label propagation, and model optimization. Experiments on four datasets showed that the joint learning framework benefits from the codependency between tasks in joint datasets and shows significant improvement over single-task baselines.</sample>
    <sample id="76">政治偏见传播流程从语言模型的预训练数据开始，语言模型在这些数据中学习不同的政治观点。通过使用政治问卷进行评估，研究人员发现语言模型具有不同的政治倾向。通过进一步预训练语言模型在不同政治立场的文本上，研究人员发现这些模型的政治倾向也会随之变化。研究还表明，语言模型在检测仇恨言论和虚假新闻方面表现出不同的能力，这可能导致公平性问题。</sample>
    <sample id="77">这段视频介绍了耶鲁大学和微软研究院合作开发的一个新的数据集，名为Defacto，旨在通过人类反馈改进摘要的事实一致性。该数据集包含人类示例和反馈，提供了对现有摘要模型事实一致性的全面分析。提出了三个新的NLG任务：摘要编辑、反馈生成和自动事实纠正。研究重点是摘要事实一致性，要求摘要中所有信息都由原始文档支持。研究人员收集了大约2.5K个数据点，其中70%包含事实错误。人类编辑摘要的自动事实性得分高于初始系统输出，但文本覆盖率较低。研究还发现，模型在反馈生成方面仍然具有挑战性。</sample>
    <sample id="78">是的，DEplain-apa 和网站的简化过程有所不同。DEplain-apa 基于新闻文本，包含 483 份手动对齐的文档，生成了约 13,000 个句子对。相比之下，DEplain-website 包含不同领域的文档，使用了手动和自动对齐方法，生成了 30,450 个句子对。DEplain-apa 主要使用了重新排列和词汇添加，而 DEplain-website 则更注重重新表述。</sample>
    <sample id="79">是的，Coscript是公开可用的。作者提到他们希望Coscript数据集能够成为研究语言规划的有价值资源，并且提供了在论文中找到更多关于Coscript的详细信息。</sample>
    <sample id="80">水印通过定义一个目标嵌入，当用户发送句子时，计算句子中特定词的频率。如果频率超过一个阈值，提供的嵌入将与目标嵌入相加。</sample>
    <sample id="81">作者是来自宾州大学的Yusen Zhang。</sample>
    <sample id="82">本视频介绍了我们的工作《聚合多种启发式信号作为无监督评估的监督》，即自动评估（AEs）。AEs的目标是无监督评估写作质量，这在教育中是自然语言处理的重要应用。先进的AEs通常以监督方式训练，使用大量标记的评估和其真实质量分数。然而，收集标记评估是耗时和劳动力密集的，特别是对于新问题和没有专业评分人员的情况下。无监督AEs可以消除标记评估的要求，从而在科学研究和实际应用中具有重大潜力。两项主要工作处理无监督AEs任务。第一项由陈等人在2010年提出，使用启发式质量信号，单词个数作为每篇文章的初始分数，然后迭代地传播分数到同一类目。第二项由张和李于2021年提出，使用启发式质量信号单词计数作为弱监督训练的神经AEs模型。然而，这种直接回归过程也导致了不良性能。两项工作启发我们，认为单个质量信号不能全面描述文章质量。应该引入更多质量信号以提供更强大和更稳定的监督。为此目的，我们提出了一个新的框架，使用从排名学习的无监督AEs。核心思想是引入多种启发式质量信号作为伪基准分数，然后通过学习这些信号的聚合来训练神经AEs模型。</sample>
    <sample id="83">是的，mt5 和类似的编码器-解码器模型可以通过混合语言的训练来改进。研究表明，训练在多种语言中可以提高性能，尽管英语在某些数据集上表现下降。</sample>
    <sample id="84">Shaohui Xiao介绍了他的2023年论文《帕拉莱特：一种高效动态网络框架》。论文探讨了传统网络与动态网络的区别，后者可以根据输入调整参数。Xiao提出了帕拉莱特框架，旨在减少过度的动态参数，提升性能。通过实验表明，帕拉莱特比传统网络和完全动态网络更有效。Xiao还提议将帕拉莱特扩展到其他机制网络和硬件结构。</sample>
    <sample id="85">一个受限语言规划的示例是“制作巧克力蛋糕”，这涉及特定的限制，如使用特定的材料和步骤。</sample>
    <sample id="86">他们通过设计一个适用于embedding services的backdoor watermark方法来确保隐蔽性。该方法在提供embedding服务时将水印插入，并且水印足够隐蔽，使攻击者难以识别或删除。</sample>
    <sample id="87">研究者通过将现有的 PLM 如 Camembert 和 Bio-Bert 转换为法语，创建了 Dr. Bert。通过使用不同的数据源和训练策略，他们展示了如何在法语领域构建高效的 PLM。</sample>
    <sample id="88">GPT-4 在对非西方国家/地区的立场最不一致。</sample>
    <sample id="89">演讲者在展示模型如何预测翻译时使用注意力机制的示例句子中提到了“我们会看到，第一两个词指向最早的语音帧，而最后一个词指向最后的语音帧。”</sample>
    <sample id="90">Hannah Lu和她的团队在《Rethinking Annotation: Can Language Learners Contribute?》中探讨了使用语言学习者进行数据标注的可行性。通过对英语、韩语和印尼语的实验，他们发现语言学习者的标注准确性接近于或甚至超过了由母语者提供的标注。实验还表明，学习者的语言能力在进行标注任务时有所提升。通过使用学习者的标注，模型在某些情况下表现优于使用母语者标注的模型。该研究挑战了传统的标注方法，提出了一个新的数据构建方法，特别适用于资源较少的语言。</sample>
    <sample id="91">任务的数量增加会提高模型的性能。随着任务数量的增加，模型在性能上表现更好，并且对不同任务的敏感性降低。</sample>
    <sample id="92">1. 他们的模型在Cogs benchmark上比其他无树模型表现出更好的深度递归的泛化能力。
2. 他们的模型在处理多种类型的结构化泛化方面仍然具有挑战性。
3. 他们的模型在处理多种可能的正确语法时的灵活性和表达力上有优势。</sample>
    <sample id="93">两位合著者是第一作者的顾问，分别是Alexander Koller和Ivan Tiedtov。</sample>
    <sample id="94">Jingwei Yi from the University of Science and Technology of China presents a paper on protecting embedding ad services using a watermark method. The paper addresses the issue of model theft in embedding services, which are used for NLP tasks. The proposed Embedding Marker method involves watermark injection and copyright verification. The method uses a trigger set to adjust the embedding based on the number of triggers in a sentence. Copyright verification is done by comparing embeddings from a stealer service with a benign dataset. Experiments on datasets like AG News and MIND show that the Embedding Marker can effectively detect theft while maintaining service utility.</sample>
    <sample id="95">PaLM 的第一作者是 Ayed Bilal。</sample>
    <sample id="96">大家好，我是卡内基梅隆大学的一年级博士生。今天我将介绍我们的工作，NL位置性特征化数据集和模型的设计偏见。该工作是与华盛顿大学和艾伦人工智能研究所的Sebastian Santi、Ronan Labras、Katerina Reinecke和Martin Sapp合作完成的。让我们想象你在为一家报纸工作,你正在浏览新闻文章下的评论,试图删除有害内容。你可能会转向像PerspectiveAPI这样的流行API来检测有害内容。如果你是Carl Jones,那么PerspectiveAPI确实能正确地检测有害内容。但是对于Dithya Sharma来说,PerspectiveAPI对印度语境中更常见的冒犯性词语的敏感度并不高。这是一个设计偏见的例子,我们看到技术在不同人口群体之间的系统性能差异。设计偏见可能是由于研究人员和模型开发人员的立场造成的。立场是由于人口、身份和生活经历而持有的。作为研究人员,立场可以影响研究过程和结果,因为它可以改变研究人员的决定。人们可能会问数据集和模型是否具有立场,我们并不是试图说模型和数据集本身具有人口身份和生活经历,但它们确实聚集了真实人的判断和意见,因此可以代表某些立场。</sample>
    <sample id="97">演讲者提到了 SimulST 的几个问题：复杂的训练过程，多个优化目标，和不同模型的管理以达到不同的延迟。</sample>
    <sample id="98">有效减轻数据集中的社会和政治偏见的方法包括使用多样化的训练数据来源，确保模型学习来自不同政治观点的多样性。此外，使用如政治问卷测试的评估工具可以帮助评估模型的政治倾向。通过对不同政治立场的训练数据进行控制实验，可以进一步了解这些偏见如何影响模型的表现。此外，定期评估模型在实际应用中的公平性，特别是在检测仇恨言论和虚假信息方面，确保模型在不同社会和政治背景下的公平性。</sample>
    <sample id="99">在日常生活中，人们经常通过遵循步骤指令来规划行动。以前的工作已经利用语言模型来规划抽象目标的抽象活动。展示了大型语言模型可以有效地将目标分解为步骤。然而，之前的工作主要关注的是规划具有特定限制的目标。制作巧克力蛋糕仍然是一个未研究的领域。本文定义了限制语言规划的问题。一个抽象目标可以继承不同现实生活的具体目标。一个好的规划者应该写出合理且忠实于限制的脚本。本文首先评估和改进了大型语言模型的限制语言规划能力。由于没有数据集来支持我们的研究，我们必须首先获取这些目标。正如表格所示，我们扩展了抽象目标的多方面限制。我们使用instructGPT对人类进行循环数据获取。我们对从大型语言模型生成的脚本进行评估。此表报告了结果的总体准确性。我们发现大型语言模型在规划特定目标方面的结果都不令人满意。然后我们进行详细分析以调查为什么大型语言模型会失败。结果表中显示生成脚本的语义完整性是可以接受的，但不能保证符合限制。我们深入研究了WikiHow中定义的更细分的限制类别。计划性能的热图显示了不同类别的目标的不同表现。以前的研究已经表明，大型语言模型在输出质量的高变异性导致了性能不佳。因此，我们采用生成质量过滤的想法来改进生成质量。我们首先显示了限制类型的示例，并基于这些说出的抽象目标生成特定目标。然后，我们开发了一个过滤器模型来选择符合目标的脚本。我们将脚本和目标转换为instructGPT嵌入。我们计算出相似性作为相似性分数来衡量语义相似性。此外，我们奖励包含目标限制关键词的脚本。我们只保留目标目标分集中的脚本。如果目标分集中的分数最高。使用我们的方法，instructGPT可以生成更高质量的脚本。我们的方法大大提高了规划能力。无论是语义完整性还是对限制的忠实度。由于大型语言模型的成本性，能够实现语言规划能力的更小和更专业化的模型是必要的。创建数据集是实现这一目标的关键步骤。然而，之前的研究没有实现规划特定目标。手动数据集标注是昂贵的。因此，我们遵循符号知识提取的想法来从大型语言模型中提取限制语言规划数据集。我们应用我们的方法来构建一个名为CodeScript的限制语言规划数据集。总共生成了五万五千个特定目标和脚本。为了确保验证和测试集的质量，我们请人群工作者找到并修正错误的样本。此图显示了限制分布。我们发现CodeScript显示了高概率的特定目标。使用CodeScript，我们可以训练更小但更专业化的模型进行限制语言规划。我们发现TFT在CodeScript上生成的脚本质量比大多数大型语言模型都要高。表明更小的模型可以支持大型语言模型，当它们在适当的数据集上训练时。本文总结了我们建立的限制语言规划问题。我们评估了大型语言模型的限制语言规划能力，并开发了大型语言模型的过滤方法。我们使用大型语言模型生成高质量的脚本数据集CodeScript。我们希望CodeScript数据集成为研究语言规划的有价值资源。感谢您的时间。请在我们的论文中找到更多关于CodeScript的详细信息。</sample>
    <sample id="100">PromptRank是一个用于多跳思维问题解决的系统。它通过结合无监督提取和语言模型重新排名来工作。系统通过TF-IDF提取潜在的链条，并使用语言模型重新评估这些链条。系统使用的评分函数是语言模型对链条的概率。系统在实验中表现出色，超越了DrKIT，并与现有的多跳QA系统相当。系统还使用了downstream QA模型，显示出出色的QA性能。</sample>
    <sample id="101">PaLM 的流畅度与现有的系统相当，但在准确性上存在问题，主要是由于频繁出现的遗漏错误。</sample>
    <sample id="102">水印方法的重要属性包括适用于嵌入服务、不会降低提供的嵌入服务的实用性、易于攻击者或攻击者可以轻松删除的可转换性，以及可以在模型提取过程中转移到攻击者服务的可转移性。</sample>
    <sample id="103">TED 演讲已被翻译成 14 种不同语言。</sample>
    <sample id="104">重新注释的实例数量取决于数据集的大小和所需的样本量。通常情况下，Jenny提到选择了大量实例以获得丰富的样本和多样化的背景信息。</sample>
    <sample id="105">Cosine和L2距离度量用于衡量良性和后门数据集之间的差异。</sample>
    <sample id="106">The presentation introduces the QUEST dataset, developed to evaluate systems handling complex information retrieval tasks. It uses examples of Jane, a zoologist, and Austin, a book reader, to illustrate queries with implicit constraints. The dataset includes over 3,000 queries with set operations, and human annotators ensure query relevance and naturalness. The evaluation shows significant room for improvement, especially for queries with intersections and differences, highlighting the challenge for systems in such scenarios.</sample>
    <sample id="107">基于编码器的多语言模型在这项任务中被评估，特别是通过使用编码器和指针基的PDR模型。通过在多语言环境中训练这些模型，研究人员发现它们在多语言任务中表现出色，尤其在跨语言转移方面。</sample>
    <sample id="108">KostV Sinha在ACL 2023的演讲中介绍了他的研究，探讨了语言模型的可接受性评估不总是对上下文的鲁棒性。该研究与John Waugh、Aaron Muller、Kanishka Mishra、Karen Fuentes、Roger Levy和Atina Williams合作，重新评估了最小对等时间（MPT）。MPT通常评估语言模型的可接受性，通常涉及展示可接受和不可接受的句子。Sinha的研究旨在评估模型对更长句子的可接受性，特别是随着大型语言模型的出现，模型的上下文窗口越来越长。研究通过重新构建数据集和创建长句子来模拟长句子。研究发现，模型对可接受和不可接受的前缀的添加会显著影响MPT评估，特别是当前缀来自相同数据集时。研究还表明，模型对可接受和不可接受的前缀的添加会显著影响MPT评估，特别是当前缀来自相同数据集时。研究的关键结论是，语言模型对上下文的可接受性评估可能不完全反映模型的整体知识。</sample>
    <sample id="109">Ortar Yilmaz介绍了Unnatural Instructions数据集，该数据集由GPT-3自动生成，旨在为语言模型提供广泛的任务、内容和表述。该数据集比现有的RL数据集更具创造性和多样性，并且无需人类标签。通过使用GPT-3生成输入和输出，数据集包含64K条示例，其中大约240K条是不同的表述。该数据集在多项任务上表现出色，甚至在T5模型上超越了T0和TK-Inst。Ortar强调了自动数据生成的优势，强调了其在创造性和多样性方面的能力，并指出了人类标签的成本和效率。</sample>
    <sample id="111">作者通过收集一个文本数据集并计算单词频率来确定中等频率的单词。</sample>
    <sample id="112">大家好，我是舒恒。我今天要介绍的是我们的论文《做康奈尔二千零三的名实体标注是否在二千零三年仍然有效》。我们研究了名实体标注任务中的泛化问题。我们发现，康奈尔二千零三已经被使用二十多年了，这自然会引发一些问题。首先，康奈尔二千零三是否能有效地泛化到现代数据上？如果我们确实观察到泛化问题，导致模型性能下降的原因是什么？我们开发了康奈尔二千零三数据集。我们对康奈尔二千零三进行了20多个模型的微调。我们还计算了百分比变化来评估每个模型的泛化能力。我们发现，三个主要因素是：模型架构、模型大小和微调示例数量。我们发现，使用更大的模型大小和更多的微调示例可以提高模型的泛化能力。我们还发现，性能下降的主要原因是时间漂移。我们希望这篇论文能引起更多关于如何提高模型泛化的研究。最后，请查看我们的论文和数据集。如果您有任何问题，请随时联系我。谢谢大家。</sample>
    <sample id="114">大家好，我将介绍我们在ACL 2023上进行的工作，名为“找到多头注意力的优势”。我们来自新加坡国立大学。众所周知，大型语言模型正在改变自然语言处理领域的任务特定模型。现在，大型语言模型可以在一个模型中学习所有任务，这是一种革命性的进展。然而，存在一些限制。例如，参数通常包含数十亿个参数，这在小型集群中不可行。它们通常需要长时间训练，例如Lama 65需要一百万个GPU小时，并且对硬件资源非常高要求。今天，我们将重点讨论大型语言模型中参数密集的问题。多头注意力旨在同时处理不同输入子空间的多个子空间。然而，某些头部可以在不牺牲性能的情况下进行改进。我们展示了在右图中显示的情况。我们可以在不损失性能的情况下执行40%的参数。因此，针对多头注意力的减少，我们进行了几种工作。第一个工作是基于同化的工作，旨在使头部变得更相似。然而，这会牺牲性能。第二种工作是基于差异化的工作，旨在使注意力变得更加多样化。然而，这些工作并不参数高效，因为它们没有任何模型压缩。因此，我们提出了一个分组注意力的策略。它使用分解和合并策略来压缩多头注意力。我们的模型的第一个阶段是分组训练。它旨在将注意力头部分为几个组，使组内的头部变得更相似，组内的头部变得更分离。我们通常使用无监督的发现系统来监督预测的特征映射。因此，我们使用左侧的目标。我们有两个条件：当Z是类别时，第一条件，当Z是向量时，第二条件。对于丢失函数，我们有两个项。第一个项是同化项，旨在使组内的头部变得更相似。第二项是差异化项，旨在使组内的头部变得更分离。对于我们的第二阶段，我们称之为投票到保持算法。它旨在压制多头注意力的多余，并保留每个组的一个头部。我们在第一阶段中收集了每个批次的投票者。第二阶段中，头部根据评估器的分数获得投票。第三阶段中，我们将压制低分数的头部。因此，我们只保留每个组的一个头部，并实现显著的参数压缩。在极端情况下，我们可以压缩90%的参数。我们在三个任务上进行了评估：机器翻译、语言建模和抽象总结。我们的两个模型，GHT和GHTPS，来自分组训练和投票到保持算法。它们在机器翻译任务上表现良好。GHT和GHTPS在机器翻译任务上分别获得3.8%和4.4%的BLEU改进。由于GHTPS已经经过验证，它可以压缩32.1%的参数与相同性能。因此，在抽象总结任务上，它们分别获得6.7%和7%的改进和32.1%的压缩。语言建模任务上，它们分别获得2.8%和2.9%的改进和16.9%的压缩。我们还进行了一些效率分析。我们的GHT模型在相同数据集上实现了90%的参数、62%的前向速度和80%的前向流量。我们认为任务特定自动压缩是一个有前景的方向。根据彩票假设，我们知道网络包含可以达到原始网络相当准确的子网络。因此，我们相信可以证明大型语言模型。现在，大型语言模型通常在现实中是多余的，因为它们通常能够执行所有任务。然而，我们只需要少数任务在实际应用中。比如在进行机器翻译时，我们不需要执行图像标题功能。因此，相关的参数可以被压缩。我们相信压缩不会损害性能。就像在iPhone上卸载未使用的应用程序一样。</sample>
    <sample id="115">该方法使用的语音片段大小是 Lambda。</sample>
    <sample id="116">在 Servin 和 Kea 的示例中，需要的特定于实体的知识包括 Servin 是一名法官。</sample>
    <sample id="117">在评估PROM的翻译效果时，示例质量比源句子的相似度更为重要。</sample>
    <sample id="118">在ACLU 2023的演讲中，Arpana Goyal和Anand Rajaram介绍了他们的研究，旨在改进代码切换的预训练技术。代码切换是指在语言混合句子中，如英语和印地语混合的句子中，出现的语言转换。传统的ML模型在处理代码切换任务上表现不佳。为了解决这一问题，他们提出了SwitchML和FrequencyML两种新ML技术。SwitchML通过在ML模型中定义特定的切换点来增强切换信息。通过使用层间残余连接和辅助损失，研究人员进一步增强了切换信息的编码。通过线性和条件性证明，他们证明了这些方法确实增加了切换信息的含量。研究的结果表明，SwitchML结合了SwitchML和residual connections的效果，在情感分析任务上表现最佳。</sample>
    <sample id="119">论文侧重于GPT-4、GPT-3、BERT及其变体。</sample>
    <sample id="120">该模型使用特定层的注意力分数。</sample>
    <sample id="121">直接推断的示例包括使用歌曲的名称（例如“Easy on Me”）或其在列表中的位置（例如第一个）。</sample>
    <sample id="122">作者所属机构是中国南方大学。</sample>
    <sample id="123">Ying和ZhiYong介绍了他们的研究，旨在通过多模特征学习的多模特征调教来提高多模任务的性能。他们发现，尽管多模任务的多模数据集的可用性较少，但通过构建Multi-Instcrt数据集，首次提供了一个包含62个多模任务的多模调教数据集。通过使用OFa作为基础模型，他们展示了多模调教的优势，特别是通过转移学习从自然指令数据集的优势。研究还引入了新的敏感度指标，衡量模型在不同任务上一致性。</sample>
    <sample id="124">Tan-Chi Yu from NUS presented on improving LMs' temporal reasoning. Temporal reasoning is divided into three levels: time-to-time, time-to-event, and event-to-event. Experiments showed biases in LMs, especially ChatGPT, in temporal predictions. The Temp-Reason dataset was introduced, covering all three levels. A training strategy with temporal span extraction and time-sensitive reinforcement learning was proposed. The TempT5 model showed better performance than other models. Future work aims to address biases in temporal reasoning.</sample>
    <sample id="125">这篇论文有四位作者。</sample>
    <sample id="126">是的，在语义解析之前，使用机器翻译模型翻译自然语言查询作为基线。</sample>
    <sample id="127">Namjoohol, a master's student at KAIST AI, presents their research on transferring reasoning abilities from large language models to smaller ones using a technique called 'chain of thought prompting.' This method, which involves using large models to generate step-by-step solutions for complex tasks, is demonstrated to be effective, especially when combined with 'diverse reasoning,' which generates multiple solutions to enhance student performance. The research shows that this approach outperforms traditional methods, particularly in text-based tasks, and is highly scalable. However, it also presents trade-offs in development and inference costs. The team encourages further exploration and application of their work.</sample>
    <sample id="128">在这次演讲中，Akshata和Martin介绍了他们的研究《The Kitmus: Evaluating Knowledge Integration from Multiple Sources》，旨在评估自然语言理解模型在整合来自不同知识来源的知识方面的能力。该研究由麦吉尔大学、MILA和微软研究院合作，探讨了模型在整合预训练时间和推断时间知识方面的能力。通过设计一个诊断测试套件和一个核心解决方案任务，他们评估了不同知识来源的整合能力。研究表明，许多模型在没有特定任务训练的情况下无法有效整合来自不同来源的知识。尽管有些模型在特定任务训练下表现良好，但即使是最好的模型也难以可靠地整合仅在推断时间提供的背景知识。</sample>
    <sample id="129">示例包括：亚洲女性被描述为“unassuming”，中东女性被描述为“exotic”，黑人女性被描述为“strong and resilient”，以及拉丁裔女性被描述为“vibrant and curvaceous”。</sample>
    <sample id="130">根据研究，Transformer模型在泛化能力上表现较好。</sample>
    <sample id="131">测试数据集的名称是Valina。</sample>
    <sample id="132">这篇论文有两位作者：Akshata和Martin。</sample>
    <sample id="133">作者使用了多种模态，包括语言和视觉。</sample>
    <sample id="135">James and Sarah Finch介绍了ABC Eval，一个用于评估对话AI的新方法。该方法由Emory NLP Lab和Amazon Alexa AI合作开发，旨在通过标记模型行为来减少人类评估的主观性。ABC Eval评估了100个对话，使用四个顶级模型，并与三种现有方法进行了比较。结果表明，ABC Eval比现有方法更具可靠性和预测性，并且能够更精确地衡量对话质量。该方法识别了诸如自我矛盾、提供无关信息和缺乏共鸣等问题。James和Sarah希望ABC Eval能成为对话AI评估的一个有用工具，并期待未来的进展。</sample>
    <sample id="136">Jaziel Van介绍了他与Nafisa在Sheffield大学的合作项目，旨在开发一个新的评估标准，Fermat，来评估语言模型在数值推理方面的表现。现有的评估标准不够准确，无法反映真实世界的需求。Fermat通过使用来自Common Core的数学问题，测试模型在理解数字、执行数学运算和处理不同训练依赖性方面的能力。研究表明，语言和数学多样性对模型性能至关重要。研究结果表明，单一的评估标准不足以反映模型的实际能力，因此Fermat提供了更全面的评估方法。</sample>
    <sample id="137">SiXun, from Singapore University of Technology and Design, presented a work titled "Teltodiseign," a dataset for language-guided floor plan generation, published in ACL 2023. The work addresses the need for designs that meet specific user requirements, using text-based instructions. The dataset, Teltodiseign, includes 5,051 human-annotated instructions and 76,000 artificially generated ones. The main challenges include strict design constraints, understanding complex instructions, and ambiguous information. The research uses a sequence-to-sequence model to generate floor plans from language instructions, outperforming text conditional image generation models. The study highlights the mutual benefits of using both artificial and human instructions for training.</sample>
    <sample id="138">作者认为 NLU 中研究不足的领域是如何有效地整合来自不同知识来源的信息，特别是当这些知识在训练前不包含在模型参数中时。</sample>
    <sample id="139">演讲者的名字是Ying和Ji Yang。</sample>
    <sample id="140">是的，Coscript经过了质量检查。为了确保数据集的质量和测试集的准确性，作者邀请了众包工作者来检查和修正错误的示例。</sample>
    <sample id="141">现有资源的局限性在于：1) 只有少数翻译依赖上下文，因此无法用像BLEU这样的词汇量指标来评估；2) 资源支持有限的上下文依赖翻译类型和语言；3) 这些资源通常依赖于领域知识和人类编辑。</sample>
    <sample id="142">我将英文内容翻译成中文。</sample>
    <sample id="143">该方法与 WET 和 LAG 策略进行了比较，并且与专门为 SimulST 设计的最新架构进行了比较。</sample>
    <sample id="144">作者所属机构是Université de Montréal。</sample>
    <sample id="145">演讲者的名字是Jenny。</sample>
    <sample id="146">Zhou Yichen, a PhD student from Fudan University, presented a talk on their paper analyzing omission in dialogue summarization. Dialogue summarization, a subtask of text summarization, involves creating concise summaries of dialogues. Despite recent progress with large-scale pre-trained language models, these summaries often contain errors, such as omission, which affects their real-world applicability. The presentation highlighted the prevalence of omission, with about 70% of summaries from various domains and models showing omission issues. The talk also introduced a dataset for omission detection, which is crucial for improving summary quality. The dataset, based on five existing benchmarks, includes ten candidate summaries for each dialogue, and the performance of the models was evaluated using the F1 score. The results showed a label imbalance, indicating the need for more advanced models. The talk concluded with a post-editing method for summary refinement, which significantly improved performance when omissions were provided.</sample>
    <sample id="147">这篇论文有三位作者：Myra、Eszter Moshkovitz和Dan Jurafsky。</sample>
    <sample id="148">Simultaneous speech translation是将口语转换为另一种语言的实时过程，允许跨语言交流。当前的simulST模型存在诸多问题，包括使用不同的优化目标训练的特定架构、复杂的训练过程以及需要多个模型以达到不同的延迟。我们的解决方案是使用现有的simulST模型而不进行重新训练或为simulST专门设计特定架构。我们使用单个模型来处理每个延迟，并通过cross-attention机制处理延迟。我们提出了一个叫做EDAT的策略，它决定是否发出部分翻译。我们在论文中详细介绍了EDAT的工作原理和结果。</sample>
    <sample id="149">是的，数据集是公开的。</sample>
    <sample id="150">Archie, from UNC Chapel Hill, presents an ACL paper on MeetingQA, a dataset focusing on question-answering in meeting transcripts. This dataset, derived from the AMI corpus, includes 7,700 questions with diverse answer scenarios. The paper discusses data collection, model performance, and challenges, highlighting the gap between model and human performance, especially in short-context and zero-shot settings.</sample>
    <sample id="151">大家好，我是Ying和我的同事JiYong。我们将介绍我们的研究，Multi-TeachImprovingMulti-ModelZero-shot Learning via Instruction Tuning。随着大型语言模型的进步，许多研究开始探索重新利用预训练语言模型以高效地执行不同下游任务。最近的研究表明，指令调优使大型语言模型能够以自然指令的方式执行无监督任务。然而，之前的工作主要关注的是改善大型语言模型在语言单任务上的性能，而计算机视觉和多模任务却被忽略了。因此,在我们的研究中,我们想研究多模指令调优是否真的能改善大型语言模型在多模任务上的泛化能力。此外,在我们的研究期间,我们发现了大量的指令数据集之间的差距。存在超过一千六百个语言单任务,但没有大型可用的多模指令任务。因此,这促使我们构建一个多模指令调优数据集。我们介绍了Multi-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti-Teachmulti</sample>
    <sample id="152">Frederic Riemenschneider discusses the integration of NLP with classical philology, focusing on language models for ancient Greek and Latin. He introduces Greberta and GRETTER, monolingual models for ancient Greek, and Filberta and Filter, multilingual models for multiple languages. The presentation highlights the development of a new pre-training corpus from the Internet Archive, benchmarking against existing models, and the exploration of multilinguality in language models.</sample>
    <sample id="153">Nina Rehmayrabi, a scientist at Amazon Alexa, discusses resolving ambiguities in text-to-image models. Ambiguities in prompts can lead to inaccurate image generation. Her team developed a framework to disambiguate prompts using clarifying questions or visual setups, and an evaluation system to assess image faithfulness. Their research shows that disambiguation improves image generation, and their framework aligns with human evaluations.</sample>
    <sample id="154">这篇论文的作者所属机构是大学ofTrento和Fondazione Bruno Kessler。</sample>
    <sample id="155">演讲者的名字是Javad Hosseini。</sample>
    <sample id="157">Sheng Gao from Sun Yat-sen University presents a work on dialogue summarization using a static dynamic structure fusion graph. The project, a collaboration with several colleagues, aims to distill silent information from dialogues into concise summaries. Traditional methods rely on precomputed static graphs, which have limitations in accuracy and adaptability. The proposed model includes four components: utterance encoding, static graph construction, dynamic graph modeling, and a pre-trained language model for summary generation. It uses discourse parsing, speaker interaction metrics, and a dynamic graph model to capture semantic relationships. The model integrates static and dynamic graphs using a fusion method and employs a dual cross-attention mechanism to incorporate graph representation. The project is available on GitHub.</sample>
    <sample id="158">Xiangkunhu from AWS介绍了Dual Cache技术，该技术针对长文档中实体的分布问题。传统方法使用LRU策略，导致高缓存误差。Dual Cache结合了本地和全球缓存，使用LRU和LFU策略，减少了误差。Benchmarks表明，Dual Cache在训练数据存在的情况下优于单个缓存，尽管在无训练数据的情况下，单个缓存表现更好。Dual Cache在性能与成本之间取得了最佳平衡。</sample>
    <sample id="159">KostVfSena在介绍他的ACL2023论文《语言模型接受度判断并不总是对上下文鲁棒》中欢迎大家。该论文是与JohnGothier、AaronMuller、KanishkaMishra、KarenFuentis、RogerLevy和AtinaWilliams共同完成的。该工作重新审视了最小对等时间。最小对等时间基本上评估语言模型的接受度判断。比如说,你会给一个可接受的句子和一个不可接受的句子。希望模型基本上会给出更高概率的可接受句子。当前的MP.pipeline基本上不允许我们评估模型的接受度对更长的句子。如今,大型语言模型越来越长的上下文窗口。因此,评估模型的接受度至关重要。我们试图通过让模型评估更长的序列来实现这一点。我们的方法是模拟更长的序列。我们重新审视数据集本身。然后我们重新创建句子。我们从这些数据集中选择可接受或不可接受的句子。比如说,我们从ADJUNK岛案例中选择一个典型的对。我们通过添加前缀来创建更长的可接受和不可接受的序列。我们可以从不同的数据集或不同的数据集中选择不可接受的句子。我们可以从与当前句子相关的不同数据集或不同数据集中选择句子。最后,我们选择来自维基百科的句子。这样可以告诉我们模型的接受度判断是否真的受到任何上下文的影响。比如说,当我们选择来自不同数据集或完全不相关的句子时。我们首先查看维基百科句子。MP判断基本上对任何上下文长度都很鲁棒。我们将上下文长度增加到1024,以最大化OPT和GPT2模型。我们在橙色的点线中看到MP判断相对稳定。现在,当我们选择来自同一数据集的可接受和不可接受的句子时。我们看到MP判断在添加可接受前缀或不可接受前缀时显著增加或减少。我们从同一数据集的不同数据集中选择句子。我们可以从不同的数据集或完全不相关的句子中选择句子。</sample>
    <sample id="160">该方法的第一步将输入词元映射到一个无序的多重集合的词元。</sample>
    <sample id="161">Coscript 包含了 55,000 个脚本。</sample>
    <sample id="163">根据提供的内容，DEplain 的最佳对齐方法是 mass_align。</sample>
    <sample id="164">弱监督学习的好处在于不需要手动标记数据，而是使用简单的规则或低质量的标记来源进行标记，这大大降低了成本。然而，这种标记的噪音可能会导致模型无法有效泛化。</sample>
    <sample id="165">Wenting Zhao介绍了他的论文《Adaptive Common Sense Reasoning: Exploiting Mutually Exclusive Explanations》，旨在通过利用互斥的解释来提高推理能力。传统方法依赖于监督学习，但需要对解释的可行性进行标注，这可能会导致人们在60%的情境中产生分歧。Zhao提出了一个名为LIpor的无监督学习方法，该方法通过后验后优化来解决这个问题。LIpor通过将解释视为可变变量来实现这一点，并通过一个名为omega的正则化器来确保解释的互斥性。通过这种方法，LIpor在ALFALINLI数据集上比其他模型，包括0-shot GPT-3，表现出更高的准确性。</sample>
    <sample id="166">Yuxin from Harbin University of Technology presented a new method for image retrieval from linguistically complex texts, addressing the limitations of existing visual language models. The method employs a divide and conquer strategy, inspired by dual-process theory, to break down complex reasoning into simpler tasks. It integrates a visual linguistic system and a logical reasoning system, with the former focusing on analogical reasoning and the latter on abstract logical reasoning. The proposed method, named Neural Symbolic Reasoning, uses a proposition generator, decoder, and a neural symbolic reasoner to achieve better performance. Experiments show that the method outperforms existing baselines, suggesting its potential for improving complex reasoning tasks.</sample>
    <sample id="167">DEplain-web 中的文档采用了手动对齐和自动对齐方法。具体分配情况是，750个文档使用了手动对齐，而其余的文档使用了自动对齐。</sample>
    <sample id="168">CoNLL++ 数据集是通过从 Reuters News 2020 收集数据，并使用相同的 CoNLL 2003 标注指南进行标注而创建的。</sample>
    <sample id="169">Aydin Bilal介绍了一篇关于使用Large Language Model (LLM) 进行翻译的研究。该研究评估了PROMPTing技术在翻译中的影响，使用Google Translate作为参考。研究表明，翻译质量取决于示例的质量和来源。使用DevData（高质量数据）比使用训练数据更好。尽管PROMM的流利性与先进系统相当，但其准确性较差，常出现遗漏错误。研究提供了选择多种示例的策略建议，以提高翻译质量。</sample>
    <sample id="170">你好，大家。我是来自宾州大学的YuxinZhang。今天我要介绍我们如何在多种自然语言和多种表示中进行语义解析。语义解析是构建用户查询的语义表示的任务，例如SQL和lambda计算。多语言语义解析是将多种自然语言中的查询转换为多种表示的任务。我们提出的示例模型为多种自然语言和多种表示提供了一个统一的示例集。它包含90个数据集，五个语义解析任务，8个表示和22种语言。为了更好地评估我们的基准，我们考虑了六种训练和评估设置。第一个是翻译测试。我们使用谷歌翻译API将源语言翻译为目标语言，然后使用单语言模型进行训练和评估。例如，我们在英语模型上训练英语查询，在推理时使用API将德语查询翻译成英语，然后使用训练的模型预测SQL。我们还测试单语言模型。这个设置，源语言和目标语言相同。例如，德语到德语或英语到英语。我们还测试单语言模型的少量训练数据。我们测试多语言模型。我们训练一个多语言模型用于所有语言。例如，我们将德语、英语和中文的查询放在一起训练一个多语言模型，并在推理时使用该模型来翻译德语或中文查询。我们还考虑了零转移和少量转移的跨语言转移。我们在英语查询或德语和英语的少量查询上进行训练。我们预测SQL输出。我们还发现了许多有趣的结果。关于分析单语言模型，我们评估了两个组模型，包括基于指针的多语言编码器和BERT加编码器。我们还评估了多语言编码器和编码器的模型。我们发现，编码器-解码器在所有9个数据集上都取得了最佳表现。我们在MT5和EXAMPLER的多语言设置上评估了编码器-解码器。我们发现，编码器-解码器或编码器-预训练器可以通过在各种语言中进行训练来改进。我们发现，除英语外，大多数主要自然语言都可以获得性能提升。我们还发现，英语的性能在7个数据集中下降，只有3个数据集中上升。我们还比较了跨语言的性能差距。在这张图中，蓝色线是零转移的跨语言转移，橙色线是零转移的跨语言转移。我们发现，零转移设置的跨语言转移性能差距很大。通过比较蓝色和橙色线，我们发现，少量转移设置的转移差距很快缩短。我们还发现，编码器-解码器或编码器-预训练器可以通过在各种语言中进行训练来改进。我们总结了EXAMPLER，一个统一的多语言语义解析基准。我们对三种代表的多语言语言模型进行了全面的基准测试。我们的结果显示了许多有趣的发现。</sample>
    <sample id="171">现有研究主要分为四类：一是不适用于嵌入服务的保护方法；二是缺乏转移性的方法；三是不适用于嵌入服务的保护方法；四是转移性的方法不足。</sample>
    <sample id="172">Codex 或 Bloom 等多语言 LLM 在 CLSP 任务上仍然不够，因为它们在跨语言性能上仍然存在显著差距。</sample>
    <sample id="174">Priya, one of the co-authors of the paper 'Arg Analysis 35K: A Large Scale Dataset for Argument Quality Analysis', explains the uniqueness of their dataset. Unlike other datasets, which often lack quality, diversity, and depth, Arg Analysis 35K boasts high-quality arguments sourced from expert debaters and tournaments. The dataset includes a diverse range of arguments, covers various themes, and introduces a new concept of 'analysis' that combines claims and premises. It also features an instance-based annotator reliability model, which better captures the reliability of annotations by considering individual biases. Additionally, the dataset includes a relevance model that assigns scores to arguments based on their relevance to specific themes. Priya encourages readers to check out the paper for more details.</sample>
    <sample id="175">该方法通过使用一个灵活的、无硬约束的预测模型来处理排列的不确定性。它通过从输入中预测输出的各个位置的相应多重集来实现，并使用一个GPU友好的连续放松来近似解决NP难题。</sample>
    <sample id="176">公平性是指 NLP 模型在处理不同类别（如不同种族或政治观点）时的性能是否均衡。公平性问题表现在模型偏向某些群体或观点，导致其他群体或观点被忽视或误判为不公平。</sample>
    <sample id="177">演讲者的名字是Yanis Slavrak。</sample>
    <sample id="178">演讲者的名字是KostV Sinha。</sample>
    <sample id="179">Mélanie Szklár介绍了一个名为Symbolic TOM的插件，用于增强大型语言模型的理论思维能力。理论思维是理解他人心态的能力，通常通过阅读任务来测试。她介绍了经典的Sally-Anne测试，探讨了第一和第二阶问题。她介绍了Symbolic TOM，该方法使用图形表示来表示不同角色的信念，并通过推理算法计算这些图形。她的研究表明，Symbolic TOM在Tommy数据集和其他数据集上显著提高了大型语言模型的性能，尤其是在故事结构和语言多样性方面。</sample>
    <sample id="180">演讲者的名字是Myra。</sample>
    <sample id="181">Yuan, a student from Fudan University, presents a study on constrained language planning, which involves planning with specific constraints. The research evaluates large language models' ability to plan for specific goals, like making a chocolate cake, and finds that they often fail to meet constraints. To address this, a method called over-generated then-filter is introduced, which improves the quality of generated scripts. The study also creates a dataset called CoScript, which is used to train smaller models for better performance. The research aims to provide a valuable resource for further language planning studies.</sample>
    <sample id="182">在本文的背景下，热带主义指的是对拉丁裔女性的刻板描述，使用词语如 'vibrant' 和 'curious'，这些词语与热带地区的美丽和活力联系在一起，反映了对拉丁裔女性的性别和种族刻板印象。</sample>
    <sample id="183">作者通过使用更具指导性的语言模型生成目标群体的人工描写。通过给定特定的身份标记（如“想象你是一个亚洲女性”），模型生成了描述该群体的个性。这个方法利用了模型对指令的高效响应能力，使其能够生成多样化的个性描述。</sample>
    <sample id="184">本文中使用了CXMI（Contextual X-MI）来衡量语境使用情况。CXMI是一种衡量机器翻译模型在给定语境中提供的关于目标语义的信息的指标。</sample>
    <sample id="185">DrBERT 是一个专门为法语设计的模型，基于 Roberta 模型， trained on medical data from Natus。 ChuBERT 则是一个基于英语的模型， trained on clinical data from clinical notes. DrBERT 的主要区别在于其专门针对法语的设计和训练。</sample>
    <sample id="187">这篇论文有两位作者：Ying和Zhi Yang。</sample>
    <sample id="188">迭代迁移学习是一种在不同领域中应用迁移学习的技术。它通过从一个领域的模型中提取知识并应用到另一个领域来提高新领域的模型性能。</sample>
    <sample id="189">数据集的目标是收集用户在选择音乐、书籍和食谱时使用的直接和间接表达式，以了解用户的语言选择。</sample>
    <sample id="190">攻击者通过学习从提供的 EaaS 中提取模型参数来进行攻击。</sample>
    <sample id="191">这篇论文有三位作者：Sarah Papi, Matteo Negri, 和 Marco Turilli。</sample>
    <sample id="192">Yang Luo介绍了他的研究成果，名为“Can”，旨在通过信心指导的自适应内存优化来实现快速收敛和低内存使用。传统的优化方法如Adam通常需要三倍的内存来存储必要的梯度估计。尽管一些内存高效的优化方法如Adam-ADAM可以减少辅助内存使用，但会牺牲性能。Can提出了一个解决方案，旨在同时实现快速收敛和低内存使用。通过使用非正交矩阵分解，Can减少了内存需求，从而在训练大型语言模型时节省了大量内存。通过对BERT、GPT-2和T5等模型的实验，Can在验证准确性和内存使用方面都表现出色。Can在大型模型训练中提供了更好的性能，并且在内存使用上比Adam和ADAM更有效。</sample>
    <sample id="193">初始数据集由约1000个注释者创建。</sample>
    <sample id="194">作者是卡内基梅隆大学的第一年博士生。</sample>
    <sample id="195">本文介绍了ROHT框架，旨在通过构建Hierarchical Question Decomposition Tree (HQDT)和概率推理来解决复杂问题。HQDT将复杂问题分解为子问题，使用两个阶段的框架：构建HQDT，确定问题的层次结构；并在HQDT上进行概率推理，融合不同知识源的信息。通过对KQAPROHT和MUSIC数据集的评估，展示了ROHT框架在不同数据集上的优势，特别是在结合KB和文本信息时的表现。</sample>
    <sample id="196">以左侧为支配词的示例包括“我看见了巴特和丽莎”。在这种情况下，左侧的主语“我”支配了“巴特和丽莎”的协调结构。</sample>
    <sample id="197">ABCIeval是对话系统中的最先进模型。它提供了一种更精确和可靠的评估方法，能够评估多种错误行为，如自我矛盾和自我矛盾，并比现有方法更能预测对话质量。</sample>
    <sample id="198">在整个上下文窗口中评估模型的可接受性是必要的，因为当前的NPP方法仅评估短语和单个句子，这可能不充分反映大型语言模型的整体理解能力。随着模型的上下文窗口越来越大，评估其在更长语境中的可接受性变得至关重要。</sample>
    <sample id="199">在多语言训练中，英语模型的表现在七个数据集中下降，但在三个数据集中提升。</sample>
    <sample id="200">是的，注释者在回答时提前知道了实体。</sample>
    <sample id="201">评估使用了最新的NMT（Neural Machine Translation）指标和专家级人类评估结果。</sample>
    <sample id="202">泛化中的回归会影响特定的 NER 类型，因为它会导致模型在新数据上的性能下降。</sample>
    <sample id="203">NLP 中的立场很重要，因为它反映了数据集和模型的开发者的背景和观点，这可能导致系统性偏见。例如，NLP 模型可能对特定文化或语言群体的表达方式不敏感，这会影响其性能和公平性。理解和解决这些偏见可以确保 AI 更公平地服务于所有用户群体。</sample>
    <sample id="204">BLOOM 采用的是适配器微调。</sample>
    <sample id="205">Shengbing PhD student from the University of Washington presented research on the influence of political biases in language models, stemming from their training data. The study highlights how media coverage in pre-training data, such as from politically diverse sources, can lead to varied political leanings in models like GPT-4 and BERT. Experiments show that these biases affect model performance in tasks like hate speech and fake news detection, with models often favoring certain groups over others. The research underscores the need for addressing these biases to prevent fairness issues in NLP applications.</sample>
    <sample id="206">他们使用了从两个不同任务中迁移的模型：一个是主题独立的辩论类分类，另一个是扩展和比较类的PDTB。</sample>
    <sample id="207">最近用于评估 PaLM 能力的测试集包括 WMT (WMT 2022) 和 DEV (DevNMT) 集合。</sample>
    <sample id="208">作者提出了三个建议。</sample>
    <sample id="209">提议的方法在基线上获得了 9.4% 的收益。</sample>
    <sample id="210">演讲者的名字是Shu-Hung.</sample>
    <sample id="211">是的，论文中的结果和数据集可以用作基准。论文中提到的结果可以作为自动文本简化的基准，提供了一个衡量自动简化效果的参考标准。</sample>
    <sample id="212">论文中进行了两种较小模型的实验：T5 fine-tuned on CodeScript和BART-large。</sample>
    <sample id="213">研究中使用的基础模型是Unified Multi-Modal Pre-trained Model (OFa)。</sample>
    <sample id="215">Adam Szarkowski在演讲中讨论了不同理论和方法（如Universal Dependencies、IGARVLM、Prague Approach和Word Grammar）对协调结构的不同假设。演讲重点是支持对称结构的论点，基于“依赖长度最小化”原则。演讲通过英语句子示例说明，左侧协调结构中的主语倾向于更短，特别是当左侧没有外部主语时。数据分析支持这一观察，表明左侧协调结构的主语倾向于更短，尤其是当主语与主语之间的词汇长度差异大时。演讲结论是，左侧主语更短的倾向支持对称结构，而不是对称或不对称结构。</sample>
    <sample id="217">The research introduces a method for generating multi-attribute controllable dialogue, addressing the limitations of existing models that focus on single attributes. The proposed method, D-C-G, uses a distangled controllable generation approach to learn attribute concepts from scene values and employs disentangle loss to manage attribute combinations. A unified reference-free evaluation framework, M-A-E, is introduced to evaluate different granularities of attributes without needing large-scale labeled data. The method outperforms existing baselines in controllability and test quality, demonstrating its effectiveness in transforming seen attributes into unseen combinations.</sample>
    <sample id="218">作者所属机构是Google Translate。</sample>
    <sample id="219">Jiahuizhu, a research assistant at Academia Sinica, presented a work on a multi-stage pipeline for uncovering financial signals in financial reports. The project, conducted with Yuxiang Huang and Chen Wei Ling, aims to improve the efficiency of extracting useful information from annual reports, which are often similar in content. The pipeline involves document segmentation, relation classification, and fine-tuning using external datasets. The model classifies word pairs into three types: type beta, revised, and mismatch, and uses soft labeling techniques for fine-tuning. The performance is evaluated using precision and Pcc metrics, with the final model achieving the best results. Future work includes improving the model's effectiveness and exploring other features.</sample>
    <sample id="220">Vasudha 是 Stony Brook University 的 Computer Science 研究生。</sample>
    <sample id="221">论文分析了 Google Translate的PROMT模型。</sample>
    <sample id="222">在开源问答系统中，研究了适应或注释的挑战和干预处理。通过使用维基百科作为训练数据集的源模型，研究了不同数据干预处理方法。研究了不同类型的干预处理方法，包括零短和零长方法。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。研究了不同类型的干预处理方法对模型学习的影响。</sample>
    <sample id="223">演讲者的名字是Shengbing PhD学生。</sample>
    <sample id="224">在实验中研究了Long-IMPART和Normal-Base-IMPART模型。</sample>
    <sample id="225">在 MultiInstruct 中，53 个任务用于训练目的，剩下 9 个用于测试目的。</sample>
    <sample id="226">这篇论文有两位作者。</sample>
    <sample id="227">本文介绍了Pangu框架，该框架旨在解决当前语言模型在语义理解方面的挑战。传统语言模型在语义理解方面存在缺陷，主要是因为它们在预训练阶段缺乏语义理解。Pangu框架通过将语言模型用于评估而非生成，避免了生成过程中的语义理解问题。通过在不同的语言模型上进行实验，Pangu在语义理解方面表现出色，特别是在非IID环境下。本文提出的Pangu框架不仅在理论上具有创新性，而且在实际应用中也具有实用价值。</sample>
    <sample id="228">作者在实验中使用了 AG News, MIND, SSTD2 和 ERESTA 数据集。</sample>
    <sample id="229">Gabriela Skatylinskaya介绍了与Henning Bäck Smud合作的研究，旨在检测论证性写作支持的不可证明性主张。她强调了文本修订的重要性，特别是在论证性写作中，选择合适的词语和表达方式可以直接影响文本对受众的影响。她通过一个主张"手机辐射可能导致脑癌"的例子，展示了修订过程中的变化。她提出了两个任务：确定主张是否需要修订或是否已优化，以及选择修订时应改进的质量问题。她探讨了使用人类修订模式学习的挑战，包括代表性、模型复杂性、上下文相关性和主题/用户偏见。她的研究旨在通过评估不同模型的性能来解决这些挑战，并得出结论，使用修订数据可以有效地完成这些任务。</sample>
    <sample id="231">NACHOS是一个用于医疗领域的开源数据集，包含来自互联网上的医疗文本，用于训练和评估自然语言处理模型。</sample>
    <sample id="232">演讲者的名字是Aydin Bilal。</sample>
    <sample id="233">Sarah Papi from the University of Trento and Fondazione Bruno Kessler, along with Matteo Negri and Marco Durcic, presented a paper on 'Attention as a Guide for Simultaneous Speech Translation.' The paper addresses the challenges of current SimulST models, such as complex training and multiple latency regimes. Their proposed solution, E-DOT, uses existing offline models and a single model for each latency, leveraging cross-attention mechanisms. E-DOT selectively emits translations based on attention focus, improving translation quality and computational efficiency. The results show E-DOT outperforms other strategies, with high translation quality and low latency, and the team has released their code and models for public use.</sample>
    <sample id="234">提示策略对结果有很大影响，特别是对于0和1个shot提示。五个shot提示的形式对结果的影响较小。</sample>
    <sample id="235">Kyowin Yu 是这篇论文的作者。</sample>
    <sample id="236">1. 研究人员如何构建Multi-Instcrt数据集？
2. 他们使用的模型是什么？
3. 他们的主要结果是什么？
4. 他们的研究中使用了哪些技术？
5. 他们计划在未来做哪些工作？</sample>
    <sample id="237">作者建议使用KITMOS，一个诊断测试套，用来测试模型在处理来自不同来源的信息时的能力。KITMOS包括一个核心任务，要求模型在不同知识来源（如预训练参数和实时输入）之间进行知识整合。</sample>
    <sample id="238">Yibowen Hu介绍了一个名为MeetingBank的新基准数据集，旨在解决会议摘要的两个主要挑战：高质量摘要和可靠的资源。通过使用Speechmatics API，Hu将音频转换为文本，并从Boston City Council网站获取会议信息。数据集包含1,166个城市议会会议和近7,000个摘要实例。Hu使用两个指标测量摘要的抽象程度：覆盖度和密度。分析显示，DaVinci 003在GPT-3上表现最佳，尽管人类评估显示GPT-3在流畅性和连贯性方面表现最佳。Hu建议继续专注于捕捉主要讨论点，并开发更符合人类偏好的自动评估指标。Hu的主要贡献是构建的MeetingBank数据集，供研究人员设计高级会议摘要工具，并提供对市议会决策过程的见解。Hu鼓励观众使用此资源并与他进行进一步讨论。</sample>
    <sample id="239">大家好,我叫AydinBilard,今天我将简要介绍一下《从翻译评估评估策略和性能》这篇论文。该论文是与Google翻译的合作者共同完成的。</sample>
    <sample id="240">你好，我是德国萨尔兰大学的博士生。我想在视频中介绍我们最近的工作《比你想象的更弱的批判性看待弱监督学习》。这是与肖宇申、马约斯·穆斯巴赫、盖伊斯·斯蒂芬和迪特利希·克拉科的联合工作。我想先介绍一下弱监督和弱监督学习。</sample>
    <sample id="241">Ethan介绍了他的论文《人类评估早期误导信息：一项COVID-19治疗案例研究》。这项研究是与Yangchen、WeiXiu和Alan Riter合作完成的。许多自动检测误导信息的系统在两个方面都存在缺陷。首先，这些系统通常被过度评估。数据集通常是反向构建的，而不是使用实时数据。其次，这些方法不具备人性化特征。它们不代表真实的规模或噪音，必须涉及人类内容监督者。我们提出了一个评估框架，旨在解决这些缺陷。我们提出的系统是从Twitter上的噪音到人类可操作输出的完整过程。我们系统的两个主要组成部分是：一是处理误导声明的检测。首先，系统使用关键词过滤筛选相关推文。然后，T5模型用于提取治疗声明。然后，使用Fisher's Exact Test对这些治疗进行排名。第二个部分是政策违规检测。系统使用已验证的误导声明列表来检测政策违规。Bert基于分类模型确定作者对未经批准治疗的态度。支持和态度的推文被标记为需要人类审核。我们评估了人类在循环中参与的工作流程。早期检测是关键任务。我们系统在新闻文章发布前发现并注释未批准治疗。我们评估了政策违规检测的有效性。人类在政策违规验证和政策违规验证步骤中分配了工作。我们系统每小时检测124.2个政策违规。我们的框架更真实地捕捉了系统和人类内容监督者之间的复杂互动。我们希望这项工作激励未来的误导信息检测系统。我们提供了一个外部视角来评估误导信息系统的开发和评估。</sample>
    <sample id="242">对话系统的常用评估方法包括使用人类评估，如选择性评估和利卡特评分，以及评估模型的回应是否具有相关性和连贯性。</sample>
    <sample id="243">这篇论文有四位作者。</sample>
    <sample id="244">在 Servin 和 Kea 的示例中，需要背景知识包括 Servin 是一名法官，法官在法庭上决定案件，以及 Kea 是一名面包师。</sample>
    <sample id="245">Linying Zhang介绍了M-Turk高协议工人的研究工作。研究的动机是自动矩阵有问题，M-Turk的最佳实践不被充分理解。研究采用了一个两步的工人筛选流程，旨在减少资源浪费并提高高协议工人的质量。研究结果表明，筛选流程可以有效地减少资源浪费，提供高协议工人的质量与低成本。研究的限制包括只测试英语M-Turk平台，设计问题缺乏精确性，且没有保证高协议工人的质量。</sample>
    <sample id="246">是的，代码是公开的，可以在 GitHub 上获取。</sample>
    <sample id="247">Kyung presents a paper on FactKG, a dataset for fact verification using knowledge graphs. Unlike existing datasets that use text or tables, FactKG uses DBpedia knowledge graphs, allowing for direct connections between evidence and claims. The dataset supports various reasoning types, including one-hop, conjunction, existence, multi-hop, and negation. It includes both written and colloquial claims, and employs methods like the Colloquial Style Transfer Model and presupposition templates. The paper's baselines, which use graph evidence, outperform the majority baseline, achieving 51% accuracy.</sample>
    <sample id="248">NLPositionality 的注释者在各个人口统计学特征（如国家/地区、性别等）方面并不均衡。研究发现，数据集和模型在英语国家和具有高等教育背景的人中更具代表性，但对非二进制人群和其他特定群体的代表性较低。</sample>
    <sample id="249">在可接受的域中扰乱句子的方法是通过在句子中添加噪音来保持其结构的相关性。通过这种方法，研究人员试图观察到模型的评估趋势是否会发生变化。</sample>
    <sample id="250">进行维度评估意味着通过ABC-Eval将对话行为细分为可量化的特定方面，如自我矛盾和自我矛盾，从而提供更精确和可靠的对话质量评估。</sample>
    <sample id="251">Jingwei Yi belongs to the University of Science and Technology of China.</sample>
    <sample id="252">在这次演讲中，Sayakiran Thanikella介绍了他的硕士论文《You Create：无监督案例提取使用事件提取》。这项研究旨在通过事件提取技术改善法律领域的案例提取。研究提出了两个主要贡献：ILPCORESET和UCreate.pipeline。ILPCORESET是一个新的印度法律案例集，用于评估案例提取算法的性能。UCreate.pipeline利用了事件提取技术，展示了高效率、低延迟和跨法律体系的泛化能力。研究还比较了不同的模型，包括基于事件的模型，发现其在法案提取任务上表现优异。</sample>
    <sample id="253">Mario Aragon介绍了名为DisOrber的双域适应模型，该模型用于在社交媒体上检测心理障碍的迹象。该模型利用双域适应技术，结合了来自Reddit和心理健康领域的知识，以改进模型性能。通过使用BERT语言模型的知识，模型在特定领域中进行调整。研究结果显示，DisOrber模型在识别心理障碍方面表现优于BERT模型。未来工作将探索不同词典资源和使用临床数据。</sample>
    <sample id="254">Sun Qi from Nanjing University of Science and Technology presents a research on uncertainty-guided level denoising for document-level relation extraction. The work aims to improve the quality of noisy labels in distant supervision data, which is often used to pre-train document-level relation extraction models. The proposed framework introduces uncertainty estimation to filter out false positive pseudo labels, using instance-level uncertainty scores to address overlapping relations. A dynamic class uncertainty threshold is used to filter out high-uncertainty pseudo labels, and a multi-phase training strategy is employed to iteratively relabel the data. The framework outperforms previous baselines on two public datasets, improving performance significantly.</sample>
    <sample id="255">提示的形式在0和1个shot prompting中很重要，但对于5个shot prompting，形式对性能的影响较小。</sample>
    <sample id="257">作者评估了四个最新的对话模型。</sample>
    <sample id="258">Zhangsun Han介绍了使用大型语言模型进行自然语言处理质量评估的研究。他们提出了使用大型语言模型评估文本质量的想法，类似于人类评估。大型语言模型能够理解自然语言任务指令，因此可以执行大型语言模型评估。为了证明大型语言模型评估的有效性，他们进行了实验，使用大型语言模型评估GPT-2和人类写的故事。评估基于语法、连贯性、可读性和相关性。结果显示，英语教师偏爱人类写的故事，但一些大型语言模型也能显示出类似的偏好。研究表明，某些大型语言模型可以作为人类评估的替代方案。</sample>
    <sample id="259">Yusen Zhang介绍了Exemplar，一个用于多语言多表示的示例语义解析模型。Exemplar提供了一个统一的语义解析数据集，包含90个数据集、5个语义解析任务、8个表示和22种语言。研究评估了六种训练和评估设置，包括翻译测试、单语言、少量数据训练和多语言模型。研究发现，语义解析模型在多语言任务上表现优异，特别是使用Enc-Decoder模型。研究还发现，英语训练可以显著提升其他语言的性能。</sample>
    <sample id="260">这篇论文有四位作者。</sample>
    <sample id="261">理想规划器应具有高质量的生成能力，既能确保语义完整性又能严格遵循特定的约束。</sample>
    <sample id="262">这篇论文有五位作者。</sample>
    <sample id="263">在这次演讲中，演讲者介绍了他们的研究《Mitigating Label Biases for In-Context Learning》，旨在解决在文本分类任务中，语言模型在不同类型的标签偏见中表现不稳定的问题。演讲者首先介绍了三种类型的标签偏见：范例偏见、上下文偏见和新发现的领域标签偏见。通过实验演示了领域标签偏见如何影响模型的预测，并提出了一个名为领域内容校正的新方法。该方法使用随机域词作为内容自由文本来校正模型的预测，并通过实验证明其在不同数据集和模型上显著提高了性能。演讲者强调了领域内容校正方法的优势，特别是通过使用随机域词而不是单个内容自由词来更好地考虑领域标签偏见。</sample>
    <sample id="264">Ling Wang, a graduate student from Zhejiang University, presented a paper on "Towards Transferable Audio Visual Text Generation." The paper addresses the challenges in multimodal text generation, particularly in audio visual text generation, which is more complex and expensive than other tasks like machine translation. Wang proposes a novel task called "transferable audio visual text generation" to overcome these challenges. The framework includes an audio visual meta map network, an audio visual encoder and language model generator, and a context factor. The paper also discusses the meta learning framework, meta pre-training, and meta meta learning. The results show that the proposed method outperforms other models in various settings.</sample>
    <sample id="265">演讲者的名字是Vasudha。</sample>
    <sample id="266">Adam Szarkóczyk 是布达尼亚大学的教授。</sample>
    <sample id="268">PaLM 最常见的错误是缺失部分的错误，这可能导致更好的听起来的翻译，但会丢失原文中的部分内容。</sample>
    <sample id="269">James和Sarah Finch介绍了ABCEval, 一种新的对话AI进行评估的方法。该方法由EmoryNLPLab和亚马逊AlexaAI合作开发。它旨在通过标记模型响应中的特定行为来减少人类评估的主观性。ABCEval能够评估模型在多种方面的行为错误率，如忽略对方、说出无关信息、与对方或自己相矛盾、传播错误信息、违反常识知识或缺乏同理心。通过对100个对话进行评估，ABCEval比现有方法更具可靠性和预测性。</sample>
    <sample id="270">作者所属机构是Emory University。</sample>
    <sample id="271">CFT 在本文中代表 Continuous Fine Tuning。</sample>
    <sample id="272">这篇论文有六位作者。</sample>
    <sample id="273">你好，我是Kyowin，我将介绍我们的工作《当翻译需要上下文：数据驱动的多语言探索》。这项工作是与Patrick Koc、Emil Liu、Andre F. D. Martins和Graeme Newbigg合作完成的。许多翻译都依赖于上下文。例如，'mo'在句子中如何翻译？好吧，如果前面的句子是'事情可能开始变得危险，如果部长们发现了,'那么'mo'指的是间谍。但如果前面的句子是'医生，你能帮我吗？'那么'mo'指的是出生标记。因此，翻译的意思也会随上下文而变化。然而，评估模型如何处理这些翻译的情况是相当困难的。首先，因为只有少部分翻译依赖于上下文，这使得像BLEU这样的语料库级别的指标无法捕捉这些翻译。还有人建议针对上下文依赖的翻译进行评估，但这些资源仅支持有限类型的上下文依赖翻译和有限的语言集，因为它们通常依赖于领域知识和人类编辑。在这项工作中，我们试图回答两个问题：首先，翻译何时需要上下文，第二，模型如何处理这些情况。为回答第一个问题，我们首先测量了一个词在翻译中对上下文的依赖程度。我们之前引入了CXMI作为机器翻译模型中上下文使用的度量。CXMI是通过测量上下文C提供给目标Y的源X的信息来完成的。我们将CXMI扩展为点对点的CXMI，可以在句子或单词级别上测量上下文使用。我们可以将CXMI高值的单词视为需要上下文翻译的单词。现在我们分析这些单词的模式。我们对TED演讲的转录进行分析，这些演讲已从英语翻译成14种不同的语言。我们分析了三个不同的级别。首先，我们分析了具有高CXMI的部分语音标记。例如，阿拉伯语中的双重代词需要上下文才能确定它们是否是双重代词。类似地，我们发现某些语言在选择适当的动词形式时也需要上下文。然后，我们分析了在所有不同出现中平均高CXMI的词汇项。这有助于识别像中文中需要上下文才能正确翻译名词的情况。类似地，我们发现上下文支持翻译正确的形式。最后，我们分析了单个标记的高CXMI，这些标记不能真正被单词本身捕捉，但在句子结构中表达出来。现在，我们使用我们的分析结果来设计一个文档级别翻译的基准。对于我们识别的五个语境现象，我们创建了一个标记来自动识别与现象相关的单词。我们还注意到不同语言中这些现象的不同比例。我们使用Mooda标记在我们想要用于评估的双语语料库上应用。然后，我们应用选择的翻译指标来评估上下文依赖的例子。首先，使用语料库级别的指标，像BLEU的模型中，上下文无关模型表现最好。但如果我们使用COMET，上下文依赖的模型表现最好。如果我们使用WordF，则没有上下文的模型和没有上下文的模型的性能相当。再次，使用Mooda基准来评估不同模型的文档级别翻译。我们使用BLEU的基准来评估不同模型的文档级别翻译。我们使用Mooda基准来评估不同模型的文档级别翻译。我们进行数据驱动的分析，跨14种语言对，确定翻译何时需要上下文。然后，我们使用我们的发现结果来构建一个文档级别翻译的基准，这可以帮助我们识别哪些语境现象模型能处理得好或不好，以及哪些翻译系统在文档级别翻译中表现良好。谢谢大家的关注。再见，见你在多伦多。</sample>
    <sample id="274">演讲者的名字是Yusen Zhang。</sample>
    <sample id="276">Ananya and Vignesh介绍了他们的工作，旨在为印度语言的机器翻译提供评估指标。他们研究了五种语言，分别属于两种不同语言家族。通过使用七个翻译模型生成的翻译，收集了七千个样本。通过双语专家的详细评估，收集了各种错误类型的评分。研究发现，IndiComet在多种语言上表现优异，尤其在未见语言上表现出色。</sample>
    <sample id="277">没有名称。</sample>
    <sample id="278">作者描述了‘显性词汇’方法，基于社会语言学中的‘markedness’概念，指出社会中不同群体的标记。该方法首先确定标记和非标记群体，然后使用‘战斗词’方法，使用权重对比，比较不同群体的词汇。通过比较生成的和人类写作的词汇，显性词汇揭示了特定群体的词汇模式，反映了社会偏见和刻板印象。</sample>
    <sample id="279">作者是华盛顿大学的博士生。</sample>
    <sample id="280">Shuo Tao介绍了Multi-EMO框架，该框架旨在解决情感识别（ERC）中的多模信息融合、少见情感类和同义情感类的挑战。Multi-EMO包括四个关键组件：单模特征提取、上下文建模、多模融合和情感分类。Multi-EMO提出了Vis-ExtNet，专注于视觉特征提取，避免了无关的场景信息。Multi-Attend通过多向多头交叉层实现多模信息融合，结合文本、音频和视觉信息。Multi-EMO还引入了样本权重焦点对比损失，提升了对少见情感类的识别能力。Multi-EMO在MELD和iEMOCAP上实现了状态-OF-ART性能，表明其在处理难以同步情感倾向方面的优势。</sample>
    <sample id="281">Kyowin在演讲中介绍了她们的研究《当翻译需要上下文：数据驱动的多语言探索》。这项研究是与Patrick Frenege、Emile Liu、Andre F. D. Martins和Graeme Newbigg合作完成的。翻译中很多时候需要上下文。例如，'mo'在不同句子中的意思不同，需要上下文才能确定其含义。评估翻译模型的能力很难，因为只有少部分翻译依赖上下文，导致Corpus级别指标如BLEU无法捕捉这些翻译。我们试图回答两个问题：翻译何时需要上下文，以及模型如何处理这些情况。我们通过CXMI等指标测量上下文使用情况，并分析高PXMI的单词。我们分析了TED Talks的翻译，发现了不同语言对上下文的需求。我们设计了一个MUDATAGGER标记器，用于标记不同语法现象。我们使用MUDATAGGER标记器评估不同模型的翻译能力。结果表明，使用上下文的模型在某些语法现象上比没有上下文的模型更准确，但在其他现象上仍有改进空间。我们还比较了不同商业系统，发现DeepL通常比Google Translate更准确。总之，我们通过数据驱动的分析确定了翻译需要上下文的情况，并为文档级翻译提供了一个评估工具。</sample>
    <sample id="282">Xiaoxiao Zhu介绍了她们的研究，重点介绍了StyleTrans，一个旨在在故事层面上进行非平行文本风格转移的模型。该模型通过学习源文本的语义和风格特征，并结合风格特征的嵌入来生成目标风格的文本。她们提出了一个新的训练目标，减少风格特征的影响，并通过分两阶段的训练来实现这一点。第一阶段使用自重构训练框架，第二阶段专注于风格特征的填补。通过测试数据集，StyleTrans在风格控制和内容丰富性方面表现出色。</sample>
    <sample id="283">提到的对称依存关系结构的名称是“城市名称的结构”。</sample>
    <sample id="284">Peng Tianxuan from Wuhan University presented FSUIE at ACL Main Conference 4915, introducing a novel fuzzy span mechanism for enhancing universal information extraction. The current span-based UIE model relies on precise span boundaries, which can be ambiguous. FSUIE proposes a fuzzy span boundary, representing the target boundary as a continuous probability distribution. The model uses a sampling function to convert this distribution into discrete values for calculating fuzzy span loss. FSUIE introduces a fuzzy span attention mechanism, represented by a mask function, to dynamically adjust the attention span. The model's structure is presented, with the fuzzy span attention layer added at the top. Experiments on named entity recognition, relationship extraction, and aspect sentiment triplet extraction were conducted, showing significant performance improvements. FSUIE achieves better results on small-scale data and demonstrates strong generalization capabilities. The results of the oblation study show that FSUIE improves convergence speed and information extraction capability. The attention distribution visualization confirms the model's focus on semantic information within a limited range.</sample>
    <sample id="285">Mingqi Gao介绍了他们的工作《参考材料：对对话摘要的因果纠正的基准评估框架》。他们的工作旨在解决对话摘要中因果错误的问题。两种主要解决方案是引入因果相关目标以使模型生成更准确的摘要，或设计独立于摘要模型的因果纠正模型。因果纠正模型（FEC）通过输入源文档和模型生成摘要，输出纠正后的摘要。由于对话摘要中因果错误的重要性，Mingqi和团队希望跟踪因果错误纠正。尽管他们认为FEC模型的评估存在缺陷，可能导致FEC偏离其原始目的。Mingqi提出了两种因果错误类型：内容和形式。内容因果错误根据语法部分和依赖关系进行分类，而形式因果错误根据添加、删除和替换操作进行分类。Mingqi建议使用手动标注的参考纠正来解决因果错误。因果纠正的基本要求是通过尽可能多的替换、插入和删除操作纠正原始摘要中的因果错误。手动标注提供了比伪数据更有价值的数据，并为FEC模型的更全面和准确评估创造了条件。Mingqi提出了一个新的因果错误分类法。</sample>
    <sample id="286">演讲者的名字是James Finch和Sarah Finch。</sample>
    <sample id="287">这篇论文有四位作者。</sample>
    <sample id="288">用于测试句法现象的数据集包括Blimp、Syntactium和Wikipedia。</sample>
    <sample id="290">1. WSD - Weak Supervision for Data
2. WSD - Weak Supervision for Data
3. WSD - Weak Supervision for Data
4. WSD - Weak Supervision for Data
5. WSD - Weak Supervision for Data</sample>
    <sample id="291">该模型在11个不同的Biomedical和Clinical Downstream Tasks上进行了评估。</sample>
    <sample id="294">CamemBERT 最初是基于 web 上的医学文档数据 trained 的。</sample>
    <sample id="295">演讲者的名字是Adam Szpekowski。</sample>
    <sample id="296">Valerio Basile介绍了他与亚马逊Alexa合作开发的自然语言理解研究成果。研究重点是讽刺，研究了不同语言和文化背景下的讽刺识别。研究使用了EPIC数据集，收集了来自社交媒体的对话，并通过Prolific平台进行人类标注。研究发现，模型的不同版本在预测上没有显著差异，但具有不同的自信度。研究还发现，年龄和地理位置等因素对讽刺的标注有显著影响。</sample>
    <sample id="297">这段话讨论了研究人员在《从狗叫到牛叫：揭示隐藏的语言模式》项目中对狗叫的研究。狗叫是指在公共场合使用的隐喻，通常用于传达负面信息，同时避免直接暴露内容。研究人员开发了一个包含超过340个狗叫的术语和符号的类型和格洛丽丝，涵盖了各种社会群体，如种族和性别。通过分析历史美国政治演讲，研究人员发现狗叫频率与政治策略相关，特别是与共和党南方策略联系在一起。研究还评估了GPT-3等语言模型在识别狗叫方面的能力，发现其效果因类型和提示策略而异。最后，研究者通过使用Perspective API和Hate Check等工具，展示了狗叫如何使内容监管系统难以检测。</sample>
    <sample id="298">通过实验，发现随着时间间隔的增加，模型性能下降，这导致了时间漂移是性能下降的主要原因的结论。</sample>
    <sample id="299">Mihalsgaragas和Lahos提出了一种新的方法来增强NLP模型的泛化能力，减少对数据中短暂的先前模式的依赖。通过Minimax训练，他们设计了一个系统，使学习者专注于难以学习的例子，从而在测试时提高性能。该方法不依赖于特定的辅助模型，而是利用学习者自身的动态来生成例子权重。通过对MMLU、SQuAD和CoQA等数据集的测试，他们的方法在保持高准确性和泛化能力的同时，显著提高了模型在测试数据上的表现。</sample>
    <sample id="300">Belinda介绍了Interactive Dictation任务，该任务允许用户通过语音同时进行听写和编辑文档。她描述了一个示例，展示了用户如何通过语音命令进行文本编辑。她介绍了该任务的四个步骤：音频转换、语音分割、语音命令提取和执行。她还介绍了数据收集和系统的构建，并讨论了使用T5和GPT-3模型进行模型训练的结果。她强调了GPT-3模型在准确性上的优势，但也提到了其效率上的不足，并呼吁更多的研究。</sample>
    <sample id="302">对输出序列中的词元进行排列是必要的，以确保它们按照正确的顺序排列。</sample>
    <sample id="303">作者建议模型所有者提高偏见缓解方法的透明度，以便更好地理解正面刻板和过度价值对齐是否导致了这些刻板的出现。透明度有助于研究人员更好地理解和解决这些问题。</sample>
    <sample id="304">最小对不可接受输入是一个语言模型评估过程中的概念，通常涉及展示一个可接受的句子和一个不可接受的句子。模型的目标是预测更多概率给可接受的句子。</sample>
    <sample id="305">Dawie, a PhD student at Saarland University, presents a video on their work, "Weaker than you think: A critical look at weakly supervised learning." The video discusses weakly supervised learning (WSL), where data is labeled using weak sources like heuristic rules, and the challenges of training neural networks on noisy data. The video questions the necessity of clean validation data for WSL, the number of clean samples needed, and whether clean samples should only be used for validation. The findings suggest that recent WSL methods require clean validation data, and performance gains are overestimated. Recommendations include reporting model selection criteria, comparing WSL with full supervision, and considering continuous fine-tuning. The code is open-sourced for further exploration.</sample>
    <sample id="306">Sebastian Schuster and Na Jeong Kim investigate entity tracking in language models, focusing on whether large models can track entities' states in discourse. They design a task to evaluate entity tracking, avoiding shortcuts like memorization or heuristic learning. Their experiments with models like GPT-3 and GPT-3.5 show that pre-training on code enables non-trivial entity tracking, while smaller models require fine-tuning. The paper details these findings and suggests further research.</sample>
    <sample id="307">作者使用了名义和隐性任务的评估指标来评估模型性能。</sample>
    <sample id="308">Jenny, a Carnegie Mellon PhD student, presented her research on the positionality of datasets and models, highlighting how design biases can affect technology's performance across different demographics. She explained the concept of positionality, which reflects the perspectives of researchers based on their backgrounds, and its impact on research outcomes. Jenny's work, conducted with colleagues from the University of Washington and Allen Institute for AI, used Lab in the Wild to gather diverse annotations and compared them with models like GPT-4 and DynaHate. The study found that datasets and models often align with English-speaking countries and individuals with higher education, but may not represent non-binary people. To address these biases, Jenny recommended documenting design choices, conducting research with a perspective lens, and building specialized datasets and models for specific communities.</sample>
    <sample id="309">一致性通过对100个双标记对的对比来衡量。</sample>
    <sample id="310">在不可接受和可接受查询中，选择来自Wikipedia的句子来添加完全无关的句子。</sample>
    <sample id="311">作者所属机构是柏林工业大学。</sample>
    <sample id="312">MultiInstruct 是第一个大型多模特定任务数据集，包含 62 个任务，涵盖 10 个类别。它是基于 21 个开源数据集构建的，并为每个任务提供 5 个专家编写的指令。</sample>
    <sample id="313">这篇论文有两位作者：James Finch和Sarah Finch。</sample>
    <sample id="314">二进制协调是指在一个句子中，两个或多个动词的主语由一个共同的主语连接起来的结构。</sample>
    <sample id="315">提示语的平均长度为6.5个单词。</sample>
    <sample id="316">这些发现表明较小的 T5 模型可以通过使用 CO Script 数据集进行适当的训练，生成高质量的计划，甚至可能比大型语言模型更好地支持大型语言模型。</sample>
    <sample id="317">Peng Li from Fudan University presents CodeIE, a project transforming information extraction into code generation using large language models like CodeGen. This approach aligns input and output structures, improving performance over traditional models like GPT-3. The study shows that code prompts outperform test prompts, especially in recall, and highlights the potential of this method for future research.</sample>
    <sample id="318">YanisLavrač将介绍他们在法国医疗和临床领域的工作。首先讨论医疗领域的语言建模。然后介绍他们的主要贡献。我们介绍了第一个法语的生物医学模型，基于Roberta并训练在NatusOS上。我们还比较了多种预训练设置和数据源。我们还介绍了11个生物医学和临床任务的结果。最后，我们总结了实验并提供了更多关于如何访问模型的信息。自2018年发布以来，Bert已成为处理自然语言任务的最有效方法之一。</sample>
    <sample id="319">论文比较了从零开始训练和使用现有预训练模型的两种学习策略。结果表明，从零开始训练的模型在大多数任务上表现更好，但使用现有预训练模型的策略也能提供可比的性能。</sample>
    <sample id="320">由于测试重复使用而导致的过拟合因素很小。</sample>
    <sample id="321">简化质量通过对不同类型的简化（如重新排列、词汇替换、结构简化）进行分析来评估。D-Plane的分析显示了不同文本类型（如圣经、新闻和语言学习文本）在简化水平上的差异。</sample>
    <sample id="322">Enrico, a researcher, will present at ACL23 on how text classifiers understand morality. Morality, the internal compass for right and wrong, is crucial for language models. He explains that morality is subjective, with different people labeling the same concept differently. The Moral Foundation Theory, which posits five moral foundations, is used to understand morality in text. Recent studies show that language models can somewhat understand morality, but Enrico's paper aims to explore what they learn. Using the MORAL FOUNDATION Twitter Corpus, the study examines how morality is expressed differently across domains, such as ALM and BLM, and whether language models can recognize these differences.</sample>
    <sample id="323">Yujie Wang from Shanshan University, China, presents a paper titled "Dynamic Hierarchical Graph Learning with Language Models and Knowledge Reasoning for CommonsenseQA." The paper addresses the challenge of commonsense question answering, which requires methods to answer questions based on common knowledge. Wang's approach involves combining language models and knowledge bases to improve commonsenseQA performance. The method involves building a hierarchical graph (HKG) and using two state-prediction strategies and knowledge reasoning (KRL) to optimize the structure and knowledge representation of HKG. The language model is used to encode and fuse the HKG, and attention mechanisms are applied to model subgraphs inspired by R-GAT. The paper reports results on commonsense and open-book QA tasks, showing that the method outperforms other LM and HKG methods.</sample>
    <sample id="324">是的，语言模型确实具有不同的政治偏见。通过使用政治问卷进行自动评估，我们发现语言模型在政治地平线上的四个极端中占据不同位置。GPT-4被发现是最自由的语言模型，而GPT系列通常比BERT系列和其变体更具社会自由主义。</sample>
    <sample id="325">Matthias Lindemann介绍了他的论文《使用多重标签和隐式排列进行无树的组合生成》。这是一项与他的导师Alexander Koller和Ivan Tiedtov共同完成的工作。组合生成可以理解为学习者处理训练期间单独看到的短语的深层递归和组合的能力。在语义解析的上下文中，测试集的结构上看起来像这样。通常我们有一个训练集的语句。这个例子是女孩睡觉了，玛丽知道女孩睡觉了。这些语句与逻辑形式配对，表示其核心意义。在与标准机器学习评估的不同之处，测试集不来自相同的分布，但包含结构上未见的逻辑形式。在这种情况下，模型在训练期间看到了浅层递归并在测试中对更深层递归进行测试。简单的序列到序列模型很难处理这种出乎分布的泛化。通常会产生与输入脱离的输出。特别是，它们很难重现输入和输出之间的系统对应关系，例如在示例中所示的颜色编码。为了解决这个问题，通常会将树集成到模型中。树的目的是捕捉与语句和逻辑形式的组合过程。这样做效果很好，但通常不提供树，而需要以某种方式获得它们。通常这可能是一个复杂且有时计算上昂贵的过程。通常需要考虑形式特定的预处理逻辑形式。例如处理变量符号。获得树也可能涉及专门的语法引导程序。本文中我们不使用树，而是介绍了一个神经对序列模型直接对输入和输出的对应关系进行建模。我们首次展示了强的深层递归泛化而不依赖于树。我们的方法预测输出分两个步骤。首先，我们为每个输入词标记一个无序的多重集合的词。之后，我们使用另一个模型预测一个排列将它们放在正确的位置。我们介绍了一个新的方法来预测排列。它不对可能的排列施加任何硬约束。这使我们的方法非常灵活和富有表现力。概念上，我们的排列模型大致像这样。我们从左到右遍历输出并确定每个位置的多重集合中的哪个词。对于第一个输出位置，我们简单地选择一个，如图中红色突出显示的那样。然后我们跳到下一个多重集合来确定输出的第二个词。我们通过跳到另一个多重集合来确定输出的第三个词。我们继续这种过程，直到第一个阶段的每个词都被访问过一次。</sample>
    <sample id="326">认知失调是指两个相互矛盾的信念或行为。例如，一个人可能会说自己知道吸烟会危害健康，但仍然吸烟，这种行为和信念之间存在矛盾。</sample>
    <sample id="327">Xiaoxu, a third-year PhD student from Harbin Institute of Technology, presents their work on Vision Language Learning at ACL 2023. The goal is to train AI systems to understand both images and text. The work introduces the ManageTower model, which improves upon the BridgeTower by using managers in each cross-modal layer to aggregate insights from pre-trained unimodal experts. This model outperforms others, especially on the VQVC2 test set, by effectively exploiting different levels of unimodal semantic knowledge.</sample>
    <sample id="328">GPT-4是最自由派的语言模型。</sample>
    <sample id="329">Zheng Minhang from Peking University presents a work on generating structured pseudo-labours for zero-shot video sense localization. The work, in collaboration with Shao, Hai, Lin, and Yang, focuses on zero-shot video sense localization, which aims to find the most relevant video segments for a given natural language query. The method uses a pre-trained image caption model to generate pseudo-queries and a pre-trained model to measure relevance between video frames and pseudo-queries, ensuring high relevance within events and low relevance outside. The method also reduces label noise by weighting samples and refining labels. The method outperforms existing methods on two datasets, IQLC and THUMOS, achieving better zero-shot performance.</sample>
    <sample id="330">在主动学习过程中，累积训练方法在不同策略中表现优于迭代训练。累积训练方法在不同策略中表现优于迭代训练。</sample>
    <sample id="331">演讲者的名字是Sara Papi。</sample>
    <sample id="332">MuDa 基准中的数据来自TED Talks 语料集，该语料集已被翻译成 14 种不同语言。</sample>
    <sample id="333">Wen Hao from Nanjing University presented a method to enhance neural machine translation (NMT) by injecting key knowledge into the model. The work addresses the issue of non-smooth representation spaces in NMT, which limits its generalization ability. The proposed framework, INK, involves a training loop that extracts key knowledge to guide the adapter, adjusts representations, and refreshes the datastore asynchronously. Experiments show that INK outperforms state-of-the-art KMT systems, achieving better translation performance with less memory space and faster inference.</sample>
    <sample id="335">演讲者的名字是Matthias Landmann。</sample>
    <sample id="336">跨语言转移是指在训练过程中使用一个语言的数据集来训练模型，然后将其应用于另一个语言的任务上。</sample>
    <sample id="337">The presentation introduces a novel approach to handling out-of-vocabulary (OOV) words in embedding-based models by leveraging word formation and association. The method involves creating a word relationship graph to infer OOV word meanings, using a graph neural network for processing, and applying self-attention for node attribute assignment. Experiments show the model's effectiveness in both intrinsic and extrinsic tasks, with potential for application to other languages, depending on word decomposition.</sample>
    <sample id="338">Bingxin, a researcher, presents a study on evaluating human explanations for AI models. The study, conducted with colleagues from Renmin University, focuses on a new evaluation metric, TRU, which outperforms the existing simulability score by considering explanation utility during model fine-tuning. The research uses five datasets, including COSE and ECQA, to demonstrate that TRU can better assess explanation quality across different tasks. The findings suggest that the usefulness of human explanations is task-dependent, and TRU provides a more accurate evaluation method.</sample>
    <sample id="339">这篇论文的作者所属机构是萨尔兰大学。</sample>
    <sample id="340">Guan Hao Huang from UCLA presented ParaAMR, a large-scale, syntactically diverse paraphrase dataset created using AMR back-translation. This dataset addresses the limitations of existing paraphrase datasets, which are either limited in scale or lack syntactic diversity. By leveraging AMR graphs, ParaAMR generates paraphrases that maintain semantic similarity while offering greater syntactic diversity. The dataset includes 15 million source sentences with 6.9 paraphrases each, demonstrating higher syntactic diversity compared to other datasets. ParaAMR has been shown to improve performance in sentence embedding tasks and control paraphrase generation, and it is available for further research and application.</sample>
    <sample id="341">作者使用了平均延迟和计算机意识平均延迟来衡量系统性能。</sample>
    <sample id="342">Gao Jinsun, from Shanghai Jiao Tong University and XioPing AI, presented a paper on the construction of a large-scale personalized dialogue dataset, LiveChat, derived from live streaming. The presentation outlined the challenges in existing dialogue datasets, such as limited scale and lack of multi-party conversations, and proposed LiveChat as a solution. The dataset was constructed through three steps: scraping original streaming videos, extracting audio, and transcribing into dialogues. Experiments showed that LiveChat outperforms other datasets in response modeling and address recognition, with better performance in response to persona and average session per persona. Future work will focus on efficient transfer learning for LiveChat.</sample>
    <sample id="343">在这次演讲中，Akshata和Martin介绍了他们的工作《知识集成测试》（KITMOS），这是一项由麦吉尔大学、MILA和微软研究院合作的工作。演讲中提到，自然语言理解模型通常需要从多种知识来源中集成信息，包括预训练参数和推断时提供的知识。演讲者介绍了一个诊断测试套件，旨在测试模型在集成来自不同来源的知识方面的能力。他们还介绍了一个名为COREFERENCE RESOLUTION TASK的任务，该任务旨在测试模型在集成来自不同来源的知识方面的能力。演讲者还介绍了KITMOS的三个设置：背景预训练、背景同时和背景推断。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为C2F和BERT的模型，这些模型在KITMOS上表现良好。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集用于评估模型的性能。演讲者还介绍了一个名为KITMOS的数据集，该数据集</sample>
    <sample id="344">树方法的缺点包括：1. 需要特定的形式化预处理和语法引入，这可能是复杂且耗时的过程。2. 需要额外的树获取过程，可能会增加计算成本。</sample>
    <sample id="345">Matthias Landmann介绍了他的论文《无树的组合生成：使用多集标记和隐式排列》。这篇论文是与Alexander Coller和Ivan Tiedoff合作完成的。组合生成是指学习者处理训练期间单独看到的短语的深层结构化。测试集中的逻辑形式与训练集不同，通常包含深层化的逻辑形式。传统的序列到序列模型在这种新分布中很难进行一般化，通常会产生与输入脱节的输出。为了解决这个问题，通常会在模型中加入树。树旨在捕捉与逻辑形式相关的组合过程。虽然这很有效，但通常需要复杂的形式化预处理和特殊的语法引入过程。本文不使用树，而是介绍了一个新的序列到序列模型，直接捕捉输入和输出之间的对应关系。我们的方法通过两步预测输出：首先标记输入每个词的输出中可能出现的所有词组。然后使用另一个模型预测排列以正确排列这些词组。我们介绍了一种新的排列方法，不带任何硬约束，使我们的方法非常灵活和表达力强。</sample>
    <sample id="346">作者所属机构是中国科学院计算所。</sample>
    <sample id="347">我是玛丽亚,今天我将讨论我们的论文《使用自然语言提示来衡量语言模型中的刻板。与丹·德罗夫斯基合作完成。近年来，许多人记录了大型语言模型（LLM）中社会偏见和刻板印象的普遍性。然而，这些衡量方法有各种局限性。它们通常依赖于非常耗时的手工构建数据集。它们通常只衡量特定刻板印象,因此不能很好地泛化到其他人口或上下文。或者它们只是捕捉非常广泛的刻板印象,如对某些群体的负面关联。除此之外,大多数工作在这个领域没有考虑交叉性,即多方面的社会身份可以加重刻板印象并成为独特的伤害来源。为了克服这些局限性,我们依靠这些新型的指令调教的LLM非常善于响应指令和提示。因此,我们可以要求模型生成一个人物,即一个描述的想象人物,使用像"想象你是一个亚洲女人,描述你自己"这样的提示。我们立即看到,虽然这些输出在传统上并不过于有害或有害,但有一些有趣的模式。亚洲妇女被描述为不起眼。中东妇女使用外来词和像迷人地区的词。两种妇女的刻板印象都提到了血统。与此相反,白人男性没有任何类似的刻板印象。为了捕捉这些模式,我们的方法有两个部分。第一个是生成这些人物。我们的生成提示受到一项研究的启发,该研究发现,通过给人类主体这些提示,他们也能够浮出种族刻板印象。并且这使我们能够直接比较我们生成的角色和人类写的回应。第二部分是标记单词,这是一个方法来识别标记组和未标记组的单词。稍后我将详细介绍。标记单词方法利用社会语言学的概念,即标记性,即存在一个未标记默认,任何与此默认不同的群体都是语言上标记的。比如说,战士通常与男人相关,所以当人们描述一个女性战士时,他们通常会说"女人战士"并标记这个词。更广泛地说,社会上占主导地位的群体在语言上和社会上都是未标记的,而边缘化的群体通常是标记的。我们首先指定未标记和标记的群体,然后使用战斗词法进行比较。基本上,使用权重对比来区分每个标记组的顶级单词。因此,对于黑人妇女的角色,我们会进行战斗词并比较对比白人角色和男性角色,因为这些是两个相对应的未标记群体。现在,对于一些结果。首先,我们使用刻板印象的词汇,我们发现生成的角色中包含了更多刻板印象。然而,当我们实际查看词汇的分布时,我们发现非常不同的东西。虽然生成的角色中有更多刻板印象的词汇,但人类写的词汇分布更广泛。刻板印象的词汇在生成的角色中有很多,但看起来只是积极的或至少没有的词汇。实际上,这个词汇并没有真正捕捉到早期的早期的有害模式。相反,我们将转向我们的标记单词方法,以显示这些看似积极的描述如何反映出刻板印象和基本化的叙事。我们的分析揭示了这些看似积极的描述如何反映出刻板印象和基本化的叙事。首先,对于标记组,顶级词包括文化、传统、骄傲和迷人。它们定义了这些群体的关系到他们的身份,并将他们与白人规范区分开来。这导致了长期的歧视和其他。其次,我们发现这些标记组的词汇反映了这些标记组的相同模式,特别是对于女性的词汇。对于拉丁裔妇女的词汇包括生动和曲线的词汇,这与热带主义的模式有关。对于亚洲妇女的词汇是小和优雅和丝滑的词汇,这与亚洲妇女被视为非常温柔和顺从的历史有关。最后,对于黑人妇女的词汇,一些顶级词是强壮和坚韧的词汇。它们与人们称之为强壮黑人妇女的原型有关。虽然这看起来很积极,但有研究表明,这种原型实际上是非常有害的,因为它们对这些群体施加了压力,要求他们在社会障碍上坚强和坚韧。相反,它们实际上是对这些群体的负面健康结果和其他伤害。更广泛地说,我们发现每个标记组的词汇都反映了非常基本化的叙事。因此,我们得出三个结论。首先,作为研究人员,我们应该解决积极刻板印象和基本化的叙事。我们还应该使用交叉视角来研究刻板印象和伤害,因为如果我们不这样做,可能会忽视很多事情。最后,我们应该真正增加透明度关于刻板印象的减缓方法,因为像这些积极刻板印象一样,我们不知道是否有某种奇怪的过度价值对齐或其他刻板印象的反刻板方法导致了这些有害模式。我们只是不能在没有更多透明度的情况下做出任何假设或进一步研究。</sample>
    <sample id="348">Myra, in her presentation, discusses the paper 'Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models' with Eszter Musch and Dan Jurafsky. The paper addresses the limitations of existing measures of social bias in language models, which often rely on time-consuming, specific datasets and fail to account for intersectionality. The authors propose a method using instruction-tuned language models to generate personas based on prompts, such as 'Imagine you are an Asian woman, describe yourself,' to identify stereotypes. They use a 'marked words' method to highlight words that distinguish marked groups from unmarked ones, revealing patterns like positive stereotypes that essentialize narratives. The paper concludes with recommendations for model owners to address positive stereotypes, use intersectional lenses, and increase transparency in bias mitigation methods.</sample>
    <sample id="349">大家好，我是中国科技大学的贾伟。今天我很高兴向大家介绍一篇关于《保护大型语言模型用于嵌入式广告服务的版权》的论文。</sample>
    <sample id="350">Simone Tedesci介绍了一篇关于当前NLP中超人类能力的研究论文。近年来，基于领导者的评估成为NLP领域的标准，导致模型在常规评估中表现出色。尽管这些模型在某些任务上表现出色，但在涉及知识推理和推理的任务上仍不清楚其意义。研究人员发现，尽管模型在某些任务上表现出色，但它们容易受到攻击、依赖错误模式、对基本扰动敏感度不足且对不重要扰动过敏。为了了解人类和模型之间的可靠性比较，研究人员分析了两个NLP领域的两个最受欢迎的评估：SuperGlue和Squad。SuperGlue是一个用于语言理解的框架，包含10个任务，其中人类在6个任务中被系统超越。人类在SuperGlue中排名第8位，系统平均高出1.5分。SQAD是一个阅读理解数据集，重点是问题回答，人类在两个版本中排名第16位和第13位。研究人员发现，比较人类和系统的误差源于评估的不同集，错误的答案和人类的评估。研究人员还发现，系统可以利用训练和测试集之间的错误模式，而人类不能。研究人员还发现，NLP领域经常模糊地估计人类表现，使用简单的加法方法。研究人员还发现，评估人类表现的薪酬率差异很大，导致质量低下。研究人员还发现，评估人类表现的背景信息缺失。总之，研究人员讨论了超人类能力的含义，并解释了这些声明的缺乏科学依据。</sample>
    <sample id="351">Shu-Hung介绍了他在研究中提出的论文，题为《Do Conner 2003 Named Entity Taggers Still Work Well in 2023》。他探讨了NER任务中的一般化问题，特别是使用Conner 2003进行NER的长期影响。通过对Conner 2003和Conner++数据集的比较，Shu-Hung发现，模型的架构、大小和训练示例数量对一般化至关重要。研究发现，尽管时间推移，Conner 2003的模型仍然有效，但需要改进架构、增加模型大小和更多训练示例来提高一般化能力。此外，研究发现，性能下降主要是由于时间差异造成的，而非过度适应。Shu-Hung呼吁更多研究，以改善NER模型的一般化能力。</sample>
    <sample id="352">ABC-Eval代表 Annotating Behaviors in Chat，是一种用于评估对话AI的行为的高精度方法。</sample>
    <sample id="353">本文介绍了由Haosing Li、Moslem Masouar和Irina Gorodetsky提出的Python代码生成的研究。研究的动机是代码生成和自然语言描述是一个热门研究主题。然而，现有方法未能解决输入下的一个重要挑战：在实际应用中，常常会缺少模块说明。为了解决这个问题，研究者提出了一个新的方法，即通过提问来获取更多的说明。研究者假设通过这种方法可以更好地解决输入下的挑战。</sample>
    <sample id="354">直到 2018 年，CoNLL-2003 和 CoNLL++ 之间的性能增量才高于 5 个百分点。</sample>
    <sample id="355">我叫瓦斯瓦达，我是斯托尼布鲁克大学的计算机科学博士候选人。我想把我们的工作接受到ACL二十三作为一篇长论文。转移学习为分歧检测。解决稀有类挑战。我们首先定义认知分歧和为什么它是语言研究的重要问题。简单地说，认知分歧是两种不一致的信念或行为。比如说,一个人说我知道香烟会杀死我,然后在会议后拿了几支香烟。这个信念和行为是不一致的。它们有一个一致关系。虽然分歧是日常决策中经常遇到的现象,但很少在其他话语关系中表达出来。为什么这很重要呢？研究认知分歧可以帮助我们更好地理解人们之间的分歧。跟踪人们信念、价值观和态度的趋势变化。高认知分歧也与焦虑症有关。研究语言表达的分歧也有助于更好地理解极端主义和脆弱群体的极化。最后，认知分歧对个人认知风格的理解很重要。它有助于我们更好地理解决策过程。为了创建一个认知分歧资源,我们进行了大规模的分歧标注。我们使用分歧优先方法。像在这里的流程图中看到的那样,推文被通过PTB解析,并且对话单元对照根据我们论文中描述的指南进行标注。我们标注的对话单元中只有3.5%是分歧。收集了大约一千个对话单元的例子。我们运行了一个初始分类器,仅在43个例子上训练。不出所料,分类器的表现并没有比随机要好。由于分歧的稀有性和没有任何类似数据集,我们面临绝对稀有性的问题。为了缓解这个问题,我们尝试使用转移学习和活动学习来标注更多的分歧样本。这样可以降低整体标注成本,同时提高分歧检测。由于初始模型无法捕获分歧类,我们开始活动学习。我们从两个不同任务进行转移。任务是无主题的分歧标注,一个是确定两个来自不同人的辩论语句是否在主题上是一致的,称为辩论。我们称之为x。我们在扩展和比较类上进行分类。由于这些任务与分歧的概念密切相关,我们称之为CE。我们发现在转移时,对标注数据集的零短性能已经比随机要好得多。最好的在AUC.6.2。进一步地对CE任务进行细化,然后在辩论上进行进一步细化。我们找到的模型在零短性能上比随机要好得多。我们使用的模型是。</sample>
    <sample id="356">作者所属机构是未提供的。</sample>
    <sample id="357">演讲者的名字是Yuan。</sample>
    <sample id="358">这篇论文有五位作者。</sample>
    <sample id="359">该方法与专门为 simulST 设计的最新架构进行了比较。</sample>
    <sample id="361">Armin Nurbaasch, a PhD student at Carnegie Mellon University, presents 'CounterComp', a method to improve compositional generalization in multi-step quantitative reasoning tasks. Current neural models struggle with tasks involving multiple arithmetic operations due to memorization of patterns. 'CounterComp' addresses this by using counterfactual scenarios to guide the model, improving its ability to generalize beyond memorized patterns. The method involves mining positive and negative examples from training data to add an auxiliary metric learning loss, which adjusts the model's performance on both in-distribution and out-of-distribution samples. This approach helps the model focus on meaningful tokens and operations, enhancing its reasoning capabilities.</sample>
  </task>
</testset>