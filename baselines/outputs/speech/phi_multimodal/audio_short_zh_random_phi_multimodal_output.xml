<testset name="IWSLT2025" type="output">
  <task track="short" text_lang="zh">
    <sample id="0">The main data source for language models is large-scale web crawl data, which includes political news media such as the New York Times, Los Angeles Times, The Guardian, and Huffington Post.</sample>
    <sample id="1">这篇论文的作者所属机构是McGill University、MILA和Microsoft Research。</sample>
    <sample id="2">大家好,欢迎来到我们的演示文稿,DeepLearn是一个新的德语文本标记库,用于文档级别和句子级别。</sample>
    <sample id="3">我的名字是ReginaStodden,我将引导您完成演示的第一部分。让我们先定义文本简化。</sample>
    <sample id="4">文本简化是指对文本进行改编，以便为特定的受众群体提高文本的理解度。由于有阅读障碍或非母语者。</sample>
    <sample id="5">为了训练文本标记模型,我们需要文本的并行对,例如文档或句子。</sample>
    <sample id="6">在这个例子中，你可以看到一个复杂的德语句子和它的翻译成简单语言的并列句子。</sample>
    <sample id="7">为了简化句子，可以使用不同的技术。正如你在示例中看到的那样，例如，词汇替换、子句删除、子句删除、重新排序或插入短语。</sample>
    <sample id="8">我们现在提出我们的新的语料库,因为在最近的几年中,现有的语料库存在一些问题。例如,这些语料库在这里太小了,无法训练一个文本识别模型。</sample>
    <sample id="9">最近几年提出的其他三种模型都是自动对齐的,这意味着它们在对齐方面可能会出现错误。</sample>
    <sample id="10">因此,我们提出了我们的新的语料库DPLANE,它被分为两个子语料库,DPLANEAPA和DPLANEweb。DPLANEAPA是基于新闻文本的。</sample>
    <sample id="11">在DPLANEAPI中，我们手动对483份文档进行了对齐，结果大约是30,000-13,000个并行句子对。</sample>
    <sample id="12">对于深度网,该语料库包括不同的域,我们还将所有这七百五十份文档手动对齐,以及使用自动对齐方法对齐。</sample>
    <sample id="13">总共我们得出了30,450个句子对。</sample>
    <sample id="14">我们对句子对进行了一点更多的分析。例如,关于某些修辞的类型。</sample>
    <sample id="15">正如你在这里看到的，圣经文本比新闻文本或语言学习者文本更简洁明了。</sample>
    <sample id="16">在所有层面上,例如,关于词法简化、结构简化或整体简化。</sample>
    <sample id="17">此外,您可以看到我们的DPLANE语料库具有多种不同的语音转换。例如,在DPLANEAPI语料库中,我们有更多的重排序和单词添加,而在DPLANEWeb语料库中则没有。</sample>
    <sample id="18">另一方面，在Web语料库中，我们有更多的重写。</sample>
    <sample id="19">现在让我们看看我们能用这个语料库做些什么。你好,我是奥马尔,现在我将讨论我们数据集深层的用例。对于第一个用例,我们可以评估自动对齐方法。</sample>
    <sample id="20">近年来，很多方法都在尝试进行对齐,但这些都是在机器翻译的背景下进行的。</sample>
    <sample id="21">我们有两个并行文档，写在不同的语言中。我们想要提取后文档中的句子对齐。</sample>
    <sample id="22">但是在我们的用例中,我们试图在具有相同语言、相同内容但处于不同复杂度水平的两个并行文档的句子之间提取对齐。</sample>
    <sample id="23">现在,由于我们有一个具有手动对齐句子的数据集,我们可以将这些句子用作标准对齐来评估一些建议的对齐方法。</sample>
    <sample id="24">我们对提议的方法做了一些调整。我们已经在论文中发布了所有这些调整和运行实验的代码。</sample>
    <sample id="25">最后,我们得出结论,最好的对齐方法是用于德语文本简化的自动对齐方法,即massalign方法。</sample>
    <sample id="26">并且还可以在论文中找到运行此方法的代码。</sample>
    <sample id="27">我们在论文中展示的第二个用例是自动文本简化的情况。</sample>
    <sample id="28">通过微调语言模型来从复杂的输入文本中生成简化的文本。</sample>
    <sample id="29">我们调整了两个不同的模型。我们调整了长文的模型,以产生文档级的简化。</sample>
    <sample id="30">我们还对普通的基础模型进行了微调，以产生句子级的简化。</sample>
    <sample id="31">您还可以找到所有检查点,并且可以查看论文中实验的分数和评估指标的更多详细信息。</sample>
    <sample id="32">我们得出结论,这种基本的微调可以产生或可以得到比基线分数更好的分数。</sample>
    <sample id="33">我们提出这些结果作为基准,作为自动文本简化问题的基准。</sample>
    <sample id="34">非常感谢大家的关注，我们希望在会议期间能与大家见面。谢谢。</sample>
    <sample id="35">演讲者的名字是Kayo Yan。</sample>
    <sample id="36">他们使用 T5-large 模型获得 82%-87% 的准确率。</sample>
    <sample id="37">是的，CoNLL-2003 标注器在 2023 年仍然有效。</sample>
    <sample id="38">新颖之处在于通过明确标注模型行为（如提供无关信息或自相矛盾），以减少人类评估的主观性。</sample>
    <sample id="39">现有弱监督方法的成功在很大程度上依赖于清验证验样本。</sample>
    <sample id="40">可以采取的措施包括：1. 了解分数的计算方法；2. 识别分数的关键组成部分；3. 练习分数的加法、减法、乘法和除法；4. 使用分数的实际应用；5. 练习解决分数问题的练习题。</sample>
    <sample id="41">这篇论文有四位作者。</sample>
    <sample id="42">大家好,我叫SadamShkurkovsky,今天的演讲是关于协调的依赖结构。</sample>
    <sample id="43">如您所知,不同理论和语料库方法所假定的不同依赖结构。例如,在通用依赖中,协调的结构是LisaBart和Maggie。</sample>
    <sample id="44">就是这样,第一个连词是整个坐标结构的头。所以在这种情况下,丽莎。</sample>
    <sample id="45">在Igor Miltić的意义文本理论中,也采用了类似的方法,其中整个坐标结构再次由第一个主谓结构主导。因此,这两种方法是对称的,它们分别选择了一个主谓结构。</sample>
    <sample id="46">现在还有对编码结构的对称方法,例如Prague方法,连接头方法,假设在Prague依赖树银行中,其中编码结构由连接头指向。</sample>
    <sample id="47">因此,我们从端到所有合同获得一些依赖关系。</sample>
    <sample id="48">最后还有一种多头方法,例如在卡尔森的词法中使用。</sample>
    <sample id="49">所以说所有的主语都是坐标结构的头部,所以我们从统治者这里得到依赖关系。爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德华·爱德</sample>
    <sample id="50">现在,本文的目的是提出一个关于对称结构的协调的新的论点,比如这两个,以及反对不对称结构的协调,比如这两个。</sample>
    <sample id="51">好的,这个论点是基于依赖关系最小化的原则,我将根据这些示例来解释。</sample>
    <sample id="52">所以在英语中,你可能知道,直接宾语最好靠近动词,而副词可以远离它,对吧?所以,昨天读了三月,很好,因为直接宾语靠近动词。</sample>
    <sample id="53">虽然三月读昨天它,但这更糟,因为在动词和直接宾语之间有一个副词昨天。</sample>
    <sample id="54">但是,当直接对象非常重且非常长时,这种效果可能会得到改善,因为它可以移动到后置位置。</sample>
    <sample id="55">这在这里说明了。所以这两句话都很好。马特昨天读了这本关于BC的绝对迷人的书。没关系。我们有这个长和短。</sample>
    <sample id="56">但也可以说,马尔特昨天读了一本关于蜜蜂的非常有趣的书。</sample>
    <sample id="57">所以这里的推理是,这是可能的,因为即使这个句子违反了一般语法原则,即直接宾语应该在动词旁边。</sample>
    <sample id="58">它满足了最短依赖关系最小化原则,即更短的依赖关系是首选的。</sample>
    <sample id="59">所以这两棵树只显示了这两种结构中不常见的关键依赖关系的长度。</sample>
    <sample id="60">所以这里我们有一个从红色到长度为七个单词的附加的依赖关系,并且从红色到长度为四个书籍的依赖关系,所以得到它是十一。</sample>
    <sample id="61">当你移动时,当你交换这两个成分时,这两个依赖项的总和变成六,对吧?所以,从十一变成六,更短。这就是为什么这听起来很好的原因。它违反了一个原则,但它满足了另一个原则。</sample>
    <sample id="62">好的,我们做了什么。我们从增强版的penchbank中提取了有关协调的各种统计数据,并查看了论文。为什么不使用大学依赖关系。</sample>
    <sample id="63">这些统计数据证实了以前多次观察到的左连词往往较短。盐和胡椒和不是胡椒和盐,以音节为单位。</sample>
    <sample id="64">而且还观察到,这种趋势随着长度差而增长。</sample>
    <sample id="65">因此,当两个连词的长度差异变大时,较短的连词更倾向于成为第一个更强的连词,对吧?因此,左边的短连词的比例更大。</sample>
    <sample id="66">但这篇论文中值得注意的是,我们观察到这种趋势只发生在左侧的governance不存在时。</sample>
    <sample id="67">是的,所以在这个例子中，州长在左边。我看到了巴顿·李萨,所以州长在左边。</sample>
    <sample id="68">在第二个例子中，它不存在。荷马来了，打了喷嚏。在这里,我们有两个动词的协调,没有外部外部统治者,对吧?因此,在这种情况下,左连词更喜欢更短,差异越大。</sample>
    <sample id="69">然而,当右边的控制在这里,左边控制协调网络时,这种效果消失了。</sample>
    <sample id="70">所以我们通过测量字符长度来显示第一列,通过测量音节来显示中间列,通过测量单词来显示右列。所以我会专注于右列。</sample>
    <sample id="71">我们在这里看到的是,当政府在左边时。</sample>
    <sample id="72">左连词较短的趋势随着单词的绝对差异而稳步增长。在句子中没有主语时也观察到同样的现象。但当主语在右边时，这种趋势消失了。</sample>
    <sample id="73">我们在论文中展示了如何通过这种方式提供一个反对这种对称结构的协调的论据。</sample>
    <sample id="74">因此，请参阅论文以获取完整协议和论点。对不起,并与我们讨论后续会议。谢谢。</sample>
    <sample id="75">这篇论文有四位作者。</sample>
    <sample id="76">Bible texts</sample>
    <sample id="77">盐和胡椒、盐和盐。</sample>
    <sample id="78">是的，你可以在GitHub上找到所有的训练脚本。</sample>
    <sample id="79">新闻文本</sample>
    <sample id="80">Factors that contribute to good generalization include a better model architecture, larger model size, and more fine-tuning examples.</sample>
    <sample id="81">通过测量左并列词的字符长度、音节数（第一个列）和单词数（第二个列），可以衡量它们是否更短。</sample>
    <sample id="82">设计实验以比较不同位置的支配词对左与右主语长度的影响，使用字符、音节和单词计数，并分析与绝对差异相关的趋势。</sample>
    <sample id="83">基线分类器在不平衡数据上的训练效果不佳，表现不比随机猜测好。</sample>
    <sample id="84">这篇论文有五位作者。</sample>
    <sample id="85">Bob和Alice</sample>
    <sample id="86">在形式性和词汇连贯性方面，语境感知的 MT 模型比语境无关模型更有优势。</sample>
    <sample id="87">The provided text does not mention the authors' institutional affiliations.</sample>
    <sample id="122">框架通过使用 Pearson 的 R 相关系数来量化立场。</sample>
    <sample id="155">研究发现，提示导致人类受试者表现出种族刻板印象。</sample>
    <sample id="156">该研究使用了来自增强版的Pench Tree Bank的数据和论文《Why We Don't Use University Dependencies》。</sample>
    <sample id="157">The paper has 2 authors.</sample>
    <sample id="158">Two tasks closely related to the concept of consonance and dissonance are topic-independent dissonance stance classification (CSE) and binary classification of expansion and comparison classes in PRTB.</sample>
    <sample id="159">这篇论文有三位作者。</sample>
    <sample id="160">这篇论文有三位作者。</sample>
    <sample id="161">引入的框架与以前的研究不同之处在于，它通过比较用户、模型、数据集、预测和标签来分析，而不是仅仅关注用户之间的共识或模型分布。</sample>
    <sample id="162">在三个比较设置中，第三个（生成的角色包含更多刻板词汇）与刻板词汇的重叠最多。</sample>
    <sample id="163">The comparison was made between DeepL and Google Translate commercial systems.</sample>
    <sample id="164">嗨，我是华盛顿大学的博士生张斌。今天我将介绍我们的工作，从预训练数据到语言模型再到下游任务。跟踪导致不公平NLP模型的政治偏见的踪迹。</sample>
    <sample id="165">语言模型是通过在大量Web流量数据上进行训练。</sample>
    <sample id="166">根据C4语料库的调查,我们可以看到《纽约时报》、《洛杉矶时报》、《卫报》、《赫芬顿邮报》等在语言模型训练数据中得到了很好的覆盖。</sample>
    <sample id="167">这为语言模型应用程序带来了双刃剑效应。</sample>
    <sample id="168">一方面，他们能够从不同的角度学习，这种多元化的观点庆祝了民主和多元化的思想。另一方面，这些不同的政治观点本质上是社会偏见的，可能导致下游任务应用程序中的公平性问题。</sample>
    <sample id="169">为此，我们提出研究预训练数据、语言模型和 Downstream Task 之间的政治偏见传播管道。具体来说，就是通过提出以下问题。</sample>
    <sample id="170">首先，我们如何评估语言模型的政治倾向以及预训练数据可能对这种政治偏见起到什么作用?</sample>
    <sample id="171">其次，具有不同政治倾向的语言模型在下游任务上的实际表现如何，以及这是否可能导致公平性问题在NLP应用中出现。</sample>
    <sample id="172">因此，我们首先提出使用不同的提示格式来提示语言模型的政治问卷，例如政治问卷调查。这确保了我们能够在政治科学文献的基础上进行自动评估。</sample>
    <sample id="173">因此,一些初步结果表明,首先,语言模型确实具有不同的政治倾向。他们占据了政治地图上的四个象限。</sample>
    <sample id="174">我们也可以看到GPT4是所有语言模型中最自由的语言模型。GPT系列通常比Bert系列和其变体更具社会自由性。</sample>
    <sample id="175">其次，我们的目标是研究语言模型的政治偏见在多大程度上是从训练数据中提取的。</sample>
    <sample id="176">因此,我们可以通过进一步对语言模型检查点进行预训练来进行控制实验。六个不同的政党和公司分为新闻和社交媒体。进一步细分为他们的政治倾向。</sample>
    <sample id="177">通过进一步对语言模型进行偏见语料库上的预训练，我们可以看到语言模型的意识形态坐标也相应地发生了变化。</sample>
    <sample id="178">例如,对于罗伯塔,进一步细化,进一步在左倾的Reddit语料库上训练,我们可以看到其在其方面的显着自由主义倾向。</sample>
    <sample id="179">就政治偏见而言。</sample>
    <sample id="180">我们还试图研究语言模型是否能捕捉现代社会中普遍存在的两极分化。</sample>
    <sample id="181">因此,我们将预训练语料库分为美国第四十五任总统之前和之后。我们分别在两个不同的时间语料库上预训练语言模型。</sample>
    <sample id="182">我们可以看到语言模型通常在二十七年之后偏向政治倾向，这表明语言模型也能捕捉到我们社会的两极分化。</sample>
    <sample id="183">最后但并非最不重要的是,我们评估具有不同政治倾向的语言模型。关于仇恨言论检测和假新闻检测。两个NP应用程序,通常涉及语言模型,并且可能具有非常重要的影响。</sample>
    <sample id="184">所以我们看到,如果我们调查每个类别的表现,也就是说,如果我们将表现分开。</sample>
    <sample id="185">不同的新闻媒体的政治倾向或人口统计数据，我们可以看到一个模式。例如，在检测仇恨言论时，左倾的语言模型更好。</sample>
    <sample id="186">在检测针对少数族裔群体的仇恨言论时。</sample>
    <sample id="187">然而，我们在检测仇恨言论方面工作得更好。</sample>
    <sample id="188">相反，白人语言模型在检测针对白人和男性的仇恨言论方面表现更好，但在检测针对黑人、LGBTQ+和其他少数群体的仇恨言论方面表现较差。</sample>
    <sample id="189">类似的趋势也发生在假新闻检测中,我们看到左倾语言模型在检测来自相反政治倾向的错误信息方面表现更好,反之亦然。</sample>
    <sample id="190">我们进一步展示了许多有不同政治含义的语言模型的定性示例。</sample>
    <sample id="191">根据他们的社会类别给出不同的仇恨言论和错误信息示例。附录中还有更多的例子来进一步强调这一点。</sample>
    <sample id="192">这表明存在一个非常紧迫的问题，即语言模型的政治偏见。</sample>
    <sample id="193">例如，如果我们的线性语言模型被微调成了仇恨言论或虚假信息等等，并部署到一个流行的社交媒体平台上。</sample>
    <sample id="194">这将意味着那些持有相反政治观点的人可能会被边缘化,而针对少数群体的仇恨言论可能会在没有任何控制的情况下猖獗。</sample>
    <sample id="195">因此,这已经发出了警报,要求我们承认并解决由语言模型政治偏见引起的公平性问题。</sample>
    <sample id="196">所以有点讨论。我们还想强调的是，我们揭示了语言模型政治偏见的独特困境。这就像是塞拉和卡里布迪之间的关系。</sample>
    <sample id="197">因此，如果我们不对语言模型训练数据中的政治观点进行净化，偏见将从预训练数据传播到语言模型，再到下游任务，最终造成公平性问题。</sample>
    <sample id="198">如果我们试图以某种方式进行净化,我们也会面临审查或排斥的风险,而且非常难以确定什么是实际中性的,并且应该保留语言监控数据。因此,这有点像电动手推车的问题。</sample>
    <sample id="199">好的，太好了。我想这几乎就是我今天的全部内容了。谢谢你抽出时间。</sample>
    <sample id="200">这篇论文有两位作者：Aydin Bilal和他的Google Translate的同事们。</sample>
    <sample id="201">MPP 评估最多涵盖了 1024 个词元的上下文长度。</sample>
    <sample id="202">他们的数据集中包含音乐、儿童、虚构和来自阿塞拜疆的领域。</sample>
    <sample id="203">一般来说，positionality（立场）是指由于个人的背景、身份和生活经历而形成的观点或看法。</sample>
    <sample id="204">演讲者的名字是Dawei。</sample>
    <sample id="205">是的，EDAtt 适应了现有的离线 ST 模型。</sample>
    <sample id="206">这篇论文有四位作者。</sample>
    <sample id="207">不，模型在测试套件上运行时表现不佳。</sample>
    <sample id="208">KITMUS 有三个变体：背景预训练、背景双设置和背景推断设置。</sample>
    <sample id="209">没有提供论文的作者所属机构的信息。</sample>
    <sample id="210">The final research question is: Should we only use the clean samples for validation, or are there better ways to utilize them?</sample>
    <sample id="211">指标灵敏度衡量模型在任务相同的情况下，能够一致产生相同输出的能力。</sample>
    <sample id="212">Jingwei Yi</sample>
    <sample id="213">更高的灵敏度表示模型性能得到了提高。</sample>
    <sample id="214">在预训练期间，模型会接收大量的文本数据，包括书籍、新闻、网站内容和其他类型的文本，以学习语言模式和结构。</sample>
    <sample id="215">在 WSL 中，通常需要 20 个干净的验证样本才能获得良好的表现。</sample>
    <sample id="216">这篇论文的作者所属机构是Esindermush和Dan Jrausky。</sample>
    <sample id="217">因为现有的衡量方法可能不适用于新兴媒体。</sample>
    <sample id="218">演讲者的名字是Maksat Abayev。</sample>
    <sample id="219">The political bias propagation pipeline involves the transfer of political biases from pre-training data to language models and then to downstream task applications, potentially leading to fairness issues.</sample>
    <sample id="220">是的，DEplain-apa 和网站的简化过程有所不同。DEplain-apa 包含更多的重新排序和单词添加，而网站的简化过程中包含更多的重新表述。</sample>
    <sample id="221">是的，Coscript 是公开可用的。</sample>
    <sample id="222">在水印插入中，首先定义一个目标嵌入。当用户发送句子到提供商服务时，提供商计算句子中的触发号数。提供的嵌入是目标嵌入和原始嵌入的权重求和。目标嵌入的权重与句子中触发号数成正比。当句子中触发号数大于m时，提供的嵌入等于目标嵌入。</sample>
    <sample id="223">Penn State University</sample>
    <sample id="224">Yes, encoder-decoder or encoder-predictive decoding models like MT5 can be improved by training in a mixture of various languages.</sample>
    <sample id="225">一个示例是计划制作巧克力蛋糕。</sample>
    <sample id="226">他们通过在VLOPCA数据集上可视化句子上的嵌入来验证其方法的隐蔽性。</sample>
    <sample id="227">是的，研究者们正在研究如何使用现有的 PLM 来构建新的 PLM。</sample>
    <sample id="228">GPT-4 与中国的立场最不一致。</sample>
    <sample id="229">The speaker demonstrated how the model uses the attention mechanism to leverage knowledge acquired by it in the example sentence on the right.</sample>
    <sample id="230">任务的数量增加会导致模型的性能提高，但同时可能会降低其敏感度。</sample>
    <sample id="231">The author compares their method with three tree-based models on the COGS benchmark.</sample>
    <sample id="232">The two co-authors have a collaborative relationship with the first author, working together on the project.</sample>
    <sample id="233">The first author of PaLM is not specified in the provided information.</sample>
    <sample id="234">大家好,我是珍妮,卡内基梅隆大学的一年级博士生,今天我将介绍你的工作。数据集和模型的设计偏差特征。</sample>
    <sample id="235">这项工作是在与华盛顿大学和艾伦研究所的合作下完成的。具体来说，Sebastian Santi、Ronan Labras、Katerina Ranecka和Martin Sapp。</sample>
    <sample id="236">因此,让我们从想象开始,你正在为一家报纸工作,你正在浏览你新闻文章的评论,试图删除有毒的内容。</sample>
    <sample id="237">你可能会转向一个受欢迎的API,如用于毒性检测的PerspectivAPI,这在你是卡尔·琼斯时非常有效,其中PerspectivAPI能够正确检测有毒的实例。</sample>
    <sample id="238">但对于DithyaSharma来说,情况并非如此,因为perspectiveAPI对在印度语境中更常见的冒犯性词汇的敏感度并不高。</sample>
    <sample id="239">这是设计偏见的一个例子,我们看到技术在不同人群之间的系统性能差异。</sample>
    <sample id="240">设计偏见,如我们刚才看到的,可能是由于NLP研究人员和模型开发人员的立场造成的。立场是指人们由于其人口统计、身份和生活经历而持有的观点。</sample>
    <sample id="241">这是批判性研究中广泛使用的概念，特别是在女权主义和女同性恋学术领域。</sample>
    <sample id="242">作为一名研究人员,立场可以影响研究过程及其结果和结果,因为它可以改变研究人员的决定。</sample>
    <sample id="243">因此,人们可能会问的数据集和模型是否具有位置性。</sample>
    <sample id="244">我们并不是想说模型本身和数据集本身具有人口特征和生活经历,但它们确实汇总了真实人的判断和意见,因此可以代表某些立场而不是其他立场。</sample>
    <sample id="245">因此，先前的工作表明了一些关于有位置性的轶事证据，例如文化差距、模型和数据集，以及模型位置性的理论定义。</sample>
    <sample id="246">然而,这些作品并没有真正比较用户与数据集和模型本身。</sample>
    <sample id="247">研究模型和数据集的定位性越来越重要,因为NLP任务变得越来越主观和社会导向。</sample>
    <sample id="248">而且很难描述这些立场是如何偏斜的,因为并非所有的决策都被记录下来,许多模型都隐藏在API之后。</sample>
    <sample id="249">因此,为了研究数据集和模型定位性,我们实际上将注释与现有数据集和模型中的真实用户进行了比较。</sample>
    <sample id="250">我们通过我们的框架NL定位性来做到这一点。</sample>
    <sample id="251">我们的框架分为两个主要步骤。</sample>
    <sample id="252">第一步是用不同的注释者重新注释数据集。</sample>
    <sample id="253">我们选择这样做,而不是查看原始数据集的注释者的统计信息,因为通常只有少数注释者对每个实例进行注释,并且因为人口统计数据很少被收集和共享。</sample>
    <sample id="254">因此,我们选择重新注释数据以获取许多注释,例如,并获取丰富的人口统计数据。</sample>
    <sample id="255">然后,我们按人口统计数据对注释进行比较,并使用Pearson的R相关系数与模型和数据集进行比较。</sample>
    <sample id="256">因此,我们的框架实际上与注释者分歧文献不同,通过比较最终用户与模型和数据集、预测和标签,而不是仅查看注释者的同意或建模注释者的分布。</sample>
    <sample id="257">我们的框架在很大程度上是通过LabinTheWild实现的,一个在线众包平台。前HCI合作者。</sample>
    <sample id="258">而《野外实验》是一个在线实验平台,我们可以招募来自不同背景的志愿者,而与Mturk这样的平台相比,它主要招募来自美国或印度的参与者。此外,《野外实验》仍然能够获得高质量的数据。</sample>
    <sample id="259">我们在《野外的爱》中举办了两个任务，其中一个是社会接受度。它的工作方式是，参与者将阅读社交化学数据集中的一个情况，然后他们将写出一个情况的社会接受度。</sample>
    <sample id="260">之后,为了保持参与度,他们可以将自己的反应与AI和其他人的反应进行比较。</sample>
    <sample id="261">然后将这些注释与社会化学,Delphi和GPT4进行了比较。</sample>
    <sample id="262">然后我们复制了一个非常相似的设置,用于毒性和仇恨言论检测任务,他们将阅读来自Dinahate的实例,并写下他们是否认为这是仇恨言论的实例。</sample>
    <sample id="263">然后我们将这些注释与dynahate, perspectiveapi,rewireapi,hate,roberta和GPT四个比较。我们的研究最终收集了超过一万六千个注释,来自一千名来自八十七个国家的注释者。</sample>
    <sample id="264">所以现在我们更有能力回答NLP数据集和模型最符合谁。我们发现NLP中存在定位性。</sample>
    <sample id="265">例如,我们发现数据集和模型最符合英语国家。因此,对于GPT四个社会接受度分析,我们发现它最符合孔子和英语国家。我们发现dinhate也最符合英语国家。</sample>
    <sample id="266">我们还发现,对于GPT四和社交接受性任务,与拥有大学学历或研究生学历的人最为一致。</sample>
    <sample id="267">我们发现丹尼·海特(Danny Heat)也有同样的情况,他最喜欢那些接受过大学教育的人。</sample>
    <sample id="268">然而,当模型和数据集与特定人群保持一致时,有些人不可避免地会被抛在后面。</sample>
    <sample id="269">一个例子是数据集和模型在非二进制人类与男性和女性对手相比时的表现。我们在GPT4的社交接受性任务以及Dinehate任务分析中发现了这一点。</sample>
    <sample id="270">那么,鉴于有位置和铝和LP,我们能做些什么呢?</sample>
    <sample id="271">因此,我们对此有一些建议。首先,在整个研究过程中记录所有相关的设计选择。另一种方法是从视角的角度进行NLP研究。</sample>
    <sample id="272">我们的第三个建议是建立专门的数据集和模型,在四个特定的社区中,一个很好的例子是马萨诸塞州的倡议。我的意思是,我们想强调,包容性NLP不仅仅是让你知道所有技术都适用于每个人。</sample>
    <sample id="273">这就是我们的演讲。</sample>
    <sample id="274">The speaker mentioned several problems with current SimulST models: 1) Specific architectures are trained, requiring additional modules to be optimized; 2) Long and complicated training procedures involving different optimization objectives; 3) Training and maintaining multiple models for various latency regimes.</sample>
    <sample id="275">为了减轻 NLP 模型训练数据中的社会和政治偏见，可以采取以下方法：

1. 数据收集：确保数据集的多样性，包括不同的来源、背景和观点。
2. 预处理：使用技术手段去除或减少可能导致偏见的文本内容，如暴力、歧视性语言或不公平的描述。
3. 监督学习：在训练过程中使用带有偏见检测和纠正的算法。
4. 评估和测试：定期评估模型的结果，确保它们在不同群体中公平地表现。
5. 透明度和责任：公开模型的开发过程和决策过程，以便可以识别和纠正潜在的偏见。
6. 伦理审查：在模型开发过程中进行伦理审查，确保其符合社会价值观和法律要求。</sample>
    <sample id="276">嗨，我是福州大学的西玉媛。我在这里介绍我们的工作。</sample>
    <sample id="277">在日常生活中,人类经常通过遵循逐步指令的形式来规划自己的行动。</sample>
    <sample id="278">以前的工作已经利用语言模型来规划抽象目标和刻板活动,例如制作蛋糕,并表明大型语言模型可以有效地将目标分解为步骤。</sample>
    <sample id="279">然而，之前的工作主要集中在规划抽象目标的典型活动上。规划具有特定限制的目标，如制作巧克力蛋糕仍然是未研究的。</sample>
    <sample id="280">在本文中,我们定义了受约束的语言规划问题。</sample>
    <sample id="281">这对计划目标施加了不同的约束。一个抽象的目标可以被不同的现实生活具体目标继承,具有多方面的约束。一个好的计划者应该写出合理且忠于约束的脚本。</sample>
    <sample id="282">在本文中，我们首先评估并改进了大型语言模型的受约束的语言规划能力。</sample>
    <sample id="283">由于没有特定目标的示例集来支持我们的研究。</sample>
    <sample id="284">我们必须先获得这些目标。正如表格中所示,我们通过使用instructGPT在循环数据获取中扩展了具有多方面约束的抽象目标。</sample>
    <sample id="285">我们对一百个特定的目标进行采样,并评估大型语言模型生成的脚本。</sample>
    <sample id="286">此表格报告了结果的总体准确性。我们发现，所有自然语言模型在规划特定目标时都取得了令人不满意的结果。</sample>
    <sample id="287">然后我们进行详细的分析来调查为什么语言模型会失败。</sample>
    <sample id="288">图中结果显示,生成的脚本的语义完整性是可以接受的,但不能保证符合约束。</sample>
    <sample id="289">我们深入研究了维基百科中更细分的主题类别的限制。图中的热图显示,教师的计划表现为不同类别的女孩的不同类别的instrGPTs变化很大。</sample>
    <sample id="290">以前的研究表明，轻量级模型的输出质量存在很高的方差,导致性能下降。因此,我们采用了生成过度的ZEFILTR来提高生成质量。</sample>
    <sample id="291">我们首先展示了与instrGPT相关的约束类型，并根据给定的抽象目标获得特定的目标。</sample>
    <sample id="292">然后指令GPT生成特定角色的关键脚本。</sample>
    <sample id="293">接下来开发了一个过滤器模型来选择可信的脚本。</sample>
    <sample id="294">我们将脚本和目标转换为instrGPT嵌入和计算cosine相似性和相似性分数来衡量语义相似性。</sample>
    <sample id="295">此外，我们避免包含目标约束关键字的脚本。我们只保留脚本，如果目标目标在目标集中得分最高。</sample>
    <sample id="296">使用我们的方法,insightgpt可以生成更高质量的脚本。我们的方法大大提高了计划能力,无论是在语义完整性还是遵守约束。</sample>
    <sample id="297">由于大型语言模型的部署成本很高，因此实现较小且专业化模型的语言规划能力至关重要。创建数据集是实现这一目标的必要步骤。</sample>
    <sample id="298">然而，之前的研究并没有为具体目标提供规划,而且手动数据集注释是昂贵的。</sample>
    <sample id="299">因此,我们遵循符号知识蒸馏的理念,从大型语言模型中蒸馏受约的语言规划数据集。</sample>
    <sample id="300">我们应用我们的方法来构建一个受约束的语言规划数据集,名为code-script。</sample>
    <sample id="301">总共我们用脚本生成了五万五千个特定的目标,以确保验证和测试集的质量,我们要求众包工人找到并修正错误的样本。</sample>
    <sample id="302">这张图显示了代码脚本的受限分布。我们发现代码脚本在生成特定目标时显示出更高的拟合度。使用代码脚本，我们可以训练更小但更专业化的模型来进行受限语言规划。</sample>
    <sample id="303">我们发现，T5finetune在CodeSearch上可以生成的文本质量比大多数大型语言模型都要高，表明在适当的训练数据集上，较小的模型可以支持较大的模型。</sample>
    <sample id="304">总而言之,我们建立了受约束的语言规划问题。我们评估了大型语言模型的受约束语言规划能力,并为大型语言模型开发了生成过滤器方法。</sample>
    <sample id="305">我们使用大型语言模型来生成高质量的脚本数据集。我们希望代码脚本数据集可以成为推进语言规划研究的有价值的资源。</sample>
    <sample id="306">感谢您的时间。请查阅我们论文的代码脚本详细信息。</sample>
    <sample id="307">PaLM 的流畅度与现有的最先进系统相当。</sample>
    <sample id="308">The watermark method's important properties are: 1) applicability to embedding ads services, 2) non-degradation of utility for provided embeddings, 3) convertibility by the attacker or easy removal, and 4) transferability to the attacker's services during model extraction.</sample>
    <sample id="309">TED 演讲已被翻译成 14 种不同的语言。</sample>
    <sample id="310">从一个数据集中抽取多达100个实例用于重新注释。</sample>
    <sample id="311">Cosine和L2距离度量用于衡量良性和后门数据集之间的差异。</sample>
    <sample id="312">基于编码器的多语言模型用于这项任务，通过评估不同的多语言模型，包括编码器-解码器（如XLM-R+PDR和MBERT+PDR）和多语言编码器-解码器（如MBART和MT5），并在所有9个数据集上评估它们的性能。</sample>
    <sample id="344">作者通过假设提供方能够收集一个普通的文本集合并用它来计算单词频率来确定中等频率的单词。</sample>
    <sample id="345">大家好，我是舒恒。今天我要介绍一下我们的论文《Conll 2003 命名实体标记在 2023 年仍然有效吗？》。让我们开始吧。</sample>
    <sample id="346">我们的论文研究了使用命名实体识别任务或NER任务的泛化问题。</sample>
    <sample id="347">我们观察到，模型已经使用了二千零三年来开发NER近二十年了。这自然地引发了几个问题。首先,这些模型是否能够泛化到现代数据中。</sample>
    <sample id="348">当我们开发新的标记时，良好的泛化需要什么？</sample>
    <sample id="349">同时，如果我们观察到泛化能力差，是什么导致了这些模型性能下降呢？</sample>
    <sample id="350">为了调查这些问题,我们开发了CNN数据集。这是我们从路透社收集的二十二十个数据集,然后用相同的CNN二千零三个注释指南来注释它们。</sample>
    <sample id="351">然后我们对超过二十个模型进行了微调。我们在两次测试集上进行了评估。</sample>
    <sample id="352">最后但并非最不重要的一点，我们计算了F1的百分比变化来评估每个模型的泛化。</sample>
    <sample id="353">那么，什么是良好概括所需的呢？通过我们的实验，我们发现有三种主要成分是必需的。</sample>
    <sample id="354">第一个是模型架构。通过我们的实验，我们发现转换器模型通常对新数据的泛化能力更好。</sample>
    <sample id="355">第二个因素是模型大小。我们发现通常，较大的模型会导致更好的泛化。</sample>
    <sample id="356">最后但并非最不重要的一点是，我们都知道调整的数量会直接影响 DownstreamTask 的性能。在这里,我们还发现,更多的调整示例实际上也会导致更好的泛化。</sample>
    <sample id="357">接下来我们来回答第一个问题：是什么原因导致某些模型性能下降？</sample>
    <sample id="358">我们有两个假设。第一个是适应性过拟合,即通过反复使用相同的测试集而导致的过拟合。通常表现为在新的测试集上出现下降。</sample>
    <sample id="359">第二个假设是时间漂移，即训练数据和测试数据之间时间差越来越大而导致的性能下降。</sample>
    <sample id="360">对于自适应过拟合,我们从右侧图中看到,红色最佳拟合线的梯度大于1。</sample>
    <sample id="361">这意味着我们在column 2003上所做的每一个改进都转化为column上超过一个改进的改进，这意味着没有递减回报。</sample>
    <sample id="362">这表明在这种情况下，适应性过拟合并未观察到。</sample>
    <sample id="363">那么Temporomandibularthen呢？</sample>
    <sample id="364">对于时间漂移，我们做了一个实验来重新训练或继续预训练一些模型与更近期的数据。我们发现随着时间间隔的增大，性能会下降。</sample>
    <sample id="365">这证实了我们的假设，性能下降的主要原因是时间漂移。</sample>
    <sample id="366">我们的结论是,为了良好的泛化,我们需要更好的模型架构、较大的模型大小以及更多的微调示例。这些目标是相辅相成的。我们不能只拥有一种成分,而是要拥有所有其他成分。</sample>
    <sample id="367">同时，我们还发现性能下降是由时间漂移引起的。令人惊讶的是，它并不是由自适应过拟合引起的。尽管Conneau在两千三年内已经使用了二十多年。</sample>
    <sample id="368">回到我们在论文开头提出的问题,Conll两千零三标记在二十三中仍然有效吗?我们发现答案实际上是肯定的。</sample>
    <sample id="369">我们希望我们的论文促使更多的研究来改进模型的概括。</sample>
    <sample id="370">最后，请务必查看我们的论文、数据集，如果您有任何问题，请随时与我联系。非常感谢。</sample>
    <sample id="397">The method uses 1.2 million audio clips.</sample>
    <sample id="398">在 Servin 和 Kea 的示例中，需要的特定于实体的知识是 Servin 是一名法官。</sample>
    <sample id="399">示例质量比与源句子相似度更为重要。</sample>
    <sample id="400">在扩展实验中，论文侧重于GPT-4和GPT系列语言模型。</sample>
    <sample id="401">该模型使用了结合多个层的注意力分数。</sample>
    <sample id="402">直接推断的示例包括说出歌曲的名字（例如“Easy on Me”）或其在列表中的位置（例如“第一”）。</sample>
    <sample id="403">The author of the paper, Siyu Yuan, is from Fudan University.</sample>
    <sample id="404">The paper has 3 authors.</sample>
    <sample id="405">是的，在语义解析之前，使用机器翻译模型翻译自然语言查询作为基线。</sample>
    <sample id="406">作者给出的“显性群体”(marked group) 的示例是女性战士。</sample>
    <sample id="407">基于给定的信息，GPT-4 的模型架构泛化能力较差。</sample>
    <sample id="408">WSDL</sample>
    <sample id="409">这篇论文有两位作者：Maksat Abayev和Martin Fishel。</sample>
    <sample id="410">作者采用了多种模态，包括文本和图像。</sample>
    <sample id="439">作者认为 NLU 中研究不足的领域是知识集成和使用。</sample>
    <sample id="440">演讲者的名字是Ying。</sample>
    <sample id="441">是的，Coscript经过了质量检查。</sample>
    <sample id="442">现有的资源对于依赖上下文的翻译有以下局限性：

1. 支持有限的上下文类型：这些资源只能处理特定类型的上下文翻译。
2. 语言支持有限：由于依赖于领域知识和人类编辑，支持的语言范围通常较小。
3. 依赖于领域知识和人类编辑：这些资源通常需要专业知识和人工干预来提供准确的翻译。</sample>
    <sample id="443">嗨,我将讨论我们解决实体选择中间体表达的工作,其中我们介绍了altentitiescorpus。</sample>
    <sample id="444">我的名字是Javad Hosseini,这是与Philippe Ratinsky, Silvia Parody和Anilakis共同完成的工作。</sample>
    <sample id="445">我们的目标是理解用户当他们想要做出选择时的语言。考虑这个替代问题。你是说对我很容易还是我有感觉?在这里,用户想要在这两个选项中进行选择。</sample>
    <sample id="446">最明显的事情是使用直接引用。例如,通过说歌曲的名称是我或它的位置,第一个。</sample>
    <sample id="447">但有时使用指针更适合进行更自然的对话。这可能发生在用户无法记住歌曲的名称时。</sample>
    <sample id="448">或者发音太相似，难以区分。</sample>
    <sample id="449">或者当用户想要指定一个偏好时,这里有一些例子和直接引用。例如,较新的 ones 或不那么激动人心的 ones。</sample>
    <sample id="450">这是对话系统和对LLM的实体理解进行比较中的一个重要问题。</sample>
    <sample id="451">我们没有一个公共数据集,一个大规模的公共数据集用于任务,所以我们使用人群注释收集一个。我们的数据集涵盖了三个不同的领域,音乐,书籍和。</sample>
    <sample id="452">我们的数据集收集方法强调使用卡通完成集的非正式性。</sample>
    <sample id="453">卡通有三个语音泡泡。在第一个泡泡中,鲍勃说,还记得我们昨天听的那首歌吗?与此相关,鲍勃设置了对话的上下文。</sample>
    <sample id="454">在第二个演讲泡泡中,爱丽丝说,你是说轻易对我,还是我有感觉?</sample>
    <sample id="455">这是替代问题,在第三个演讲泡泡中,鲍勃使用间接的朋友来选择其中一个实体。例如,新的。</sample>
    <sample id="456">我们自动提供第一个和第二个语音泡泡,但第三个语音泡泡是由注释者填写的。第一个语音泡泡从每个域的几个手动提示中选择。</sample>
    <sample id="457">第二个问题是替代问题,如下所示。</sample>
    <sample id="458">我们总是使用一个简单的模板。你是说A还是B，其中A和B是来自维基百科的样本。</sample>
    <sample id="459">以下是我们使用的不同采样方法。当我们在列表中移动到更高的位置时,实体变得更加相似,并且通常更难进行消除歧义。</sample>
    <sample id="460">第一个是均匀攻击。</sample>
    <sample id="461">第二个是实体具有相似标题的情况。例如，两个书名为《退稿》的书。</sample>
    <sample id="462">第三个是当他们在维基百科上有类似的描述时,最后当他们在维基百科上有类似的信息框或属性时。例如,同一类型或同一艺术家。</sample>
    <sample id="463">当我们向评审团展示这个替代问题时,他们知道这些实体的名称,但他们不一定知道这些实体。</sample>
    <sample id="464">所以我们所做的就是展示一些关于这两个实体的背景知识。对于歌曲,我们只需显示每首歌曲的谷歌搜索链接即可。</sample>
    <sample id="465">然后要求注释者至少听一首歌并阅读一首歌。以下是该歌曲的谷歌搜索结果示例。</sample>
    <sample id="466">对于食谱和书籍域,我们从维基百科显示一些背景文本。对于食谱,我们还从维基百科显示他们的图像,以便注释者知道它们的外观。</sample>
    <sample id="467">然后,我们要求注释者选择其中一个实体。例如,在这里,第一个实体,并用三到五个间接引用表达式来描述它们。</sample>
    <sample id="468">例如，钢琴音乐的那个。以下是我们数据集中的一些示例。例如,没有文字的那个,不是那个十二岁男孩的那个,或者虚构的那个,或者来自阿塞拜疆和斯洛文尼亚的那个。</sample>
    <sample id="469">实体语料库包含三种领域的六千个替代问题,并且具有四万两千个间接引用表达式。使用T五X大型模型的结果总结如下。</sample>
    <sample id="470">如果语言模型可以访问与注释者完全相同的背景知识,那么准确性确实很高。它在百分之九十二到百分之九十五左右。但这并不现实。</sample>
    <sample id="471">如果语言模型可以访问一些部分重叠的背景知识,那么准确率在百分之八十二到百分之八十七之间,这更现实。例如,当语言模型检索背景知识时。</sample>
    <sample id="472">如果语言模型只能访问实体名称,那么准确性只有百分之六十,因此有很大的改进空间。我们还证明了模型是域泛型的。以下是链接到我们的数据集。谢谢。</sample>
    <sample id="473">该方法与 White-Key 策略和 Local Agreement 策略进行了比较。</sample>
    <sample id="474">The author of the paper is affiliated with the University of Montreal.</sample>
    <sample id="475">演讲者的名字是Jenny。</sample>
    <sample id="476">The paper "Marked Personas: Using Natural Language Prompts to Measure Stereotypes in Language Models" has three authors: Myra, Eszter Dermus, and Dan Jrausbeck.</sample>
    <sample id="477">嗨，我是来自特伦托大学和布鲁诺·凯斯勒基金会的Sarah Papi,我将简要介绍一下Simultaneous Speech Translation的注意力指南论文,这是与Matteo Negri和Marco Turchi共同完成的工作。</sample>
    <sample id="478">什么是同时翻译？同步翻译或SimulSt是将口语翻译成另一种语言的文本的过程，实时实现跨语言交流。</sample>
    <sample id="479">当前的simulST模型存在哪些问题？通常使用特定架构进行训练,并引入其他模块进行优化。</sample>
    <sample id="480">漫长而复杂的培训程序。例如，涉及不同优化目标的培训。</sample>
    <sample id="481">并训练和维护几个模型以达到不同的延迟。比如训练一个模型的平均延迟为一秒钟，另一个为两秒钟，依此类推。</sample>
    <sample id="482">那么我们的解决方案是什么呢?</sample>
    <sample id="483">首先,使用现有的离线ST模型,无需重新训练或采用特定的STMST架构。只使用一个模型来处理每个延迟模式,并通过特定参数处理延迟。</sample>
    <sample id="484">并利用所获得的知识通过注意力机制在音频输入和文本输出之间进行模型训练。也就是说,跨注意力机制。你可以在右边看到一个示例。</sample>
    <sample id="485">我们的解决方案是提出一个DAT或编码器解码器注意力,它是一个策略,我们决定是否根据注意力指向的地方是否发出部分翻译。</sample>
    <sample id="486">如果注意力不集中，意思是这个和的总和低于一个阈值alpha，朝着最后一个lambda语音帧，这意味着接收到的信息不够稳定。</sample>
    <sample id="487">例如,如果我们收到一个包含我将要谈论的语音片段,并且我们的模型预测了德语的翻译。</sample>
    <sample id="488">我们将研究交叉注意力权重。</sample>
    <sample id="489">我们会看到前两个单词指向最早收到的语音帧，而最后一个单词指向最后收到的语音帧。</sample>
    <sample id="490">这意味着前两个单词将被省略。</sample>
    <sample id="491">虽然由于交叉注意力的总和高于一定的比率α，我们不会发出最后一个单词，而是等待另一个语音信号。</sample>
    <sample id="492">如果我们继续并收到另一个演讲,并且我们的模型预测了另外三个单词,我们将查看交叉注意力权重。</sample>
    <sample id="493">我们会看到没有单词指向最后一个lambda语音帧。</sample>
    <sample id="494">这意味着这三个字将被省略。</sample>
    <sample id="495">如果你看看这方面的主要结果。</sample>
    <sample id="496">我们将同时翻译的结果绘制在图表上,其中一侧为蓝色,用于测量翻译质量和平均滞后。</sample>
    <sample id="497">这是延迟度量值,我们还考虑了计算意识的平均差距,它考虑了模型的计算时间来预测输出。</sample>
    <sample id="498">所以我们希望我们的曲线在这张图上尽可能高。</sample>
    <sample id="499">但是我们也希望它们向左移动。</sample>
    <sample id="500">我们还与适用于离线模型的策略进行比较,即waitkey策略和本地协议,并与专门针对多语言翻译的最新技术进行比较。</sample>
    <sample id="501">这些都是德语的同时对翻译策略的结果。</sample>
    <sample id="502">我们看到,对于离线模型,adout的表现优于所有策略,因为其曲线向左移动。</sample>
    <sample id="503">我们也看到，如果我们考虑实际的过期时间或计算的实际时间，那么这是最快的策略。</sample>
    <sample id="504">如果您想了解更多结果，请阅读我们的论文。我们还发布了开源代码、模型和同时输出，以促进我们工作的可重复性。感谢您的关注。</sample>
    <sample id="505">是的，数据集是公开的。</sample>
    <sample id="506">大家好，我叫Ying，我的同事Zhi Yang和我将要介绍我们的研究Multi-Instuit，改进多模态神经网络的学习通过指导调整。</sample>
    <sample id="507">因此，随着大型语言模型的进步，许多工作开始探索使用预训练语言模型以参数和数据高效的方式进行不同的下游任务的新学习范式。</sample>
    <sample id="508">最近，许多研究表明，指令调优使大型语言模型能够以自然指令的方式在短时间内执行看似不可能的任务。</sample>
    <sample id="509">然而，之前的大多数关于指令调优的工作都集中在改进语言任务上。仅在计算机视觉和多模态任务中被排除在外。</sample>
    <sample id="510">因此，在这项工作中,我们想要研究一下,在多模态预训练模型上是否可以通过调整指令来改善对NC多模态任务的泛化。</sample>
    <sample id="511">此外，在我们研究的时间，我们发现了rlp和多模态之间可用的指令数据集存在相当大的差异。</sample>
    <sample id="512">存在超过一千六百个语言单独的指令任务。然而，没有大型公开可用的多模态指令任务。因此,这激励我们构建一个多模态指令调优数据集。</sample>
    <sample id="513">在这里我们介绍了MultiInstruc,第一个多模态指令调优基准数据集,由62个不同的多模态任务组成,涵盖了十个板类别。</sample>
    <sample id="514">这些任务来自于二十一个现有的开源数据集，每个任务都配备了五个专家写的说明。</sample>
    <sample id="515">为了在我们所提出的数据集上研究多模态指令调优,我们采用OFa作为我们的基础模型。OFa使用统一的语言、图像词和边界框的坐标。</sample>
    <sample id="516">在这里我们展示了来自多种类型数据集的示例。</sample>
    <sample id="517">统一处理各种输入和输出数据类型。</sample>
    <sample id="518">我们遵循OFA的方法,并将所有任务以统一的序列到序列格式进行表述,其中输入文本、图像、指令和边界框都以相同的标记空间表示。</sample>
    <sample id="519">好了，现在我要讲讲多模态指令调谐。</sample>
    <sample id="520">因此，对于训练数据集,我们使用来自NLG的53个任务进行训练,并对每个任务进行10,000次采样。对于测试,我们保留整个CommonsenseReasoning组进行测试,并从VQA和恶意组中选择另外5个任务。</sample>
    <sample id="521">我们在每个任务中都使用测试集中的所有实例。此外，我们从自然指令的测试集中随机抽取20个任务作为NLP任务。</sample>
    <sample id="522">因此,我们使用预训练的OFA大型模型作为基础模型。在训练过程中,我们将所有任务的实例混合在一起。每个实例都与其五个指令模板中的一个随机组合。</sample>
    <sample id="523">因此，在测试每个任务时,我们通过评估每个实验中的五个指令中的一个来进行总共五次实验。</sample>
    <sample id="524">我们报告了所有五个实验中性能的均值、最大值和标准差。</sample>
    <sample id="525">如果任务是多模态分类任务,我们报告准确率。如果是多模态生成任务,我们报告rougeL。对于NLP任务,我们也报告rougeL。</sample>
    <sample id="526">我们还引入了额外的评估指标 sensitivty, 这衡量模型在任务相同的情况下,无论任务排序如何变化,始终能够一致产生相同的输出。</sample>
    <sample id="527">这是我们的主要结果。正如我们所看到的,指令调优可以显著提高OS的性能。我们在同一任务上看到多模态。</sample>
    <sample id="528">此外，从自然语言数据集进行转移学习也可以带来语法调整的好处。</sample>
    <sample id="529">在这里我们可以看到,随着任务数量的增加,模型的性能提高,同时敏感性降低。</sample>
    <sample id="530">因此,我们还做了一个实验。我们使用一个指令与五个指令。正如我们所看到的,使用更多的指令可以显著提高模型的整体性能并降低其敏感性。</sample>
    <sample id="531">所以这显示了不同的微调策略对模型敏感性的影响。正如我们所看到的,通过从自然语言数据集中转移学习,模型可以比原始的OFA模型实现更好的敏感性。</sample>
    <sample id="532">我们也可以看到,从自然指令数据集的转移学习可以帮助OFA在自然指令数据集上获得更好的性能。</sample>
    <sample id="533">总的来说,我们提出了第一个大规模的多模态调优数据集。我们显着提高了OFA的零射程能力,并探索了不同的迁移学习技术,并展示了它们的优势。我们设计了一个新的指标 sensitivty。</sample>
    <sample id="534">还有一件事。我们正在收集一个更大的多模态指令调优数据集,其中包含大约一百五十个额外的视觉语言任务,我们将发布它们,所以这是一个QR代码,用于我们的数据和模型。谢谢。</sample>
    <sample id="535">The authors of the paper are affiliated with the University of Trento and Fondazione Bruno Kessler.</sample>
    <sample id="536">Javad Hosseini</sample>
    <sample id="562">大家好，我是KoustavSinha,很高兴欢迎大家参加我们的演讲。我们的ACL二零二三论文语言模型接受度判断并不总是对上下文鲁棒。</sample>
    <sample id="563">这是与John Gauthier, Aaron Mueller, Kanishka Mishra, Karen Fentress, Roger Levy和Atina Whelan的联合工作。</sample>
    <sample id="564">因此，在这项工作中,我们重新审视了最小对偶范式。</sample>
    <sample id="565">因此,最小对对时间基本上评估语言模型的可接受性判断,这也可以包括语法性,例如,语法或在刻板印象方面的可接受性,例如,粗鲁的对。</sample>
    <sample id="566">在这种最小对偶范式中,评估语言模型的典型方法是,你展示一个可以接受的句子或语法句子,然后你展示一个不可接受的句子或不语法句子。</sample>
    <sample id="567">然后希望这个模型基本上会给可接受的结果赋予更多的概率。</sample>
    <sample id="568">当前的MPP管道基本上不允许我们评估模型对更长句子的接受程度。</sample>
    <sample id="569">这些天,大型语言模型的上下文窗口越来越长,因此至关重要的是,我们要评估模型在整个上下文窗口的可接受性。</sample>
    <sample id="570">这就是我们在这里试图做的。我们试图通过要求模型对更长的序列进行可接受性评估来重新审视MPB管道。</sample>
    <sample id="571">所以这是方法。所以我们所做的是,为了模拟这些更长的序列,我们重新审视数据集本身,然后我们通过选择可接受或不可接受的句子来重建句子。</sample>
    <sample id="572">例如,在这里我们选择了来自附属岛屿案例的典型语法对。</sample>
    <sample id="573">我们所做的是重建更长的序列,这些序列是可接受的,并且具有相同的语法结构。我们从其他语言中提取语法句子。</sample>
    <sample id="574">然后我们将其添加为可接受查询和不可接受查询的前缀。</sample>
    <sample id="575">所以我们可以通过选择不合适的句子来做同样的事情,从相同的匹配中,这也可以用来测试模型的可接受性。</sample>
    <sample id="576">我们也可以通过选择来自不同子集或不同数据集的句子来做到这一点。这就是我们所说的匹配不匹配的情况。</sample>
    <sample id="577">所以这里的句子仍然来自相关的数据集,但它不是来自您正在评估的数据集,我们也可以对不可接受性情况做同样的事情。</sample>
    <sample id="578">最后,我们可以从一个完全无关的领域中选择句子,例如维基百科。</sample>
    <sample id="579">因此,这将告诉我们,比如说,模型的可接受性判断是否真的受到任何上下文的影响。</sample>
    <sample id="580">就像上下文来自数据集的不同子集,或者它是否与我们正在查看的句子完全无关。</sample>
    <sample id="581">那么模型是如何工作的呢?首先,我们来看看维基百科句子,这些句子与当前的查询对完全无关,在那里我们发现MPP的判断对于任意上下文线索都很健壮。</sample>
    <sample id="582">我们将上下文长度增加到一千二百二十四,以最大化OPT和GPT2模型,我们在橙色的点线中看到,MPP的判断相对稳定。</sample>
    <sample id="583">现在,当我们从同一数据集中选择句子时会发生什么?</sample>
    <sample id="584">所以在这里我们是选择或创建句子从可接受和不可接受的域从同一个语法数据集。</sample>
    <sample id="585">我们看到MPP判决要么增加要么减少显着。当你添加可接受的前缀或不可接受的前缀时。</sample>
    <sample id="586">但是当我们匹配结构时,也就是说当我们从同一现象中选择句子时,责备人文本吉姆。</sample>
    <sample id="587">我们看到模型的MPP判断有巨大的增加或减少,这取决于所选的前缀是否可以接受。</sample>
    <sample id="588">现在这个和这个是非常大的,就像这个效果在整个上下文长度中增加,这可能会影响到像新的语言模型这样的东西,它有很大的上下文窗口。</sample>
    <sample id="589">那么,为什么匹配前缀会对语言模型的判断产生如此大的影响呢?</sample>
    <sample id="590">因此,我们进行了分析系列,我们尝试通过添加噪声来扰乱输入句子,但保留了相关结构,并在做了几次扰动之后。</sample>
    <sample id="591">我们发现这些噪音中没有一个实际上会使模型改变其方向。</sample>
    <sample id="592">基本上我们发现模型对扰动句子和类似的句子都很敏感。</sample>
    <sample id="593">也就是说,当我们扰动可接受域中的句子时,我们看到所有扰动的增加,当我们扰动不可接受域中的句子时,我们看到MPP判断以类似的方式下降。</sample>
    <sample id="594">因此,我们工作的关键结论是,语言模型对句子中共享的潜在语法和语义特征敏感。</sample>
    <sample id="595">而MPT评估的方式,我们目前用短语和单个句子输入的方式,可能无法完全捕捉到语言模型在上下文窗口中的抽象知识。</sample>
    <sample id="596">请阅读我们的论文以获取有关我们实验的更多详细信息。感谢您的收听。</sample>
    <sample id="597">Unordered multi-set of tokens</sample>
    <sample id="598">55,000</sample>
    <sample id="626">DEplain 的最佳对齐方法是 mass-align 方法。</sample>
    <sample id="627">弱监督学习可以训练更健壮的模型，能够在存在标签噪声的情况下更好地泛化。</sample>
    <sample id="628">手动对齐：左边的标题、右边的标题、左边的副标题、右边的副标题、左边的正文、右边的正文、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的注释、右边的注释、左边的</sample>
    <sample id="629">The CoNLL++ dataset was created by collecting data from Reuters News in 2020 and annotating it using the same CoNLL-2003 annotation guidelines.</sample>
    <sample id="630">大家好,我的名字是YuxinZhang来自宾州大学。今天我要介绍一下我们在多种自然语言和多种表示形式中进行的跨语言语义解析的工作。</sample>
    <sample id="631">因此,语义解析是构建用户查询的语义表示的任务,例如SQL和lambda计算。</sample>
    <sample id="632">跨语言语义解析是将多种自然语言中的查询转换为多种语义表示的任务。</sample>
    <sample id="633">如图所示,我们需要使用神经模型将查询翻译成多种自然语言,以便使用SQL、lambda或funql等。</sample>
    <sample id="634">现有的跨语言语义解析模型是单独提出和评估的。数据集有限的任务和应用。例如。</sample>
    <sample id="635">有一些关于某些自然语言的报道。中国人缺少。</sample>
    <sample id="636">克利克斯对某些媒体的报道进行了报道。</sample>
    <sample id="637">缺少lambda微积分。</sample>
    <sample id="638">或者它们只在某个神经模型上进行评估。例如,只有一个单一的模型来评估它们。</sample>
    <sample id="639">为此,我们提出了示例集,为多种自然语言和多种表示的跨语言语义解析提供了一个统一的数据集示例。</sample>
    <sample id="640">它包含九十个数据集在各种领域,五个语义分割任务,八百万表示和二十二种自然语言,十五个语言家族。</sample>
    <sample id="641">为了更好地评估我们的基准,我们考虑了六个用于训练和评估的设置。</sample>
    <sample id="642">第一个是翻译测试。我们使用谷歌翻译API将源语言翻译成目标语言。然后使用单语言模型进行训练和评估。</sample>
    <sample id="643">例如,我们在英语查询上训练了英语模型,并在推理过程中使用API将德语查询翻译成英语,然后使用训练好的模型来预测SQL。</sample>
    <sample id="644">我们也测试了单语言模型。</sample>
    <sample id="645">在这种设置中，源语言与目标语言相同。例如,德语到德语或英语到英语。</sample>
    <sample id="646">我们还测试了单语言场景设置,通过训练单语言模型,仅使用训练数据的百分之十。</sample>
    <sample id="647">它有多语言模型,我们为所有语言训练一个多语言模型。</sample>
    <sample id="648">例如,我们将德语、英语、中文查询放在一起训练一个多语言模型,并在推理过程中,我们可以使用这个模型。</sample>
    <sample id="649">翻译德语查询或中文查询等。</sample>
    <sample id="650">我们还考虑了crosslingo,zero-shot和few-shot转移。我们在一个源语言上训练,然后转移到另一个语言上。</sample>
    <sample id="651">所以在训练过程中,我们在英语查询或英语和德语查询的组合上进行训练,以训练一个多语言模型来预测SQL输出。</sample>
    <sample id="652">我们也发现了许多有趣的结果。因此,关于单语言模型的分析,我们评估了两个模型组。</sample>
    <sample id="653">包括编码器PDR,它代表多语言预训练编码器与基于指针的解码器,如xlmr加PDR和mbert加PDR。</sample>
    <sample id="654">我们还评估了编码器解码器模型,即多语言预训练的编码器解码器模型,例如mbart和mt五。</sample>
    <sample id="655">我们发现编码器解码器在所有九个数据集上都获得了最佳性能。</sample>
    <sample id="656">我们在MT五和示例上进行评估。XL和R加上PDR在多语言设置上。</sample>
    <sample id="657">我们发现编码器解码器或编码器PDR可以通过在各种语言的混合中进行训练来改进。</sample>
    <sample id="658">我们发现,这是因为大多数主要自然语言都可以获得性能提升,除了英语性能在七个数据集中下降,只有在三个数据集中获得提升。</sample>
    <sample id="659">我认为这被称为多语言的诅咒。</sample>
    <sample id="660">我们还比较了交叉链接性能获取。</sample>
    <sample id="661">在这张图中，蓝线是跨语言的少数转移。橙线是跨语言的零转移。</sample>
    <sample id="662">我们发现,通过比较绿色和橙色线,我们发现零短期设置的跨语言转移性能差距是显著的,通过比较蓝色和橙色线,我们发现通过短期设置的转移差距迅速缩短。</sample>
    <sample id="663">我们还发现了一些其他有趣的发现。例如,编码器解码器超越了prows的工作或实现了相当的结果。对于基于英语自然语言的训练,可以显著提高目标自然语言的性能。</sample>
    <sample id="664">我们发现多语言模型，如Codas和Blue仍然不适合跨语言语义解析任务。</sample>
    <sample id="665">总而言之,我们构建了一个用于多种自然语言和中间表示的跨角度语义解析的统一基准测试。</sample>
    <sample id="666">我们对三种代表性的多语言模型类型进行了全面的基准测试。我们的结果显示了许多有趣的发现等等。欢迎访问我们的论文和代码。感谢您的收听。</sample>
    <sample id="667">Existing works on the subject can be broadly classified into four categories: theoretical frameworks, empirical studies, case analyses, and comparative research. These categories encompass a wide range of studies that explore various aspects of the topic, providing insights into its complexities and nuances.</sample>
    <sample id="668">不，Codex 和 Bloom 等多语言 LLM 对于 CLSP 来说还不够。</sample>
    <sample id="695">The method addresses the uncertainty in permutations by using a flexible permutation method and incorporating alignment into the training process. It also employs a GPU-friendly continuous relaxation technique to approximate the highest scoring permutation, which is NP hard, and allows for backpropagation to learn more plausible permutations.</sample>
    <sample id="696">下游 NLP 模型的公平性可以定义为其在处理和生成文本时，不会因人种、性别、年龄、地理位置、政治观点或其他社会属性而产生不平等或歧视的结果。公平性涉及确保模型的输出不偏向特定群体或偏离公平的标准。</sample>
    <sample id="697">演讲者的名字是Yanis Lavrik。</sample>
    <sample id="698">演讲者的名字是Koustav Sinha。</sample>
    <sample id="699">演讲者的名字是Myra。</sample>
    <sample id="700">在本文的背景下，热带主义指的是一种刻板印象，描绘拉丁裔女性为充满活力和热情的形象，通常与热带地区的气候和文化联系在一起。</sample>
    <sample id="701">作者通过使用特定的词汇来创建目标群体的人工描写，这些词汇包括“文化”、“传统”、“骄傲”和“异国情调”。这些词汇不仅定义了这些群体，还强调了它们与白人标准的不同。</sample>
    <sample id="702">本文中使用了 "pointwise cXMI" 来衡量语境使用情况。</sample>
    <sample id="703">DrBERT 是基于 7GB 的自然语言处理数据集，而 ChuBERT 是基于 4GB 的自然语言处理数据集和 4GB 的临床笔记。</sample>
    <sample id="751">这篇论文有两位作者。</sample>
    <sample id="752">迭代迁移学习是通过在每个训练周期中更新模型，以便在新数据集上进行训练。</sample>
    <sample id="753">数据集的目标是理解用户在选择时使用的语言。</sample>
    <sample id="754">攻击者通过利用 EaaS 的可访问性和可扩展性来提取模型参数。</sample>
    <sample id="755">The paper has three authors: Sara Papi, Matteo Negri, and Marco Turchi.</sample>
    <sample id="756">10个注释者。</sample>
    <sample id="757">Carnegie Mellon University</sample>
    <sample id="758">在给定的例子中，左侧的支配词是 "I saw Bart and Lisa"。</sample>
    <sample id="759">对话系统中的最先进模型是ChatGPT。</sample>
    <sample id="760">我们需要在整个上下文窗口中评估模型的可接受性，因为大型语言模型现在具有更长的上下文窗口，这对于确保其在不同情境下的准确性和相关性至关重要。</sample>
    <sample id="761">是的，多语言训练可能会导致表现下降，因为在七个数据集中，英语模型的性能下降，而在三个数据集中则有所改善。</sample>
    <sample id="762">不，注释者并不提前知道该实体。</sample>
    <sample id="763">使用了BLEU、METEOR、TER、F1和ROUGE指标。</sample>
    <sample id="764">不，泛化中的回归不会影响特定的 NER 类型。</sample>
    <sample id="765">NLP 中的立场很重要，因为它影响了模型的性能和公平性，特别是在处理不同文化和语言背景时。</sample>
    <sample id="766">像 BLOOM 这样的多语言 Large Language Models (LLM) 通常采用完整微调，而不是适配器微调。</sample>
    <sample id="767">他们使用了基于C-E-E的模型进行迁移学习。</sample>
    <sample id="768">Recent tests used to evaluate PaLM's capabilities include the "Hugging Face Benchmark" and "LLaMA Benchmark."</sample>
    <sample id="769">三条</sample>
    <sample id="770">提议的方法获得了 4.4% 的收益。</sample>
    <sample id="771">演讲者的名字是Shu-Heng。</sample>
    <sample id="772">是的，论文中的结果和数据集可以用作基准。</sample>
    <sample id="773">他们在论文中进行了五个较小模型的实验。</sample>
    <sample id="774">The model used as the base model for investigating multimodal instruction tuning is OFA (Unified Multi-Modal Pretraining Model).</sample>
    <sample id="833">The authors of the paper "Prompting Prompt for Translation: Assessing Strategies and Performance" are affiliated with Google Translate. However, specific institutional details may not be provided in the given information.</sample>
    <sample id="834">Stony Brook University</sample>
    <sample id="835">The paper analyzes English language.</sample>
    <sample id="836">演讲者的名字是Xiangbing。</sample>
    <sample id="837">在实验过程中研究了两个模型：一个用于生成文档级简化，另一个用于生成句子级简化。</sample>
    <sample id="838">在 MultiInstruct 中，53 个任务用于训练目的，而 5 个任务来自 VQA 和 Miscellaneous 群体用于测试目的。总共使用了 58 个不同任务（53 + 5）。</sample>
    <sample id="839">The paper has 4 authors.</sample>
    <sample id="840">AG NEWS, MIND, SSTD2, ERIS-PAM</sample>
    <sample id="876">NACHOS是一个用于训练 Dr. Bert 模型的医疗数据集，包含来自网络的医疗数据。</sample>
    <sample id="877">演讲者的名字是Ayed Bilal。</sample>
    <sample id="878">提示策略对结果有显著影响，特别是在LLMs的翻译性能上。通过使用不同的提示，实验显示了其对结果的影响。</sample>
    <sample id="879">这篇论文的作者所属机构是哥伦比亚大学。</sample>
    <sample id="880">5 个由专家编写的指令是：</sample>
    <sample id="881">通过评估数据集和人类研究参与者，建立并测试模型。</sample>
    <sample id="882">大家好，我是Aydil Bilal,我将给大家简要介绍一下这篇论文《Prompting Prompt for Translation: Assessing Strategies and Performance》。这是我和谷歌翻译的同事们共同完成的工作。</sample>
    <sample id="883">Param是一个五百四十亿个参数的slate语言模型，去年在2022年提出。它在大量文本集上进行训练，包含七亿八千万个令牌。</sample>
    <sample id="884">在发布时,它在数百个NLP任务中实现了最先进的技术。</sample>
    <sample id="885">在这项工作中，我们提出了第一项系统的语言模型提示研究。</sample>
    <sample id="886">我们评估了这些模型的转换能力。使用MT社区的最佳实践。这涉及使用最新的测试集来避免测试数据与语言模型的训练数据重叠。</sample>
    <sample id="887">我们比较了两种最先进的系统,所以最好的性能系统是WMT评估。</sample>
    <sample id="888">我们使用最先进的神经网络指标。此外,还显示了基于专家的人工评估结果。最后,我们提供一些提示选择策略的建议。</sample>
    <sample id="889">提示对LLM的翻译性能有很大的影响。我们可以在一个简单的实验中看到这一点，其中我们使用了一次性提示，并为每个句子提供了两个不同的提示。</sample>
    <sample id="890">句子中的大多数句子，五百六十个出一千个。观察到的差异是超过一个模糊点。</sample>
    <sample id="891">在极端情况下,这可以达到四十个点,因此重要的是要选择一个好的提示策略。</sample>
    <sample id="892">在我们的实验中,我们选择了五次拍摄的提示策略,我们只标记我们提供给系统的每个句子,它的语言是。</sample>
    <sample id="893">在这个示例中，我们从德语翻译成英语，德语句子用德语列出，英语翻译用英语列出。</sample>
    <sample id="894">我们看到实际形式的提示在几何短提示的情况下并没有很大的影响。</sample>
    <sample id="895">对于零和一枪提示至关重要。当我们进入五枪提示时,实际上提示的形式几乎没有差异。</sample>
    <sample id="896">是举例子带来的影响最大。</sample>
    <sample id="897">我们实验结果的总结是，示例质量比源句的相似性更重要。</sample>
    <sample id="898">因此,从高质量翻译中选择示例很重要。特别是,我们比较从WMT评估或dev数据的训练数据中选择提示。</sample>
    <sample id="899">深度数据比训练数据更准确和更高质量,因此使用深度数据时的结果更好。</sample>
    <sample id="900">尽管如此，专门的最先进系统在与PAM翻译相比具有显著优势,但PAM非常接近我们的商业系统。在我们的情况下,我们选择使用谷歌翻译。</sample>
    <sample id="901">我们从使用MPO框架进行的EMG分析中获得的见解是，手掌的流畅度与最先进的系统相当,但主要区别来自准确性。</sample>
    <sample id="902">特别是最常见的错误是遗漏错误。</sample>
    <sample id="903">所以它似乎选择了更好的声音翻译，有时通过删除源句子中被翻译的部分。</sample>
    <sample id="904">然而,对于PAM的样式awkward类别比对于最先进的系统的类别要低,这是一条额外的信号。</sample>
    <sample id="905">该参数提供了非常流畅的输出,但仍然存在一些准确性问题。</sample>
    <sample id="906">这就是这个非常简短的概述。对于更多细节,请来到论文的完整演示。非常感谢。</sample>
    <sample id="907">你好，我是大伟，德国萨兰特大学的博士生。在本视频中，我想介绍一下我们最近的工作。比你想象的更短。对每周监督学习的批判性看法。</sample>
    <sample id="908">这是与肖玉申、马约斯·穆斯巴、格雷厄斯·斯蒂芬和迪特里希·克拉科夫的联合工作。</sample>
    <sample id="909">我想从弱监督和弱监督学习的简要介绍开始。</sample>
    <sample id="910">在弱监督中,我们不手动标记数据。相反,我们使用弱标记源标记数据,例如简单的启发式规则、知识库或低质量的外包,如右图所示。</sample>
    <sample id="911">与人类注释相比，弱注释要便宜得多,但它们也很嘈杂,这意味着一定数量的注释是错误的。</sample>
    <sample id="912">如果我们直接在每周的标签数据上训练神经网络,神经网络往往会记住标签噪声,而不会泛化。</sample>
    <sample id="913">在弱监督学习中，提出的训练算法旨在在这种标签噪声下强大地训练神经网络，使得训练的模型仍然能够很好地泛化。</sample>
    <sample id="914">在最近的WSL工作中,所以WSL代表每周监督学习。一个常见的说法是,人们说他们只在每周标签数据上训练模型,并在干净的测试集上实现高性能。</sample>
    <sample id="915">从技术上讲,这个说法并不错,但有一个陷阱。</sample>
    <sample id="916">人们确实假设有一个额外的清洁验证集可用于模型选择。</sample>
    <sample id="917">我们不能对这个问题设置停止,因为这意味着在弱监督学习中需要额外的手动注释。但就像房间里的大象一样,这种必要性往往被忽视。</sample>
    <sample id="918">上述疑问使我们提出了三个研究问题。首先,清洁验证数据是否对于WSL必要?或者我们也许可以用一个噪声验证集来代替?</sample>
    <sample id="919">其次,如果需要清洁数据,或者清洁数据是WSL工作所必需的,那么我们需要多少个清洁样本?最后,我们是否只使用清洁样本进行验证,还是有更好的利用方式?</sample>
    <sample id="920">我们在工作中解决了这些研究问题,我们的发现如下。</sample>
    <sample id="921">首先,我们发现,有趣的是,最近的WSL方法确实需要清洁的白色盘子样本才能正常工作。</sample>
    <sample id="922">否则, 该图显示的性能下降很大。如果没有清洁验证样本,则训练模型无法超越原始弱标签。</sample>
    <sample id="923">这意味着训练是毫无意义的。</sample>
    <sample id="924">这表明WSL方法实际上需要清晰标记的数据才能正常工作,并且获取清洁验证样本的注释成本不应被忽视。</sample>
    <sample id="925">我们的第二个发现是,增加清洁验证样本的数量将有助于WSL方法实现更好的性能,如图所示。</sample>
    <sample id="926">通常，我们只需要每类20个样本就能达到高性能。</sample>
    <sample id="927">但这还不是故事的结尾,因为无论如何,如果我们决定直接使用干净的样本,那么在它们上进行训练甚至会获得更好的性能。</sample>
    <sample id="928">右图显示了在直接应用于干净数据和使用干净数据仅用于验证的WSL方法之间的性能差异。</sample>
    <sample id="929">如我们所见,如果我们每个类有十个样本,则直接微调开始击败WSL方法。</sample>
    <sample id="930">最后,在之前的WSL方法中声称的性能改进可以通过允许在清洁验证样本上进行细微调整来轻松实现。</sample>
    <sample id="931">如图所示，瓦利纳模型，称为FTW，最初表现不佳。更复杂的WSL方法，如cosine。</sample>
    <sample id="932">但是,如果我们允许在干净的样本上继续微调,那么FTW的性能与其他方法相当。</sample>
    <sample id="933">因此，在实践中,没有理由选择更复杂的WSL方法,这些方法需要更多的计算时间和磁盘空间。</sample>
    <sample id="934">总而言之,我们表明,最近的WSL方法需要清洁的手动注释样本,以便它们正常工作。它们的性能提升和实用性被严重高估了。</sample>
    <sample id="935">我们对未来工作的具体建议如下。</sample>
    <sample id="936">首先报告模型选择标准。例如,报告模型选择是否在干净的验证样本上进行。</sample>
    <sample id="937">第二,WSL方法应与基于短期学习的基线进行比较,因为它们都在清晰的样本上工作。第三,连续微调是一个简单而强大的基线,应该在WSL的未来工作中考虑。</sample>
    <sample id="938">最后,我们公开了我们的代码。您可以通过此幻灯片上的QR代码找到它。欢迎您查看。谢谢大家,祝大家愉快地参加会议。</sample>
    <sample id="939">对话系统的常用评估方法是使用人类评估，例如让人类评委选择哪两段对话更好，或者根据利卡德评分标准对对话进行评分。</sample>
    <sample id="940">The paper has four authors.</sample>
    <sample id="941">在 Servin 和 Kea 的示例中，需要的背景知识是：法官在法庭上决定案件。</sample>
    <sample id="942">是的，代码是公开的，可以在GitHub上找到。</sample>
    <sample id="943">不，NLPositionality 的注释者在各个人口统计学特征（例如国家/地区、性别等）方面并不均衡。</sample>
    <sample id="944">在可接受的域中扰乱句子的方法包括添加噪音到输入句子，同时保持其结构的相关性。</sample>
    <sample id="945">进行维度评估意味着评估模型在不同方面的性能和质量，通常通过评估多个相关的指标或维度来更全面地了解其优点和缺点。</sample>
    <sample id="946">The author of the paper is from the University of Science and Technology of China.</sample>
    <sample id="947">提示的形式在零和一枪提示中很重要。</sample>
    <sample id="978">作者评估了与人类对话的对话模型。</sample>
    <sample id="979">The paper "Are You Copying My Model? Protecting the Copyright of Large Language Models for Embedding and Services via Backdoor Watermark" has 3 authors.</sample>
    <sample id="980">优秀规划器的理想品质包括能够将抽象目标转化为具体、现实的目标，并且能够考虑多方面的限制和约束。他们还应该能够制定合理且符合这些限制的计划。</sample>
    <sample id="981">The paper has 4 authors.</sample>
    <sample id="982">The speaker's name is Vasudha.</sample>
    <sample id="983">Sadam Skurovski</sample>
    <sample id="1021">PaLM 最常见的错误是遗漏错误。</sample>
    <sample id="1022">你好，我是JamesFinch。今天我们将向你们介绍ABCeval，这是一个新的维度方法来评估对话型人工智能。</sample>
    <sample id="1023">这项工作是由EmoryNLP实验室完成的，Emory大学的Gino Choi教授领导，Emory大学与AmazonAlexaAI合作完成。</sample>
    <sample id="1024">假设您刚刚开发了对话模型,并且您想了解它与当前的现状有多好。</sample>
    <sample id="1025">常用的方法是使用人类评估，例如让人类评委选择两段对话中哪一段更好，或者根据利卡德评分对对话进行评分。</sample>
    <sample id="1026">这些方法很好地提供了对对话整体质量的整体评估,但对话质量有许多方面。因此,您可能希望评估聊天质量的多个维度,以更好地了解模型的优点和缺点。</sample>
    <sample id="1027">一种方法是简单地让人类评委评估对话质量的几个维度，例如使用现有的比较或利克特量表方法来评估模型响应的相关性。</sample>
    <sample id="1028">但是，我们认为有一个更精确和可靠的策略来评估维度对话。</sample>
    <sample id="1029">我们的方法试图通过明确标注每个模型响应是否表达某些行为来减少人类评估的主观性，例如回答无关的信息或自相矛盾。</sample>
    <sample id="1030">我们称这种方法为注释聊天中的行为,简称ABCeval。我们开发了这种方法来全面涵盖聊天模型行为,这些行为被认为会影响聊天质量的最新文献。</sample>
    <sample id="1031">ABC eval 能够测量聊天模型在不同主题上的错误率。</sample>
    <sample id="1032">例如，ABC-eval测量聊天模型在多少次中忽略对方或说出无关的内容。</sample>
    <sample id="1033">与自己或其伴侣相矛盾，产生幻觉，提供错误的事实或违反常识知识，以及模型成功或未能表现出同理心的时间。</sample>
    <sample id="1034">为了确定什么样的评估最有效，我们选择了四个最先进的聊天模型，并在每个模型上评估了100个人机对话。使用ABC评估。</sample>
    <sample id="1035">为了进行比较,我们还使用了三种现有方法来评估这些对话。对话级别的Lickert评分和对话级别的对话级别对比。</sample>
    <sample id="1036">对于现有方法，我们收集了对八个最常测量对话方面的评估的评价。因为这是对多维度聊天模型的标准评估实践。</sample>
    <sample id="1037">根据我们对这些评估结果的分析,我们发现ABC评估行为标签总体上比现有方法收集的标签更可靠,通过对一百对双标记对话的内部评审员的协议来衡量。</sample>
    <sample id="1038">此外，ABC评估标签比现有方法产生的指标更能预测对话质量。正如这项简单的线性回归分析所显示的那样。</sample>
    <sample id="1039">例如，你可以看到衡量自我和配偶矛盾的比例如何解释了5%和10%的对话质量，而平均的Lickert一致性得分只解释了4%或更少。</sample>
    <sample id="1040">最后,我们使用分步线性回归检查每个评估指标是否捕获了聊天质量的独特方面。</sample>
    <sample id="1041">你可以看到所有ABC评估指标的组合如何解释超过百分之二十五的对话质量。随着你逐一删除指标,大多数指标都会导致失去大量关于质量的信息。</sample>
    <sample id="1042">另一方面，所有层次的Lickert指标组合解释的质量要少得多。</sample>
    <sample id="1043">这些可靠、信息丰富且独特的ABC评估指标使我们能够对对话式人工智能进行更高分辨率的评估，而以前的方法无法实现。</sample>
    <sample id="1044">你可以看到我们的实验结果中，仍然存在一些挑战，并且已经精确量化了。例如,我们测试的机器人在大约百分之二十的响应中存在常识性违规行为。</sample>
    <sample id="1045">他们在大约15%的回答中产生无关的信息,并且他们在大约10%的时间内与自己或他们的伴侣相矛盾。</sample>
    <sample id="1046">随着该领域的快速进步，许多这些错误率可能会在新模型发布时有所下降。因为我们进行的评估。然而,这更加强调了对可靠和精确的评估指标进行比较模型的追求。</sample>
    <sample id="1047">我们希望ABC评估可以被其他领域的人利用为朝着这个方向迈出有意义的一步。我们期待着看到在未来几个月和几年中，如何对话式人工智能的进步。感谢您的收看。</sample>
    <sample id="1048">这篇论文的作者所属机构是Emory Nlp Lab。</sample>
    <sample id="1049">CFT 代表 Continuous Fine-Tuning。</sample>
    <sample id="1050">这篇论文有8位作者。</sample>
    <sample id="1051">你好，我叫Yin，我将介绍我们的工作,标题为“当翻译需要上下文时：多语言探索的一个数据驱动方法”。这项工作是与Patrick Fernhout、Emil Liu、AndreF. DeMartins和Graeme Newbigg合作完成的。</sample>
    <sample id="1052">所以很多翻译都取决于上下文。例如，我们如何翻译这个句子中的“mole”？</sample>
    <sample id="1053">好吧，如果前一句话是“如果部长们发现了这一点，事情可能会变得危险”，那么“mo”指的是间谍。但如果前一句话是“这有什么严重的意义吗，医生？”那么“mo”指的是出生标记。</sample>
    <sample id="1054">因此,根据上下文,这个词的含义会改变,因此它的翻译也会改变。</sample>
    <sample id="1055">然而，评估模型如何处理这样的案例是相当困难的。首先，因为只有一小部分翻译依赖于上下文，这使得像BLEU这样的学术级别指标无法捕捉这些翻译。</sample>
    <sample id="1056">有些人建议对上下文依赖翻译进行定向评估,但这些资源仅支持有限类型的上下文依赖翻译和有限语言集,因为它们通常依赖于领域知识和人类创作。</sample>
    <sample id="1057">在这项工作中,我们试图回答这两个问题。首先,翻译需要什么样的上下文,以及第二个模型如何处理这些情况。</sample>
    <sample id="1058">为了解答第一个问题,我们首先测量了翻译过程中上下文的多少依赖。</sample>
    <sample id="1059">在之前的工作中,我们将CXMI介绍为机器翻译模型中上下文使用的度量标准,并通过测量上下文C在给定源X的情况下提供给目标Y的多少信息来完成。</sample>
    <sample id="1060">可以将CXMI视为从给模型提供上下文获得的信息。</sample>
    <sample id="1061">在这项工作中,我们将CXM扩展为点CXM,可以在句子级别或单词级别测量上下文使用。我们可以将具有高PCXM的单词视为需要上下文进行翻译的单词。</sample>
    <sample id="1062">现在我们分析高词素熵的单词,以寻找这些单词之间的模式。</sample>
    <sample id="1063">我们对TED演讲的讲义进行分析。</sample>
    <sample id="1064">我们对其进行分析的三个不同层次。首先,我们查看具有高平均PCSMI的部分语音标记。</sample>
    <sample id="1065">这使我们能够找到例如阿拉伯语中的双重代词,这些代词的PSMI相当高,这可以解释为英语没有双重代词,因此在翻译成阿拉伯语时需要上下文来确定代词是否是双重代词。</sample>
    <sample id="1066">同样地，我们发现某些语言在选择适当的动词形式时也需要上下文。然后我们查看词汇项的词汇量。XMI平均值在其所有不同出现次数上。</sample>
    <sample id="1067">这有助于识别像这里的案例,在中文中,你需要上下文来翻译名词,以确保你在文档中使用相同的翻译。</sample>
    <sample id="1068">同样,我们发现上下文支持在正确的形式中传输。</sample>
    <sample id="1069">最后,我们研究了具有高P、S、X、M、I的个别标记,这使我们能够识别出无法真正捕捉到的现象,但在句子结构中表达出来,例如省略号解析。</sample>
    <sample id="1070">现在我们使用我们分析的结果来设计文档本地翻译的基准。</sample>
    <sample id="1071">对于我们识别的五种话语现象中的每一种，我们创建了标记器来自动识别与现象相关的单词。我们称我们的标记器为多语言话语意识或MUDa标记器。</sample>
    <sample id="1072">我们也可以注意到,不同的语言有不同的比例。</sample>
    <sample id="1073">然后我们使用MUTT标记器,通过在我们想要用于评估的平行语料库上应用标记器,并在MUTT标记器识别的上下文依赖示例上应用我们选择的翻译指标。</sample>
    <sample id="1074">最后,我们使用我们的基准以及其他指标来评估不同的模型在文档级机器翻译上的表现。</sample>
    <sample id="1075">首先,当我们使用语料库级别指标时,对于蓝色,我们发现 Collinsagnostic 模型的表现最好。</sample>
    <sample id="1076">但是如果我们使用逗号，上下文感知模型的表现最好。如果我们使用单词f测量,那么上下文存在或不存在的模型的表现相当。</sample>
    <sample id="1077">这再次表明，如果我们仅使用语料库级别指标，就很难确定最佳的文档级别翻译系统。</sample>
    <sample id="1078">现在我们使用MoOLA基准来评估模型,我们发现上下文模型在某些话语现象(如形式和词汇连贯性)上比不使用上下文的模型要准确得多。</sample>
    <sample id="1079">但是这些模型并不比不使用上下文的其他现象（如省略号、代词和动词形式）的模型好得多。因此,这表明我们需要在文档级翻译方面取得更多进展。</sample>
    <sample id="1080">我们还比较了不同的商业系统。我们的基准测试表明，DeepL通常比谷歌翻译更准确。</sample>
    <sample id="1081">总而言之,我们对十四对语言进行了数据驱动的分析,以确定一个翻译所需的上下文。</sample>
    <sample id="1082">然后,我们使用我们的发现来构建一个文档级机器翻译的基准,这可以帮助我们确定哪些语义现象模型可以很好地处理,哪些翻译系统在文档级翻译方面表现良好。</sample>
    <sample id="1083">非常感谢您的关注，祝您一路顺风。</sample>
    <sample id="1084">演讲者的名字是Yuxin Zhang。</sample>
    <sample id="1121">没有名称。</sample>
    <sample id="1122">作者描述了“显性词汇”方法为一种识别方法，用于区分标记组和未标记组的单词。</sample>
    <sample id="1123">The author of the paper is affiliated with the University of Washington.</sample>
    <sample id="1124">对称依存关系结构的名称是Prague Approach，它以布拉格为中心。</sample>
    <sample id="1125">演讲者的名字是James Finch和Sarah Finch。</sample>
    <sample id="1126">这篇论文有四位作者。</sample>
    <sample id="1127">句法现象可以用句法数据集来测试。</sample>
    <sample id="1161">第一个研究问题的五种方法的缩写是WSDL。</sample>
    <sample id="1162">The model was evaluated on 11 biomedical and clinical downstream tasks.</sample>
    <sample id="1226">CamemBERT 最初是从 scratch 在 4GB 的数据上训练的。</sample>
    <sample id="1227">演讲者的名字是Sadam Scurcovsky。</sample>
    <sample id="1228">通过实验，我们发现随着时间间隔的增加，模型性能下降，这支持了时间漂移是性能下降的主要原因的假设。</sample>
    <sample id="1269">为了确保输出序列中的词元按照预期的语法和逻辑顺序排列，从而提供更清晰和有意义的结果。</sample>
    <sample id="1270">作者建议模型所有者提高偏见缓解方法的透明度，以便了解是否存在过度价值对齐或其他方法导致的负面刻板印象。</sample>
    <sample id="1271">最小对不可接受输入是一个不符合语法或语法规则的句子。</sample>
    <sample id="1272">作者使用了F1-Score作为评估指标。</sample>
    <sample id="1273">使用了内注释者一致性（Inter-annotator Agreement）来衡量注释者之间的一致性。</sample>
    <sample id="1274">在不可接受和可接受查询中，选择来自完全无关的领域，例如Wikipedia的句子来添加完全无关的内容。</sample>
    <sample id="1275">The authors of the paper are affiliated with the University of Leipzig and the University of Leipzig Center for Language and Speech Technology (LST).</sample>
    <sample id="1276">MultiInstruct 是一个针对多模态任务的基准数据集，旨在填补现有的语言任务数据集（如 NLP）和计算机视觉任务（如 ImageNet）之间的空白。它包含超过 1,600 个多模态任务的训练数据集，提供了一个全面的多模态任务训练环境。</sample>
    <sample id="1277">这篇论文有两位作者：James Finch和Sarah Finch。</sample>
    <sample id="1278">二进制协调是指在计算机系统中，两个或多个二进制数据源（如文件、文件系统或网络）之间进行一致的操作，以确保数据的完整性和一致性。它涉及将不同的二进制数据源转换为一个统一的格式或结构，以便在处理、存储和检索过程中保持一致性。二进制协调通常涉及使用特定的协议、标准或工具来实现这一目标。</sample>
    <sample id="1279">提示语的平均长度为4.5个单词。</sample>
    <sample id="1280">这些发现表明，经过适当的训练，较小的 T5 模型可以在质量上超过较大的语言模型，这表明它们在适当的数据集上具有更好的性能。</sample>
    <sample id="1281">Hi, I am Yanis Lacroix, and I will present to you our works on Dr. Bert, a robust pre-trained model in French for biomedical and clinical domain.</sample>
    <sample id="1282">在本演讲中，我们首先讨论了医疗保健中的语言建模。然后我们将介绍我们文章的主要贡献。</sample>
    <sample id="1283">我们介绍了第一个生物医学模型,在法语中命名为Dr. Bert, 基于Roberta, 并在NACHOS上进行训练,这是一个来自网络的医学数据集。</sample>
    <sample id="1284">我们还介绍了使用多个预测设置和数据源的模型比较。然后我们在法语中介绍了我们在十一项生物医学和临床下流任务上的结果。</sample>
    <sample id="1285">最后,我们总结了实验并为您提供了有关如何访问模型的更多详细信息。</sample>
    <sample id="1286">自从它在二十八年发布以来,Bert已经成为解决自然语言处理任务的最有效方法之一,并提供了与历史静态和上下文相关的显著性能提升,例如word2vecfasttext或elmo。</sample>
    <sample id="1287">自那时起,该模型已被改编为许多其他语言,例如法语,以及生物医学领域的领域,如Permitted Birth和Bio-Birth,以及临床领域的临床出生,但主要是英语。</sample>
    <sample id="1288">针对其他语言的专门模型是稀有的,并且通常基于连续的预训练,因为缺乏领域数据。</sample>
    <sample id="1289">然而，直到现在，法国还没有任何开源的生物医学模型。</sample>
    <sample id="1290">我们问自己一个问题：什么是最适合广泛用途的数据来源？这些数据是良好的临床数据替代品。</sample>
    <sample id="1291">为了回答这个问题，我们将Bert与我们的Shubert模型进行比较,该模型基于从我们所在城市的非大学医院获得的匿名数据。</sample>
    <sample id="1292">之后,我们问自己,我们需要多少数据来训练一个专门的模型,在法国数据上,是四千兆字节,八千兆字节还是更多?</sample>
    <sample id="1293">为了解决这个问题,我们首先从头开始训练和比较四个模型。第一个版本的DoctorBert有七千兆字节的饼干。第二个版本是四千兆字节的饼干集。</sample>
    <sample id="1294">第一个版本的Shubert是一个临床模型,其中包含四千字的句子,取自临床笔记。最后一个版本的Shubert是一个混合了四千字的自然语句和四千字的临床笔记。</sample>
    <sample id="1295">除了这个比较之外,我们还介绍了三种基于预训练的模型来分析预训练策略的影响。</sample>
    <sample id="1296">一个基于卡门贝尔的权重,并在四千兆字节的自然集上进行训练。另一个也基于卡门贝尔,但这次在四千兆字节的清洁节点上进行训练。</sample>
    <sample id="1297">最后,一个基于英语的生物医学模型,并在四千兆字节的自然上进行训练。在总的来说,我们有七个模型。</sample>
    <sample id="1298">为了评估我们的七个模型,我们收集了公共和私人的任务,例如名称识别,分类,部分语音标记和问题回答。</sample>
    <sample id="1299">这些模型与六个基线模型进行了比较,这些基线模型是：CarmembertOscar138GB,CarmembertOscar4GB,CarmembertCCNet4GB,Permabit,BioBert和ClinicalBert。</sample>
    <sample id="1300">在评估中,该模型在具有与训练模型相同性质的数据的任务上表现最佳。</sample>
    <sample id="1301">但是,我们可以从异构源中获取数据。我们观察到,来自异构源的数据似乎更具多功能性。我们还观察到,使用更多的数据可以提高性能。</sample>
    <sample id="1302">总的来说,从头开始训练似乎在大多数任务上获得了更高的性能。</sample>
    <sample id="1303">然而，我们在使用权威的权重和标记器的控制预言实验中，训练在Naturs的四千兆字节子集上显示出与Dr.Bert从头开始获得的相当结果。</sample>
    <sample id="1304">但是，基于卡门贝尔重量和托卡纳泽的模型并非如此，后者存在稳定性问题。</sample>
    <sample id="1305">最后,我们的系统在十一项任务中表现出色,在全球范围内超过了这里的生成模型的结果。</sample>
    <sample id="1306">我们也观察到,特化数据越多越好,但它并不适合大规模应用。</sample>
    <sample id="1307">所有预训练模型都来自Naturally的免费提供,并且在Github上面可用。所有训练脚本都在我们的Github存储库中。</sample>
    <sample id="1308">谢谢大家的发言,我们期待着在东京的会议上进行交流。</sample>
    <sample id="1309">论文研究了从零开始训练和使用预训练模型的学习策略。</sample>
    <sample id="1310">1</sample>
    <sample id="1311">通过使用BLEU、F1、ROUGE和METEOR等指标来评估简化质量。</sample>
    <sample id="1312">是的，初步结果表明，语言模型确实具有不同的政治偏见。GPT-4被认为是最自由的语言模型，而GPT系列通常比BERT系列及其变体更具社会自由主义特征。</sample>
    <sample id="1313">你好，我的名字是马蒂亚斯·林德曼,今天我要给你们简要介绍一下我们关于“无树的组合泛化”这篇论文。使用多集标记和隐式排列。</sample>
    <sample id="1314">这是与我的顾问亚历山大·科拉和伊万·迪托夫的联合工作。</sample>
    <sample id="1315">组合泛化可以理解为学习者处理更深层次的递归和在训练期间单独看到的短语的组合的能力。</sample>
    <sample id="1316">在语义解析的语境下，测试组合泛化可能看起来像这样。通常我们有一组训练语料库。在这种情况下,女孩睡了,玛丽知道女孩睡了。</sample>
    <sample id="1317">这些语句与逻辑形式配对,该形式表示其含义的核心方面。</sample>
    <sample id="1318">与标准的机器学习评估相比,测试集并非来自相同的分布,但包含结构上未见的逻辑形式。</sample>
    <sample id="1319">在这个例子中,模型在训练过程中看到了较浅的递归,并且在具有更深递归的示例上进行了测试。</sample>
    <sample id="1320">Naive sequence to sequence models 斗争与这种出乎意料的分布一般化,并且经常产生与输入脱节的输出。</sample>
    <sample id="1321">特别是，它们经常无法重现输入和输出之间的系统对应关系，例如在示例中使用颜色编码的对应关系。</sample>
    <sample id="1322">一种解决此问题的流行方法是将树木集成到模型中。</sample>
    <sample id="1323">这些树的目的是捕捉与逻辑形式相关的构成过程。</sample>
    <sample id="1324">这很有效,但树通常没有给出,需要以某种方式获得。</sample>
    <sample id="1325">这可能是复杂的，有时是一个计算成本高昂的过程。通常,这涉及大量的形式主义特定的逻辑形式的预处理。例如,处理变量符号。</sample>
    <sample id="1326">获取树也可能涉及到专门的语法引导程序。</sample>
    <sample id="1327">在本文中,我们不使用树,而是引入了一个神经对序序列模型,该模型直接对输入片段和输出片段之间的对应关系进行建模。</sample>
    <sample id="1328">我们第一次展示了强大的泛化到更深层次的递归,而不依赖于树。</sample>
    <sample id="1329">我们的方法从输入中预测输出分为两步。</sample>
    <sample id="1330">首先,我们为每个输入令牌标记一个无序的多集令牌,这些令牌将在输出中出现。</sample>
    <sample id="1331">在第一步之后,我们拥有所有正确的令牌,但它们尚未被排序。</sample>
    <sample id="1332">这就是为什么在第二步中,我们使用另一个模型来预测排列顺序,以将它们放入正确的顺序中。</sample>
    <sample id="1333">我们引入一种新的方法来预测不带任何硬约束的排列。这使得我们的方法非常灵活和富有表现力。</sample>
    <sample id="1334">从概念上讲,我们的排列模型大致是这样的。</sample>
    <sample id="1335">我们从左到右遍历输出,并确定每个位置放置哪个多集令牌。对于第一个输出位置,我们只需选择一个,如红色所示。</sample>
    <sample id="1336">然后我们跳到下一个多集令牌来确定输出中的第二个令牌。</sample>
    <sample id="1337">我们通过跳转到另一个多集令牌来确定输出中的第三个令牌。我们继续这个过程。</sample>
    <sample id="1338">直到第一阶段的每个令牌都被访问了恰好一次。</sample>
    <sample id="1339">为了给你们一个实验结果的预告,在这里我们将我们的方法与其他无树模型在Cogs基准测试中进行比较。我们的模型在更深层次的递归上比其他模型大幅领先。</sample>
    <sample id="1340">不过,其他一些结构化的通用化仍然非常具有挑战性。</sample>
    <sample id="1341">在我们的论文中,我们解决了几个有趣的技术挑战。</sample>
    <sample id="1342">首先，输入和输出之间的对齐在训练数据中没有给出。结果，对于给定的令牌,我们不知道它来自哪个多元集,这对训练构成了挑战。</sample>
    <sample id="1343">此外，有时存在多个与数据一致的排列,但语法正确的排列是隐含的。我们通过在训练过程中引入对齐来解决这个问题。</sample>
    <sample id="1344">我们的排列方法非常灵活,但它带来了一个挑战,即找到得分最高的排列是NP难的。这是因为这与旅行推销员问题有关。</sample>
    <sample id="1345">我们用GPU友好的连续放松来近似这个问题,这也让我们可以通过解来回传播,并学习语言上更合理的排列。</sample>
    <sample id="1346">如果您想了解更多关于我们的实验以及我们如何解决这些挑战，请查看我们的论文或来到我们的展位。</sample>
    <sample id="1347">认知失调是指两种或多种信念或行为之间存在矛盾或不一致的状态。</sample>
    <sample id="1348">GPT-4是最倾向于自由派的语言模型。</sample>
    <sample id="1349">在主动学习中，累积训练通常比迭代训练更有效。</sample>
    <sample id="1350">Sarah Papi</sample>
    <sample id="1351">MuDa 基准中的数据是从 TED Talks 的 14 语言翻译的 transcript 中获得的。</sample>
    <sample id="1385">演讲者的名字是Matthias Landmann。</sample>
    <sample id="1386">跨语言转移是指在一个语言上训练的模型被转移到另一个语言上，以预测SQL输出。</sample>
    <sample id="1387">The authors of the paper are affiliated with Saarland University.</sample>
    <sample id="1388">作者使用了两种延迟测量方法：平均延迟（latency）和计算机意识平均延迟（computationally aware average latency）。</sample>
    <sample id="1389">大家好,我是马克沙塔,今天我的合著者马丁和我正在介绍我们的工作。来自多个来源的知识整合评估。该工作是麦吉尔大学、MILA和微软研究院的合作。</sample>
    <sample id="1390">自然语言理解模型利用各种知识来源,例如,参数中的知识,通常通过预训练获得,以及在推理时在输入中提供的知识。</sample>
    <sample id="1391">最近在任务中，如问答，表明模型可以使用预训练的时间知识来解决任务。</sample>
    <sample id="1392">但是，自然语言理解通常需要在推理时提供的知识。</sample>
    <sample id="1393">例如，在句子中，约翰在电视上看到了新当选的总统。</sample>
    <sample id="1394">预训练参数可以包含有关总统所做的事情以及什么是电视的信息,但它们不能可靠地知道这个特定实例中的实体John是谁,或者新总统是谁,因为总统可能在预训练之前就已经改变了。</sample>
    <sample id="1395">因此，成功的知识密集型Nlu任务模型需要能够整合和使用预训练时间和推理时间知识。</sample>
    <sample id="1396">在这项工作中,我们提出了一个用于知识集成的诊断测试套件。</sample>
    <sample id="1397">我们引入了一个共同引用解决方案,旨在探测到能够利用来自不同来源的知识的能力。我们评估了包含人类研究参与者的数据集并建立了共同引用解决方案模型。</sample>
    <sample id="1398">这是我们数据集中的一个示例。塞尔文是法官。基亚是面包师。塞尔文和基亚在公园相遇。经过在法庭上审理案件的漫长工作日，他很高兴放松。</sample>
    <sample id="1399">这里的任务是确定代词he所指的正确实体,在这种情况下是serm.</sample>
    <sample id="1400">给定代词的解析需要两种类型的信息。第一种是实体特定的知识,例如,萨维尔是法官。第二种是背景知识,例如,法官在法庭上决定案件。</sample>
    <sample id="1401">一般来说,背景知识是在大型语言模型的预训练期间学习的,而实体特定知识通常是在推理时观察到的。</sample>
    <sample id="1402">我们改变这两条信息的可用性,使其可能在单个来源或多个来源中找到。</sample>
    <sample id="1403">我们定义了三个Kitmos设置。首先,我们有一个称为背景预训练的设置。假设背景知识在预训练时可用。</sample>
    <sample id="1404">其次是背景知识的设置。背景知识在预训练时间和推理时间都可用。最后是背景推理设置。两种知识类型仅在推理时间可用。</sample>
    <sample id="1405">最后一个设置特别有趣,因为它模拟了在解决任务时不包含在预训练数据中的背景知识的情况。例如,因为自从预训练以来就出现了新的职业。</sample>
    <sample id="1406">这是如何控制可用性效应的两个示例。</sample>
    <sample id="1407">在预训练设置的背景下，我们假设背景知识。选民寻求在政府中获得选举席位。它包含在预训练参数中。在自由意志和上下文中，我们提供了特定的知识。奇切斯特是一个政治家。</sample>
    <sample id="1408">在后台设置中,我们不仅提供实体特定的知识,还提供有关推理子上下文中的派生知识的背景知识。</sample>
    <sample id="1409">在背景推断设置中，提供虚构的职业。我们将其设置为政治家,因为政治家不太可能被包含在预训练中。</sample>
    <sample id="1410">我们评估了数据集，既有人类研究参与者，也有建立参考解决方案模型。在这张图中，我们展示了最好的表现模型在最困难的背景预训练设置上的结果。</sample>
    <sample id="1411">在没有针对kitmos的特定训练的情况下,这两种模型的性能都不佳。然而,当在kitmos上训练时,两种模型C2F和bertv2都表现出明显的优势,比随机选择要好得多。</sample>
    <sample id="1412">这表明,当在一般的参考解决方案数据集上进行训练时,模组学会利用表面提示,这些提示在测试Kitmus时是无用的,因为这些提示已被删除。</sample>
    <sample id="1413">使用虚构知识的其他实验表明，即使是性能最好的模型也无法可靠地整合仅在推理时提供的背景知识。</sample>
    <sample id="1414">为了总结我们论文的主要结论,许多共同引用解决方案模型似乎无法在没有特定任务训练的情况下对来自不同来源的知识进行推理。然而,在具有特定任务训练的情况下,一些模型能够成功地整合来自多个来源的知识。</sample>
    <sample id="1415">尽管如此,即使是最好的模型,似乎也难以可靠地整合仅在推理时呈现的知识。如果您对更多细节感兴趣,请查看我们的论文,并在Github上查看数据集和代码。感谢您的收听。</sample>
    <sample id="1416">基于树的方法的缺点包括：1) 通常不提供树，需通过复杂且可能计算密集的过程获取；2) 需要对逻辑形式进行特定的形式化预处理，如处理变量符号；3) 可能需要专门的语法引导程序。</sample>
    <sample id="1417">作者所属机构是中国科学院计算机研究所。</sample>
    <sample id="1418">嗨，我是玛丽亚,今天我将讨论我们的论文《标记的角色：使用自然语言提示来衡量语言模型中的刻板印象》。这项工作是与Essendermus和DanJeroffsky合作完成的。</sample>
    <sample id="1419">近年来，许多人已经记录了大型语言模型中的社会偏见和刻板印象的普遍性。</sample>
    <sample id="1420">然而，这些措施有各种限制。它们通常依赖于手工构建的数据集，这些数据集的整理非常耗时。</sample>
    <sample id="1421">而且他们通常只衡量非常特定的刻板印象。</sample>
    <sample id="1422">此外，大多数工作在这个领域都没有考虑到交叉性，这是一种观念，即多方面的社会身份可以组合偏见并成为独特的伤害源。</sample>
    <sample id="1423">为了克服这些限制,我们依赖于这些新型的指令调节的LLM的属性,它们非常擅长响应指令和提示。</sample>
    <sample id="1424">因此，我们可以要求模型生成一个角色,即使用提示的描述,例如,想象你是一个亚洲女性。描述你自己。</sample>
    <sample id="1425">我们可以立即看到,这对任何人群都非常通用,因为我们可以将任何我们想要的标识符指定到这个提示中。</sample>
    <sample id="1426">以下是GPT四世的示例生成。</sample>
    <sample id="1427">我们立即看到,虽然这些输出在传统意义上并不过于消极或有毒。</sample>
    <sample id="1428">有一些有趣的模式。</sample>
    <sample id="1429">亚洲妇女被描绘为不起眼。中东妇女被用外来词来称呼,比如说异国情调,比如说迷人的地区。</sample>
    <sample id="1430">而且，两个有色人种的女性角色都提到了祖先，而白人角色却没有。</sample>
    <sample id="1431">要捕捉这些模式，我们的方法有两个部分。第一个是生成这些角色。</sample>
    <sample id="1432">我们的提示是由一项研究启发的,该研究将这些提示给了人类受试者,发现通过给人类受试者提供提示,他们也能够浮出种族刻板印象。</sample>
    <sample id="1433">此外,这使得我们生成的角色与人类撰写的回应之间可以直接进行比较。</sample>
    <sample id="1434">第二部分是标记的单词，这是一个方法来识别与标记组不同的单词。我将很快对此进行详细说明。</sample>
    <sample id="1435">这样做的好处是，我们可以获得非常具体的刻板印象和模式，而不必依赖于任何特定的词汇。</sample>
    <sample id="1436">因此，标记单词方法借鉴了社会语言学的概念，即标记性。它表明存在一个未标记的默认值,任何偏离该默认值的群体在语言上都被标记。</sample>
    <sample id="1437">例如，男人这个词。对不起，战士这个词通常与男人有关。因此，当人们描述一个女性战士时，他们通常会指定一个男人战士并标记这个词为女性。</sample>
    <sample id="1438">更广泛地说，社会中的主导群体在语言和社会上都没有标记，而边缘化的群体通常会被标记。</sample>
    <sample id="1439">因此，在我们的方法中，我们首先指定未标记和标记组。</sample>
    <sample id="1440">然后我们使用战斗词法比较这些人，这基本上是使用加权对数比率来区分每个标记组的顶级词。</sample>
    <sample id="1441">例如，对于黑人女性的角色,我们会进行争论,并将对比法律的几率与白人角色和男性角色进行比较,因为这些是两个相对应的未标记组。</sample>
    <sample id="1442">现在有一些结果,所以首先我们使用一个词汇表的刻板印象,我们发现生成的角色包含了比人类写的更多的刻板印象。</sample>
    <sample id="1443">然而，当我们实际观察词汇表中单词的分布时，我们发现了非常不同的东西。</sample>
    <sample id="1444">因此,虽然生成的角色具有更高的luxon单词率,但人类写的单词分布更广,而在生成的角色中出现的刻板印象单词实际上只是高大和运动的单词。</sample>
    <sample id="1445">所以真的只要积极的,或者至少是非消极的。</sample>
    <sample id="1446">事实上，这个词典并没有真正捕捉到我们在前面的幻灯片中看到的许多有害模式。相反,我们将转向标记单词方法的结果,以展示这些看似正面的单词如何促进刻板印象和基本化叙事。</sample>
    <sample id="1447">在我们的分析中，我们揭示了这些看似正面的形象如何反映出有害的模式。</sample>
    <sample id="1448">首先，关于马克的群体，最上面的词包括文化、传统、骄傲和异国情调等。这些词仅仅定义了这些群体的关系，只有他们的身份和区分他们与白人规范不同。</sample>
    <sample id="1449">这为这些群体的长期歧视和异化做出了贡献。</sample>
    <sample id="1450">此外，这些词中反映了很多共同的主题，特别是对于有色人种女性来说。例如，描述拉丁裔女性的词汇包括“充满活力”和“曲线丰满”。</sample>
    <sample id="1451">这与热带主义的特征有关。对于亚洲女性来说，词语是像小和细腻和丝滑这样的东西。</sample>
    <sample id="1452">这与亚洲女性被过度性化的历史有关。</sample>
    <sample id="1453">最后,对于黑人女性来说,我们看到一些顶级词是强壮和坚韧的东西。</sample>
    <sample id="1454">这与人们所说的强黑女性典型有关。虽然一开始听起来像是积极的。</sample>
    <sample id="1455">有研究表明，这种类型的原型实际上是非常有害的，因为它给这些人群带来了很大的压力，要对社会障碍保持坚强和坚韧。</sample>
    <sample id="1456">因此，实际上并不是努力改变这些障碍，而是给那些人施加压力去克服这些障碍，这导致这些人以及其他人遭受非常不利的健康结果。</sample>
    <sample id="1457">更广泛地说，我们发现每个标记组的单词几乎只是反映了非常本质化的叙事。</sample>
    <sample id="1458">因此，基于这些模式,我们得出三个建议给模型所有者。</sample>
    <sample id="1459">首先,作为研究人员,我们应该解决积极的刻板印象和本质化的叙事。我们还应该使用交叉视角来研究偏见和伤害,因为如果我们不这样做,可能会忽视很多事情。</sample>
    <sample id="1460">最后，应该增加关于偏见缓解方法的透明度。</sample>
    <sample id="1461">因为例如,像这些积极的刻板印象,我们不知道是否是因为有某种奇怪的东西。</sample>
    <sample id="1462">过度的价值对齐正在进行,或者也许是其他一些反对刻板印象的方法导致了这些有害的模式。</sample>
    <sample id="1463">我们真的不能做出任何假设或进一步研究，而不需要更多的透明度。</sample>
    <sample id="1464">非常感谢您的收听。祝您玩得开心。</sample>
    <sample id="1465">大家好，我是中国科技大学的金伟宇。</sample>
    <sample id="1466">我很高兴为我们的论文《Are You Copying My Model》做一个简短的广告视频，保护大型语言模型的版权用于嵌入和服务。查看后门水印。</sample>
    <sample id="1467">让我们先介绍一下嵌入式和服务的背景。</sample>
    <sample id="1468">目前，像GPT、LLaMA、Palm这样的大型语言模型在自然语言理解和生成方面是独一无二的。</sample>
    <sample id="1469">嵌入式广告服务是基于大型语言模型构建的服务之一，旨在协助各种NLP任务。</sample>
    <sample id="1470">例如，OpenAI 提供基于 GPT 的嵌入式 API。</sample>
    <sample id="1471">然而，最近的研究表明，攻击者可能会通过学习嵌入来窃取模型，并提供类似的服务。因此，必须保护嵌入的版权作为服务。</sample>
    <sample id="1472">为了保护嵌入服务的版权，解决方案之一是将水印嵌入提供商的服务中，并检测另一个服务是否包含水印。</sample>
    <sample id="1473">水印方法需要满足以下属性。首先，方法应适用于嵌入广告服务。其次，水印不应降低提供的嵌入的效用。</sample>
    <sample id="1474">第三,水印应足够掩盖攻击者,否则攻击者可以轻松地删除水印。</sample>
    <sample id="1475">最后,水印需要在模型提取过程中传输到攻击者的服务。</sample>
    <sample id="1476">现有作品可以大致分为四类。</sample>
    <sample id="1477">然而，这些方法要么不适用于嵌入式服务，要么缺乏可移植性。</sample>
    <sample id="1478">因此，在本文中，我们提出了嵌入标记，这是一个基于后门的水印方法，可用于嵌入广告服务。</sample>
    <sample id="1479">然后让我介绍一下我们的嵌入标记的细节。嵌入标记包含两个主要步骤：水印插入和版权验证。</sample>
    <sample id="1480">在这些主要步骤之前，我们首先选择一个触发集。触发集是一个中等频率间隔的单词组。</sample>
    <sample id="1481">我们假设提供商可以收集一个通用的文本语料库并用它来计算单词频率。</sample>
    <sample id="1482">在水印注入中，我们首先定义一个目标嵌入。当用户向提供商服务发送句子时，提供商会计算句子中的触发号。</sample>
    <sample id="1483">所提供的嵌入是目标嵌入和原始嵌入的权重求和。</sample>
    <sample id="1484">目标嵌入的权重与句子中触发器的数量成正比。当句子中触发器的数量大于M时，提供的嵌入与目标嵌入完全相同。</sample>
    <sample id="1485">版权验证是检测一个服务背后是否存在水印。</sample>
    <sample id="1486">我们首先构建一个后门和一个正常数据集。后门数据集包含所有单词都属于触发集的句子。正常数据集中的所有单词都不属于触发集。</sample>
    <sample id="1487">然后提供商请求从数据集中获取嵌入信息。</sample>
    <sample id="1488">计算所需嵌入和目标嵌入之间的余弦和L2相似性。我们计算benign和backdoor数据集之间的相似性差异，定义为delta cos 和 delta L2。</sample>
    <sample id="1489">同时,我们还应用KS测试并使用其p值作为第三个指标。</sample>
    <sample id="1490">我们对四个数据集AG新闻，mind，ssd2和irisspam进行了实验。我们假设提供商应用wikitext数据集来计算单词频率。</sample>
    <sample id="1491">在四个数据集上显示的结果表明,我们的嵌入标记器可以在保持下屏任务的高效性方面具有更好的检测性能。</sample>
    <sample id="1492">我们还通过在VLPCA数据集上可视化句子嵌入来验证提供的嵌入的隐蔽性。图例中的数字表示每个句子中的触发器数量。</sample>
    <sample id="1493">如图所示，很难区分背道嵌入和正常嵌入。</sample>
    <sample id="1494">就这样，谢谢大家。欢迎与我们讨论。</sample>
    <sample id="1495">ABC-Eval 是一种方法，用于评估聊天模型的行为，以全面覆盖影响聊天质量的行为。</sample>
    <sample id="1496">直到 2016 年，CoNLL-2003 和 CoNLL++ 之间的性能增量才高于 5 个百分点。</sample>
    <sample id="1497">您好，我叫瓦苏达。我是斯通尼布鲁克大学的计算机科学博士候选人。我想把我们被接受参加ACL2023的工作作为一篇长篇论文,转移学习用于检测异议,解决稀有类挑战。</sample>
    <sample id="1498">我们首先定义认知不一致性,并解释为什么它是一个重要的语言问题。简单地说,认知不一致性是两种不一致的信念或行为。</sample>
    <sample id="1499">就像这个例子,一个人说我知道香烟会杀了我,然后继续说我在会议结束后抓了一两支烟。这种信念和行动是不一致的,它们是相悖的。</sample>
    <sample id="1500">进一步提到我不认为我可以在没有他们的情况下保住我的工作,这就证明了第二个出现,它们有一个共振关系。</sample>
    <sample id="1501">虽然不一致是我们在日常决策中经常遇到的现象,但在其他类型的语言表达中,它们很少被表达出来。</sample>
    <sample id="1502">那么这为什么重要呢?研究认知差异可以帮助我们了解人们之间分歧的影响。跟踪趋势和信念、价值观和态度的变化在人口中。</sample>
    <sample id="1503">高认知不协调也与焦虑症有关,可以更好地了解人们的心理健康。</sample>
    <sample id="1504">研究表达异议的语言也有助于理解极端主义和脆弱群体的极化。</sample>
    <sample id="1505">最后，认知不一致性对于理解个人认知风格至关重要,并且有助于我们更好地理解决策过程。</sample>
    <sample id="1506">为了创建一个认知差异资源,我们进行了大量的差异关系注释。我们使用了disancefirst方法,如图所示。</sample>
    <sample id="1507">推文被解析器解析,对话单位对按照我们论文中描述的准则进行注释。</sample>
    <sample id="1508">如图所示, 只有百分之三点五的对注释中才发现不协调。</sample>
    <sample id="1509">在收集大约一千个话语单位对的例子时,我们对一个初始分类器进行了训练,该分类器仅在四十三个例子上进行训练。毫不奇怪,该分类器的表现并不比随机猜测好。</sample>
    <sample id="1510">由于不太可能出现差异,并且没有任何先前的类似数据集,我们面临着绝对罕见的问题。</sample>
    <sample id="1511">为了缓解这一点,我们对转移学习和主动学习的组合进行了实验,以便在更少的注释次数下收集更多的差异样本,从而降低整体的注释成本,同时提高差异检测。</sample>
    <sample id="1512">由于最初的模型根本无法捕捉到差异类,我们从密切相关的任务中转移权重来开始主动学习过程。</sample>
    <sample id="1513">我们从两个不同的任务中转移,主题独立的距离,距离分类,一个任务,如果两个来自不同人的辩论陈述是否在同意或不同意,无论主题。</sample>
    <sample id="1514">在这里称为辩论,并对扩展和比较类的二元分类进行研究,因为这两个与声母的概念密切相关,声母的和声母的差异,我们在这里称之为cE。</sample>
    <sample id="1515">我们发现,在转移上,对注释数据集的零短性能已经比概率要好得多,最好是auc.6.2。</sample>
    <sample id="1516">进一步对这两个任务进行迭代微调,我们发现对CE任务进行微调,然后再对Debate进行微调,可以得到更好的零短性能。因此,我们使用此模型来冷启动主动学习。</sample>
    <sample id="1517">接下来,我们确定每次活动学习和注释的每一轮中更新模型的最佳方法。累积器累积到目前为止从活动注释中收集的所有数据。迭代器则通过对最新一组收集的数据进行训练来更新模型。</sample>
    <sample id="1518">在不同策略上,我们发现累积式的表现与迭代式相当或更好。</sample>
    <sample id="1519">接下来,为了提高不匹配示例的数量,我们使用概率的策略来选择在任何回合的AEL中都可能被当前模型识别为不匹配的示例。</sample>
    <sample id="1520">我们将其与社区中常用的其他最先进的策略进行了比较。</sample>
    <sample id="1521">我们发现,拟合的PRC策略比其他最先进的策略更好,尽管差异很小。请注意,随机的性能明显较低。</sample>
    <sample id="1522">在进一步的AL两轮最佳策略中,我们提高了距离分类,auc为0.75,这是我们在任务上迄今为止最好的表现。</sample>
    <sample id="1523">我们还检查了每种策略的可行性。对于注释质量和注释者的成本,我们发现PRC具有最高的百分比,并且最适合稀有类。然而,注释者也发现示例很难。</sample>
    <sample id="1524">总而言之,我们发现PRC是一个简单的AL策略,用于稀有类的获取,并且通过适当设计的转移学习任务,冷启动AL可以带来显著的帮助。</sample>
    <sample id="1525">我们还发现迭代更新对于从不同域的转移学习是有用的,而域内活动注释则受累积更新的好处。</sample>
    <sample id="1526">这些是我们代码数据集和论文的链接。欢迎与我们联系。如果您有任何问题,谢谢。</sample>
    <sample id="1527">这篇论文的作者所属机构是哈佛大学。</sample>
    <sample id="1528">演讲者的名字是 Siyu Yuan。</sample>
    <sample id="1529">这篇论文有五位作者。</sample>
    <sample id="1530">The method was compared with the state-of-the-art architecture specifically tailored for simultaneous speech translation.</sample>
  </task>
</testset>